<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> ‚Äì Documentation</title>
    <link>/docs/</link>
    <description>Recent content in Documentation on </description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Compression</title>
      <link>/docs/concepts/compression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/compression/</guid>
      <description>
        
        
        &lt;p&gt;Ondat compression is handled on a per volume basis and is disabled by
default in v2.2+, as performance is generally increased when compression is
disabled due to block alignment. This means that there is a trade
off between volume performance and the space the volume occupies on the backend
device.&lt;/p&gt;
&lt;p&gt;Compression can be enabled by setting the &lt;a href=&#34;/docs/reference/labels&#34;&gt;label&lt;/a&gt;
&lt;code&gt;storageos.com/nocompress=false&lt;/code&gt; on a volume at volume creation time.&lt;/p&gt;
&lt;p&gt;Ondat utilises the &lt;a href=&#34;https://lz4.github.io/lz4/&#34;&gt;lz4 compression algorithm&lt;/a&gt;
when writing to the backend store and when compressing &lt;a href=&#34;/docs/concepts/replication&#34;&gt;replication
traffic&lt;/a&gt; before it is sent across the network.&lt;/p&gt;
&lt;p&gt;Ondat detects whether a block can be compressed or not by creating a
heuristic that predicts the size of a compressed block. If the heuristic
indicates that the compressed block is likely to be larger than the
original block then the uncompressed block is stored. Block size increases post
compression if the compression dictionary is added to a block that cannot be
compressed. By verifying whether blocks can be compressed, disk efficiency is
increased and CPU resources are not wasted on attempts to compress
uncompressible blocks. Ondat&amp;rsquo;s patented on-disk format is used to tell
whether individual blocks are compressed without overhead. As such volume
compression can be dynamically enabled/disabled even while a volume is in use.&lt;/p&gt;
&lt;p&gt;When compression and &lt;a href=&#34;/docs/reference/encryption&#34;&gt;encryption&lt;/a&gt; are both enabled
for a volume, blocks are compressed then encrypted.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Fencing</title>
      <link>/docs/concepts/fencing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/fencing/</guid>
      <description>
        
        
        &lt;h2 id=&#34;statefulset-behaviour&#34;&gt;StatefulSet behaviour&lt;/h2&gt;
&lt;p&gt;In order to understand what Ondat Fencing for Kubernetes is and when it is
needed, it is required to first understand the behaviour of StatefulSets.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&#34;&gt;StatefulSets&lt;/a&gt;
are the de facto Kubernetes controller to use for stateful applications. The
StatefulSet controller offers guarantees around pod uniqueness, sticky
identities and the persistence of PVCs beyond the lifetime of their pods. As
such, StatefulSets have different characteristics and provide different
guarantees than Deployments.&lt;/p&gt;
&lt;p&gt;Deployments guarantee the amount of healthy replicas by reconciling towards the
deployment desired  state. Attempts to align the number of healthy pods with
the deployment&amp;rsquo;s desired state happen as fast as possible by aggressively
initializing and terminating pods. If one pod is terminating, another will be
automatically scheduled to start even if the first pod is not yet completely
terminated. Stateless applications benefit from this behaviour as one pod
executes the same work as any other in the deployment.&lt;/p&gt;
&lt;p&gt;StatefulSets, on the other hand, guarantee that every pod scheduled has a
unique identity, which is to say that only a single copy of a pod is running in
the cluster at any one time. Whenever scheduling decisions are made, the
StatefulSet controller ensures that only one copy of this pod is running at any
time. If a pod is deleted, a new pod will not be scheduled until the first pod
is fully terminated. This is an important guarantee as FileSystems need to be
unmounted before they can be remounted in a new pod. Any ReadWriteOnce PVC
defining a device requires this behaviour to ensure the consistency of the data
and thus the PVC.&lt;/p&gt;
&lt;p&gt;To protect data integrity, Kubernetes guarantees that there will never be more
than one instance of a StatefulSet Pod running at a time. It assumes that when
a node is determined to be offline it may still be running the workload but
partitioned from the network. Since Kubernetes is unable to
verify that the Pod has been stopped it errs on the side of caution and does
not allow a replacement to start on another node.&lt;/p&gt;
&lt;p&gt;Kubernetes does reschedule pods from some controllers when nodes become
unavailable. The default behaviour is that when a node becomes unavailable its
status becomes &amp;ldquo;Unknown&amp;rdquo; and after the &lt;code&gt;pod-eviction-timeout&lt;/code&gt; has passed pods
are scheduled for deletion. By default, the &lt;code&gt;pod-eviction-timeout&lt;/code&gt; is 300
seconds.&lt;/p&gt;
&lt;p&gt;For this reason, Kubernetes requires manual intervention to initiate timely
failover of a StatefulSet Pod. The Ondat Fencing Controller gives the
capability to enable fast failover of workloads when a node goes offline.&lt;/p&gt;
&lt;p&gt;For more information on the rationale behind the design of StatefulSets please
see the Kubernetes design proposal for &lt;a href=&#34;https://github.com/kubernetes/design-proposals-archive/blob/main/storage/pod-safety.md&#34;&gt;Pod
Safety&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;ondat-fencing-controller&#34;&gt;Ondat Fencing Controller&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° The Ondat Fencing Controller is part of the Ondat API Manager which
is deployed in high availability when Ondat is installed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;HA for StatefulSet applications can be achieved with the Ondat Fencing
feature&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Since Ondat is able to determine when a node is no longer able to access a
volume and has protections in place to ensure that a partitioned or formerly
partitioned node can not continue to write data, it can work with Kubernetes to
perform safe, fast failovers of Pods, including those running in StatefulSets.&lt;/p&gt;
&lt;p&gt;When Ondat detects that a node has gone offline or become partitioned, it
marks the node offline and performs volume failover operations.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/storageos/api-manager/tree/master/controllers/fencer&#34;&gt;Ondat Fencing
Controller&lt;/a&gt;
watches for these node failures and determines if there are any pods assigned
to the failed node with the label &lt;code&gt;storageos.com/fenced=true&lt;/code&gt;, and if the pods
have any PVCs backed by Ondat volumes.&lt;/p&gt;
&lt;p&gt;When a Pod has Ondat volumes and if they are all healthy, the Ondat
fencing controller deletes the Pod to allow it to be rescheduled on another
node. It also deletes the VolumeAtachments for the corresponding volumes so
that they can be immediately attached to the new node.&lt;/p&gt;
&lt;p&gt;No changes are made to Pods that have Ondat volumes that are unhealthy.
This is usually because a volume was configured to not have any replicas, and the
node with the single copy of the data is offline. In this case it is better to
wait for the node to recover.&lt;/p&gt;
&lt;p&gt;Fencing works with both dynamically provisioned PVCs and PVCs referencing
pre-provisioned volumes.&lt;/p&gt;
&lt;p&gt;The fencing feature is opt-in and Pods must have the
&lt;code&gt;storageos.com/fenced=true&lt;/code&gt; label set, and be using at least one Ondat
volume, to enable fast failover.&lt;/p&gt;
&lt;p&gt;For more information about how to enable pod fencing, see our &lt;a href=&#34;/docs/operations/fencing&#34;&gt;Fencing
Operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install</title>
      <link>/docs/reference/cluster-operator/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cluster-operator/install/</guid>
      <description>
        
        
        &lt;p&gt;To install the operator follow the installation page for your orchestrator.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;/docs/install/kubernetes&#34;&gt;Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/install/rancher&#34;&gt;Rancher&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/install/openshift&#34;&gt;OpenShift&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Metric Exporter</title>
      <link>/docs/concepts/metric-exporter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/metric-exporter/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Following the &lt;a href=&#34;https://prometheus.io/docs/instrumenting/exporters/&#34;&gt;exporter pattern&lt;/a&gt;, we maintain and distribute our own &lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt; exporter for monitoring &amp;amp; alerting of Ondat volumes. The metrics our exporter publishes include data on volume health, capacity &amp;amp; traffic.&lt;/p&gt;
&lt;p&gt;Our exporter‚Äôs source code can be found &lt;a href=&#34;https://github.com/ondat/metrics-exporter&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Please see our &lt;a href=&#34;/docs/operations/metric-exporter/&#34;&gt;operations page&lt;/a&gt; to get started.&lt;/p&gt;
&lt;p&gt;Additionally, we distribute Grafana dashboards to visualize the data. They can be found &lt;a href=&#34;https://github.com/ondat/metrics-exporter/tree/main/grafana&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Likewise, we distribute example alerting rules for our metrics using &lt;a href=&#34;https://prometheus.io/docs/alerting/latest/alertmanager/&#34;&gt;Alertmanager&lt;/a&gt;, they can be found &lt;a href=&#34;https://github.com/ondat/metrics-exporter/tree/main/alertmanager&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Contributions to both are welcome!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è When setting up a &lt;a href=&#34;https://github.com/prometheus-operator/prometheus-operator/blob/1e4acb010642067bb918eebb75410191640a95c6/Documentation/user-guides/getting-started.md&#34;&gt;ServiceMonitor&lt;/a&gt; be sure to create the rules in the same namespace as your Prometheus resource and have its &lt;code&gt;selector&lt;/code&gt; field match the labels of ours services exposing metrics (see example manifest &lt;a href=&#34;/docs/operations/metric-exporter/&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you have suggestions for metrics you would like us to gather or improvements to our Grafana or Alertmanager integration, please let us know on our &lt;a href=&#34;https://slack.storageos.com/&#34;&gt;public slack&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Namespaces</title>
      <link>/docs/concepts/namespaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/namespaces/</guid>
      <description>
        
        
        &lt;p&gt;Ondat namespaces are an identical concept to Kubernetes namespaces. They
are intended to allow an Ondat cluster to be used by multiple teams across
multiple projects.&lt;/p&gt;
&lt;p&gt;It is not necessary to create Ondat namespaces manually, as Ondat maps
Kubernetes namespaces on a one-to-one basis when PersistentVolumeClaims using
the Ondat StorageClass are created.&lt;/p&gt;
&lt;p&gt;üí° Access to Namespaces is controlled through user or group level &lt;a href=&#34;/docs/concepts/policies&#34;&gt;policies&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Nodes</title>
      <link>/docs/concepts/nodes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/nodes/</guid>
      <description>
        
        
        &lt;p&gt;An Ondat node is any machine (virtual or physical) that is running the
Ondat daemonset pod. A node must be running a daemonset pod in order to
consume and/or present storage.&lt;/p&gt;
&lt;p&gt;Nodes can be run in several modes.&lt;/p&gt;
&lt;h2 id=&#34;hyperconverged-mode&#34;&gt;Hyperconverged Mode&lt;/h2&gt;
&lt;p&gt;By default Ondat nodes run in &lt;code&gt;hyperconverged&lt;/code&gt; mode. This means that the
node hosts data from Ondat volumes and can present volumes to applications.&lt;/p&gt;
&lt;p&gt;A hyperconverged node can store data from a volume and present volumes to
applications regardless of whether the data for the volume consumed is placed
on that node or is being served remotely. Remote volumes like this are handled
by an internal protocol to present block device access to applications running
on different nodes from the one to which their backing data store is attached.&lt;/p&gt;
&lt;p&gt;Ondat implements an extension of a Kubernetes Scheduler object that
influences the placement of Pods on the same nodes as their data.&lt;/p&gt;
&lt;h2 id=&#34;compute-only-mode&#34;&gt;Compute-only Mode&lt;/h2&gt;
&lt;p&gt;Alternatively, a node can run in &lt;code&gt;computeonly&lt;/code&gt; mode, which means no storage is
consumed on the node itself and the node only presents volumes hosted by
other nodes. Volumes presented to applications running on compute only nodes
are therefore all remote. Compute only nodes can be very useful for topologies
where nodes are ephemeral and should not host data, but the ephemeral nodes
host applications that require Ondat volumes. The nodes that are not
intended to hold data, but just to present Ondat volumes, can be set as
&lt;code&gt;computeonly&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A node can be marked as compute only at any point in time by adding the label
&lt;code&gt;storageos.com/computeonly=true&lt;/code&gt;, following the &lt;a href=&#34;/docs/reference/labels&#34;&gt;labels reference&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;storage-mode&#34;&gt;Storage Mode&lt;/h2&gt;
&lt;p&gt;Finally, nodes can be set to storage mode. Nodes set to storage mode don&amp;rsquo;t
present data locally - instead all data is accessed through the network. This
topology is enforced by tainting the relevant nodes to ensure that application
workloads cannot be scheduled there.&lt;/p&gt;
&lt;p&gt;This mode is ideal for ensuring maximum stability of data access as the node is
isolated from resource drains that may occur due to applications running
alongside. For redundancy purposes, in high load clusters it is ideal to have
several nodes running in this mode.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Cluster Topologies</title>
      <link>/docs/concepts/cluster-topologies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/cluster-topologies/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Ondat makes it possible for cluster administrators to design and implement different cluster topologies, depending on types of workloads, use cases, priorities and needs. The topology approaches recommended below are idealised representations of possible Ondat clusters and can be mixed, modified and changed at execution time.&lt;/p&gt;
&lt;p&gt;Ondat performs file Input/Output (I/O) operations over the network, which is how the platform ensures that data is always available throughout your cluster. This also affords cluster administrators certain possibilities of organising their clusters in ways explained below.&lt;/p&gt;
&lt;h3 id=&#34;hyper-converged-cluster-topology&#34;&gt;Hyper-converged Cluster Topology&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/hyperconverged.png&#34; alt=&#34;Hyper-converged Cluster Topology&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Hyper-converged_infrastructure&#34;&gt;&lt;em&gt;hyper-converged&lt;/em&gt;&lt;/a&gt; cluster topology model leverages the available block storage attached to all the worker nodes in a Kubernetes cluster, creating a single storage pool that stores and present data for stateful workloads deployed and running.
&lt;ul&gt;
&lt;li&gt;This cluster topology gives the best flexibility to Ondat and Kubernetes schedulers, and provides maximum choice for optimal pod placement when pods are being assigned to nodes in a cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;No matter how or where workloads are deployed on worker nodes, Ondat will ensure that the data from workloads is stored, persistent and always accessible.&lt;/li&gt;
&lt;li&gt;New Ondat deployments will place workloads locally where possible using this hyper-converged cluster topology out of the box.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;centralised-cluster-topology&#34;&gt;Centralised Cluster Topology&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/centralised.png&#34; alt=&#34;Centralised Cluster Topology&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;centralised&lt;/em&gt; cluster topology model leverages the available block storage attached to only a &lt;em&gt;subset&lt;/em&gt; of worker nodes (creating a dedicated, storage-optimised &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/node-pools&#34;&gt;node pool&lt;/a&gt;) in a Kubernetes cluster, whilst the rest of the worker nodes are dedicated to running general and compute-intensive workloads,
&lt;ul&gt;
&lt;li&gt;Deployed workloads in centralised cluster that require data persistency will access a dedicated storage pool that is located on the declared subset of worker nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This cluster topology can be beneficial if, for example, cluster administers want to take advantage and effectively utilise high performance-optimised hardware components of a particular set of worker nodes for different types of workloads being deployed.&lt;/li&gt;
&lt;li&gt;The cluster topology can also aid in avoiding downtime issues that can arise from unaccounted resource/capacity planning and allocation for workloads, since storage-optimised nodes and compute-optimised workloads are compartmentalised.&lt;/li&gt;
&lt;li&gt;In addition, another suitable use case for this topology is for elastic worker node fleets with burst-able workloads. A fleet can be quickly expanded with new worker nodes for compute-intensive workloads on demand, whilst maintaining a centralised data storage pool that is not impacted by rapid auto cluster scaling.&lt;/li&gt;
&lt;li&gt;To configure this cluster topology for a new Ondat deployment, cluster administrators would need to apply an Ondat node label called &lt;code&gt;storageos.com/computeonly&lt;/code&gt; to nodes, which would inform Ondat that it &lt;em&gt;should not&lt;/em&gt; use the nodes to join a storage pool.
&lt;ul&gt;
&lt;li&gt;Review the &lt;a href=&#34;https://docs.ondat.io/docs/reference/labels/&#34;&gt;Feature Labels&lt;/a&gt; reference page for more information on how to enable Ondat features correctly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Components</title>
      <link>/docs/concepts/components/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/components/</guid>
      <description>
        
        
        &lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;Ondat is a software-defined storage platform for running stateful applications in Kubernetes.&lt;/p&gt;
&lt;p&gt;Fundamentally, Ondat uses the storage attached to the nodes in the Ondat cluster to create and present virtual volumes into containers. Space on the host is consumed from the mount point &lt;code&gt;/var/lib/storageos/data&lt;/code&gt;, so it is therefore recommended that disk devices are used exclusively for Ondat, as described in &lt;a href=&#34;/docs/operations/managing-host-storage&#34;&gt;Managing Host Storage&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ondat is agnostic to the underlying storage and runs equally well on
bare metal, in virtual machines or on cloud providers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/ondat-deployment.png&#34; alt=&#34;Ondat cluster components&#34;&gt;&lt;/p&gt;
&lt;p&gt;Read about &lt;a href=&#34;https://www.ondat.io/platform/platform-overview&#34;&gt;the cloud native storage principles behind
Ondat&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;ondat-on-kubernetes&#34;&gt;Ondat on Kubernetes&lt;/h1&gt;
&lt;p&gt;Ondat is architected as a series of containers that fulfil separate,
discrete functions.&lt;/p&gt;
&lt;p&gt;Links where appropriate have been given to our open-source GitHub repository.&lt;/p&gt;
&lt;h2 id=&#34;ondat-cluster-operatorhttpsgithubcomstorageosoperator&#34;&gt;&lt;a href=&#34;https://github.com/storageos/operator&#34;&gt;Ondat Cluster Operator&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Responsible for the creation and maintenance of the Ondat cluster. This
operator is primarily responsible for ensuring that all the relevant
applications are running in your cluster.&lt;/p&gt;
&lt;h2 id=&#34;ondat-controlplane&#34;&gt;Ondat Controlplane&lt;/h2&gt;
&lt;p&gt;Responsible for monitoring and maintaining the state of volumes and nodes
in the cluster. The Controlplane and the Dataplane run together in a single
container, managed by a daemonset. The Controlplane works with etcd to maintain
state consensus in your cluster.&lt;/p&gt;
&lt;h2 id=&#34;ondat-dataplane&#34;&gt;Ondat Dataplane&lt;/h2&gt;
&lt;p&gt;Responsible for all I/O path related tasks; reading, writing, compression
and caching.&lt;/p&gt;
&lt;h2 id=&#34;ondat-scheduler&#34;&gt;Ondat Scheduler&lt;/h2&gt;
&lt;p&gt;Responsible for scheduling applications on the same node as an application&amp;rsquo;s
volumes. Ondat uses a custom Kubernetes scheduler to handle pod placement,
ensuring that volumes are deployed on the same nodes as the relevant workloads
as often as possible.&lt;/p&gt;
&lt;h2 id=&#34;csi-helperhttpsgithubcomstorageosexternal-provisioner&#34;&gt;&lt;a href=&#34;https://github.com/storageos/external-provisioner&#34;&gt;CSI helper&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Responsible for registering Ondat with Kubernetes as a CSI driver. It
is necessary because the internal persistent volume controller running in
Kubernetes controller-manager does not have any direct interfaces to CSI
drivers. It monitors PVC objects created by users and creates/deletes volumes
for them.&lt;/p&gt;
&lt;h2 id=&#34;ondat-api-managerhttpsgithubcomstorageosapi-manager&#34;&gt;&lt;a href=&#34;https://github.com/storageos/api-manager&#34;&gt;Ondat API manager&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Acts as a middle-man between various APIs. It has all the capabilities of a
Kubernetes Operator and is also able to communicate with the Ondat control
plane API. This application handles typical operator tasks like labelling or
removing nodes from Ondat when removed from the Kubernetes. It is
continually  monitoring the state of the cluster and moving it towards the
desired state when necessary.&lt;/p&gt;
&lt;p&gt;Ondat is deployed by the Ondat Cluster Operator. In Kubernetes, the
Ondat Controlplane and Dataplane are deployed in a single pod managed by a
daemonset.  This daemonset runs on every node in the cluster that will consume
or present storage. The Scheduler, CSI helper, Cluster Operator and API Manager
run as separate pods and are controlled as deployments.&lt;/p&gt;
&lt;p&gt;Ondat is designed to feel familiar to Kubernetes and Docker users. Storage
is managed through standard StorageClasses and PersistentVolumeClaims, and
&lt;a href=&#34;/docs/reference/labels&#34;&gt;features&lt;/a&gt; are controlled by
Kubernetes-style labels and selectors, prefixed with &lt;code&gt;storageos.com/&lt;/code&gt;. By
default, volumes are cached to improve read performance and compressed to
reduce network traffic.&lt;/p&gt;
&lt;p&gt;Any pod may mount an Ondat virtual volume from any node that is also
running Ondat, regardless of whether the pod and volume are
collocated on the same node. Therefore, applications may be started or
restarted on any node and access volumes transparently.&lt;/p&gt;
&lt;h2 id=&#34;ondat-node-guard&#34;&gt;Ondat Node Guard&lt;/h2&gt;
&lt;p&gt;The Node Guard is a key component of the rolling upgrade feature. It blocks certain nodes from being upgraded or drained thus avoiding data loss in the cluster.&lt;/p&gt;
&lt;p&gt;The Node Guard will detect if a volume is reconciling (for example, one that does not have enough synced replicas), at which point a node manager pod on the same node as the reconciling volume&amp;rsquo;s master and replicas become unready. Ondat uses a PodDisruptionBudget (PDB) to stop more than 1 node manager pod being unavailable at any point in time. This prevents the rolling upgrade from continuing until the PDB is satisfied and all volumes have fully reconciled&lt;/p&gt;
&lt;p&gt;If the PDB is set to 1 and a Control Plane volume on a node is not ready for a long period of time, this will stop the upgrade process. The &lt;code&gt;api-managercomponent&lt;/code&gt; will be able to dynamically set the PDB value if it can determine the health of the volume. If the &lt;code&gt;api-managercomponent&lt;/code&gt; knows that a volume will not be ready, it can increase the PDB &lt;code&gt;maxUnavailable&lt;/code&gt; value, allowing the upgrade to continue. The Node Guard container will log when it is available to upgrade, it will also log the reason if upgrade is not possible.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The Node Guard container only monitors volumes that host a deployment on its node (for example, it doesn‚Äôt care if a volume is unhealthy if the node it&amp;rsquo;s running on hosts none of the volumes primary and replicas)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è There is some latency between a volume becoming unhealthy and the Node Guard noticing, due to the polling nature of both the &lt;code&gt;api-managercomponent&lt;/code&gt; volume sync Kubernetes readiness endpoints)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ondat-node-manager&#34;&gt;Ondat Node Manager&lt;/h2&gt;
&lt;p&gt;The Node manager is an out-of-band pod used for node management.  It runs on all nodes that run the &lt;code&gt;StorageOS&lt;/code&gt; node container and is a separate pod so that it can be restarted independently of the node container.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Data Encryption</title>
      <link>/docs/concepts/encryption/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/encryption/</guid>
      <description>
        
        
        &lt;p&gt;Ondat supports encryption for data-at-rest and data-in-transit.&lt;/p&gt;
&lt;p&gt;Data-in-transit is data as it is travelling between nodes. It is encrypted by
default with mTLS. Data-at-rest is the data stored in your volumes as &lt;a href=&#34;/docs/concepts/volumes&#34;&gt;blob files&lt;/a&gt;. Encryption of these blob files
is optional and can be enabled by adding a label to your volume definitions
before they&amp;rsquo;re provisioned.&lt;/p&gt;
&lt;p&gt;For information on how to enable encryption on your volumes, see our
&lt;a href=&#34;/docs/operations/encryption&#34;&gt;Encryption Operations&lt;/a&gt; page.&lt;/p&gt;
&lt;h2 id=&#34;how-volumes-are-encrypted&#34;&gt;How volumes are encrypted&lt;/h2&gt;
&lt;p&gt;Volumes are encrypted using AES-256 in the XTS-AES mode with 512-bit keys, as
specified by IEEE Standard 1619-2007. There is a non-zero performance impact of
using encrypted volumes. A 10-25% cost in read/write throughput can be
expected from XTS-AES, dependent on workload. Thin provisioning still applies
to encrypted volumes.&lt;/p&gt;
&lt;h2 id=&#34;encryption-key-generation&#34;&gt;Encryption Key Generation&lt;/h2&gt;
&lt;p&gt;On PVC creation, &lt;a href=&#34;/docs/reference/labels#storageos-volume-labels&#34;&gt;if encryption is enabled&lt;/a&gt;, Ondat will
automatically generate up to two keys as Kubernetes secrets. Both keys are
stored in the same namespace as the PVC.&lt;/p&gt;
&lt;p&gt;Firstly, if it doesn&amp;rsquo;t already exist, a namespace key is generated. It is
always named &lt;code&gt;storageos-namespace-key&lt;/code&gt; and only one exists per namespace.&lt;/p&gt;
&lt;p&gt;Secondly a volume key is created for each encrypted volume. It has a name in
the format &lt;code&gt;storageos-volume-key-&amp;lt;random-id&amp;gt;&lt;/code&gt;, with no connection to the name
of the volume. The volume it is associated with can be determined by looking at
the &lt;code&gt;storageos.com/pvc&lt;/code&gt; label on the secret. The
&lt;code&gt;storageos.com/encryption-secret-name&lt;/code&gt; and
&lt;code&gt;storageos.com/encryption-secret-namespace&lt;/code&gt; annotations are added to the PVC by
an admission controller to map the PVC back to its secret.&lt;/p&gt;
&lt;p&gt;The encryption key is passed to Ondat as part of the CSI volume creation
request and is used to encrypt the volume.&lt;/p&gt;
&lt;h2 id=&#34;encryption-key-use&#34;&gt;Encryption Key Use&lt;/h2&gt;
&lt;p&gt;The volume specific secret is needed whenever a volume is attached to a node
for use by a pod. When this happens, the Ondat node container&amp;rsquo;s Service
Account reads the secret and passes it to the Ondat controlplane.&lt;/p&gt;
&lt;p&gt;A volume missing its key or with a malformed key will be unable to attach.&lt;/p&gt;
&lt;p&gt;The key is stored in memory by Ondat only on the node that the volume is
being used on. As a result, encryption and decryption are performed where the
data is consumed, rather than where it is stored.&lt;/p&gt;
&lt;p&gt;Because of this, the use of encrypted volumes is transparent to the user.
There is a complete integration between Kubernetes applications and
Ondat encryption.&lt;/p&gt;
&lt;h2 id=&#34;key-management-best-practices&#34;&gt;Key Management Best Practices&lt;/h2&gt;
&lt;p&gt;Ondat saves encryption keys in Kubernetes Secrets.
Backups are therefore imperative in case the Kubernetes Etcd is lost.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Ondat has no ability to decrypt a volume whose encryption keys have been
lost.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Secrets in Kubernetes are not encrypted by default, they are stored in the
Kubernetes Etcd in simple base64 encoding. As Ondat encryption keys are
stored as Kubernetes Secrets, this means that anyone with access to a
Kubernetes Etcd installation can read encryption keys and decrypt volumes,
unless the cluster has an external secrets store.&lt;/p&gt;
&lt;p&gt;For better security check Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/&#34;&gt;secret
encryption&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Secrets are not garbage-collected by Ondat. To clean up completely upon
deletion of a volume it is necessary to also delete that volume&amp;rsquo;s secret. There
is no benefit to doing this, however.&lt;/p&gt;
&lt;h2 id=&#34;key-management-with-kubernetes-kms-provider&#34;&gt;Key Management with Kubernetes KMS provider&lt;/h2&gt;
&lt;p&gt;Ondat encryption keys are stored within Etcd as Kubernetes secrets. Whilst
the Etcd and kubernetes secrets &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/&#34;&gt;can also be
encrypted&lt;/a&gt;,
many organisations choose to use an external KMS provider.&lt;/p&gt;
&lt;p&gt;To address this from a Kubernetes limitations perspective and provide an
agnostic solution, our encryption design allows the user to benefit from any
Kubernetes KMS provider plugin to envelop the secrets into the KMS provider
encryption scheme.&lt;/p&gt;
&lt;p&gt;Ondat allows customers to transparently integrate any supported KMS plugin
with Ondat encryption key management using the standard Kubernetes API and
Kubernetes KMS provider framework. The below figure provides an overview of the
process.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/gui-v2/kms-key-management.png&#34; alt=&#34;KMS Key Management&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The KMS plugin is deployed within the Kubernetes cluster.&lt;/li&gt;
&lt;li&gt;The KMS plugin is configured to act as a broker between the Kubernetes API
server and the KMS server API endpoint.&lt;/li&gt;
&lt;li&gt;At volume creation, Ondat will create a Kubernetes secret using
Kubernetes API calls&lt;/li&gt;
&lt;li&gt;The KMS plugin will handle the Kubernetes API Secret creation call and
interface to the KMS server instance.&lt;/li&gt;
&lt;li&gt;The KMS server will return the secret using its encryption envelop scheme.&lt;/li&gt;
&lt;li&gt;The KMS plugin will store the encrypted secret within the Kubernetes Etcd.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Contact the &lt;a href=&#34;mailto:sales@storageos.com&#34;&gt;Ondat sales team&lt;/a&gt; for more
information about the dedicated Ondat Vault KMS plugin integration
offering.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Feature Labels</title>
      <link>/docs/concepts/labels/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/labels/</guid>
      <description>
        
        
        &lt;p&gt;Feature labels are a powerful and flexible way to control storage features.&lt;/p&gt;
&lt;p&gt;Applying specific feature labels triggers compression, replication and other
storage features. No feature labels are present by default.&lt;/p&gt;
&lt;h2 id=&#34;ondat-node-labels&#34;&gt;Ondat Node labels&lt;/h2&gt;
&lt;p&gt;Nodes do not have any feature labels present by default.  When Ondat is run
within Kubernetes, the Ondat API Manager syncs any Kubernetes node labels
to the corresponding Ondat node. The Kubernetes node labels act as the
&amp;ldquo;source of truth&amp;rdquo;, so labels should be applied to the Kubernetes nodes rather
than to Ondat nodes. This is because the Kubernetes node labels overwrite
the Ondat node labels on sync.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Label&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Values&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Compute only&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/computeonly&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;true / false&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Specifies whether a node should be &lt;code&gt;computeonly&lt;/code&gt; where it only acts as a client and does not host volume data locally, otherwise the node is hyperconverged (the default), where the node can operate in both client and server modes.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;You can set the compute-only label on the Kubernetes node and the label will be
synced to the Ondat node (labels take an eventual consistency reconciliation
time of up to a minute (or less)).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl label node &lt;span style=&#34;color:#000&#34;&gt;$NODE&lt;/span&gt; storageos.com/computeonly&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ondat-volume-labels&#34;&gt;Ondat Volume labels&lt;/h2&gt;
&lt;p&gt;Volumes do not have any feature labels present by default.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The encryption, caching and compression labels can only apply
at provisioning time, they can&amp;rsquo;t be changed during execution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Label&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Values&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Caching&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/nocache&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;true / false&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Switches off caching.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Compression&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/nocompress&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;true / false&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Switches off compression of data at rest and in transit (compression is not enabled by default to maximise performance).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Encryption&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/encryption&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;true / false&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Encrypts the contents of the volume. For each volume, a key is automatically generated, stored, and linked with the PVC.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Failure Mode&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/failure-mode&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;hard, soft, alwayson or integers [0, 5]&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Sets the failure mode for a volume, either explicitly using a failure mode or implicitly using a replica threshold. The default setting of a failure mode is &lt;code&gt;hard&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Replication&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/replicas&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;integers [0, 5]&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Sets the number of replicas i.e full copies of the data across nodes. Typically 1 or 2 replicas is sufficient (2 or 3 instances of the data); latency implications need to be assesed when using more than 2 replicas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Topology-Aware Placement&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/topology-aware&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;true / false&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enables Topology-Aware Placement&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Topology Domain Key&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/topology-key&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;custom region&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Define the failure domain for the node by using a custom key. If you don&amp;rsquo;t define a custom key, the label defaults to the &lt;code&gt;topology.kubernetes.io/zone&lt;/code&gt; value.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To create a volume with a feature label, choose one of the following options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Option 1: PVC Label&lt;/p&gt;
&lt;p&gt;Add the label in the PVC definition, for instance:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;v1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PersistentVolumeClaim&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;pvc-3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;labels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storageos.com/replicas&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Label &amp;lt;-----&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storageClassName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;accessModes&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;ReadWriteOnce&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;1G&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Option 2: Set label in the StorageClass&lt;/p&gt;
&lt;p&gt;Any PVC using the StorageClass inherits the label. The PVC label takes
precedence over the StorageClass parameters.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storage.k8s.io/v1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;StorageClass&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos-replicated&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;provisioner&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;csi.storageos.com&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;allowVolumeExpansion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;parameters&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;csi.storage.k8s.io/fstype&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ext4&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storageos.com/replicas&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storageos.com/encryption&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;csi.storage.k8s.io/secret-name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos-api&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;csi.storage.k8s.io/secret-namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The Ondat API manager periodically syncs labels from Kubernetes PVCs
to the corresponding Ondat volume. Therefore changes to Ondat volume
labels should be made to the corresponding Kubernetes PVC rather than to the
Ondat volume directly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ondat-pod-labels&#34;&gt;Ondat Pod labels&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Label&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Values&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Pod fencing&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/fenced&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;true / false&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Targets a pod to be fenced in case of node failure. The default value is &lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è For a pod to be fenced by Ondat, a few requirements described in the
&lt;a href=&#34;/docs/operations/fencing&#34;&gt;Fencing Operations&lt;/a&gt; page need to be fulfilled.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl label pod &lt;span style=&#34;color:#000&#34;&gt;$POD&lt;/span&gt; storageos.com/fenced&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It is recommended to define the fenced label in the pod&amp;rsquo;s manifest, i.e in the
Statefulset definitions. Statefulsets pass labels to their
VolumeClaimTemplates. You must set the label only at the
&lt;code&gt;spec.template.metadata.labels&lt;/code&gt;. Otherwise, the Ondat volumes will fail to
provision as only special accepted labels can be passed to volumes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-statefulset
spec:
  selector:
    matchLabels: &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# &amp;lt;----- Note that the matchLabels don&amp;#39;t have the fenced label&lt;/span&gt;
      env: prod
  serviceName: my-statefulset-svc
  replicas: &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;
  template:
    metadata:
      labels:   &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# &amp;lt;----- Note that the fenced label IS PRESENT&lt;/span&gt;
        env: prod
        storageos.com/fenced: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
    spec:
      containers:
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Files</title>
      <link>/docs/concepts/rwx/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/rwx/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Ondat must have a licence applied to use RWX Volumes. RWX volumes are supported on all licence tiers, including our Community Edition licence. For more information, please visit &lt;a href=&#34;/docs/operations/licensing/#types-of-licenses&#34;&gt;Licensing&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat supports ReadWriteMany (RWX) &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes&#34;&gt;access
mode&lt;/a&gt;
Persistent Volumes. A RWX PVC can be used simultaneously by many Pods in the
same Kubernetes namespace for read and write operations.&lt;/p&gt;
&lt;p&gt;Ondat RWX Volumes are based on a shared filesystem - in the case of our
implementation, this is NFS.&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;For each RWX Volume, the following components are involved:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ondat ReadWriteOnly (RWO) Volume&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ondat provisions a standard &lt;a href=&#34;/docs/concepts/volumes&#34;&gt;Volume&lt;/a&gt; that provides
a block device for the file system of the NFS server. This
means that every RWX Volume has its own RWO Volume. This allows RWX Volumes to
leverage the synchronous replication and automatic failover functionality of
Ondat, providing the NFS server with high availability.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NFS-Ganesha server&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For each RWX Volume, an NFS-Ganesha server is spawned by Ondat. The NFS
server runs in user space on the Node containing the primary Volume. Each NFS
server uses its own RWO Volume to store data so the data of each Volume is
isolated.&lt;/p&gt;
&lt;p&gt;Ondat binds an ephemeral port to the host network interface for each
NFS-Ganesha server. The NFS export is presented using NFS v4.2. Check the
&lt;a href=&#34;/docs/prerequisites/firewalls&#34;&gt;prerequisites page&lt;/a&gt; to see the
range of ports needed for Ondat RWX Volumes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ondat API Manager&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ondat fully integrates with Kubernetes. The Ondat API Manager Pod
monitors Ondat RWX Volumes to create and maintain a Kubernetes Service
that points towards each RWX Volume&amp;rsquo;s NFS export endpoint. The API Manager is
responsible for updating the Service endpoint when a RWX Volume failover
occurs.&lt;/p&gt;
&lt;h2 id=&#34;provisioning-and-using-rwx-pvcs&#34;&gt;Provisioning and using RWX PVCs&lt;/h2&gt;
&lt;p&gt;The sequence in which a RWX PVC is provisioned and used is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A PersistentVolumeClaim (PVC) is created with RWX access mode using any
Ondat StorageClass.&lt;/li&gt;
&lt;li&gt;Ondat dynamically provisions the PV.&lt;/li&gt;
&lt;li&gt;A new Ondat RWO Volume is provisioned internally (not visible in
Kubernetes).&lt;/li&gt;
&lt;li&gt;When the RWX PVC is consumed by a pod, an NFS-Ganesha server is instantiated
on the same Node as the primary Volume. The NFS-Ganesha server thus uses the
RWO Ondat Volume as its backend disk.&lt;/li&gt;
&lt;li&gt;The Ondat API Manager publishes the host IP and port for the NFS service
endpoint, by creating a Kubernetes Service that points to the NFS-Ganesha
server export endpoint.&lt;/li&gt;
&lt;li&gt;Ondat issues a NFS mount on the Node where the Pod using the PVC is
scheduled.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;high-availability&#34;&gt;High availability&lt;/h2&gt;
&lt;p&gt;RWX Volumes failover in the same way as standard RWO Ondat Volumes. The
replica Volume is promoted upon detection of Node failure and the NFS-Ganesha
server is started on the Node containing the promoted replica. The Ondat
API Manager updates the endpoint of the Volume&amp;rsquo;s NFS service, causing traffic
to be routed to the URL of the new NFS-Ganesha server. The NFS client in the
application Node (where the user&amp;rsquo;s Pod is running) automatically reconnects.&lt;/p&gt;
&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;All feature labels that work on RWO Volumes will also work on RWX Volumes.&lt;/li&gt;
&lt;li&gt;A Ondat RWX Volume is matched one-to-one with a PVC. Therefore the
Ondat RWX Volume can only be accessed by Pods in the same Kubernetes
namespace.&lt;/li&gt;
&lt;li&gt;Ondat RWX Volumes support volume resize. Refer to the &lt;a href=&#34;/docs/operations/resize&#34;&gt;resize&lt;/a&gt;
documentation for more details.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Kubectl Plugin</title>
      <link>/docs/reference/kubectl-plugin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/kubectl-plugin/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The Ondat kubectl plugin is a utility tool that accepts imperative and declarative modes which allows cluster administrators to seamlessly install, troubleshoot, upgrade or uninstall Ondat. The plugin can also be used to connect and manage Ondat clusters on the &lt;a href=&#34;https://docs.ondat.io/docs/ondat-portal/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.
&lt;ul&gt;
&lt;li&gt;The project repository is open source and can be located on &lt;a href=&#34;https://github.com/storageos/kubectl-storageos&#34;&gt;GitHub&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;install-the-ondat-kubectl-plugin&#34;&gt;Install The Ondat Kubectl Plugin&lt;/h3&gt;
&lt;h4 id=&#34;linux&#34;&gt;Linux&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl --silent --show-error --location --output kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  https://github.com/storageos/kubectl-storageos/releases/download/v1.3.0/kubectl-storageos_1.3.0_linux_amd64.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; tar --extract --file kubectl-storageos.tar.gz kubectl-storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x kubectl-storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo mv kubectl-storageos /usr/local/bin/ &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Plugin version installed:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; kubectl-storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;macos-darwin&#34;&gt;macOS (Darwin)&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl --silent --show-error --location --output kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  https://github.com/storageos/kubectl-storageos/releases/download/v1.3.0/kubectl-storageos_1.3.0_darwin_amd64.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; tar --extract --verbose --file kubectl-storageos.tar.gz kubectl-storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x kubectl-storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo mv kubectl-storageos /usr/local/bin/ &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Plugin version installed:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; kubectl-storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;windows&#34;&gt;Windows&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# PowerShell&lt;/span&gt;
Invoke-WebRequest https://github.com/storageos/kubectl-storageos/releases/download/v1.3.0/kubectl-storageos_1.3.0_windows_amd64.tar.gz -OutFile kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; tar -xf kubectl-storageos.tar.gz kubectl-storageos.exe &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; Remove-Item kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; Write-Host &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Plugin version installed:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; .&lt;span style=&#34;color:#4e9a06&#34;&gt;\k&lt;/span&gt;ubectl-storageos.exe version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;others&#34;&gt;Others&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;For more information on different binaries, supported architectures and checksum file verification, see the full page of &lt;a href=&#34;https://github.com/storageos/kubectl-storageos/releases&#34;&gt;releases&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;usage&#34;&gt;Usage&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Get the version of the plugin installed;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Get more information on the available commands in the plugin;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl storageos help
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;StorageOS kubectl plugin

Usage:
  kubectl-storageos [flags]
  kubectl-storageos [command]

Aliases:
  kubectl-storageos, kubectl storageos

Available Commands:
  bundle           Generate a support bundle
  completion       Generate completion script
  disable-portal   Disable StorageOS Portal Manager
  enable-portal    Enable StorageOS Portal Manager
  help             Help about any command
  install          Install StorageOS and (optionally) ETCD
  install-portal   Install StorageOS Portal Manager
  preflight        Test a k8s cluster for StorageOS pre-requisites
  uninstall        Uninstall StorageOS and (optionally) ETCD
  uninstall-portal Uninstall StorageOS Portal Manager
  upgrade          Ugrade StorageOS
  version          Show kubectl storageos version

Flags:
  -h, --help   help for kubectl-storageos

Use &amp;quot;kubectl-storageos [command] --help&amp;quot; for more information about a command.
&lt;/code&gt;&lt;/pre&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Rolling Upgrades Protection For Orchestrators</title>
      <link>/docs/concepts/rolling-upgrades/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/rolling-upgrades/</guid>
      <description>
        
        
        &lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° This feature is currently available as a Technical Preview from release &lt;code&gt;2.7.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can use our rolling upgrade protection feature to upgrade your cluster&amp;rsquo;s orchestrator without causing downtime or failure of Ondat.&lt;/p&gt;
&lt;p&gt;If the volumes containing the data for your stateful workloads do not wait to successfully synchronize in-between nodes upgrading, this can potentially cause data inconsistency and downtime. As such it is necessary to perform these upgrades intelligently.&lt;/p&gt;
&lt;p&gt;We are developing a solution to this problem for you. It is currently a tech preview but now, for example, Ondat can support a Google Anthos one-click upgrade without any downtime.&lt;/p&gt;
&lt;p&gt;To use the rolling upgrade feature, follow the steps &lt;a href=&#34;/docs/operations/using-rolling-upgrades&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat SaaS Platform Installation Guide</title>
      <link>/docs/ondat-portal/installation-portal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/ondat-portal/installation-portal/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the kubectl storageos plugin is installed. Follow the &lt;a href=&#34;https://docs.ondat.io/docs/reference/kubectl-plugin/&#34;&gt;install guide for kubectl storageos&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è You must enable port 443 for egress in your ACLs if a VPC is used.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1-set-up-your-cluster&#34;&gt;Step 1: Set up your cluster&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Open &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Log into your account using your credentials&lt;/li&gt;
&lt;li&gt;In the main navigation, open the &lt;strong&gt;Cluster&lt;/strong&gt; tab&lt;/li&gt;
&lt;li&gt;On the &lt;strong&gt;Cluster&lt;/strong&gt; screen, click the &lt;strong&gt;Add Cluster&lt;/strong&gt; button&lt;/li&gt;
&lt;li&gt;Enter a name for the cluster and choose the &lt;strong&gt;Cluster Location&lt;/strong&gt; using the radio buttons&lt;/li&gt;
&lt;li&gt;Click &lt;strong&gt;Add Cluster&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-2-connect-cluster-to-the-ondat-saas-platform&#34;&gt;Step 2: Connect Cluster to the Ondat SaaS Platform&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: The CLI command will only be displayed &lt;strong&gt;once&lt;/strong&gt;
Note: Latest GA version of Ondat will be installed onto your cluster&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Make sure you follow all the prerequisites displayed on the screen. You can find more information &lt;a href=&#34;/docs/prerequisites/&#34;&gt;here&lt;/a&gt; for the prerequisites of using Ondat.&lt;/li&gt;
&lt;li&gt;Copy the cli command displayed on the screen&lt;/li&gt;
&lt;li&gt;Execute the cli command on your machine&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Snapshots</title>
      <link>/docs/concepts/snapshots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/snapshots/</guid>
      <description>
        
        
        &lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;The Ondat Snapshot feature can be used in conjunction with &lt;a href=&#34;https://www.kasten.io/&#34;&gt;Kasten
K10&lt;/a&gt; to snapshot, backup and restore Kubernetes
applications. This functionality is useful for:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Disaster recovery scenarios&lt;/li&gt;
&lt;li&gt;Rolling back unwanted changes&lt;/li&gt;
&lt;li&gt;Auditing purposes&lt;/li&gt;
&lt;li&gt;Moving applications between clusters&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h1&gt;
&lt;p&gt;To utilize the Ondat Snapshot feature the following prerequisites must be met:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ondat v2.8.0 or later is installed in the cluster&lt;/li&gt;
&lt;li&gt;Kasten K10 is installed in the cluster. See the Kasten 10 docs for the full list of
&lt;a href=&#34;https://docs.kasten.io/latest/install/requirements.html#&#34;&gt;prerequisites&lt;/a&gt;.
Kasten supports Kubernetes versions up to 1.22.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;what-are-snapshots-backups-and-restores&#34;&gt;What are snapshots, backups and restores?&lt;/h1&gt;
&lt;p&gt;A ‚Äúsnapshot‚Äù is a point-in-time copy of a PVC. Snapshots are modeled via the
&lt;code&gt;VolumeSnapshot&lt;/code&gt; and &lt;code&gt;VolumeSnapshotContent&lt;/code&gt; Kubernetes API objects. Snapshots
have limited use as they live within the cluster and cannot be used to restore
the PVC if the node holding the snapshot is lost.&lt;/p&gt;
&lt;p&gt;A ‚Äúbackup‚Äù is the process of materialising a new PVC, whose data source is a
previously created snapshot and then extracting the data to a location outside
of the cluster. The Ondat Snapshots feature integrates with Kasten K10 to
provide backup functionality.&lt;/p&gt;
&lt;p&gt;A ‚Äúrestore‚Äù is the process of restoring an application from a given backup. The
Ondat Snapshots feature integrates with Kasten K10 to provide restore
functionality.&lt;/p&gt;
&lt;h1 id=&#34;how-does-it-work&#34;&gt;How does it work?&lt;/h1&gt;
&lt;p&gt;The Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volume-snapshots/&#34;&gt;Volume
Snapshots&lt;/a&gt;
feature provides users with a set of custom resource definitions (CRD) and APIs
to create and manage volume snapshots. Storage providers can then implement the
necessary CSI APIs to integrate with this feature. This is exactly what we‚Äôve
done at Ondat. Additional tools, like Kasten K10, can then be utilised to
orchestrate and automate snapshotting, backups and restores.&lt;/p&gt;
&lt;p&gt;Please see the &lt;a href=&#34;/docs/operations/backups-and-restores-with-kastenk10&#34;&gt;Backups and restores with Kasten
K10&lt;/a&gt; for a full
walk through.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The Ondat Snapshot feature is not fully CSI compliant. As such the feature
can only be used with Kasten K10 and with restoration from an external backup.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;scope-and-limitations&#34;&gt;Scope and limitations&lt;/h1&gt;
&lt;p&gt;The feature has the following limitations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The feature has been designed to work with Kasten K10 only. This is not a
fully CSI compliant implementation of the spec.&lt;/li&gt;
&lt;li&gt;Restoring via Kasten 10 from a ‚Äúlocal snapshot‚Äù is not supported with the
Ondat Snapshot feature. Users may only restore applications using a Kasten K10
‚ÄúExternal backup‚Äù.&lt;/li&gt;
&lt;li&gt;Snapshotting RWX volumes is not supported. This is because it is next to
impossible to ensure that a NFS mounted volume is in a suitable state for
snapshotting. For RWX volumes, the user only has access to the filesystem on
the NFS client. It is not possible to run &lt;code&gt;fsfreeze&lt;/code&gt; on this mountpoint - NFS
does not support it. Thus the user can not quiesce the filesystem and we can
not take a &amp;ldquo;consistent&amp;rdquo; snapshot.&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Topology-Aware Placement (TAP)</title>
      <link>/docs/concepts/tap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/tap/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° This feature is available in release &lt;code&gt;v2.5.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat Topology-Aware Placement is a feature that enforces placement of data
across failure domains to guarantee high availability.&lt;/p&gt;
&lt;p&gt;TAP uses default labels on nodes to define failure domains. For instance, an
Availability Zone. However, the key label used to segment failure domains can
be defined by the user per node. Also, TAP is an opt in feature per volume.&lt;/p&gt;
&lt;h2 id=&#34;benefits-of-enabling-the-topology-aware-placement-tap-feature&#34;&gt;Benefits of enabling the Topology-Aware Placement (TAP) feature&lt;/h2&gt;
&lt;p&gt;Deploying a stateful application on a clusters with multiple nodes without TAP
enabled can result in suboptimal placement for high availability. Not enabling
TAP can cause following problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unschedulable pods due to resource, affinity, and taint issues when a full
failure domain experiences a failure&lt;/li&gt;
&lt;li&gt;volume replicas placed within the same zone as a primary volume&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/tap.png&#34; alt=&#34;tap&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;enabling-topology-aware-placement&#34;&gt;Enabling Topology-Aware Placement&lt;/h2&gt;
&lt;p&gt;Topology-Aware Placement can be enabled by applying the label
&lt;code&gt;storageos.com/topology-aware=true&lt;/code&gt; to a PVC or as a parameter of its
StorageClass.&lt;/p&gt;
&lt;h2 id=&#34;topology-domains&#34;&gt;Topology Domains&lt;/h2&gt;
&lt;p&gt;A topology domain is a set of nodes. The domain is identified by a label, which
can be defined by the user. The default label that Ondat uses to segment nodes
in failure domains is &lt;code&gt;topology.kubernetes.io/zone&lt;/code&gt;. However, you can define
your own topology key by setting the key string in the label
&lt;code&gt;storageos.com/topology-key&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To enable TAP on your volumes, follow the
&lt;a href=&#34;/docs/operations/tap&#34;&gt;TAP operations&lt;/a&gt; page.&lt;/p&gt;
&lt;h2 id=&#34;behaviour&#34;&gt;Behaviour&lt;/h2&gt;
&lt;p&gt;The Topology-Aware Placement attempts to distribute sensitive data across
different failure domains. Hence, a primary volume and its replicas are
scattered across failure domains. That is implemented following a best effort
algorithm. In case that the TAP rules can&amp;rsquo;t be fulfilled the placement
algorithm will attempt a best approach placement (even if new replicas
are in the same failure domain).
The best effort placement allows the system to place replicas on the same
failure domains when a full domain has failed catastrophically. Hence, the
system self heals as fast as possible without waiting for the nodes on the
failed domain to recover.&lt;/p&gt;
&lt;p&gt;It is the user&amp;rsquo;s responsibility to rebalance the data when the failed domain
has recovered its availability. That can be achieved by recreating the replicas
of a volume. Future versions of Ondat will facilitate the procedure by allowing
a volume drain.&lt;/p&gt;
&lt;h2 id=&#34;failure-modes&#34;&gt;Failure Modes&lt;/h2&gt;
&lt;p&gt;Failure modes are a complimentary feature of the Topology-Aware Placement
functionality. Failure modes allow you to define how many replicas of a volume
can become unavailable before the volume is marked as read-only. For more
information , see the
&lt;a href=&#34;/docs/concepts/replication#failure-modes&#34;&gt;failure mode concepts page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For example, assuming that your cluster has three topology zones, A, B and C,
and your deployment has a master and two replicas, Ondat will attempt to
place one volume in each topology zone.&lt;/p&gt;
&lt;p&gt;If zone A fails, I/O to your volume will stop completely if the Failure Mode is
&lt;code&gt;hard&lt;/code&gt;. If the Failure Mode is &lt;code&gt;soft&lt;/code&gt;, I/O will continue while volume failover
is in progress, and a new replica will be placed in an operational zone. Note
that if zone A recovers, the cluster will &lt;strong&gt;not&lt;/strong&gt; automatically rebalance.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;soft&lt;/code&gt; failure mode will not tolerate the failure of multiple replicas at
once, and will suspend I/O in this case. If you wish to tolerate more than one
failed replica, then you can set this as an integer using the &lt;code&gt;&amp;lt;integer&amp;gt;&lt;/code&gt;label.&lt;/p&gt;
&lt;p&gt;If individual nodes within a topology zone fail, the replicas will fail over to
other nodes within that zone. Once nodes in the zone are exhausted, placement
will revert to best-effort.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Upgrade</title>
      <link>/docs/upgrade/upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/upgrade/upgrade/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide provides instructions on how to upgrade Ondat.&lt;/p&gt;
&lt;h2 id=&#34;upgrading-an-ondat-v2-cluster&#34;&gt;Upgrading An Ondat &lt;code&gt;v2&lt;/code&gt; Cluster&lt;/h2&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Ensure that you have read the &lt;a href=&#34;/docs/prerequisites/pidlimits&#34;&gt;PIDs prerequisite introduced in Ondat
v2.3&lt;/a&gt; and that you have checked the init
container logs to ensure your environments PID limits are set correctly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Pull down the new Ondat container image &lt;code&gt;storageos/node:v2.8.0&lt;/code&gt; onto the
nodes beforehand so that the cluster spins up faster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Speak with our support team &lt;a href=&#34;/docs/support/&#34;&gt;here&lt;/a&gt; so we can assist you
with your upgrade.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---backup-ondat-deployment-manifests&#34;&gt;Step 1 - Backup Ondat Deployment Manifests&lt;/h3&gt;
&lt;p&gt;Make sure that you keep a backup of all the Ondat YAML files. You can also
backup the &lt;code&gt;StatefulSet&lt;/code&gt; yaml files to keep track of the replicas.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod -n storageos -o yaml &amp;gt; storageos_operator.yaml
kubectl get storageoscluster -n storageos -o yaml &amp;gt; storageos_cr.yaml
kubectl get statefulset --all-namespaces &amp;gt; statefulset-sizes.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2---scale-down-stateful-applications-to-zero&#34;&gt;Step 2 - Scale Down Stateful Applications To Zero&lt;/h3&gt;
&lt;p&gt;Scale all of the stateful applications that use Ondat volumes to 0.&lt;/p&gt;
&lt;h3 id=&#34;step-3---upgrade-ondat&#34;&gt;Step 3 - Upgrade Ondat&lt;/h3&gt;
&lt;p&gt;Run the following command using the kubectl storageos plugin.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure you are using the latest version of the kubectl storageos plugin.
You can make use of the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;installation guide&lt;/a&gt;
and get the latest version
&lt;a href=&#34;https://github.com/storageos/kubectl-storageos&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos upgrade
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;üí° Please use the &lt;code&gt;--etcd-tls-enabled&lt;/code&gt; if using TLS with your ETCD.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° If you are using a namespace other than &lt;code&gt;storageos&lt;/code&gt; for your Ondat
install, please use &lt;code&gt;--uninstall-stos-operator-namespace&lt;/code&gt; argument because it
uninstalls the cluster first and then reinstalls it with the new version.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° If at any point something goes wrong with the upgrade process, backups of
all the relevant Kubernetes manifests can be found in &lt;code&gt;~/.kube/storageos/&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;step-4---scale-up-stateful-applications&#34;&gt;Step 4 - Scale Up Stateful Applications&lt;/h3&gt;
&lt;p&gt;Once the Ondat upgrade is complete and the core components are back online,
scale up the stateful applications that use Ondat volumes back up to their
respective replica count.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Platform Upgrade</title>
      <link>/docs/upgrade/using-rolling-upgrades/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/upgrade/using-rolling-upgrades/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to enable protection for your orchestrator&amp;rsquo;s rolling upgrades using the &lt;a href=&#34;/docs/concepts/rolling-upgrades/#node-guard&#34;&gt;Node Guard&lt;/a&gt; and &lt;a href=&#34;/docs/concepts/rolling-upgrades/#node-manager&#34;&gt;Node Manager&lt;/a&gt;. This feature helps prevent your persistent storage volumes from becoming unhealthy during the rolling downtime of an orchestrator upgrade.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è This feature is currently in tech preview, we only recommend using this feature on your test clusters.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the requirements of &lt;a href=&#34;https://kubernetes.io/docs/tasks/run-application/configure-pdb/&#34;&gt;configuring a Pod Disruption Budget (PDB)&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è If your volume does not have any replicas, the rolling upgrades feature will not start on any StorageOS node until you have one or more replicas on all your volumes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è This feature supports the following platforms: Google Anthos, and Google GKE with future support to be expanded to Amazon EKS, Openshift, and Rancher.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Using Ondat for the internal registry is not recommended. OpenShift requires the internal registry to be available but Ondat volumes may become unavailable during the upgrade.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è For Openshift: The PDB feature is only stable in Kubernetes v1.21+ and Openshift v4.8+.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---enable-node-manager--node-guard&#34;&gt;Step 1 - Enable Node Manager &amp;amp; Node Guard&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Add the following lines to the &lt;code&gt;StorageOSCluster&lt;/code&gt; spec:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeManagerFeatures&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeGuard&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Alternatively, you can run the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get storageoscluster -n storageos storageoscluster -o yaml &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; sed -e &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;s|^spec:$|spec:\n  nodeManagerFeatures:\n    nodeGuard: &amp;#34;&amp;#34;|&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; kubectl apply -f - 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;You will see new pods getting created, one pod per node in a cluster called Node Manager. If you enable the Node Guard during the first installation, Node Guard might fall into a temporary &lt;code&gt;CrashLoopBackoff&lt;/code&gt; loop until all cluster components are up and running.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Node Guard has a few configuration options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MINIMUM_REPLICAS&lt;/code&gt;: minimum replica number of any volume. Default: 1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;WATCH_ALL_VOLUMES&lt;/code&gt;: watch all volumes on every node, otherwise Node Guard watches volumes and their replicas on the node where it is running. Extra safety option with a performance impact. Default: false&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeManagerFeatures&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeGuard&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;MINIMUM_REPLICAS=2,WATCH_ALL_VOLUMES=true&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2---rolling-upgrades-is-ready&#34;&gt;Step 2 - Rolling Upgrades Is Ready&lt;/h3&gt;
&lt;p&gt;Congratulations, you are now ready to start the rolling upgrade process of your orchestrator!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è GKE and AKS take care of the pod disruption budget for one hour. After this period, they drain the node, which would destroy the volume.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è EKS takes care of PDB for 50 mins, after this period upgrade would fail unless it was forced.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Node Guard has a one-day termination period by default. The final termination period heavily depends on the platform you use. During the termination period, you should SSH into the node to create a backup in the worst-case scenario.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Volumes are healthy, all in sync but &lt;code&gt;storageos-node-manager&lt;/code&gt; pod is hanging on the &lt;code&gt;Terminating&lt;/code&gt; state.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The long termination period of Node Manager tries to keep failed node - and volumes on it - up and running as long as possible. This gives a chance to create a backup from an accidentally deleted machine. In case, Node Guard isn&amp;rsquo;t able to determine volume statuses, because of a network issue or missing StorageOS service, you have to delete pod manually by executing the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl delete pods -n storageos storageos-node-manager-XYZ --grace-period&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt; --force
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;A node has been removed accidentally or not in the official &lt;code&gt;graceful termination&lt;/code&gt; way before drain, and two Node Manager pods - one in &lt;code&gt;Pending&lt;/code&gt; and the other in &lt;code&gt;Terminating&lt;/code&gt; states - are hanging on the same node.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Node Manager deployment tolerates almost every issue on the target node to protect your data. On the other hand, Node Manager doesn&amp;rsquo;t tolerate itself on the same node. If a node goes down before Kubernetes was able to properly delete StorageOS Node daemonset, after the termination phase it re-schedules Node Manager pod to ensure the right number of replicas. But the pod isn&amp;rsquo;t able to be scheduled, because of the toleration. Meantime Kubernetes isn&amp;rsquo;t able to remove the pod in &lt;code&gt;Terminating&lt;/code&gt; state, because Kubelet isn&amp;rsquo;t responding.&lt;/p&gt;
&lt;p&gt;The only way to solve this situation is to delete the node from Kubernetes cluster by executing the command below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl delete node XYZ
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Kubernetes has introduced Non-Graceful Node Shutdown Alpha in 1.24. This new feature allows cluster admins to mark failing nodes as &lt;code&gt;NoExecute&lt;/code&gt; or &lt;code&gt;NoScedule&lt;/code&gt;. Both options should solve the scheduling issue of Node Manager pod by decreasing the number of daemonset instances to the right number at Kubernetes API level, but in the absence of Kubelet termination of pods would still hangin.&lt;/p&gt;
&lt;/blockquote&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Policies</title>
      <link>/docs/concepts/policies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/policies/</guid>
      <description>
        
        
        &lt;p&gt;Ondat policies are a way to control user and group access to Ondat
&lt;a href=&#34;/docs/concepts/namespaces&#34;&gt;Namespaces&lt;/a&gt;. To grant a user or group
access to a namespace, a policy needs to be created mapping the user or group
to the namespace.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Users always have access to the default namespace&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For more information on how to use policies, see the
&lt;a href=&#34;/docs/operations/policies&#34;&gt;Policies operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Quick Start Guide - Non-Production</title>
      <link>/docs/install/quick-start-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/quick-start-guide/</guid>
      <description>
        
        
        &lt;p&gt;This guide will provide step by step instructions on how to install Ondat onto your cluster, with the &lt;a href=&#34;https://github.com/ondat/charts&#34;&gt;Ondat helm chart&lt;/a&gt;, for a non-production environment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è This guide is for a non-production installation. Please follow the &lt;a href=&#34;https://docs.ondat.io/docs/install/&#34;&gt;other installation guides&lt;/a&gt; for a production-ready installation of Ondat&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;helm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat requires certain kernel modules to function. In particular it requires &lt;a href=&#34;http://linux-iscsi.org/wiki/Main_Page&#34;&gt;Linux-IO&lt;/a&gt;, an open-source implementation of the SCSI target, on all nodes that will execute Ondat (usually the workers).
More information can be &lt;a href=&#34;../prerequisites/systemconfiguration.md&#34;&gt;found here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This guide assumes you already have a Kubernetes cluster, with &lt;strong&gt;at least&lt;/strong&gt; 3 worker nodes.&lt;/p&gt;
&lt;h3 id=&#34;this-guide-works-on-the-following-kubernetes-distributions&#34;&gt;This guide works on the following Kubernetes distributions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Vanilla Kubernetes&lt;/li&gt;
&lt;li&gt;Rancher&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-1---install-ondat-helm-charts&#34;&gt;Step 1 - Install Ondat Helm Charts&lt;/h2&gt;
&lt;p&gt;Add the Ondat chart repository to Helm:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo add ondat https://ondat.github.io/charts
helm repo update
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;step-2---install-local-path-provisioner&#34;&gt;Step 2 - Install Local Path Provisioner&lt;/h2&gt;
&lt;p&gt;Etcd requires a storage class before Ondat can be started. For non-production environments the Local Path Provisioner storage class can be used.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following command can be used to ensure the Local Path Provisioner was successfully deployed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&amp;gt; kubectl get pod,storageclass --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
NAME                                         READY   STATUS    RESTARTS   AGE
pod/local-path-provisioner-c4d687f4c-bxmjt   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          3h10m

NAME                                     PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
storageclass.storage.k8s.io/local-path   rancher.io/local-path   Delete          WaitForFirstConsumer   &lt;span style=&#34;color:#204a87&#34;&gt;false&lt;/span&gt;                  3h10m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;step-3---customise-and-install-the-helm-chart&#34;&gt;Step 3 - Customise and install the helm chart&lt;/h2&gt;
&lt;p&gt;A few changes need to be made to the default helm chart values, so it can run in smaller non-production sized clusters.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to set the values of &lt;code&gt;ONDAT_USERNAME&lt;/code&gt; and &lt;code&gt;ONDAT_PASSWORD&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ONDAT_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;changeme&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ONDAT_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;changeme&amp;#34;&lt;/span&gt;

helm install ondat ondat/ondat --create-namespace --namespace storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--set ondat-operator.cluster.admin.username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ONDAT_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;,&lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;ondat-operator.cluster.admin.password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ONDAT_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;,&lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;etcd-cluster-operator.cluster.namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd,&lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;etcd-cluster-operator.cluster.replicas&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;3,&lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;etcd-cluster-operator.cluster.storageclass&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path,&lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;etcd-cluster-operator.cluster.storage&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;6Gi,&lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;etcd-cluster-operator.cluster.resources.requests.cpu&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;100m,&lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;etcd-cluster-operator.cluster.resources.requests.memory&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;300Mi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;step-4---wait-until-the-storageos-storage-class-has-been-created&#34;&gt;Step 4 - Wait until the storageos storage class has been created&lt;/h2&gt;
&lt;p&gt;It can take a few seconds for the storageos storage class to be created. This needs to happen before it can be set as the default storage class.&lt;/p&gt;
&lt;p&gt;The following command can be used to ensure the storageos storage class was successfully deployed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&amp;gt; kubectl -n storageos get storageclass -w
NAME         PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-path   rancher.io/local-path   Delete          WaitForFirstConsumer   &lt;span style=&#34;color:#204a87&#34;&gt;false&lt;/span&gt;                  3h4m
storageos    csi.storageos.com       Delete          Immediate              &lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;                   75m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;step-5---set-the-default-storage-class&#34;&gt;Step 5 - Set the default storage class&lt;/h2&gt;
&lt;p&gt;Set the storageos storage class as the default.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl patch storageclass local-path -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;metadata&amp;#34;: {&amp;#34;annotations&amp;#34;:{&amp;#34;storageclass.kubernetes.io/is-default-class&amp;#34;:&amp;#34;false&amp;#34;}}}&amp;#39;&lt;/span&gt;
kubectl patch storageclass storageos -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;metadata&amp;#34;: {&amp;#34;annotations&amp;#34;:{&amp;#34;storageclass.kubernetes.io/is-default-class&amp;#34;:&amp;#34;true&amp;#34;}}}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;step-6---ensure-everything-is-running&#34;&gt;Step 6 - Ensure everything is running&lt;/h2&gt;
&lt;p&gt;It can take a couple of minutes for the cluster to converge. A ready cluster will look like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&amp;gt; kubectl -n storageos get pods,storageclass,svc                    
NAME                                           READY   STATUS    RESTARTS      AGE
pod/ondat-controller-manager-5f7f669b4-fqj57   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;             73m
pod/ondat-controller-manager-5f7f669b4-jmbfk   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;             73m
pod/ondat-ondat-operator-675c4c9c88-9jgrv      2/2     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;             73m
pod/ondat-proxy-6887466cd5-vlkq6               1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;             73m
pod/storageos-api-manager-6677c95579-qdght     1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;             71m
pod/storageos-api-manager-6677c95579-rzwqr     1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;71m ago&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;   71m
pod/storageos-csi-helper-6fbb8cc7d9-h767k      4/4     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;             71m
pod/storageos-node-fmtrd                       3/3     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;72m ago&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;   72m
pod/storageos-node-h54xp                       3/3     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;72m ago&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;   72m
pod/storageos-node-jm5th                       3/3     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;72m ago&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;   72m
pod/storageos-scheduler-664886b7b-8jrv2        1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;             72m

NAME                                     PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
storageclass.storage.k8s.io/local-path   rancher.io/local-path   Delete          WaitForFirstConsumer   &lt;span style=&#34;color:#204a87&#34;&gt;false&lt;/span&gt;                  3h1m
storageclass.storage.k8s.io/storageos    csi.storageos.com       Delete          Immediate              &lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;                   72m

NAME                                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;    AGE
service/ondat-proxy                     ClusterIP   10.100.222.57    &amp;lt;none&amp;gt;        80/TCP     73m
service/storageos                       ClusterIP   10.102.114.114   &amp;lt;none&amp;gt;        5705/TCP   72m
service/storageos-api-manager-metrics   ClusterIP   10.105.234.54    &amp;lt;none&amp;gt;        8080/TCP   71m
service/storageos-operator              ClusterIP   10.109.66.235    &amp;lt;none&amp;gt;        8443/TCP   73m
service/storageos-operator-webhook      ClusterIP   10.103.117.39    &amp;lt;none&amp;gt;        443/TCP    73m
service/storageos-webhook               ClusterIP   10.108.126.126   &amp;lt;none&amp;gt;        443/TCP    71m

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&amp;gt; kubectl -n storageos-etcd get pods,pdb
NAME                         READY   STATUS    RESTARTS   AGE
pod/storageos-etcd-0-jbmq6   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          73m
pod/storageos-etcd-1-nhbk6   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          72m
pod/storageos-etcd-2-n9b9w   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          72m

NAME                                        MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
poddisruptionbudget.policy/storageos-etcd   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt;               N/A               &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;                     73m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;applying-a-licence-to-the-cluster&#34;&gt;Applying a Licence to the Cluster&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on the &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Replication</title>
      <link>/docs/concepts/replication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/replication/</guid>
      <description>
        
        
        &lt;p&gt;Ondat replicates volumes across nodes for data protection and high
availability. Synchronous replication ensures strong consistency for
applications such as databases and Elasticsearch, incurring one network round
trip on writes.&lt;/p&gt;
&lt;p&gt;The basic model for Ondat replication is of a master volume with distributed
replicas. Each volume can be replicated between 0 and 5 times, which are
provisioned to 0 to 5 nodes, up to the number of remaining nodes in the cluster.&lt;/p&gt;
&lt;p&gt;In this diagram, the master volume &lt;code&gt;D&lt;/code&gt; was created on node 1, and two replicas,
&lt;code&gt;D2&lt;/code&gt; and &lt;code&gt;D3&lt;/code&gt; on nodes 3 and 5.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/high-availability.png&#34; alt=&#34;Ondat replication&#34;&gt;&lt;/p&gt;
&lt;p&gt;Writes that come into &lt;code&gt;D&lt;/code&gt; (step 1) are written in parallel to &lt;code&gt;D2&lt;/code&gt; and &lt;code&gt;D3&lt;/code&gt;
(step 2). When both replicas and the master acknowledge that the data has been
written (step 3), the write operation return successfully to the application
(step 4).&lt;/p&gt;
&lt;p&gt;For most applications, one replica is sufficient (&lt;code&gt;storageos.com/replicas=1&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;All replication traffic on the wire is compressed using the lz4 algorithm, then
streamed over tcp/ip to target port tcp/5703.&lt;/p&gt;
&lt;p&gt;If the master volume is lost, a replica is promoted to master (&lt;code&gt;D2&lt;/code&gt; or &lt;code&gt;D3&lt;/code&gt;
above) and a new replica is created and synced on an available node (Node 2 or
4). This is transparent to the application and does not cause downtime.&lt;/p&gt;
&lt;p&gt;If a replica volume is lost and there are enough remaining nodes, a new replica
is created and synced on an available node. While a new replica is created and
being synced, the volume&amp;rsquo;s health will be marked as degraded.&lt;/p&gt;
&lt;p&gt;If the lost replica comes back online before the new replica has finished
synchronizing, then Ondat will calculate which of the two synchronizing
replicas has the smallest difference compared to the master volume and keep
that replica. The same holds true if a master volume is lost and a replica is
promoted to be the new master. If possible, a new replica will be created and
begin to sync. Should the former master come back online it will be demoted to
a replica and the replica will the smallest difference to the current master
will be kept.&lt;/p&gt;
&lt;p&gt;While the replica count is controllable on a per-volume basis, some
environments may prefer to set &lt;a href=&#34;/docs/reference/labels#storageos-storageclass-labels&#34;&gt;default labels on the StorageClass&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;delta-sync&#34;&gt;Delta Sync&lt;/h2&gt;
&lt;p&gt;Ondat implements a delta sync between a volume master and its replicas.
This means that if a replica for a volume goes offline, that when the replica
comes back online only the regions with changed blocks need to be synchronized.
This optimization reduces the time it takes for replicas to catch up, improving
volume resilience. Additionally, it reduces network and IO bandwidth which can
reduce costs when running in public clouds.&lt;/p&gt;
&lt;h2 id=&#34;topology-aware-placement&#34;&gt;Topology-Aware Placement&lt;/h2&gt;
&lt;p&gt;Ondat Topology-Aware Placement is a feature that enforces placement of data
across failure domains to guarantee high availability.&lt;/p&gt;
&lt;p&gt;TAP uses default labels on nodes to define failure domains. For instance, an
Availability Zone. For more detail on TAP, check the
&lt;a href=&#34;/docs/reference/tap&#34;&gt;reference page&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;failure-modes&#34;&gt;Failure Modes&lt;/h2&gt;
&lt;p&gt;Ondat failure modes offer different guarantees with regards to a volume&amp;rsquo;s
mode of operation in the face of replica failure. If the failure mode is not
specified it defaults to &lt;code&gt;Hard&lt;/code&gt;. Volume failure modes can be dynamically
updated at runtime.&lt;/p&gt;
&lt;h3 id=&#34;hard&#34;&gt;Hard&lt;/h3&gt;
&lt;p&gt;Hard failure mode requires that the number of declared replicas matches the
available number of replicas at all times. If a replica fails Ondat will
attempt creation of a new replica for 90 seconds. After 90s if the old replica
is not available and a new replica cannot be provisioned, Ondat cannot
guarantee that the data is stored on the number of multiple nodes requested by
the user. Ondat will therefore set the volume to be read-only.&lt;/p&gt;
&lt;p&gt;If a volume has gone read-only there are two stages to making it read-write
again. Firstly, sufficient replicas must be provisioned to match the desired
replica count. Depending on your environment, additional nodes and/or disk
capacity may be required for this. Secondly, the volume must be remounted -
necessitating pod deletion/recreation in Kubernetes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos.com/failure-mode: hard
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Number of nodes required for hard failure mode&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When a node fails, a new replica is provisioned and synced as described above.
To ensure that a new replica can always be created, an additional node should
be available. To guarantee high availability using &lt;code&gt;storageos.com/failure-mode: hard&lt;/code&gt;, clusters using volumes with 1 replica must have at least 3 storage
nodes. When using volumes with 2 replicas, at least 4 storage nodes, 3
replicas, 5 nodes, etc.&lt;/p&gt;
&lt;p&gt;Minimum number of storage nodes = 1 (primary) + N (replicas) + 1&lt;/p&gt;
&lt;h3 id=&#34;soft&#34;&gt;Soft&lt;/h3&gt;
&lt;p&gt;Soft failure mode allows a volume to continue serving I/O even when a replica
goes offline and a new replica fails to provision. So long as there are not
less than max(1,  n-1) available replicas where n is the number of replicas for
the volume.&lt;/p&gt;
&lt;p&gt;For example, if a volume with 2 replicas loses 1 replica, then I/O would
continue to be served since 1 replica remaining &amp;gt;= max(1, 1). If a volume with
1 replica loses 1 replica, then I/O would halt after 90 seconds since 0
replicas remaining &amp;lt; max(1, 0).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos.com/failure-mode: soft
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Number of nodes required for soft failure mode&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To ensure that a &lt;code&gt;storageos.com/failure-mode: soft &lt;/code&gt; volume is highly available, clusters using volumes with 1 replica must have at
least 2 storage nodes. When using volumes with 2 replicas, at least 3 storage
nodes, 3 replicas, 3 nodes, etc.&lt;/p&gt;
&lt;p&gt;Minimum number of storage nodes = 1 (primary) + N (replicas)&lt;/p&gt;
&lt;h3 id=&#34;threshold&#34;&gt;Threshold&lt;/h3&gt;
&lt;p&gt;Threshold failure mode allows the user to set the minimum required number of
online replicas for a volume. For example for a volume with 2 replicas, setting
the threshold to 1 would allow a single replica to be offline, whereas setting
threshold to 0 would allow 2 replicas to be offline.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos.com/failure-mode: &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;0-5&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Number of nodes required for threshold failure mode&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The minimum number of nodes for a &lt;code&gt;threshold&lt;/code&gt; volume is determined by the
threshold that is set.&lt;/p&gt;
&lt;p&gt;Minimum number of storage nodes = 1 (primary) + T (threshold)&lt;/p&gt;
&lt;h3 id=&#34;alwayson&#34;&gt;AlwaysOn&lt;/h3&gt;
&lt;p&gt;AlwaysOn failure mode allows all replicas for a volume to be offline and keeps
the volume writeable. A volume with failure mode AlwaysOn will continue to
serve I/O regardless of how many replicas it currently has. This mode should be
used with caution as it effectively allows for only a single copy of the data
to be available.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos.com/failure-mode: alwayson
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Number of nodes required for AlwaysOn failure mode&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;storageos.com/failure-mode: alwayson&lt;/code&gt; volume is highly available albeit at
the cost of reliability. The minimum node count here is 1 as the loss of all
replicas will be tolerated.&lt;/p&gt;
&lt;p&gt;Minimum number of storage nodes = 1 (primary)&lt;/p&gt;
&lt;p&gt;For details about how to use the labels on the VolumesCheck, see the &lt;a href=&#34;/docs/operations/failure-modes&#34;&gt;failure modes operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Volumes</title>
      <link>/docs/concepts/volumes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/volumes/</guid>
      <description>
        
        
        &lt;p&gt;Ondat volumes are a logical construct which represent a writeable volume
and exhibit standard POSIX semantics. Ondat presents volumes as mounts into
containers via the Linux LIO subsystem.&lt;/p&gt;
&lt;p&gt;Conceptually, Ondat volumes have a frontend presentation, which is what
the application sees, and a backend presentation, which is the actual on-disk
format. Depending on the configuration, frontend and backend components may be
on the same or different hosts.&lt;/p&gt;
&lt;p&gt;Volumes are formatted using the linux standard ext4 filesystem by default.
Kubernetes users may change the default filesystem type to ext2, ext3, ext4, or
xfs by setting the fsType parameter in their StorageClass (see &lt;a href=&#34;/docs/reference/filesystems#persistent-volume-filesystems&#34;&gt;Supported Filesystems&lt;/a&gt; for more
information). Different filesystems may be supported in the future.&lt;/p&gt;
&lt;p&gt;Ondat volumes are represented on disk in two parts. Actual volume data is
written to blob files in &lt;code&gt;/var/lib/storageos/data/dev[\d+]&lt;/code&gt;. Inside these
directories, each Ondat block device gets two blob files of the form
&lt;code&gt;vol.xxxxxx.y.blob&lt;/code&gt;, where x is the inode number for the device, and y is an
index between 0 and 1. We provide two blob files in order to ensure that
certain operations which require locking do not impede in-flight writes to the
volume.&lt;/p&gt;
&lt;p&gt;In systems which have multiple &lt;code&gt;/var/lib/storageos/data/dev[\d+]&lt;/code&gt; directories,
two blob files are created per block device. This allows us to load-balance
writes across multiple devices. In cases where dev directories are added after
a period of runtime, later directories are favoured for writes until the data
is distributed evenly across the blob files.&lt;/p&gt;
&lt;p&gt;Metadata is kept in directories named &lt;code&gt;/var/lib/storageos/data/db[\d+]&lt;/code&gt;. We
maintain an index of all blocks written to the blob file inside the metadata
store, including checksums. These checksums allow us to detect bitrot, and
return errors on reads, rather than serve bad data. In future versions we may
implement recovery from replicas for volumes with one or more replicas defined.&lt;/p&gt;
&lt;p&gt;Ondat metadata requires approximately 2.7GB of storage per 1TiB of allocated
blocks in the associated volume. This size is consistent irrespective of data
compression defined on the volume.&lt;/p&gt;
&lt;p&gt;To ensure deterministic performance, individual Ondat volumes must fit on a single
node.&lt;/p&gt;
&lt;h2 id=&#34;minimum-volume-size&#34;&gt;Minimum Volume Size&lt;/h2&gt;
&lt;p&gt;The minimum volume size Ondat supports is 1GB.&lt;/p&gt;
&lt;h2 id=&#34;trim&#34;&gt;TRIM&lt;/h2&gt;
&lt;p&gt;Ondat volumes support TRIM/Unmap which allows the space allocated to
deleted blocks to be reclaimed from the backend blob files that back each
volume when a TRIM call is made. Support for TRIM is enabled by default for all
uncompressed volumes, volumes are created without compression enabled by
default. For more information on how to TRIM a filesystem, see &lt;a href=&#34;/docs/operations/trim&#34;&gt;TRIM operations&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;volume-resize&#34;&gt;Volume Resize&lt;/h2&gt;
&lt;p&gt;Ondat supports offline resize of volumes. This means that a volume cannot be
resized while it is in use. Furthermore, in order for a resize operation to
take place the volume must not be attached to a node. This is to ensure that
the volume is not in use.&lt;/p&gt;
&lt;p&gt;This means that if a Kubernetes pod is currently consuming a volume that a
resize request has been issued for, the resize will not be actioned until the
pod is terminated and the volume is detached from the node. The Ondat
controlplane will then attach the volume to the node that holds the master
deployment and resize the underlying block device and then run resize2fs to
expand the filesystem.&lt;/p&gt;
&lt;p&gt;For a walkthrough of how to resize a volume, see the &lt;a href=&#34;/docs/operations/resize&#34;&gt;Volume Resize&lt;/a&gt; operations page.&lt;/p&gt;
&lt;h2 id=&#34;volume-encryption&#34;&gt;Volume Encryption&lt;/h2&gt;
&lt;p&gt;Volumes can be configured on creation to have encryption-at-rest. Data
is encrypted with XTS-AES and decrypted upon use. Please see
the &lt;a href=&#34;/docs/reference/encryption&#34;&gt;Encryption&lt;/a&gt; reference page for
more information.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Amazon Elastic Kubernetes Service (EKS)</title>
      <link>/docs/install/amazon-web-services-eks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/amazon-web-services-eks/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° This page has an example installation using &lt;a href=&#34;https://eksctl.io/&#34;&gt;eksctl&lt;/a&gt;
to get started quickly and easily. For a declarative installation with
&lt;a href=&#34;https://github.com/aws-ia/terraform-aws-eks-blueprints&#34;&gt;Amazon EKS Blueprints for
Terraform&lt;/a&gt;, refer to
our &lt;a href=&#34;https://github.com/ondat/terraform-eksblueprints-ondat-addon/tree/main/blueprints/getting-started&#34;&gt;getting-started
blueprint&lt;/a&gt;
for the Ondat EKS Blueprints addon.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto an &lt;a href=&#34;https://aws.amazon.com/eks/&#34;&gt;Amazon Elastic
Kubernetes Service&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat
kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to
successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt;
page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utilities are installed on your local machine
and are available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/cli/&#34;&gt;aws&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://eksctl.io/&#34;&gt;eksctl&lt;/a&gt;, at least version &lt;code&gt;&amp;gt;=0.83.0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after
installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS
Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running EKS cluster with a minimum of 5 worker nodes
and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control
(RBAC)&lt;/a&gt;
permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your EKS clusters use &lt;a href=&#34;https://cloud-images.ubuntu.com/docs/aws/eks/&#34;&gt;Ubuntu for
EKS&lt;/a&gt; as the default node
operating system with an optimised kernel. For kernel versions below
&lt;code&gt;linux-aws-5.4.0-1066.69&lt;/code&gt; or &lt;code&gt;linux-aws-5.13.0-1014.15&lt;/code&gt;, the module
&lt;code&gt;tcm_loop&lt;/code&gt; is not included in the base kernel distribution. In that case, the
package &lt;code&gt;linux-modules-extra-$(uname -r)&lt;/code&gt; is additionally required on each of
the nodes - this can be installed automatically by adding extra steps to the
node&amp;rsquo;s user data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;To find the latest Ubuntu for EKS AMI, search your region for the image:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;AWS_REGION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;eu-west-2&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Insert your preferred region here&lt;/span&gt;
aws ec2 describe-images &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--filters &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Name=owner-id,Values=099720109477&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Name=architecture,Values=x86_64&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Name=root-device-type,Values=ebs&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Name=virtualization-type,Values=hvm&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--query &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Images[?contains(Name, `ubuntu-eks`)] | [?contains(Name, `testing`) == `false`] | [?contains(Name, `minimal`) == `false`] | [?contains(Name, `hvm-ssd`) == `true`] | sort_by(@, &amp;amp;CreationDate)| [-1].ImageId&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--output text &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--region &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$AWS_REGION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;In this example, we have used &lt;a href=&#34;https://eksctl.io/introduction/&#34;&gt;eksctl&lt;/a&gt; to
create a cluster with 3 nodes of size &lt;code&gt;t3.large&lt;/code&gt; running Ubuntu for EKS in
the &lt;code&gt;eu-west-2&lt;/code&gt; region. We have provided &lt;code&gt;100 GB&lt;/code&gt; of disk space for each
node. Note that by default, Ondat will store data locally in the node&amp;rsquo;s file
system under the path &lt;code&gt;/var/lib/storageos&lt;/code&gt; on each node in &lt;a href=&#34;/docs/concepts/nodes/#hyperconverged-mode&#34;&gt;hyperconverged
mode&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;In a production infrastructure, we would create multiple Elastic Block Store
(EBS) Volumes tweaked for performance or use ephemeral SSD storage and &lt;a href=&#34;/docs/concepts/volumes/&#34;&gt;mount
our volumes under data device directories&lt;/a&gt; with some
additions to user data. We would also implement some form of snapshots or
backup of these underlying volumes to ensure continuity in a disaster
scenario.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# cluster.yaml&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;---&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;eksctl.io/v1alpha5&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ClusterConfig&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ondat-cluster&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;eu-west-2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;1.22&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;addons&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;aws-ebs-csi-driver&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;iam&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;withOIDC&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;managedNodeGroups&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ondat-ng-2a&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;availabilityZones&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;eu-west-2a&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;minSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;maxSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;desiredCapacity&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;instanceType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i3en.xlarge&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;amiFamily&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Ubuntu2004&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ssh&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;allow&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;publicKeyName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;&amp;lt;key-name&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;labels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;{&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ondat&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;node}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;gp3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeEncrypted&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;disableIMDSv1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;iam&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;withAddonPolicies&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ebs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;preBootstrapCommands&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkdir -p /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;echo &amp;#34;/dev/nvme1n1 /var/lib/storageos ext4 defaults,discard 0 1&amp;#34; &amp;gt;&amp;gt; /etc/fstab&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkfs.ext4 /dev/nvme1n1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mount /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ondat-ng-2b&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;availabilityZones&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;eu-west-2b&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;minSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;maxSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;desiredCapacity&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;instanceType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i3en.xlarge&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;amiFamily&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Ubuntu2004&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ssh&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;allow&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;publicKeyName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;&amp;lt;key-name&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;labels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;{&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ondat&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;node}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;gp3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeEncrypted&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;disableIMDSv1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;iam&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;withAddonPolicies&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ebs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;preBootstrapCommands&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkdir -p /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;echo &amp;#34;/dev/nvme1n1 /var/lib/storageos ext4 defaults,discard 0 1&amp;#34; &amp;gt;&amp;gt; /etc/fstab&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkfs.ext4 /dev/nvme1n1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mount /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ondat-ng-2c&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;availabilityZones&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;eu-west-2c&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;minSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;maxSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;desiredCapacity&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;instanceType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i3en.xlarge&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;amiFamily&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Ubuntu2004&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ssh&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;allow&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;publicKeyName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;&amp;lt;key-name&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;labels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;{&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ondat&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;node}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;gp3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeEncrypted&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;disableIMDSv1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;iam&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;withAddonPolicies&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ebs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;preBootstrapCommands&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkdir -p /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;echo &amp;#34;/dev/nvme1n1 /var/lib/storageos ext4 defaults,discard 0 1&amp;#34; &amp;gt;&amp;gt; /etc/fstab&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkfs.ext4 /dev/nvme1n1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mount /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note the &lt;code&gt;&amp;lt;key-name&amp;gt;&lt;/code&gt; field in the publicKeyName parameter, please make sure you update this to match your ssh key name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;eksctl create cluster --config-file&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;cluster.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è With the above configuration, volumes will be deleted when the nodes they
are attached to are terminated. Be sure to keep snapshots, for example by
using &lt;a href=&#34;https://aws.amazon.com/blogs/storage/automating-amazon-ebs-snapshot-and-ami-management-using-amazon-dlm/&#34;&gt;Data Lifecycle
Manager&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;p&gt;First, provision your &lt;code&gt;kubeconfig&lt;/code&gt; for &lt;code&gt;kubectl&lt;/code&gt; and test that you can connect
to Kubernetes:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws eks update-kubeconfig --region &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$AWS_REGION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; --name ondat-cluster
kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you receive the message &lt;code&gt;No resources found&lt;/code&gt; or see nodes marked as
&lt;code&gt;NotReady&lt;/code&gt;, wait for 2-3 minutes in order for your nodes to transition to
&lt;code&gt;Ready&lt;/code&gt; and check again to ensure they are running before proceeding through
the next steps.&lt;/p&gt;
&lt;h3 id=&#34;step-1---conducting-preflight-checks&#34;&gt;Step 1 - Conducting Preflight Checks&lt;/h3&gt;
&lt;p&gt;Run the following command to conduct preflight checks against the EKS cluster
to ensure that Ondat prerequisites are in place before continuing with
installation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2---installing-ondat&#34;&gt;Step 2 - Installing Ondat&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt;
environment variables that will be used to manage your Ondat instance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set the &lt;code&gt;StorageClass&lt;/code&gt; for etcd to use.&lt;/p&gt;
&lt;p&gt;If you used the &lt;code&gt;eksctl&lt;/code&gt; cluster configuration defined above, the gp3 storage
class is available so you can skip to the next step. Otherwise you can set up
the EBS CSI Driver as follows. It is important to note that the Ondat etcd
usage of disk depends on the size of the Kubernetes cluster. However, it is
recommended that the disks have at least 800 IOPS at any point in time. The
best cost effective storage class that fulfils such requirements is gp3. If gp2
is used, it is paramount to use a volume bigger than 256Gi as it will have
enough IOPS even when the burstable credits are exhausted.&lt;/p&gt;
&lt;p&gt;To use a gp3 storage class in Kubernetes it is required to install the Amazon
CSI Driver. Follow &lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html&#34;&gt;this
guide&lt;/a&gt; to
install. The procedure is comprehended by the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/csi-iam-role.html&#34;&gt;Create IAM permissions&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the CSI driver&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/managing-ebs-csi.html&#34;&gt;Using EKS addon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/aws-ebs-csi-driver/blob/master/docs/install.md&#34;&gt;Using self-managed add on&lt;/a&gt; (AWS clusters, but not in EKS)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the &lt;code&gt;gp3&lt;/code&gt; &lt;code&gt;StorageClass&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;EOF
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: StorageClass
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: storage.k8s.io/v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  name: gp3
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;allowVolumeExpansion: true
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;provisioner: ebs.csi.aws.com
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;volumeBindingMode: WaitForFirstConsumer
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;parameters:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  type: gp3
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;gp3&amp;#34;&lt;/span&gt;

kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-storage-class&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;The installation process may take a few minutes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-3---verifying-ondat-installation&#34;&gt;Step 3 - Verifying Ondat Installation&lt;/h3&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core
components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-4---applying-a-licence-to-the-cluster&#34;&gt;Step 4 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our
Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing
operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Azure Kubernetes Service (AKS)</title>
      <link>/docs/install/microsoft-azure-aks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/microsoft-azure-aks/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://azure.microsoft.com/en-gb/services/kubernetes-service/&#34;&gt;Microsoft Azure Kubernetes Service (AKS)&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utilities are installed on your local machine and are available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running AKS cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your AKS cluster uses &lt;a href=&#34;https://ubuntu.com/&#34;&gt;Ubuntu&lt;/a&gt; as the default node operating system with an optimised kernel. Any Ubuntu-based node operating system with a kernel version greater than &lt;code&gt;4.15.0-1029-azure&lt;/code&gt; is compatible with Ondat.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---conducting-preflight-checks&#34;&gt;Step 1 - Conducting Preflight Checks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following command to conduct preflight checks against the AKS cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2---installing-ondat&#34;&gt;Step 2 - Installing Ondat&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-3---verifying-ondat-installation&#34;&gt;Step 3 - Verifying Ondat Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-4---applying-a-licence-to-the-cluster&#34;&gt;Step 4 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: DigitalOcean Kubernetes (DOKS)</title>
      <link>/docs/install/digitalocean-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/digitalocean-kubernetes/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://www.digitalocean.com/products/kubernetes&#34;&gt;DigitalOcean Managed Kubernetes (DOKS)&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utilities are installed on your local machine and are available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running DOKS cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your DOKS cluster version is greater than or equal to &lt;code&gt;v1.21.10&lt;/code&gt; or &lt;code&gt;v1.22.7&lt;/code&gt; as they will have the required kernel modules available for Ondat to run successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---conducting-preflight-checks&#34;&gt;Step 1 - Conducting Preflight Checks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following command to conduct preflight checks against the DOKS cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2---installing-ondat&#34;&gt;Step 2 - Installing Ondat&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-3---verifying-ondat-installation&#34;&gt;Step 3 - Verifying Ondat Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-4---applying-a-licence-to-the-cluster&#34;&gt;Step 4 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Google Anthos</title>
      <link>/docs/install/anthos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/anthos/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://cloud.google.com/anthos&#34;&gt;Google Anthos&lt;/a&gt; cluster using the &lt;a href=&#34;https://docs.ondat.io/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utilities are installed on your local machine and are available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ondat.io/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running Google Anthos cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your Google Anthos cluster use &lt;a href=&#34;https://cloud.google.com/anthos/clusters/docs/on-prem/1.8/concepts/using-containerd&#34;&gt;&lt;code&gt;ubuntu_containerd&lt;/code&gt;&lt;/a&gt; as the default node operating system. This node operating system image has the required kernel modules available for Ondat to run successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---conducting-preflight-checks&#34;&gt;Step 1 - Conducting Preflight Checks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following command to conduct preflight checks against the Google Anthos cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2---installing-ondat&#34;&gt;Step 2 - Installing Ondat&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è If you are installing Ondat and connecting to an &lt;em&gt;existing etcd cluster&lt;/em&gt;, then you must include the &lt;code&gt;--skip-etcd-endpoints-validation&lt;/code&gt; flag in the bash script below.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-3---verifying-ondat-installation&#34;&gt;Step 3 - Verifying Ondat Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-4---applying-a-licence-to-the-cluster&#34;&gt;Step 4 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Google Kubernetes Engine (GKE)</title>
      <link>/docs/install/google-kubernetes-engine-gke/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/google-kubernetes-engine-gke/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://cloud.google.com/kubernetes-engine&#34;&gt;Google Kubernetes Engine (GKE)&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° For users who are looking to deploy Ondat onto a &lt;a href=&#34;https://cloud.google.com/anthos&#34;&gt;Google Anthos&lt;/a&gt; cluster, a recommendation would be to review &lt;a href=&#34;https://docs.ondat.io/docs/install/anthos/&#34;&gt;Google Anthos installation guide&lt;/a&gt; for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utilities are installed on your local machine and are available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running GKE cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your GKE cluster uses  &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/node-images#ubuntu&#34;&gt;&lt;code&gt;ubuntu_containerd&lt;/code&gt;&lt;/a&gt; as the default node operating system. This node operating system image has the required kernel modules available for Ondat to run successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---conducting-preflight-checks&#34;&gt;Step 1 - Conducting Preflight Checks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following command to conduct preflight checks against the GKE cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2---installing-ondat&#34;&gt;Step 2 - Installing Ondat&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-3---verifying-ondat-installation&#34;&gt;Step 3 - Verifying Ondat Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-4---applying-a-licence-to-the-cluster&#34;&gt;Step 4 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Kubernetes</title>
      <link>/docs/install/kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/kubernetes/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://kubernetes.io/docs/setup/&#34;&gt;Kubernetes&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;. Ondat requires an &lt;code&gt;etcd&lt;/code&gt; cluster to successfully run, which can be deployed through two different methods listed below;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Embedded &lt;code&gt;etcd&lt;/code&gt; Deployment&lt;/strong&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster operator into your Kubernetes cluster&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;External &lt;code&gt;etcd&lt;/code&gt; Deployment&lt;/strong&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster in dedicated virtual machines&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° For users who are looking to deploy Ondat onto a managed/specific Kubernetes distribution such AKS, EKS, GKE, RKE or DOKS, a recommendation would be to review the &lt;a href=&#34;https://docs.ondat.io/docs/install/&#34;&gt;Install&lt;/a&gt; section and choose the appropriate installation guide for your Kubernetes distribution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° This guide outlines an &lt;em&gt;imperative&lt;/em&gt; installation using our &lt;code&gt;kubectl&lt;/code&gt; plugin. Ondat can also be &lt;a href=&#34;/docs/install/declarative-install/&#34;&gt;installed declaratively&lt;/a&gt; using either Helm or the aforementioned plugin.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utilities are installed on your local machine and are available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running Kubernetes cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your Kubernetes cluster uses a Linux distribution that is officially supported by Ondat as your node operating system and has the required LinuxIO related kernel modules are available for Ondat to run successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;option-a---using-an-embedded-etcd-deployment&#34;&gt;Option A - Using An Embedded &lt;code&gt;etcd&lt;/code&gt; Deployment&lt;/h3&gt;
&lt;h4 id=&#34;step-1---install-local-path-provisioner&#34;&gt;Step 1 - Install Local Path Provisioner&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the Local Path Provisioner was successfully deployed and ensure that that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;step-2---conducting-preflight-checks&#34;&gt;Step 2 - Conducting Preflight Checks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to conduct preflight checks against the Kubernetes cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-3---installing-ondat&#34;&gt;Step 3 - Installing Ondat&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-storage-class&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;option-b---using-an-external-etcd-deployment&#34;&gt;Option B - Using An External &lt;code&gt;etcd&lt;/code&gt; Deployment&lt;/h3&gt;
&lt;h4 id=&#34;step-1---setup-an-etcd-cluster&#34;&gt;Step 1 - Setup An &lt;code&gt;etcd&lt;/code&gt; Cluster&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that you have an &lt;code&gt;etcd&lt;/code&gt; cluster deployed first before installing Ondat. For instructions on how to set up an external &lt;code&gt;etcd&lt;/code&gt; cluster, review the &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/etcd/#production---etcd-on-external-virtual-machines&#34;&gt;&lt;code&gt;etcd&lt;/code&gt; documentation&lt;/a&gt; page.&lt;/li&gt;
&lt;li&gt;Once you have an &lt;code&gt;etcd&lt;/code&gt; cluster up and running, ensure that you note down the list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values that will be used when configuring Ondat in &lt;strong&gt;Step 3&lt;/strong&gt;.
&lt;ul&gt;
&lt;li&gt;For example, &lt;code&gt;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---conducting-preflight-checks-1&#34;&gt;Step 2 - Conducting Preflight Checks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to conduct preflight checks against the Kubernetes cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-3---installing-ondat-1&#34;&gt;Step 3 - Installing Ondat&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance. In addition, define and export a &lt;code&gt;ETCD_ENDPOINTS&lt;/code&gt; environment variable, where the value will be a list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values noted down earlier in &lt;strong&gt;Step 2&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-endpoints&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-4---verifying-ondat-installation-1&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;applying-a-licence-to-the-cluster&#34;&gt;Applying a Licence to the Cluster&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Overview</title>
      <link>/docs/introduction/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/introduction/overview/</guid>
      <description>
        
        
        &lt;p&gt;Over the past several months, we&amp;rsquo;ve been hard at work on Ondat V2, which
contains some significant enhancements over our v1 product. We&amp;rsquo;ve built V2
based on our observations of trends in the industry, as well as our own
experience.&lt;/p&gt;
&lt;p&gt;Many of our customers want to run big clusters - in the tens or hundreds of
nodes. In these sorts of big environments, the challenges multiply. Not only do
we need to scale well, but we also need to be more failure tolerant. Bigger
environments typically suffer higher failure rates (more nodes = greater chance
of something failing), but are also subject to all sorts of transient
conditions such as network partitions.&lt;/p&gt;
&lt;p&gt;The second trend we&amp;rsquo;ve seen become increasingly common is the desire to run
multiple clusters, and consume storage between them in some way - sometimes to
implement novel topologies such as a centralised storage cluster with
satellites consuming the storage, and sometimes to replicate data between those
clusters for HA or DR purposes.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve built V2 with these architectures and design patterns in mind. Not only
does it scale well, but it contains the foundations we need to implement a rich
set of multi-cluster functionality.&lt;/p&gt;
&lt;h2 id=&#34;-upgraded-control-plane&#34;&gt;üöÄ Upgraded Control Plane&lt;/h2&gt;
&lt;p&gt;At the heart of the V2 release is an upgraded control plane. We&amp;rsquo;ve changed a
lot here. Firstly, our usage of etcd is vastly improved. We&amp;rsquo;ve learnt a lot
about the subtleties of distributed consensus in the last year, particularly in
noisy or unpredictable environments. Not only is Ondat V2 much lighter on
your etcd cluster, but it&amp;rsquo;s a lot more tolerant of transient failure conditions
that are often found in cloud environments, or clusters under heavy load.&lt;/p&gt;
&lt;p&gt;We spent some time describing and testing our internal state machine using the
&lt;a href=&#34;https://en.wikipedia.org/wiki/TLA+&#34;&gt;TLA+&lt;/a&gt; formal verification language. This
allows us to have a much higher degree of confidence that our algorithms will
behave correctly, particularly under hard-to-test edge cases and failure
conditions.&lt;/p&gt;
&lt;p&gt;Additionally, we&amp;rsquo;ve changed the way volumes behave with respect to centralised
scheduling. Each volume group (consisting of a master and 0 or more replicas)
now behaves as a strongly consistent unit allowing it to take action
independent of the activities of the rest of the cluster. Other state can be
distributed around the cluster using eventually consistent mechanisms. This
approach inherently scales better and allows Ondat V2 to effectively manage
many more nodes and volumes than before.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve implemented TLS on all endpoints. Not only does this give you encrypted
traffic between nodes in your storage cluster, it also protects all endpoints
with strong, public key based authentication. Today&amp;rsquo;s IT environments can&amp;rsquo;t
rely on firewalls to keep bad actors out - they must implement security at all
layers within the stack - defense in depth. While we recognise that this brings
a welcome relief to many security conscious administrators, we also know that
managing certificate authorities (CAs) can be an unwelcome source of
complexity. For this reason, Ondat V2 implements an internal CA by default,
to manage this complexity for you. If you&amp;rsquo;d prefer to integrate your own CA, we
support that too - it&amp;rsquo;s up to you.&lt;/p&gt;
&lt;p&gt;Finally - our logging has undergone a complete transformation in this edition. We
know that systems engineers and operators don&amp;rsquo;t just value headline features,
but that observability and diagnostics are equally important. All logs are now
decorated with rich context to help you understand what is happening within
your cluster, and we&amp;rsquo;ll output in json by default, for easy ingestion into log
aggregators such as Elasticsearch.&lt;/p&gt;
&lt;h2 id=&#34;-upgraded-data-plane&#34;&gt;üöÄ Upgraded Data Plane&lt;/h2&gt;
&lt;p&gt;Not to be outdone, our data plane contains some significant improvements.&lt;/p&gt;
&lt;p&gt;Firstly, we&amp;rsquo;ve completely re-written our sync algorithm (see &lt;a href=&#34;/docs/concepts/volumes&#34;&gt;Delta Sync&lt;/a&gt;, used when seeding or catching up replicas
that have been offline or partitioned. Our new algorithm uses a &lt;a href=&#34;https://en.wikipedia.org/wiki/Hash_list&#34;&gt;Hash
List&lt;/a&gt; to sync only changed sections of
a volume (similar in some ways to what rsync does). Ondat maintains these
hashes during normal operation, meaning that when resyncing a failed replica,
for example after a node reboot, we can very quickly and efficiently catch this
replica up, rather than needing to promote and build a new one from scratch.
This improves resiliency within your cluster, and prevents using excessive
network bandwidth during failover conditions - at a time when it might be
needed the most.&lt;/p&gt;
&lt;p&gt;Secondly, a new threading model, with dynamic pool sizing, means that Ondat
is faster, a lot faster. In our tests we observed improvements across the
board, with improvements in throughput of up to 135% for some scenarios.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: OpenShift</title>
      <link>/docs/install/openshift/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/openshift/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto an &lt;a href=&#34;/docs/platforms/openshift&#34;&gt;Openshift&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the
&lt;a href=&#34;/docs/prerequisites/&#34;&gt;prerequisites for Ondat&lt;/a&gt; are
satisfied before proceeding. Including the deployment of an etcd cluster and
configuration of CRI-O PID limits.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è If you have installed OpenShift in AWS ensure that the requisite ports are
opened for the worker nodes&#39; security group.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° For OpenShift upgrades, refer to the
&lt;a href=&#34;/docs/platforms/openshift#openshift-upgrades&#34;&gt;OpenShift platform page&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat v2 supports OpenShift v4. For more information, see the &lt;a href=&#34;/docs/platforms/openshift&#34;&gt;OpenShift platform&lt;/a&gt; page.&lt;/p&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;option-a-via-operatorhub&#34;&gt;Option A: Via Operatorhub&lt;/h3&gt;
&lt;h4 id=&#34;step-1-operatorhub&#34;&gt;Step 1: Operatorhub&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Select the &lt;code&gt;OperatorHub&lt;/code&gt; from the Catalog sub menu and search for StorageOS&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Choose between using the RedHat Marketplace or the Community Operators
installation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select StorageOS and click &lt;strong&gt;Install&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select the relevant install options.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure the &lt;code&gt;Approval Strategy&lt;/code&gt; is set to &lt;strong&gt;Manual&lt;/strong&gt;. This option makes sure that the StorageOS
Operator doesn&amp;rsquo;t upgrade versions without explicit approval.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the approval procedure by clicking on the operator name.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On &lt;strong&gt;Subscription Details&lt;/strong&gt;, click the approval link.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On &lt;strong&gt;Review Manual Install&lt;/strong&gt; panel in the &lt;strong&gt;Components&lt;/strong&gt; tab, click &lt;strong&gt;Approve&lt;/strong&gt; to confirm the installation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Ondat Cluster Operator is installed along the required CRDs.&lt;/p&gt;
&lt;h4 id=&#34;step-2-authentication&#34;&gt;Step 2: Authentication&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a Secret in the &lt;code&gt;openshift-operators&lt;/code&gt; project and select the YAML option to create a secret containing the &lt;code&gt;username&lt;/code&gt; and an
&lt;code&gt;password&lt;/code&gt; key. The username and password defined in the secret will be
used to authenticate when using the Ondat CLI and GUI. Take note of
which project you created the secret in.&lt;/p&gt;
&lt;p&gt;Input the secret as YAML for simplicity.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;v1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Secret&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos-api&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;openshift-operators&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;kubernetes.io/storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# echo -n &amp;#39;&amp;lt;secret&amp;gt;&amp;#39; | base64&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;username&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;c3RvcmFnZW9z&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;password&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;c3RvcmFnZW9z&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go to the &lt;strong&gt;Operators&lt;/strong&gt;-&amp;gt;&lt;strong&gt;Installed Operators&lt;/strong&gt; and verify that the StorageOS Cluster Operator is installed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go to the &lt;strong&gt;StorageOS Cluster&lt;/strong&gt; section.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &lt;strong&gt;Create StorageOSCluster&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° An Ondat Cluster is defined using a Custom Resource Definition&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the Custom Resource&lt;/p&gt;
&lt;p&gt;The StorageOS cluster resource describes the Ondat cluster that will be
created. Parameters such as the &lt;code&gt;secretRefName&lt;/code&gt;, the &lt;code&gt;secretRefNamespace&lt;/code&gt; and
the &lt;code&gt;kvBackend.address&lt;/code&gt; are mandatory.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Additional &lt;code&gt;spec&lt;/code&gt; parameters are available on the &lt;a href=&#34;/docs/reference/cluster-operator/configuration&#34;&gt;Cluster Operator configuration&lt;/a&gt; page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;apiVersion: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos.com/v1&amp;#34;&lt;/span&gt;
kind: StorageOSCluster
metadata:
  name: storageos
  namespace: openshift-operators
spec:
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Ondat Pods are in kube-system by default&lt;/span&gt;
  secretRefName: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-api&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Reference the Secret created in the previous step&lt;/span&gt;
  secretRefNamespace: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;openshift-operators&amp;#34;&lt;/span&gt;  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Namespace of the Secret created in the previous step&lt;/span&gt;
  k8sDistro: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;openshift&amp;#34;&lt;/span&gt;
  kvBackend:
    address: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;storageos-etcd-client.etcd:2379&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Example address, change for your etcd endpoint&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# address: &amp;#39;10.42.15.23:2379,10.42.12.22:2379,10.42.13.16:2379&amp;#39; # You can set ETCD server ips&lt;/span&gt;
  resources:
    requests:
      memory: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;512Mi&amp;#34;&lt;/span&gt;
      cpu: &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# nodeSelectorTerms:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#   - matchExpressions:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#     - key: &amp;#34;node-role.kubernetes.io/worker&amp;#34; # Compute node label will vary according to your installation&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       operator: In&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       values:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       - &amp;#34;true&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the StorageOS Cluster resource status is &lt;strong&gt;Running&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It can take up to a minute to report the Ondat Pods ready.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the StorageOS Pods in the &lt;code&gt;kube-system&lt;/code&gt; project&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A Status of 3/3 in the &lt;strong&gt;Ready&lt;/strong&gt; column for the Daemonset Pods indicates that Ondat is
bootstrapped successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;option-b-via-red-hat-marketplace&#34;&gt;Option B: Via Red Hat Marketplace&lt;/h3&gt;
&lt;h4 id=&#34;step-1-red-hat-markerplace&#34;&gt;Step 1: Red Hat Markerplace&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The installation of Ondat using the Red Hat Marketplace requires the
Openshift cluster to be registered to the Marketplace Portal, including the
roll out of the &lt;code&gt;PullSecret&lt;/code&gt; in your cluster. Failure to do so will result in a
image pull authentication failure with the Red Hat registry.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Select the &lt;code&gt;OperatorHub&lt;/code&gt; from the Catalog sub menu and search for StorageOS.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Choose the RedHat Marketplace option.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select StorageOS and click &lt;strong&gt;Purchase&lt;/strong&gt;. Note that Openshift needs to be
registered with the Red Hat Marketplace portal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select the relevant install option.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Project Edition is suitable for production workloads, Developer Edition
for personal experimentation and evaluation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Specify the product configuration to fit your needs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to your software within Red Hat Marketplace and install the
StorageOS software as specified in the image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the Operator. Set the update approval strategy to &lt;strong&gt;Automatic&lt;/strong&gt; to
ensure that you always have the latest version of StorageOS installed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Ondat Cluster Operator is installed into your specified cluster.&lt;/p&gt;
&lt;h4 id=&#34;step-2-authentication-1&#34;&gt;Step 2: Authentication&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a Secret in the &lt;code&gt;openshift-operators&lt;/code&gt; project and select the YAML option to create a secret containing the &lt;code&gt;username&lt;/code&gt; and an
&lt;code&gt;password&lt;/code&gt; key. The username and password defined in the secret will be
used to authenticate when using the Ondat CLI and GUI. Take note of
which project you created the secret in.&lt;/p&gt;
&lt;p&gt;Input the secret as YAML for simplicity.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;v1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Secret&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos-api&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;openshift-operators&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;kubernetes.io/storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# echo -n &amp;#39;&amp;lt;secret&amp;gt;&amp;#39; | base64&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;username&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;c3RvcmFnZW9z&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;password&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;c3RvcmFnZW9z&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to StorageOS on your &lt;strong&gt;Installed Operators&lt;/strong&gt; tab.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Verify that the StorageOS Cluster Operator is installed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open to the &lt;strong&gt;StorageOS Cluster&lt;/strong&gt; tab and click &lt;strong&gt;Create StorageOSCluster&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° A StorageOSCluster is defined using a Custom Resource(CR) Definition.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the CR Definition:&lt;/p&gt;
&lt;p&gt;The Ondat cluster resource describes the Ondat cluster that will be
created. Parameters such as the &lt;code&gt;secretRefName&lt;/code&gt;, the &lt;code&gt;secretRefNamespace&lt;/code&gt; and
the &lt;code&gt;kvBackend.address&lt;/code&gt; are mandatory.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Additional &lt;code&gt;spec&lt;/code&gt; parameters are available on the &lt;a href=&#34;/docs/reference/cluster-operator/configuration&#34;&gt;Cluster Operator configuration&lt;/a&gt; page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;apiVersion: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos.com/v1&amp;#34;&lt;/span&gt;
kind: StorageOSCluster
metadata:
  name: storageos
  namespace: openshift-operators
spec:
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Ondat Pods are in kube-system by default&lt;/span&gt;
  secretRefName: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-api&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Reference the Secret created in the previous step&lt;/span&gt;
  secretRefNamespace: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;openshift-operators&amp;#34;&lt;/span&gt;  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Namespace of the Secret created in the previous step&lt;/span&gt;
  k8sDistro: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;openshift&amp;#34;&lt;/span&gt;
  kvBackend:
    address: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;storageos-etcd-client.etcd:2379&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Example address, change for your etcd endpoint&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# address: &amp;#39;10.42.15.23:2379,10.42.12.22:2379,10.42.13.16:2379&amp;#39; # You can set ETCD server ips&lt;/span&gt;
  resources:
    requests:
      memory: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;512Mi&amp;#34;&lt;/span&gt;
      cpu: &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# nodeSelectorTerms:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#   - matchExpressions:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#     - key: &amp;#34;node-role.kubernetes.io/worker&amp;#34; # Compute node label will vary according to your installation&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       operator: In&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       values:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       - &amp;#34;true&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the StorageOS Cluster status is &lt;strong&gt;Running&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° It can take up to a minute to report the Ondat Pods ready.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the StorageOS Pods in the &lt;code&gt;kube-system&lt;/code&gt; project.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° A Status of 3/3 in the &lt;strong&gt;Ready&lt;/strong&gt; column for the Daemonset Pods indicates that Ondat is
bootstrapped successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;license-cluster&#34;&gt;License cluster&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a license, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;
&lt;h2 id=&#34;first-ondat-volume&#34;&gt;First Ondat volume&lt;/h2&gt;
&lt;p&gt;If this is your first installation you may wish to follow the &lt;a href=&#34;/docs/operations/firstpvc&#34;&gt;Ondat volume guide&lt;/a&gt; for an example of how
to mount an Ondat volume in a Pod.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Rancher Kubernetes Engine (RKE)</title>
      <link>/docs/install/rancher/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/rancher/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://rancher.com/products/rke&#34;&gt;Rancher Kubernetes Engine (RKE)&lt;/a&gt; cluster. Ondat can be installed on a RKE cluster through two different methods;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Using &lt;a href=&#34;https://github.com/rancher/partner-charts/tree/main/charts/ondat-operator/ondat-operator&#34;&gt;Ondat&amp;rsquo;s Helm chart&lt;/a&gt; through &lt;a href=&#34;https://rancher.com/docs/rancher/v2.6/en/helm-charts/&#34;&gt;Rancher&amp;rsquo;s Apps &amp;amp; Marketplace&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utility is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running RKE cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your RKE cluster uses a Linux distribution that is officially supported by Rancher as your node operating system and has the required LinuxIO related kernel modules are available for Ondat to run successfully. A strong recommendation would be to review &lt;a href=&#34;https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/&#34;&gt;SUSE Rancher Support Matrix&lt;/a&gt; documentation to ensure that you are using a supported Linux distribution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;option-a---using-ondat-kubectl-plugin&#34;&gt;Option A - Using Ondat Kubectl Plugin&lt;/h3&gt;
&lt;h4 id=&#34;step-1---install-ondat-kubectl-plugin&#34;&gt;Step 1 - Install Ondat Kubectl Plugin&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that the Ondat kubectl plugin is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---install-local-path-provisioner&#34;&gt;Step 2 - Install Local Path Provisioner&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;By default, a newly provisioned RKE cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the Local Path Provisioner was successfully deployed and ensure that that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;step-3---conducting-preflight-checks&#34;&gt;Step 3 - Conducting Preflight Checks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to conduct preflight checks against the RKE cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-4---installing-ondat&#34;&gt;Step 4 - Installing Ondat&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-storage-class&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-5---verifying-ondat-installation&#34;&gt;Step 5 - Verifying Ondat Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;option-b---using-ranchers-apps--marketplace&#34;&gt;Option B - Using Rancher&amp;rsquo;s Apps &amp;amp; Marketplace&lt;/h3&gt;
&lt;h4 id=&#34;step-1---setup-an-etcd-cluster&#34;&gt;Step 1 - Setup An &lt;code&gt;etcd&lt;/code&gt; Cluster&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ensure that you have an &lt;code&gt;etcd&lt;/code&gt; cluster deployed first before installing Ondat through the Helm chart located on Apps &amp;amp; Marketplace. There are two different methods listed below with instructions on how to deploy an &lt;code&gt;etcd&lt;/code&gt; cluster;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/etcd/#testing---installing-etcd-into-your-kubernetes-cluster&#34;&gt;Embedded Deployment&lt;/a&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster operator into your RKE cluster, recommended for &lt;strong&gt;non production&lt;/strong&gt; environments.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/etcd/#production---etcd-on-external-virtual-machines&#34;&gt;External Deployment&lt;/a&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster in dedicated virtual machines, recommended for &lt;strong&gt;production&lt;/strong&gt; environments.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you have an &lt;code&gt;etcd&lt;/code&gt; cluster up and running, ensure that you note down the list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values that will be used when configuring Ondat in &lt;strong&gt;Step 3&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For example, &lt;code&gt;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---locate-ondat-operator-helm-chart&#34;&gt;Step 2 - Locate Ondat Operator Helm Chart&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;In the Rancher UI, under the RKE cluster where Ondat will be deployed - select the &lt;strong&gt;Menu&lt;/strong&gt; button in the top-left corner of the page and then select &lt;strong&gt;Apps &amp;amp; Marketplace&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Under &lt;strong&gt;Apps &amp;amp; Marketplace&lt;/strong&gt;, a &lt;strong&gt;Charts&lt;/strong&gt; page will be displayed where you can locate the &lt;a href=&#34;https://github.com/rancher/partner-charts/tree/main/charts/ondat-operator/ondat-operator&#34;&gt;Ondat Operator Helm chart&lt;/a&gt; by searching for &amp;ldquo;&lt;strong&gt;Ondat&lt;/strong&gt;&amp;rdquo; in the search filter box.&lt;/li&gt;
&lt;li&gt;Once you have located the Ondat Operator Helm chart, select the chart. This will direct you to a page showing you more information about the Ondat Operator and how to install it.&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;step-3---customising--installing-the-helm-chart&#34;&gt;Step 3 - Customising &amp;amp; Installing The Helm Chart&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Upon selecting the &lt;strong&gt;Install&lt;/strong&gt; button in the previous step, you will be directed to a page to configure the &lt;strong&gt;Application Metadata&lt;/strong&gt;. Define the namespace and application name where Ondat will be deployed and click &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Parameter&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Namespace&lt;/td&gt;
&lt;td&gt;&lt;code&gt;storageos&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Namespace name for the deployment.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Name&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ondat-operator&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Application name for the deployment.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The next page will allow you to configure the Ondat Operator through Helm chart values. Under &lt;strong&gt;Edit Options&lt;/strong&gt;, you are provided with 3 configurable sections called;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Questions&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Container Images&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;StorageOS Cluster&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select the &lt;strong&gt;StorageOS Cluster&lt;/strong&gt; section. This will show you a form with configurable parameters that have predefined values for an Ondat deployment. Below are following parameters that will need to be populated before beginning the installation;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Parameter&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Password&lt;/td&gt;
&lt;td&gt;&lt;code&gt;$STORAGEOS_PASSWORD&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Password of the StorageOS administrator account. Must be at least 8 characters long, for example &amp;gt; &lt;code&gt;storageos&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;External &lt;code&gt;etcd&lt;/code&gt; address(es)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;$ETCD_ENDPOINTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;List of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values. Prefer multiple direct endpoints over a single load-balanced endpoint, for example &amp;gt; &lt;code&gt;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° &lt;strong&gt;Advanced Users&lt;/strong&gt; - For users who are looking to make further customisations to the Helm chart through additional configurable parameters or import your own &lt;code&gt;StorageOSCluster&lt;/code&gt; custom resource manifest, review the Ondat Operator &lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/ondat-operator/README.md&#34;&gt;README.md&lt;/a&gt; document, &lt;a href=&#34;/docs/reference/cluster-operator/configuration&#34;&gt;Cluster Operator Configuration&lt;/a&gt; and  &lt;a href=&#34;/docs/reference/cluster-operator/examples&#34;&gt;Cluster Operator Examples&lt;/a&gt; reference pages for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the parameters have been successfully populated, select &lt;strong&gt;Install&lt;/strong&gt; to deploy Ondat.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# only if the etcd cluster was deployed inside the RKE cluster.&lt;/span&gt;
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;applying-a-licence-to-the-cluster&#34;&gt;Applying a Licence to the Cluster&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Rancher Kubernetes Engine 2 (RKE2)</title>
      <link>/docs/install/rancher-gov/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/rancher-gov/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://docs.rke2.io/&#34;&gt;Rancher Kubernetes Engine 2 (RKE2)&lt;/a&gt;, also known as RKE Government, cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utilities are installed on your local machine and are available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running RKE2 cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your RKE2 cluster uses a Linux distribution that is officially supported by RKE2 as your node operating system and the required LinuxIO related kernel modules are available for Ondat to run successfully. A strong recommendation would be to review &lt;a href=&#34;https://docs.rke2.io/install/requirements/#operating-systems&#34;&gt;RKE2 Operating System Requirements&lt;/a&gt; documentation to ensure that you are using a supported Linux distribution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---install-local-path-provisioner&#34;&gt;Step 1 - Install Local Path Provisioner&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;By default, a newly provisioned RKE2 cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;step-2---conducting-preflight-checks&#34;&gt;Step 2 - Conducting Preflight Checks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following command to conduct preflight checks against the RKE2 cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-3---installing-ondat&#34;&gt;Step 3 - Installing Ondat&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-storage-class&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-5---applying-a-licence-to-the-cluster&#34;&gt;Step 5 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Configuration</title>
      <link>/docs/reference/cluster-operator/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cluster-operator/configuration/</guid>
      <description>
        
        
        &lt;h2 id=&#34;storageoscluster-resource-configuration&#34;&gt;StorageOSCluster Resource Configuration&lt;/h2&gt;
&lt;p&gt;The following table lists the configurable spec parameters of the StorageOSCluster custom resource and their default values.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Parameter&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Description&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Default&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.deploymentStrategy&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI helper deployment strategy (&lt;code&gt;statefulset&lt;/code&gt; or &lt;code&gt;deployment&lt;/code&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;statefulset&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.enable&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable CSI setup&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.enableControllerPublishCreds&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable CSI controller publish credentials&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.enableNodePublishCreds&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable CSI node publish credentials&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.enableProvisionCreds&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable CSI provision credentials&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;debug&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable debug mode for all the cluster nodes&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;disableTelemetry&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Disable telemetry reports&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.apiManagerContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ondat API Manager container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/api-manager:v1.0.0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.csiClusterDriverRegistrarContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI Cluster Driver Registrar Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;quay.io/k8scsi/csi-cluster-driver-registrar:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.csiExternalAttacherContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI External Attacher Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;quay.io/k8scsi/csi-attacher:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.csiExternalProvisionerContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI External Provisioner Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/csi-provisioner:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;√¨mages.csiLivenessProbeContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI Liveness Probe Container Image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;quay.io/k8scsi/livenessprobe:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.csiNodeDriverRegistrarContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI Node Driver Registrar Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;quay.io/k8scsi/csi-node-driver-registrar:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.hyperkubeContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Deprecated field - HyperKube Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Default dependent on Scheduler version&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.initContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ondat init container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/init:2.1.0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.kubeSchedulerContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Kube scheduler container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Default dependent on Scheduler version&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.nfsContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ondat nfs container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/nfs:1.0.0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.nodeContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ondat node container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/node:v2.7.0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;k8sDistro&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The name of the Kubernetes distribution is use, e.g. &lt;code&gt;rancher&lt;/code&gt; or &lt;code&gt;eks&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;kvBackend.address&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Comma-separated list of addresses of external key-value store. (&lt;code&gt;1.2.3.4:2379,2.3.4.5:2379&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;kvBackend.backend&lt;/code&gt; (v2 deprecated)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Name of the key-value store to use. Set to &lt;code&gt;etcd&lt;/code&gt; for external key-value store.&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;embedded&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;nodeSelectorTerms&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Set node selector for storageos pod placement&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;resources&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Set resource requirements for the containers&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;secretRefName&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Reference name of storageos secret within the namespace&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.annotations&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Annotations of the Service used by the cluster&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.externalPort&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;External port of the Service used by the cluster&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;5705&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.internalPort&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Internal port of the Service used by the cluster&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;5705&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.name&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Name of the Service used by the cluster&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.type&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Type of the Service used by the cluster&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;ClusterIP&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;sharedDir&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Path to be shared with kubelet container when deployed as a pod&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;/var/lib/kubelet/plugins/kubernetes.io~storageos&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageClassName&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The name of the default StorageClass created for Ondat volumes&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;tlsEtcdSecretRefName&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Secret containing etcd client certificates&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;tolerations&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Set pod tolerations for storageos pod placement&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

      </description>
    </item>
    
    <item>
      <title>Docs:  Dashboard Page Reference</title>
      <link>/docs/ondat-portal/dashboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/ondat-portal/dashboard/</guid>
      <description>
        
        
        &lt;p&gt;The &lt;strong&gt;Dashboard&lt;/strong&gt; gives you an unified and summarised view of the application you have deployed. If there are any persistent volumes in error this will be indicated on the dashboard as a red side line next to the application name and will also give you the number of affected volumes.&lt;/p&gt;
&lt;p&gt;Your deployed application can be one of the following types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Replica&lt;/strong&gt; - ensures that one or more pods are running at any given time, according to configuration. Usually, &lt;code&gt;ReplicaSets&lt;/code&gt; are managed by Deployments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;StatefulSet&lt;/strong&gt; - represents a stateful application that both manages one or more pods, ensures that they are running at any given time and provides certain guarantees about the order and uniqueness of the pods.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deployment&lt;/strong&gt; - provides a desired state for one or more sets of pods without guaranteeing order or uniqueness.&lt;/p&gt;
&lt;p&gt;To view more details about each application, go to the &lt;strong&gt;Applications&lt;/strong&gt; tab.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs:  Applications Page Reference</title>
      <link>/docs/ondat-portal/applications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/ondat-portal/applications/</guid>
      <description>
        
        
        &lt;p&gt;The &lt;strong&gt;Applications&lt;/strong&gt; tab displays all of your applications. For a detailed explanation of the view, refer to the table below:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Column&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Description&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Possible Values&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;App Name&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The name of the app&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;String&lt;/code&gt; (can contain special characters)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Kind&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the kind of application.&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Replica&lt;/strong&gt; &lt;br /&gt;  &lt;strong&gt;StatefulSet&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Deployment&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Pods&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The number of pods for your application&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;Integer&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Pod Status&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the number of pods that are ready/syncing or with unknown/failed status&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Ready&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Syncing&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Unknown&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Failed&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;PV Amount&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the amount of PVs taken up by the app&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;Integer&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;PVs Size&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the size of all Persistent volumes as a percentage of all available storage on all pods&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Available GB on the pods&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;PVs Status&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the number of PVs that are ready/syncing or with unknown/failed status&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Ready&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Syncing&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Unknown&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Failed&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;detailed-view-of-the-application&#34;&gt;Detailed View of the Application&lt;/h2&gt;
&lt;p&gt;To view more details of your application, click &lt;strong&gt;View Details&lt;/strong&gt; and you will be given an overview of the status of the app.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cluster Operator examples</title>
      <link>/docs/reference/cluster-operator/examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cluster-operator/examples/</guid>
      <description>
        
        
        &lt;p&gt;Before deploying an Ondat cluster, create a Secret to define the Ondat
API Username and Password in base64 encoding.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;END
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: Secret
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  name: &amp;#34;storageos-api&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  namespace: &amp;#34;default&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  labels:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    app: &amp;#34;storageos&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;type: &amp;#34;kubernetes.io/storageos&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;data:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  username: c3RvcmFnZW9z
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  password: c3RvcmFnZW9z
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;END&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This example contains a default password, for production installations, use a
unique, strong password.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure that the encoding of the credentials doesn&amp;rsquo;t have special characters such as &amp;lsquo;\n&amp;rsquo;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;You can define a base64 value by &lt;code&gt;echo -n &amp;quot;mystring&amp;quot; | base64&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Create a &lt;code&gt;cluster-config.yaml&lt;/code&gt; according to your needs from the examples below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create -f cluster-config.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that Ondat will be deployed in &lt;code&gt;spec.namespace&lt;/code&gt; (storageos by
default), irrespective of what NameSpace the CR is defined in.&lt;/p&gt;
&lt;p&gt;¬† &lt;!-- this is a blank line --&gt;&lt;/p&gt;
&lt;h1 id=&#34;examples&#34;&gt;Examples&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;You can checkout all the parameters configurable in the
&lt;a href=&#34;/docs/reference/cluster-operator/configuration&#34;&gt;configuration&lt;/a&gt;
page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;All examples must reference the &lt;code&gt;storageos-api&lt;/code&gt; Secret.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;secretRefName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-api&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Reference to the Secret created in the previous step&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;installing-with-an-external-etcd&#34;&gt;Installing with an external etcd&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kvBackend&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;address&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;10.43.93.95:2379&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# IP of the SVC that exposes ETCD&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# address: &amp;#39;10.42.15.23:2379,10.42.12.22:2379,10.42.13.16:2379&amp;#39; # You can specify individual IPs of the etcd servers&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If using Etcd with mTLS, it is required to create the secret with the TLS
material on the same namespace as the StorageOSCluster resource. Reference it&amp;rsquo;s
name with the following parameter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# External mTLS secured etcd cluster specific properties&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;tlsEtcdSecretRefName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-etcd-secret&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Secret containing etcd client certificates, within the StorageOSCluster CR namespace&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Follow the &lt;a href=&#34;/docs/operations/etcd/storageos-secret-info&#34;&gt;etcd operations&lt;/a&gt; page to setup the
secret with the Etcd client certificate, client key and CA.&lt;/p&gt;
&lt;h2 id=&#34;installing-to-a-subset-of-nodes&#34;&gt;Installing to a subset of nodes&lt;/h2&gt;
&lt;p&gt;In this case we select nodes that are workers. To make sure that Ondat doesn&amp;rsquo;t start in Master nodes.&lt;/p&gt;
&lt;p&gt;You can see the labels in the nodes by &lt;code&gt;kubectl get node --show-labels&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeSelectorTerms&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;matchExpressions&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;key&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;node-role.kubernetes.io/worker&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;operator&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;In&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;values&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# OpenShift uses &amp;#34;node-role.kubernetes.io/compute=true&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Rancher uses &amp;#34;node-role.kubernetes.io/worker=true&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Kops uses &amp;#34;node-role.kubernetes.io/node=&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Different provisioners and Kubernetes distributions use node labels
differently to specify master vs workers. Node Taints are not enough to
make sure Ondat doesn&amp;rsquo;t start in a node. The &lt;code&gt;JOIN&lt;/code&gt; variable is defined
by the operator by selecting all the nodes that match the &lt;code&gt;nodeSelectorTerms&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;specifying-a-shared-directory-for-use-with-kubelet-as-a-container&#34;&gt;Specifying a shared directory for use with kubelet as a container&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sharedDir&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;/var/lib/kubelet/plugins/kubernetes.io~storageos&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;defining-pod-resource-requests-and-reservations&#34;&gt;Defining pod resource requests and reservations&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;512Mi&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#   cpu: &amp;#34;1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# limits:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#   memory: &amp;#34;4Gi&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We have the following limits for all of our components:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;         &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;api-manager&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;         &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;           &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;250m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;200Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;           &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;10m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;provisioner&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;securityContext&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;privileged&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;5m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;30Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;attacher&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;50m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;1m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;30Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;resizer&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;50m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;1m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;30Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos-scheduler&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;           &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;200Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;10m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;50Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;specifying-custom-tolerations&#34;&gt;Specifying custom Tolerations&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;tolerations&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;key&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;key1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;operator&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Equal&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;value&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;value1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;effect&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;EffectToTolerate&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;key&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;key2&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;operator&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Exists&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Custom tolerations specified in the StorageOSCluster definition are added to
all Ondat components; the Ondat daemonset, CSI helper and scheduler.&lt;/p&gt;
&lt;p&gt;In the above example a toleration &lt;code&gt;key1=value1:EffectToTolerate&lt;/code&gt; would be
tolerated and &lt;code&gt;key2&lt;/code&gt; would be tolerated regardless of the value and effect. For
more information about tolerations see the &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/&#34;&gt;Kubernetes
documentation&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cluster Operator upgrade</title>
      <link>/docs/reference/cluster-operator/upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cluster-operator/upgrade/</guid>
      <description>
        
        
        &lt;h2 id=&#34;upgrade-ondat-operator-from-yaml-manifest&#34;&gt;Upgrade Ondat operator from yaml manifest&lt;/h2&gt;
&lt;p&gt;Upgrade the Ondat operator using the following yaml manifest.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl apply -f https://github.com/storageos/cluster-operator/releases/download/v2.4.4/storageos-operator.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;üí° When you run the above command Ondat Operator resources will be updated.
Since, the Update Strategy of the Ondat Operator Deployment is set to
rolling update, a new Ondat Operator Pod will be created. Only when
the new Pod enters the Running Phase will the old Pod be deleted.
Your Ondat Cluster will not be affected while the Ondat
Operator is upgrading.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;upgrade-ondat-operator-using-helm&#34;&gt;Upgrade Ondat Operator using Helm&lt;/h2&gt;
&lt;p&gt;If you have installed the Ondat Operator using the &lt;a href=&#34;https://github.com/storageos/charts/tree/master/stable/storageos-operator#installing-the-chart&#34;&gt;Helm Chart&lt;/a&gt;, then you can upgrade the operator using the following commands.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ helm list

NAME            REVISION        STATUS          CHART                           APP VERSION     NAMESPACE   
storageos-v1   4               DEPLOYED        storageos-operator-0.2.11       1.3.0           storageos-operator
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;helm repo update
helm upgrade $NAME storageos/storageos-operator
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;üí° When you run the above command Ondat Operator resources will be updated.
Since, the Update Strategy of the Ondat Operator Deployment is set to
rolling update, a new Ondat Operator Pod will be created. Only when
the new Pod enters the Running Phase will the old Pod be deleted.
Your Ondat Cluster will not be affected while the Ondat
Operator is upgrading.&lt;/p&gt;
&lt;/blockquote&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Supported Platforms and Orchestrators</title>
      <link>/docs/introduction/platforms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/introduction/platforms/</guid>
      <description>
        
        
        &lt;h2 id=&#34;os&#34;&gt;OS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linux X86_64&lt;/li&gt;
&lt;li&gt;Kernels satisfying our module &lt;a href=&#34;/docs/prerequisites/systemconfiguration&#34;&gt;prerequisites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.x kernels have a limitation of 256 active volumes per node&lt;/li&gt;
&lt;li&gt;4.x kernels have a limitation of 4096 active volumes per node&lt;/li&gt;
&lt;li&gt;We are distribution agnostic as long as our prerequisites are met&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;orchestrators&#34;&gt;Orchestrators&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 1.19 to 1.23&lt;/li&gt;
&lt;li&gt;OpenShift 4.0+&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Air-Gapped Install</title>
      <link>/docs/install/airgap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/airgap/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto clusters that don&amp;rsquo;t have direct access to the internet - i.e., &lt;a href=&#34;https://en.wikipedia.org/wiki/Air_gap_%28networking%29&#34;&gt;air-gapped&lt;/a&gt; environments. Air-gapped environments require cluster administrators to explicitly ensure that Ondat components are locally available before the installation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° This guide is recommended for &lt;strong&gt;advanced users&lt;/strong&gt; who have experience and permissions to be able to manage air-gapped deployments in their environment. The full procedure for this deployment method is estimated to take ~60 minutes to complete.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Below is a quick summary of the procedure that will be covered in this guide:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install the Ondat kubectl plugin.&lt;/li&gt;
&lt;li&gt;Generate the Ondat deployment manifests for your use case.&lt;/li&gt;
&lt;li&gt;Push Ondat container images to your private registry.&lt;/li&gt;
&lt;li&gt;Modify the Ondat deployment manifests.&lt;/li&gt;
&lt;li&gt;Install Ondat onto your air-gapped cluster.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat so your set up would be successful. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utility is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running Kubernetes cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your Kubernetes cluster uses a Linux distribution that is officially supported by Ondat as your node operating system.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure that the node operating system have the required LinuxIO related kernel modules are available for Ondat to run successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---install-ondat-kubectl-plugin&#34;&gt;Step 1 - Install Ondat Kubectl Plugin&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that the Ondat kubectl plugin is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-2---conducting-preflight-checks&#34;&gt;Step 2 - Conducting Preflight Checks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to conduct preflight checks against the Kubernetes cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-3---generate-ondat-deployment-manifests&#34;&gt;Step 3 - Generate Ondat Deployment Manifests&lt;/h3&gt;
&lt;h4 id=&#34;option-a---using-an-embedded-etcd-deployment&#34;&gt;Option A - Using An Embedded &lt;code&gt;etcd&lt;/code&gt; Deployment&lt;/h4&gt;
&lt;h5 id=&#34;install-local-path-provisioner&#34;&gt;Install Local Path Provisioner&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Different Kubernetes distributions may include a CSI driver as part of the deployment. Cluster administrators can leverage the CSI driver provided by their distribution if they don‚Äôt want to use a Local Path Provisioner. If so, ensure that the  &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt;  environment variable points to the correct value for your Kubernetes distribution‚Äôs default StorageClass name.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Download the Local Path Provisioner.&lt;/span&gt;
wget https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Get the list of images and push them to your private registry.&lt;/span&gt;
grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;image:&amp;#34;&lt;/span&gt; local-path-storage.yaml

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Modify the manifest and add the private registry URL to pull the images.&lt;/span&gt;
vi local-path-storage.yaml

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Deploy the Local Path Provisioner.&lt;/span&gt;
kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non-production&lt;/strong&gt; clusters, as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to its state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;generate-manifests&#34;&gt;Generate Manifests&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance. In addition, define and export a &lt;code&gt;KUBERNETES_VERSION&lt;/code&gt; environment variable, where the value will be the exact version of your Kubernetes cluster where Ondat is going to be deployed - for example, &lt;code&gt;v1.23.5&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v1.23.5&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with the &lt;code&gt;--dry-run&lt;/code&gt; flag to generate the Ondat deployment Kubernetes manifests in a directory, called &lt;code&gt;storageos-dry-run&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --dry-run &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-storage-class&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --k8s-version&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To review the list of manifests generated in the newly created &lt;code&gt;storageos-dry-run&lt;/code&gt; directory, run the following commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-dry-run/
ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;option-b---using-an-external-etcd-deployment&#34;&gt;Option B - Using An External &lt;code&gt;etcd&lt;/code&gt; Deployment&lt;/h4&gt;
&lt;h5 id=&#34;setup-an--etcd--cluster&#34;&gt;Setup An  &lt;code&gt;etcd&lt;/code&gt;  Cluster&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that you have an  &lt;code&gt;etcd&lt;/code&gt;  cluster deployed first before installing Ondat. For instructions on how to set up an external  &lt;code&gt;etcd&lt;/code&gt;  cluster, review the  &lt;a href=&#34;/docs/prerequisites/etcd/#production---etcd-on-external-virtual-machines&#34;&gt;&lt;code&gt;etcd&lt;/code&gt;  documentation&lt;/a&gt;  page.&lt;/li&gt;
&lt;li&gt;Once you have an  &lt;code&gt;etcd&lt;/code&gt;  cluster up and running, ensure that you note down the list of  &lt;code&gt;etcd&lt;/code&gt;  endpoints as comma-separated values that will be used when configuring Ondat.
&lt;ul&gt;
&lt;li&gt;For example,  &lt;code&gt;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;generate-manifests-1&#34;&gt;Generate Manifests&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance. In addition, define and export a &lt;code&gt;KUBERNETES_VERSION&lt;/code&gt; environment variable, where the value will be the exact version of your Kubernetes cluster where Ondat is going to be deployed - for example, &lt;code&gt;v1.23.5&lt;/code&gt;. Lastly, define and export a &lt;code&gt;ETCD_ENDPOINTS&lt;/code&gt; environment variable, where the value will be a list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v1.23.5&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with the &lt;code&gt;--dry-run&lt;/code&gt; flag to generate the Ondat deployment Kubernetes manifests in a directory, called &lt;code&gt;storageos-dry-run&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --dry-run &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --skip-etcd-endpoints-validation &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-endpoints&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --k8s-version&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To review the list of manifests generated in the newly created &lt;code&gt;storageos-dry-run&lt;/code&gt; directory, run the following commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-dry-run/
ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-4---push-ondat-images-to-private-registry&#34;&gt;Step 4 - Push Ondat Images To Private Registry&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Get the list of all the container images required for Ondat to be deployed successfully and push them to your private registry which will be accessible through your air-gapped environment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;grep --extended-regexp &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;RELATED|image:&amp;#34;&lt;/span&gt; *.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You will also need to pull the kubernetes scheduler image for your release and push that to your private registry.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v1.23.5&amp;#34;&lt;/span&gt;
docker pull k8s.gcr.io/kube-scheduler:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-5---modify-deployment-manifests&#34;&gt;Step 5 - Modify Deployment Manifests&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;etcd-operator&lt;/code&gt;&lt;/strong&gt; - Modify the &lt;code&gt;2-etcd-operator.yaml&lt;/code&gt; manifest and apply the following changes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Locate the &lt;code&gt;storageos-etcd-controller-manager&lt;/code&gt;  &lt;code&gt;Deployment&lt;/code&gt; YAML, navigate to &lt;code&gt;manager&lt;/code&gt; container and locate the &lt;code&gt;args&lt;/code&gt; section.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In this section, add a flag called &lt;code&gt;--etcd-repository=&lt;/code&gt; where the value will be your &lt;code&gt;$PRIVATE_REGISTRY_URL/quay.io/coreos/etcd&lt;/code&gt;. For example;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Before modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;containers&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;args&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;enable-leader-election&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;proxy-url=storageos-proxy.storageos-etcd.svc&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# After modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;containers&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;args&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;enable-leader-election&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;proxy-url=storageos-proxy.storageos-etcd.svc&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;etcd-repository=$PRIVATE_REGISTRY_URL/quay.io/coreos/etcd  &lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;etcd-cluster&lt;/code&gt;&lt;/strong&gt; - Modify the &lt;code&gt;3-etcd-cluster.yaml&lt;/code&gt; manifest and apply the following changes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Locate the &lt;code&gt;storageos-etcd&lt;/code&gt;  &lt;code&gt;CustomResource&lt;/code&gt; YAML, navigate to the &lt;code&gt;storage&lt;/code&gt; section and set the &lt;code&gt;storage&lt;/code&gt; size value from &lt;code&gt;1Gi&lt;/code&gt; to &lt;code&gt;256Gi&lt;/code&gt;. For example;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Before modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeClaimTemplate&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;1Gi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# After modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeClaimTemplate&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;256Gi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;storageos-operator&lt;/code&gt;&lt;/strong&gt; - Modify the &lt;code&gt;0-storageos-operator.yaml&lt;/code&gt; manifest and apply the following changes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Locate the &lt;code&gt;storageos-operator&lt;/code&gt; &lt;code&gt;Deployment&lt;/code&gt; YAML, navigate to the &lt;code&gt;manager&lt;/code&gt; and &lt;code&gt;kube-rbac-proxy&lt;/code&gt; containers.  Proceed to change the existing image registry URLs to point to your private registry URLs where the Ondat images reside. For example;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Before modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manager&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/operator:v2.7.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kube-rbac-proxy&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/brancz/kube-rbac-proxy:v0.10.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# After modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manager&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/operator:v2.7.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kube-rbac-proxy&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/brancz/kube-rbac-proxy:v0.10.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Locate the &lt;code&gt;storageos-related-images&lt;/code&gt; &lt;code&gt;ConfigMap&lt;/code&gt; YAML, navigate to the environment variables that are prefixed with &lt;code&gt;RELATED_IMAGE_&lt;/code&gt;. Proceed to change the existing image registry URLs to point to your private registry URLs where the Ondat images reside. For example;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Before modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ConfigMap&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_API_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/api-manager:v1.2.9&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_ATTACHER_V3&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/k8scsi/csi-attacher:v3.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_PROVISIONER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/csi-provisioner:v2.1.1-patched&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_RESIZER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/k8scsi/csi-resizer:v1.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_LIVENESS_PROBE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/k8scsi/livenessprobe:v2.2.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_NODE_DRIVER_REGISTRAR&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/k8scsi/csi-node-driver-registrar:v2.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_NODE_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/node-manager:v0.0.6&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_PORTAL_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/portal-manager:v1.0.2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_STORAGEOS_INIT&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/init:v2.1.2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_STORAGEOS_NODE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/node:v2.7.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_NODE_GUARD&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/node-guard:v0.0.4&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# After modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ConfigMap&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_API_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/api-manager:v1.2.9&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_ATTACHER_V3&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/k8scsi/csi-attacher:v3.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_PROVISIONER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/csi-provisioner:v2.1.1-patched&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_RESIZER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/k8scsi/csi-resizer:v1.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_LIVENESS_PROBE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/livenessprobe:v2.2.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_NODE_DRIVER_REGISTRAR&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/k8scsi/csi-node-driver-registrar:v2.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_NODE_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/node-manager:v0.0.6&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_PORTAL_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/portal-manager:v1.0.2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_STORAGEOS_INIT&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/init:v2.1.2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_STORAGEOS_NODE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/node:v2.7.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_NODE_GUARD&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/node-guard:v0.0.4&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;storageos-cluster&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° &lt;strong&gt;Optional&lt;/strong&gt; - For users who are looking to make further customisations to their &lt;code&gt;StorageOSCluster&lt;/code&gt; custom resource in the &lt;code&gt;1-storageos-cluster.yaml&lt;/code&gt; manifest, review the &lt;a href=&#34;https://docs.ondat.io/docs/reference/cluster-operator/configuration&#34;&gt;Cluster Operator Configuration&lt;/a&gt; and &lt;a href=&#34;https://docs.ondat.io/docs/reference/cluster-operator/examples&#34;&gt;Cluster Operator Examples&lt;/a&gt; reference pages for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;step-6---installing-ondat&#34;&gt;Step 6 - Installing Ondat&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl&lt;/code&gt; command to install Ondat with the generated manifests in the &lt;code&gt;storageos-dry-run&lt;/code&gt; directory.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Apply the Operators and CustomResourceDefinitions (CRDs) first.&lt;/span&gt;
find . -name &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*-operator.yaml&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; xargs -I&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt; kubectl apply --filename &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Apply the Custom Resources next.&lt;/span&gt;
find . -name &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*-cluster.yaml&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; xargs -I&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt; kubectl apply --filename &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The installation process may take a few minutes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-7---verifying-ondat-installation&#34;&gt;Step 7 - Verifying Ondat Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# only if the etcd cluster was deployed inside the Kubernetes cluster.&lt;/span&gt;
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-8---applying-a-licence-to-the-cluster&#34;&gt;Step 8 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Declarative Install</title>
      <link>/docs/install/declarative-install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/declarative-install/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a Kubernetes cluster declaratively. Ondat can be installed declaratively onto a Kubernetes cluster through two different methods;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Using the &lt;a href=&#34;https://github.com/ondat/charts/tree/main/charts/ondat&#34;&gt;Ondat Helm chart&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure the following CLI utility is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure you have a running Kubernetes cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Make sure your Kubernetes cluster uses a Linux distribution that is officially supported by Ondat as your node operating system and has the required LinuxIO related kernel modules are available for Ondat to run successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;option-a---using-ondat-kubectl-plugin&#34;&gt;Option A - Using Ondat Kubectl Plugin&lt;/h3&gt;
&lt;h4 id=&#34;step-1---install-ondat-kubectl-plugin&#34;&gt;Step 1 - Install Ondat Kubectl Plugin&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that the Ondat kubectl plugin is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---install-local-path-provisioner&#34;&gt;Step 2 - Install Local Path Provisioner&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Different Kubernetes distributions may include a CSI driver as part of the deployment. Cluster administrators can leverage the CSI driver provided by their distribution if they don&amp;rsquo;t want to use a Local Path Provisioner. If so, ensure that the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable points to the correct value for your Kubernetes distribution&amp;rsquo;s default StorageClass name.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters, as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;step-3---conducting-preflight-checks&#34;&gt;Step 3 - Conducting Preflight Checks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to conduct preflight checks against the Kubernetes cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-4---generate-ondat-yaml-kubernetes-manifests&#34;&gt;Step 4 - Generate Ondat YAML Kubernetes Manifests&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance. In addition, define and export a &lt;code&gt;KUBERNETES_VERSION&lt;/code&gt; environment variable, where the value will be the exact version of your Kubernetes cluster where Ondat is going to be deployed - for example, &lt;code&gt;v1.23.5&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v1.23.5&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with the &lt;code&gt;--dry-run&lt;/code&gt; flag to generate the Ondat YAML Kubernetes manifests in a directory, called &lt;code&gt;storageos-dry-run&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --dry-run &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-storage-class&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --k8s-version&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To review the list of manifests generated in the newly created &lt;code&gt;storageos-dry-run&lt;/code&gt; directory run the following commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-dry-run/
ls storageos-dry-run/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;step-4---installing-ondat&#34;&gt;Step 4 - Installing Ondat&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl&lt;/code&gt; command to install Ondat with the generated manifests in the &lt;code&gt;storageos-dry-run&lt;/code&gt; directory. The manifests  can also be used in your &lt;a href=&#34;https://www.weave.works/technologies/gitops/&#34;&gt;GitOps&lt;/a&gt; workflow to deploy Ondat, enabling you to have a fully declarative approach towards managing your infrastructure deployments.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° &lt;strong&gt;Advanced Users&lt;/strong&gt; - For users who are looking to make further customisations to their &lt;code&gt;StorageOSCluster&lt;/code&gt; custom resource manifest, review the &lt;a href=&#34;/docs/reference/cluster-operator/configuration&#34;&gt;Cluster Operator Configuration&lt;/a&gt; and  &lt;a href=&#34;/docs/reference/cluster-operator/examples&#34;&gt;Cluster Operator Examples&lt;/a&gt; reference pages for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Apply the Operators and CustomResourceDefinitions (CRDs) first.&lt;/span&gt;
find . -name &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*-operator.yaml&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; xargs -I&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt; kubectl apply --filename &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Apply the Custom Resources next.&lt;/span&gt;
find . -name &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*-cluster.yaml&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; xargs -I&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt; kubectl apply --filename &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-5---verifying-ondat-installation&#34;&gt;Step 5 - Verifying Ondat Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;option-b---using-ondats-helm-chart&#34;&gt;Option B - Using Ondat&amp;rsquo;s Helm Chart&lt;/h3&gt;
&lt;h4 id=&#34;step-1---install-helm&#34;&gt;Step 1 - Install Helm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that the &lt;a href=&#34;https://helm.sh/&#34;&gt;Helm 3&lt;/a&gt; CLI utility is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;helm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---setup-an-etcd-cluster-external-etcd&#34;&gt;Step 2 - Setup An &lt;code&gt;etcd&lt;/code&gt; Cluster (External etcd)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you are installing &lt;code&gt;etcd&lt;/code&gt; externally, ensure that you have deployed the cluster before installing Ondat through the Helm chart. There are two different methods listed below with instructions on how to deploy an &lt;code&gt;etcd&lt;/code&gt; cluster;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/etcd/#testing---installing-etcd-into-your-kubernetes-cluster&#34;&gt;Embedded Deployment&lt;/a&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster operator into your Kubernetes cluster, recommended for &lt;strong&gt;non production&lt;/strong&gt; environments.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/etcd/#production---etcd-on-external-virtual-machines&#34;&gt;External Deployment&lt;/a&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster in dedicated virtual machines, recommended for &lt;strong&gt;production&lt;/strong&gt; environments.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you have an &lt;code&gt;etcd&lt;/code&gt; cluster up and running, ensure that you note down the list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values that will be used when configuring Ondat in &lt;strong&gt;Step 4&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For example, &lt;code&gt;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---setup-a-storageclass-for-etcd-internal-etcd&#34;&gt;Step 2 - Setup a &lt;code&gt;StorageClass&lt;/code&gt; for &lt;code&gt;etcd&lt;/code&gt; (Internal etcd)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you are installing &lt;code&gt;etcd&lt;/code&gt; inside the cluster, ensure that you have at least 3 (recommend 5) nodes ready to ensure high availability. It is recommended that these nodes are placed in different physical or virtual locations (ie. Datacenters or availability zones) for maximum resilience.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Before installing Ondat with &lt;code&gt;etcd&lt;/code&gt;, create the &lt;code&gt;StorageClass&lt;/code&gt; that you want to use for &lt;code&gt;etcd&lt;/code&gt;. Note that this cannot be &lt;code&gt;storageos&lt;/code&gt; as Ondat depends on etcd to function. The following procedure will install a local path &lt;code&gt;StorageClass&lt;/code&gt; that will work in all configurations, ideally there is another more resilient option (eg. Gp3 on AWS) available that can be used instead.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Different Kubernetes distributions may include a CSI driver as part of the deployment. Cluster administrators can leverage the CSI driver provided by their distribution if they don&amp;rsquo;t want to use a Local Path Provisioner. If so, ensure that the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable points to the correct value for your Kubernetes distribution&amp;rsquo;s default StorageClass name.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters, as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;step-3---configure-ondats-helm-chart-repository&#34;&gt;Step 3 - Configure Ondat&amp;rsquo;s Helm Chart Repository&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Add the Ondat Helm chart repository, update the local Helm repository index using the following &lt;code&gt;helm repo&lt;/code&gt; commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo add ondat https://ondat.github.io/charts
helm repo update
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check to confirm that the Ondat Helm chart repository is available using the following &lt;code&gt;helm&lt;/code&gt; commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo list
helm search repo &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ondat&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;step-4---customising--installing-ondats-operator-helm-chart&#34;&gt;Step 4 - Customising &amp;amp; Installing Ondat&amp;rsquo;s Operator Helm Chart&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;There are two ways to conduct an installation with Helm, &lt;strong&gt;declaratively&lt;/strong&gt; by creating a custom &lt;code&gt;values.yaml&lt;/code&gt; (recommended method) or &lt;strong&gt;interactively&lt;/strong&gt; by using the &lt;code&gt;--set&lt;/code&gt; flags to overwrite specific values for the deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° &lt;strong&gt;Advanced Users&lt;/strong&gt; - For users who are looking to make further customisations to the Helm chart through additional configurable parameters or manually create your own &lt;code&gt;StorageOSCluster&lt;/code&gt; custom resource manifest, review the Ondat chart &lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/ondat/README.md&#34;&gt;README.md&lt;/a&gt; document, &lt;a href=&#34;/docs/reference/cluster-operator/configuration&#34;&gt;Cluster Operator Configuration&lt;/a&gt; and  &lt;a href=&#34;/docs/reference/cluster-operator/examples&#34;&gt;Cluster Operator Examples&lt;/a&gt; reference pages for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;declarative-recommended&#34;&gt;Declarative (Recommended)&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Make a copy of the &lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/ondat/values.yaml&#34;&gt;&lt;code&gt;values.yaml&lt;/code&gt;&lt;/a&gt; configuration file, rename it to &lt;code&gt;custom-values.yaml&lt;/code&gt;, then ensure that the following configurable parameters have been populated before beginning the installation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/ondat/values.yaml#L23&#34;&gt;&lt;code&gt;ondat-operator.cluster.admin.password&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Password to authenticate to the StorageOS API with. This must be at least&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# 8 characters long.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;password&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# for example -&amp;gt; storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If an external etcd installation is being used&lt;/strong&gt;, add &lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/ondat/values.yaml&#34;&gt;&lt;code&gt;ondat-operator.cluster.kvBackend.address&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Key-Value store backend.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kvBackend&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;address&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# for example -&amp;gt; 203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If an internal etcd installation is being used&lt;/strong&gt;, set &lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/ondat/values.yaml&#34;&gt;&lt;code&gt;etcd-cluster-operator.cluster.storageclass&lt;/code&gt;&lt;/a&gt;, set this to the StorageClass installed earlier&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Storageclass for etcd backing storage&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# NOTE: We CANNOT use storageos here as this is the egg to Ondat&amp;#39;s chicken&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storageclass&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;local-path&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters, as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the parameters above have been defined, run the following  &lt;code&gt;helm install&lt;/code&gt;  command to install Ondat using the Helm chart. Ensure that you use the &lt;code&gt;--values=&lt;/code&gt; flag with your &lt;code&gt;custom-values.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install ondat ondat/ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --create-namespace &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --values&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;custom-values.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes. If you are installing etcd internally, the Ondat pods may initially fail to connect and enter an &lt;code&gt;Error&lt;/code&gt; state - they will retry automatically until etcd becomes available.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;interactive&#34;&gt;Interactive&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variable that will be used to manage your Ondat instance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;If you are using an internal etcd cluster&lt;/strong&gt;, define and export a &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable, where the value will be the StorageClass to use for etcd volumes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;If you are using an external etcd cluster&lt;/strong&gt;, define and export a &lt;code&gt;ETCD_ENDPOINTS&lt;/code&gt; environment variable, where the value will be a list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values noted down earlier in &lt;strong&gt;Step 2&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;helm install&lt;/code&gt;  command to install Ondat using the Helm chart.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Internal Etcd&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install ondat ondat/ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --create-namespace &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set ondat-operator.cluster.admin.password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set etcd-cluster-operator.cluster.storageclass&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;External etcd&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install ondat ondat/ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --create-namespace &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set ondat-operator.cluster.admin.password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set ondat-operator.cluster.kvBackend.address&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set etcd-cluster-operator.cluster.create&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;false&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-5---verifying-ondat-installation-1&#34;&gt;Step 5 - Verifying Ondat Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# only if the etcd cluster was deployed inside the Kubernetes cluster.&lt;/span&gt;
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;applying-a-licence-to-the-cluster&#34;&gt;Applying a Licence to the Cluster&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: System Configuration</title>
      <link>/docs/prerequisites/systemconfiguration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/systemconfiguration/</guid>
      <description>
        
        
        &lt;p&gt;Ondat requires certain kernel modules to function. In particular it requires &lt;a href=&#34;http://linux-iscsi.org/wiki/Main_Page&#34;&gt;Linux-IO&lt;/a&gt;, an open-source implementation of the SCSI target, on all nodes that will execute Ondat (usually the workers).&lt;/p&gt;
&lt;h2 id=&#34;distribution-specifics&#34;&gt;Distribution Specifics&lt;/h2&gt;
&lt;p&gt;Current (non-EOL) versions of the following distributions are supported by default:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SUSE Linux Enterprise Server&lt;/li&gt;
&lt;li&gt;Red Hat Enterprise Linux&lt;/li&gt;
&lt;li&gt;CentOS&lt;/li&gt;
&lt;li&gt;Debian&lt;/li&gt;
&lt;li&gt;Ubuntu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following distributions include the prerequisite modules but are not yet tested exhaustively by the Ondat team:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bottlerocket&lt;/li&gt;
&lt;li&gt;Google ContainerOS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following distributions are currently not supported:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Linux (lacks &lt;code&gt;target_core_mod&lt;/code&gt; and &lt;code&gt;target_core_user&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° If you require help with a specific issue with a listed distribution, &lt;a href=&#34;https://github.com/ondat/documentation/issues&#34;&gt;raise an issue on GitHub&lt;/a&gt; or reach out to us on our &lt;a href=&#34;https://slack.storageos.com&#34;&gt;Community Slack&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;kernel-modules&#34;&gt;Kernel Modules&lt;/h2&gt;
&lt;p&gt;We require the following modules to be loaded:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;target_core_mod&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tcm_loop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;configfs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;target_core_user&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;uio&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Other applications utilising &lt;a href=&#34;http://linux-iscsi.org/wiki/LIO&#34;&gt;TCMU&lt;/a&gt; cannot be run concurrently with Ondat. Doing so may result in corruption of data. On startup, Ondat will detect if other applications are using TCMU.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In most modern distributions, including those listed above, the modules are distributed as part of the Linux kernel package and are included by default. In some older distributions, they were part of a kernel extras package that needed to be installed separately. The script &lt;a href=&#34;https://github.com/storageos/init/blob/master/scripts/01-lio/enable-lio.sh&#34;&gt;enable-lio.sh&lt;/a&gt; from Ondat&amp;rsquo;s init container can be used to ensure that all kernel-level dependencies are installed, any errors will indicate which components are missing.&lt;/p&gt;
&lt;p&gt;For example, in Ubuntu versions prior to 22.04 several modules were not included in the base kernel configuration. The commands to install &lt;code&gt;linux-modules-extra&lt;/code&gt; to obtain these additional modules required for Ondat were:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;sudo apt-get update
sudo apt-get install -y linux-modules-extra-&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;uname -r&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;automatic-configuration&#34;&gt;Automatic Configuration&lt;/h2&gt;
&lt;p&gt;Once required kernel modules are installed on the system, for convenience we
provide a container which will ensure the appropriate modules are loaded and
ready for use at runtime. You will need to run the init container prior to starting Ondat.&lt;br&gt;
Our installation guides for Kubernetes and OpenShift include this step.&lt;/p&gt;
&lt;h2 id=&#34;manual-configuration&#34;&gt;Manual Configuration&lt;/h2&gt;
&lt;p&gt;For those wishing to manage their own kernel configuration, rather than using
the init container, perform the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ensure kernel modules are all loaded per list above&lt;/li&gt;
&lt;li&gt;Ensure configfs is loaded and mounted at /sys/kernel/config&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Release Notes</title>
      <link>/docs/release-notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/release-notes/</guid>
      <description>
        
        
        &lt;p&gt;We recommend always using &amp;ldquo;tagged&amp;rdquo; versions of Ondat rather than &amp;ldquo;latest&amp;rdquo;,
and to perform upgrades only after reading the release notes.&lt;/p&gt;
&lt;p&gt;The latest tagged release is &lt;code&gt;2.8.0&lt;/code&gt;. For
installation instructions see our
&lt;a href=&#34;/docs/reference/cluster-operator/install&#34;&gt;Install&lt;/a&gt; page.&lt;/p&gt;
&lt;p&gt;The latest CLI release is &lt;code&gt;2.8.0&lt;/code&gt;, available from
&lt;a href=&#34;https://github.com/storageos/go-cli/releases&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;upgrading&#34;&gt;Upgrading&lt;/h1&gt;
&lt;p&gt;To upgrade from version 1.x to 2.x, contact Ondat &lt;a href=&#34;/docs/support&#34;&gt;support&lt;/a&gt; for assistance.&lt;/p&gt;
&lt;h2 id=&#34;280---release-2022-06-29&#34;&gt;2.8.0 - Release 2022-06-29&lt;/h2&gt;
&lt;p&gt;2.8.0 Release Notes&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° For Ondat 2.8.0, we recommend having at least a 5 node cluster when running etcd within Kubernetes, as we recommend running etcd with 5 replicas.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;new&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;k8s&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Etcd in Production: We have added support for putting ETCD in your cluster in a production environment&lt;/li&gt;
&lt;li&gt;Modified CSI provisioner to work with Snapshots&lt;/li&gt;
&lt;li&gt;Ondat volumes metrics exporter: we have added a Prometheus endpoint to allow users to view metrics for Ondat Volumes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have relaxed some Ondat specific security checks for the ReadWriteOnce node volumes that we were doing in the control plane ahead of the new volume mode ReadWriteOncePod which is being introduced in k8s 1.22. This will align the Ondat RWO volumes with the spec and we will in a future release also implement support for &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;RWOP&lt;/a&gt; for users that wish to implement these existing controls.
&lt;ul&gt;
&lt;li&gt;Please note that the relaxation of these security checks could mean that Deployment objects using RWO volumes (if a rolling strategy is used for example) will be able to mount the volume concurrently on the same node, for this reason we suggest users are creating workloads using stateful sets or use RWX volumes for these deployments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Snapshot GA: we added the Snapshot feature to allow users to back up their Ondat data outside of their Kubernetes clusters in conjunction with a backup solution&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Portal Manager&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatic licencing: we added a feature to allow automatic deployment of licence to your cluster when you connect to our Ondat SaaS Platform&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;k8s&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fixed a bug where the StorageOS operator would occasionally restart&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;270---released-2022-04-11&#34;&gt;2.7.0 - Released 2022-04-11&lt;/h2&gt;
&lt;h3 id=&#34;new-1&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;k8s &amp;amp; Orchestrator Rolling Upgrade&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tech Preview: Kubernetes rolling upgrade for AWS EKS, Google Anthos, Google GKE, Microsoft Azure, Openshift and Rancher
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è This is a tech preview, we only recommend using this feature on your test clusters&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Operator&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Updated memory limit&lt;/li&gt;
&lt;li&gt;Introduced topology spread constraint with &lt;code&gt;ScheduledAnyway&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;API Manager&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adds a feature so when a PVC is not found scheduling will not be blocked&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set &lt;code&gt;Only_Numeric_Owners&lt;/code&gt; to true on NFSv4 setting on Ganesha&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Removed support for FUSE. Ondat now only supports TCMU. &lt;code&gt;target_core_user&lt;/code&gt; must now be used. Read &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/systemconfiguration/&#34;&gt;System Configuration&lt;/a&gt; for more information&lt;/li&gt;
&lt;li&gt;Rewrote the RPC interface between the Control Plane and the Data Plane. All of the old &lt;code&gt;ctl&lt;/code&gt; tools have been removed&lt;/li&gt;
&lt;li&gt;Removed the 32-bit mappings and uses the UUIDs passed by the CP directly to address presentations and deployments
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è If you decide to upgrade to 2.7.0 and want to downgrade, you can only roll back to 2.6.0, not earlier versions. Roll back instruction can be found &lt;a href=&#34;/docs/operations/downgrade-ondat-2.7-to-2.6&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-1&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;Operator&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fixed a bug that sometimes caused the operator to enter a deadlock state after Ondat cluster CR object deletion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fixed an issue where Ondat was not able to unmount volumes in rare instances, then occasionally causing volumes to become unhealthy&lt;/li&gt;
&lt;li&gt;Fixed an issue that caused replicas to go into the ‚Äúunknown‚Äù state during failover in somne rare instances&lt;/li&gt;
&lt;li&gt;Fixed an issue to now display output all dataplane logs even if they don&amp;rsquo;t have the expected syntax&lt;/li&gt;
&lt;li&gt;Fixed an issue so Ondat would speculatively configure the replica in the dataplane before we advertise ourselves to the master&lt;/li&gt;
&lt;li&gt;Fix an issue where goroutines attempting to dial remote nodes could be blocked&lt;/li&gt;
&lt;li&gt;Fix an issue so Ondat volume would remain mounted and online during temporary network issues when pod is on remote, master and replica&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fix non-null terminated buffer which could lead to garbled logs&lt;/li&gt;
&lt;li&gt;Fix client-server network to improve robustness&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;260---released-2022-02-14&#34;&gt;2.6.0 - Released 2022-02-14&lt;/h2&gt;
&lt;h3 id=&#34;new-2&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;Portal Manager:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initial release of the Portal Manager, which supports the connection to Ondat
SaaS Platform.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubectl Plugin:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have added a &lt;code&gt;--dry-run&lt;/code&gt; flag into install command, so you can view the
installation manifests written locally to &lt;code&gt;./storageos-dry-run/&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;We have added capability for conducting an airgapped installation. The new
options can also be used outside of an airgapped cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Operator:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have defined the resource requests and resource limits for the Ondat
components (csi-attacher, csi-provisioner, csi-resizer, api-manager,
cluster-operator and ondat-scheduler).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ondat supports Kubernetes v1.23&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Components&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have added a new component called Node Guard that once enabled allows
you to do rolling upgrades to the orchestrator without any downtime. This
component is disabled by default and we do not recommend using the feature
for production workloads as it is a technical preview feature.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;25---released-2021-12-06&#34;&gt;2.5 - Released 2021-12-06&lt;/h2&gt;
&lt;h3 id=&#34;fixed-2&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;Dataplane:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deadlock with unordered UNMAP commands.&lt;/li&gt;
&lt;li&gt;Spurious log message when detaching a volume - you would often see a spurious
warning message ‚Äúmissing fs configuration for presentation_id=2001&amp;quot;. We&amp;rsquo;ve
fixed the issue that led to this log message, by ensuring deletion of LUN
(Logical Unit Number).&lt;/li&gt;
&lt;li&gt;Stop potential shutdown hangs - &lt;code&gt;directfs initiator&lt;/code&gt; could restart
connections after shutdown has been requested. This race condition has been
removed.&lt;/li&gt;
&lt;li&gt;Misleading log message when &lt;code&gt;SetVolumeConsumerCount&lt;/code&gt; is called - log message
now only sent in correct scenarios.&lt;/li&gt;
&lt;li&gt;Volume backup tool in disaster recovery scenarios - the volume backup tool is
used to extract volume data in disaster recovery scenarios. There was an
issue that prevented the tool from running whilst the Dataplane was running.
This has been fixed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;new-3&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;Dataplane:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faster replica syncing - new replicas can be provisioned faster and rejoining
replicas sync faster. Non-contiguous data regions are collated into the same
RPC. Ondat now syncs multiple regions concurrently maximising the network
bandwidth.&lt;/li&gt;
&lt;li&gt;Improved network performance - Up to 2.3 times faster speed and even higher
on high-latency networks.&lt;/li&gt;
&lt;li&gt;Improved error-handling mechanism for synchronise cache commands - we have
ensured error messages are propagated when SYNCHRONIZE_CACHE_16 commands
fail.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/tap&#34;&gt;Topology-Aware Placement&lt;/a&gt; is a feature
that enforces placement of data across failure domains to guarantee high
availability.&lt;/li&gt;
&lt;li&gt;Track logs from control plane to data plane with extra details.&lt;/li&gt;
&lt;li&gt;The command-line tool can now display the availability zone of each of the volume&amp;rsquo;s
deployments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;New &lt;a href=&#34;/docs/reference/kubectl-plugin&#34;&gt;kubectl plugin&lt;/a&gt; to
manage Ondat.&lt;/li&gt;
&lt;li&gt;Upgrades to the operator and improved development speed - StorageOS cluster
status now reflects cluster deployment status. Users can now change log-level
port to new operator and we have given users increased flexibility for users
to configure StorageOS images.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;244---released-2021-09-08&#34;&gt;2.4.4 - Released 2021-09-08&lt;/h2&gt;
&lt;h3 id=&#34;fixed-3&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;controlplane: Fix an issue with timeouts when opening gRPC connections to
other nodes in the cluster.&lt;/li&gt;
&lt;li&gt;controlplane: Changes to GUI licensing workflow - See our &lt;a href=&#34;/docs/reference/licence&#34;&gt;Licensing
page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;dataplane: Fix an issue where failed IO network connections could be
erroneously restarted while we are trying to shutdown.&lt;/li&gt;
&lt;li&gt;k8s: Leader election requires ability to patch events.&lt;/li&gt;
&lt;li&gt;k8s: Node label sync could fail to apply updated label.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v242---released-2021-07-15&#34;&gt;v2.4.2 - Released 2021-07-15&lt;/h2&gt;
&lt;h3 id=&#34;fixed-4&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;controlplane: Improve error message when unable to set the cluster-wide log
level on an individual node.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Fix rare assert when retrying some writes under certain conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Log format string safety improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Backuptool reliability improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Allow api-manager to patch events for leader election.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v241---released-2021-06-30&#34;&gt;v2.4.1 - Released 2021-06-30&lt;/h2&gt;
&lt;h3 id=&#34;new-4&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cluster-wide log level configuration via Custom Resource.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-5&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;controlplane: Improve error message during failed &lt;code&gt;--label&lt;/code&gt; argument parsing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane: Double-check the OS performs the NFS mount as directed, and
unmount on error.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane: Improved FSM and sync CC logging.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Log message quality, quantity and visibility improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Volume backup tool error reporting improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s: Pod scheduler fixes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v240---released-2021-05-27&#34;&gt;v2.4.0 - Released 2021-05-27&lt;/h2&gt;
&lt;p&gt;This release adds production-grade &lt;a href=&#34;/docs/reference/encryption&#34;&gt;encryption at rest&lt;/a&gt; for Ondat volumes, as well as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/concepts/fencing&#34;&gt;Fencing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/trim&#34;&gt;TRIM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/concepts/replication#failure-modes&#34;&gt;Failure modes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubernetes-object-sync&#34;&gt;Kubernetes object sync&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: v2.4.0 &lt;em&gt;requires&lt;/em&gt; Kubernetes 1.17 or newer.&lt;/p&gt;
&lt;h3 id=&#34;new-5&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Volume encryption-at-rest.&lt;/li&gt;
&lt;li&gt;Fencing support.&lt;/li&gt;
&lt;li&gt;Block trim support.&lt;/li&gt;
&lt;li&gt;Kubernetes label sync.&lt;/li&gt;
&lt;li&gt;Kubernetes node and namespace delete sync.&lt;/li&gt;
&lt;li&gt;Failure tolerance threshold support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-6&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;controlplane/api: Compression is not disabled by default when provisioning
volumes via the API.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/api: Spec has incorrect response body for partial bundle.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/csi: Error incorrectly returned when concurrent namespace
creation requests occur.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: GetDiagnostics RPC response does not indicate if
node timed out collecting some data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: Invalid character &amp;lsquo;\u0080&amp;rsquo; looking for beginning of
value via CLI when a node is down.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnosticutil: Include attachment type in unpacking local
volumes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnotics: Node timing out during local diagnostics is missing
logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/healthcheck: Combined sources fires callback in initialisation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/volumerpc: &amp;ldquo;Got unknown replica state 0&amp;rdquo; discards results.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Check blob writes don&amp;rsquo;t exceed internal limit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Checking the return code of InitiatorAddConnection().&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Director signal hander thread is not joined.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Don&amp;rsquo;t block I/O when many retries are in progress.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: gRPC API robustness improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Initiator needs to include the node UUID in Endpoint.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Low-level I/O engines don&amp;rsquo;t propagate IO failures via Wait().&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Log available contextual information where possible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Ensure BackingStore is not deleted twice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Serialise LIO create/delete operations to avoid kernel bug.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Dataplane shutdown time can exceed 10 seconds.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Fix non-threadsafe access on TCMU device object.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Don&amp;rsquo;t hold lock unecessarily in Rdb::Reap.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: First ip octet should not be 0, 127, 169 or 224.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Keygen should only operate on Ondat PVCs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add perm to allow VolumeAttachment finalizer removal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Fix apiManagerContainer tag in v1 deploy CRD.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Fix docker credentials check.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Fix ServiceAccountName in the OLM bundle.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Set webhook service-for label to be unique.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;controlplane/api: Make version provided consistent for NFS/Host attach
handler.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/attachtracker: Cleanup NFS mounts at shutdown.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/build: Migrate to go modules for dependency management.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/build: Use sentry prod-url if build branch has &amp;ldquo;release&amp;rdquo; prefix.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/cli: Colour for significant feedback.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/cli: Update node must set compute only separately to other
labels.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/cli: Warn user that updating labels action can be reverted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/csi: Bound request handlers with timeout similar to HTTP API.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/csi: Remove error obfuscation and clarify log messages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/csi: Stop logging not found.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/dataplane: Remove UUID mappings during failed presentation
creation rollback.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/dataplaneevents: Decorate logs with extra event details.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: Asymmetrically encrypt bundles.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: Collect FSM state.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: Support single node bundle collection.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnosticutil: Decorate log entries with well-known field
corresponding to node id/name.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnosticutil: Parallelise unpacking of disjoint data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnosticutil: Unpack gathered NFS config data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/fsm: Perform state match check before version check.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/k8s: Use secret store.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/log: Fix race condition writing logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/log: Handle originator timestamps from dataplane logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/meta: Error checking code uses Go 1.13 error features.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/rpc: Make CP gRPC calls to the DP configuration endpoints
idempotent.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/sentry: Prevent some unnecessary alerts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/slog: Clean up error logging in RPC provision stack.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/states: Add the &amp;ldquo;from&amp;rdquo; state as a log field for state transition
msgs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/store/etcd: Decorate lock logs with associated ID fields.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/ui: Warn user that updating labels action will be reverted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/vendor: Bump service repository.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/volume: Encryption support in kubernetes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fs: Don&amp;rsquo;t return from PresentationCreate RPC until the device is
fully created.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fs: Each LUN should have it&amp;rsquo;s own HBA.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fs: Improve device ready check.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/internals: Improve DP stats implementation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/internals: Major director refactor.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/log: Logs should output originating timestamps.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/log: Move to log3 API exclusively.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/log: Remove log2.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/log: Set log_level and log_filter via the supctl tool.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/rdb: Handle unaligned I/O in RdbPlugin.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/rdb: Implement low-level &amp;ldquo;delete block&amp;rdquo; functionality.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/rdb: rocksdb Get() should use an iterator.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/story: Support for block unmapping.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/story: Add backuptool binary to export volume data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/story: Volume encryption-at-rest.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/sync: Add retries for failed sync IOs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/sync: VolumeHash performance improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/sys: Find and check OS pids.max on startup.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Don&amp;rsquo;t attempt service creation if the owning PVC doesn&amp;rsquo;t
exist.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Compare SC and PVC creation time during label sync.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add action to ensure modules tidy &amp;amp; vendored.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add defaults from StorageClass.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add fencing controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add flag and support for cert validity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add flags to disable label sync controllers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add namespace delete controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add node delete controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add OpenTelemetry tracing with Jaeger backend.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add PVC label sync controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add PVC mutating controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add support for failure-mode label.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add support for volume encryption.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Allow multiple mutators.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Build and tests should use vendored deps.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Bump controller-runtime to v0.6.4.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Encrypt only provisioned PVCs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Fix tracing example.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Introduce StorageClass to PVC annotation mutator.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Log API reason.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Migrate namespace delete to operator toolkit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Migrate node delete to operator toolkit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Migrate to kubebuilder v3.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Node label sync.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Node label update must include current reserved labels.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Pass context to API consistently.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Rename leader election config map.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: RFC 3339 and flags to configure level &amp;amp; format.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Run shared volume controller with manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Set initial sync delay.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Set Pod scheduler.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Standardise on ObjectKeys for all API function signatures.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Ondat API interface and mocks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Update dependencies and go version 1.16.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Update to new external object sync.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Use composite client in admission controllers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Use Object interface.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Changes to the StorageOSCluster CR get applied to Ondat.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Increase provisioner timeout from 15 to 30s.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Reduce CSI provisioner worker pool.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Set priority class for helper pods.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add pod anti-affinity to api-manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add pvc mutator config.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add rbac for api-manager fencing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add RBAC for encryption key management.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add RBAC needed for csi-resizer v1.0.0.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add webhook resource migration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add workflow to push image to RedHat registry.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Bump csi-provisioner to v2.1.1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Call APIManagerWebhookServiceTest test.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Delete CSI expand secret when cluster is deleted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Docker login to avoid toomanyrequests error.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Move pod scheduler webhook to api-manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: RBAC to allow sync functions move to api-manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Remove pool from StorageClass, not used in v2.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Remove some other v1.14 specific logic.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Set the default container for kubectl logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Update code owners.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Update CSI sidecar images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Validate minimum Kubernetes version.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v234---released-2021-03-24&#34;&gt;v2.3.4 - Released 2021-03-24&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;controlplane/build: Use Sentry prod-url for release branches (CP-4600).&lt;/li&gt;
&lt;li&gt;controlplane/csi: Improve CSI handler timeout (CP-4585).&lt;/li&gt;
&lt;li&gt;controlplane/dataplane: UUID mapping cleanup on failed volume creation (CP-4588).&lt;/li&gt;
&lt;li&gt;controlplane/slog: Improve RPC error logging (CP-4616).&lt;/li&gt;
&lt;li&gt;dataplane: Allocate fewer aio contexts per volume (DP-305)&lt;/li&gt;
&lt;li&gt;dataplane: Defer fallocate(2) until first write (DP-312).&lt;/li&gt;
&lt;li&gt;dataplane: Don&amp;rsquo;t fail replica sync if inter-node connection establishment is slow (DP-319, DP-280).&lt;/li&gt;
&lt;li&gt;dataplane: Improve logging around gRPC context cancellations (DP-315).&lt;/li&gt;
&lt;li&gt;dataplane: Improve rollback for failed volume creation (DP-308).&lt;/li&gt;
&lt;li&gt;dataplane: New support tool to cleanup orphaned volume storage (DP-307).&lt;/li&gt;
&lt;li&gt;dataplane: supctl can reap named volumes (DP-309).&lt;/li&gt;
&lt;li&gt;k8s: API token reset failures should trigger re-authentication directly (#38).&lt;/li&gt;
&lt;li&gt;k8s: Increase lint timeout to reduce CI errors (#305).&lt;/li&gt;
&lt;li&gt;k8s: Remove PriorityClass from helper pods (#312).&lt;/li&gt;
&lt;li&gt;k8s: Toleration defaults for helper pods (#311).&lt;/li&gt;
&lt;li&gt;k8s: Use ubi-minimal base image directly (#307).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v233---released-2021-02-12&#34;&gt;v2.3.3 - Released 2021-02-12&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Support CSI ListVolumes() API, addressing volume attach problems seen by some
customers.&lt;/li&gt;
&lt;li&gt;Quality-of-life fixes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;new-6&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;operator: Use CSI attacher v3 for k8s 1.17+.&lt;/li&gt;
&lt;li&gt;controlplane/csi: ListVolumes support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-7&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;api-manager: Reset API after token refresh error.&lt;/li&gt;
&lt;li&gt;operator: Set scheduler when PVCs use default StorageClass.&lt;/li&gt;
&lt;li&gt;operator: Update base container image.&lt;/li&gt;
&lt;li&gt;controlplane/volumerpc: &amp;ldquo;Got unknown replica state 0&amp;rdquo; discards results.&lt;/li&gt;
&lt;li&gt;controlplane/healthcheck: Combined sources fires callback in initialisation.&lt;/li&gt;
&lt;li&gt;controlplane/fsm: Perform state match check before version check.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v232---released-2020-11-25&#34;&gt;v2.3.2 - Released 2020-11-25&lt;/h2&gt;
&lt;h3 id=&#34;fixed-8&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;controlplane/rejoin: Failure to delete data causes re-advertise loop.&lt;/li&gt;
&lt;li&gt;controlplane/rejoin: Handle timeout waiting for progress report.&lt;/li&gt;
&lt;li&gt;dataplane/log: Change buffering of &lt;code&gt;symmetra&lt;/code&gt; output to prevent stalls.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v231---released-2020-11-16&#34;&gt;v2.3.1 - Released 2020-11-16&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Allows access to &lt;code&gt;ReadWriteMany&lt;/code&gt; shared volumes when running containers as a
non-root user.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-9&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;nfs: root squash to uid=0 is now configured on all shared volumes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v230---released-2020-10-31&#34;&gt;v2.3.0 - Released 2020-10-31&lt;/h2&gt;
&lt;p&gt;This release adds production-grade shared file support to v2, previously a
technology preview in v1.&lt;/p&gt;
&lt;h3 id=&#34;breaking&#34;&gt;Breaking&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;v2.3.0&lt;/code&gt; operator is no longer able to run Ondat v1.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;new-7&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Adds support for &lt;code&gt;ReadWriteMany&lt;/code&gt; shared volumes.  See
&lt;a href=&#34;/docs/concepts/rwx&#34;&gt;ReadWriteMany&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Adds &lt;code&gt;api-manager&lt;/code&gt; deployment to support shared volumes.  See &lt;a href=&#34;https://github.com/storageos/api-manager&#34;&gt;the api
manager&lt;/a&gt; GitHub repository for more
information.&lt;/li&gt;
&lt;li&gt;Kubernetes 1.19 support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved-1&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;dataplane: Reduce replication thread usage by having the replication processes
share the main thread pool.  This helps ensure that there isn&amp;rsquo;t a spike in
thread usage when a node recovers and begins re-syncing its volumes.  This is
particularly relevant on CRIO-based orchestrators such as Openshift where the
default maximum allowed PID limit (which also governs the thread limit) is
low.&lt;/li&gt;
&lt;li&gt;dataplane: Detect and log the effective maximum PID limit on startup.&lt;/li&gt;
&lt;li&gt;dataplane: Internal device presentation mappings are now ephemeral and are not
persisted across reboots.&lt;/li&gt;
&lt;li&gt;dataplane: Disabled default verbose logging for fdatasync/flushWAL timers.&lt;/li&gt;
&lt;li&gt;dataplane: Log both volume inode and UUID in replication error messages for
easier correlation.&lt;/li&gt;
&lt;li&gt;dataplane: On startup, ensure any remnant devices that may have been left
after an unclean shutdown have been properly cleared.&lt;/li&gt;
&lt;li&gt;dataplane: Signal when all startup tasks complete.  This ensures no IO can be
initiated before this time.&lt;/li&gt;
&lt;li&gt;ha: Implement a backoff when attempting to repoint an attached volume after
the master has failed.&lt;/li&gt;
&lt;li&gt;ha: Replicas can now rejoin after an asymmetric partition. This can occur when
the master has not lost communication to the replica, but the replica can&amp;rsquo;t
communicate with the master.  Previously the replica would not be able to
rejoin until the master determined it had failed.&lt;/li&gt;
&lt;li&gt;ha: A master that was partitioned can now re-join to the new master as a
replica.&lt;/li&gt;
&lt;li&gt;api: node label changes update target node prior to committing new state.&lt;/li&gt;
&lt;li&gt;api: Validation errors now include more information on the failure and how to
resolve.&lt;/li&gt;
&lt;li&gt;csi: Volume resize error messages (e.g. capacity exceeded) now passed through
in CSI response.&lt;/li&gt;
&lt;li&gt;csi: Volume attachment is now verified prior to mount for more instructive
error message.&lt;/li&gt;
&lt;li&gt;csi: Returns &lt;code&gt;RESOURCE EXHAUSTED&lt;/code&gt; error when attempting to exceed maximum of
250 Ondat volume attachments per node.&lt;/li&gt;
&lt;li&gt;diagnostics: Multiple improvements to bundle collection and collected data.&lt;/li&gt;
&lt;li&gt;ui: Allow collection of partial diagnostics bundles.&lt;/li&gt;
&lt;li&gt;ui: Tolerate clock skew when authenticating via the UI.&lt;/li&gt;
&lt;li&gt;licensing: Read-through cache added.  Licence updates will take up to 60s to
propagate to all nodes.&lt;/li&gt;
&lt;li&gt;cli: Set replicas output formatting.&lt;/li&gt;
&lt;li&gt;init: Checks the effective maximum PID limit and warns if less than the
Ondat recommended PID limit (32,768).  CRIO-based distributions such as
Openshift have a much lower default value (1024).  Consult
&lt;a href=&#34;/docs/prerequisites/pidlimits&#34;&gt;prerequisites&lt;/a&gt; for more
information.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-10&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;dataplane: Fixes &lt;code&gt;transport endpoint is not connected&lt;/code&gt; on startup after an
unclean shutdown.&lt;/li&gt;
&lt;li&gt;csi: Volume unmount requests now succeed when the mountpoint has
already been removed by the orchestrator.&lt;/li&gt;
&lt;li&gt;csi: Volume detach requests now succeed when the volume has already been
deleted.  Previously the volume would be stuck in &lt;code&gt;Terminating&lt;/code&gt; status.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v220---released-2020-08-18&#34;&gt;v2.2.0 - Released 2020-08-18&lt;/h2&gt;
&lt;p&gt;This release focuses on performance. We analysed existing performance
characteristics across a variety of real-world use cases and ended up with
improvements across the board. Of particular note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sequential reads have improved by up to 130%&lt;/li&gt;
&lt;li&gt;Sequential writes have improved by up to 737%&lt;/li&gt;
&lt;li&gt;Random reads have improved by up to 45%&lt;/li&gt;
&lt;li&gt;Random writes have improved by up to 135%&lt;/li&gt;
&lt;li&gt;I/O for large block sizes (128K) has improved by up to 353%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are extremely proud of our performance and we love to talk about it. Have a
look at the &lt;a href=&#34;/docs/introduction/self-eval#Benchmarking&#34;&gt;Benchmarking&lt;/a&gt; section of the
self-evaluation guide and consider sharing
your results. Our PRE engineers are available to discuss in our &lt;a href=&#34;https://storageos.slack.com&#34;&gt;slack
channel&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;new-8&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Data engine revamp focused on provable consistency and performance. Key
characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Metadata is stored in an optimised index, lowering I/O latency and improving
performance for all workloads.&lt;/li&gt;
&lt;li&gt;Large block reads/writes are now be handled in a single operation.
Applications like Kafka will go much faster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On-disk compression is now disabled by default as in most scenarios this
offers better performance. To enable on-disk compression for a specific
workload, see &lt;a href=&#34;/docs/concepts/compression&#34;&gt;compression&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved-2&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;dataplane: The number of I/O threads are now determined by the number of
processing cores available.  This improves scalability and performance on
larger servers.&lt;/li&gt;
&lt;li&gt;ha: Improve partition tolerance behaviour when a volume master that has lost
its connection to etcd rejoins.&lt;/li&gt;
&lt;li&gt;ha: Allow replicas in unhealthy states to be remediated and re-used while
maintaining partition tolerance.&lt;/li&gt;
&lt;li&gt;ha: When a master fails and the new master is not yet available, introduce a
back-off to the redirection logic to avoid spamming the logs with connection
failure errors.&lt;/li&gt;
&lt;li&gt;ha: Ignore health advertisements for local node. Local nodes are handled
directly.&lt;/li&gt;
&lt;li&gt;node delete: Only refuse to delete a node if the node health can be
authoritatively verified to be in use.&lt;/li&gt;
&lt;li&gt;api: Increase HTTP server write timeout.&lt;/li&gt;
&lt;li&gt;cli/ui: Allow partial diagnostic bundle downloads.&lt;/li&gt;
&lt;li&gt;ui: Namespace dropdown can now be scrolled.&lt;/li&gt;
&lt;li&gt;ui: Add &amp;ldquo;Job title&amp;rdquo; to UI licence form.&lt;/li&gt;
&lt;li&gt;logging: Log version at startup at INFO level.&lt;/li&gt;
&lt;li&gt;logging: Lower verbosity of SCSI warnings that do not apply to Ondat.&lt;/li&gt;
&lt;li&gt;diagnostics: Include logs that have been rotated.&lt;/li&gt;
&lt;li&gt;diagnostics: Bundle collection across providers is now done in parallel.&lt;/li&gt;
&lt;li&gt;build: Update base image to RHEL 8.2.&lt;/li&gt;
&lt;li&gt;operator: Removed DB migration utility required for v1.3 -&amp;gt; v1.4 upgrades.&lt;/li&gt;
&lt;li&gt;operator: Automatically refreshes Ondat API token without failing
requests when the token expires.&lt;/li&gt;
&lt;li&gt;operator: Updated CSI attacher and provisioner to latest upstream.&lt;/li&gt;
&lt;li&gt;operator: Remove &lt;code&gt;cluster.local&lt;/code&gt; suffix on Pod scheduler service address.
This allows the scheduler to work in clusters with custom DNS configuration.&lt;/li&gt;
&lt;li&gt;operator: Defaults are now set for most CSI configuration options in the
StorageOSCluster custom resource.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-11&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;csi: When unmount request is received for a volume that has already been
unmounted, return success.&lt;/li&gt;
&lt;li&gt;csi: Verify volume is attached on the node before mounting it.&lt;/li&gt;
&lt;li&gt;xfs: Support older RHEL kernels which have an XFS library that does not
allow reflinks/dedupe.&lt;/li&gt;
&lt;li&gt;dataplane: Reserve 1GiB of capacity on the target disk to allow manual cleanup
operations, rather than filling target disk to capacity.&lt;/li&gt;
&lt;li&gt;operator: In some cases &lt;code&gt;/var/lib/storageos&lt;/code&gt; could fail to unmount cleanly
after a restart. This resulted in multiple entries in &lt;code&gt;/proc/mounts&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v210---released-2020-06-26&#34;&gt;v2.1.0 - Released 2020-06-26&lt;/h2&gt;
&lt;h3 id=&#34;new-9&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;csi: Volume expansion now supported in offline mode. To expand a volume, stop
any workloads accessing the volume, then edit the PVC to increase the
capacity. For more information, see our &lt;a href=&#34;/docs/operations/resize&#34;&gt;Volume Resize&lt;/a&gt; operations page and the &lt;a href=&#34;https://kubernetes-csi.github.io/docs/volume-expansion.html&#34;&gt;&lt;code&gt;CSI Volume Expansion&lt;/code&gt;&lt;/a&gt;
page.&lt;/li&gt;
&lt;li&gt;api: Volume configuration including replica count can now be updated while
the volume is in use. Other updateable fields include labels and
description.&lt;/li&gt;
&lt;li&gt;failover: Before determining that a node is offline and performing recovery
operations, the I/O path is also verified. This provides more robust failure
detection and ensures that nodes that are still responding to I/O do not get
replaced. This I/O path verification is in addition to the gossip-based
failure detection.&lt;/li&gt;
&lt;li&gt;operator: Default tolerations are now set for the Ondat node container.
This helps ensure that the Ondat node container does not get evicted when
the node is running low on resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved-3&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;api: Added checks to prevent deletion of a node with active volumes, or if it
is the master of at least one volume. This helps prevent orphaned volumes.&lt;/li&gt;
&lt;li&gt;cli: Add an &lt;code&gt;--offline-delete&lt;/code&gt; flag to allow removal of volumes whose master
and replica nodes are offline. This allows cleanup of orphaned volumes.&lt;/li&gt;
&lt;li&gt;ui: Add an offline volume delete option.&lt;/li&gt;
&lt;li&gt;ui: Volumes can now be detached from the UI.&lt;/li&gt;
&lt;li&gt;cli: Labels are no longer truncated.&lt;/li&gt;
&lt;li&gt;api: When a new node is added to the cluster, its capacity is available to use
immediately.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-12&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ui: Favicon was missing.&lt;/li&gt;
&lt;li&gt;ui: Duplicate volumes could be shown on the node details page.&lt;/li&gt;
&lt;li&gt;operator: During uninstall a ClusterRoleBinding was not removed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v200---released-2020-05-05&#34;&gt;v2.0.0 - Released 2020-05-05&lt;/h2&gt;
&lt;h3 id=&#34;new-10&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;operator: Ondat containers now run in the &lt;code&gt;kube-system&lt;/code&gt; namespace by
default to allow the &lt;code&gt;system-node-critical&lt;/code&gt; priority class to be set. This
instructs Kubernetes to start Ondat before application Pods, and to evict
Ondat only after application Pods have finished. This setting was
previously recommended in documentation; it is now the default.&lt;/li&gt;
&lt;li&gt;operator: Ondat CSI helper containers now run as privileged. This ensures
that the CSI endpoint can be seen on systems with SELinux enabled.&lt;/li&gt;
&lt;li&gt;ui: replication progress for new or re-joining replicas is now displayed.&lt;/li&gt;
&lt;li&gt;ui: show warning for unlicensed clusters.&lt;/li&gt;
&lt;li&gt;cli: new commands:
&lt;ul&gt;
&lt;li&gt;licence management&lt;/li&gt;
&lt;li&gt;get policy&lt;/li&gt;
&lt;li&gt;create namespace&lt;/li&gt;
&lt;li&gt;create policy&lt;/li&gt;
&lt;li&gt;describe user&lt;/li&gt;
&lt;li&gt;describe namespace&lt;/li&gt;
&lt;li&gt;describe policy&lt;/li&gt;
&lt;li&gt;delete user&lt;/li&gt;
&lt;li&gt;delete namespace&lt;/li&gt;
&lt;li&gt;delete policy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;licence: removed the default licence expiry date added for &lt;code&gt;v2.0.0-rc.1&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved-4&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;dataplane: improved retry behaviour for network I/O.&lt;/li&gt;
&lt;li&gt;cli: &amp;ldquo;get volumes&amp;rdquo; for all namespaces should be done in parallel.&lt;/li&gt;
&lt;li&gt;cli: help text document config file&lt;/li&gt;
&lt;li&gt;ui: link node name and get to node details on the volume details page.&lt;/li&gt;
&lt;li&gt;ui: node details add available capacity spinner.&lt;/li&gt;
&lt;li&gt;ui: node list remove capacity values / address port.&lt;/li&gt;
&lt;li&gt;ui: node list show master/replica counts.&lt;/li&gt;
&lt;li&gt;ui: node list remove edit action.&lt;/li&gt;
&lt;li&gt;ui: format entity labels.&lt;/li&gt;
&lt;li&gt;ui: node details link volumes.&lt;/li&gt;
&lt;li&gt;ui: align buttons for licences.&lt;/li&gt;
&lt;li&gt;ui: k8s warning in &amp;ldquo;create volume&amp;rdquo; modal.&lt;/li&gt;
&lt;li&gt;ui: node list remove &amp;ldquo;API&amp;rdquo; from &amp;ldquo;API Address&amp;rdquo;&lt;/li&gt;
&lt;li&gt;ui: add some details about the Licence on the licence page.&lt;/li&gt;
&lt;li&gt;api: include valid for duration in login response.&lt;/li&gt;
&lt;li&gt;licence: restrict nodes which are unregistered after 24 hours.&lt;/li&gt;
&lt;li&gt;scheduler: return error for namespace/volume not found&lt;/li&gt;
&lt;li&gt;dataplane: start gRPC threads separately from rest of the supervisor.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-13&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;&amp;laquo;&amp;laquo;&amp;laquo;&amp;lt; HEAD&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ui: centre licence types.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ui: capacity in ui is per namespace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cli: fail gracefully if missing some output details (i.e. no node exists for ID).
=======&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ui: centre licence types.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ui: capacity in ui is per namespace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cli: fail gracefully if missing some output details (i.e. no node exists for ID).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;main&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;v200-rc1---released-2020-03-31&#34;&gt;v2.0.0-rc.1 - Released 2020-03-31&lt;/h2&gt;
&lt;p&gt;Initial release of version 2.x. See &lt;a href=&#34;https://storageos.com/storageos-2-0-release-blog&#34;&gt;Ondat v2.0 Release
Blog&lt;/a&gt; for details.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Availability of IPv6</title>
      <link>/docs/prerequisites/ipv6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/ipv6/</guid>
      <description>
        
        
        &lt;h2 id=&#34;availability-of-ipv6-address-family&#34;&gt;Availability of IPv6 Address Family&lt;/h2&gt;
&lt;p&gt;Certain Ondat components need to be able to listen on a standard
dual-stack socket of type AF_INET6. The IPv6 address family must be supported
on the server so that this socket can be allocated. Ondat does not require
IPv6 to be configured on the server - no addressing or routing needs to be in
place, however Ondat does need this functionality to be enabled in the
kernel.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Firewalls</title>
      <link>/docs/prerequisites/firewalls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/firewalls/</guid>
      <description>
        
        
        &lt;h2 id=&#34;port-list&#34;&gt;Port list&lt;/h2&gt;
&lt;p&gt;Ondat daemons listen on specific ports, which we require to be accessible
between all nodes in the cluster:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Port Number&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;TCP/UDP&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5701&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;gRPC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5703&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;DirectFS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5704&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Dataplane Supervisor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5705&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;REST API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5710&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;gRPC API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5711&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP &amp;amp; UDP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Gossip service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25705-25960&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;RWX Volume Endpoints&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Ondat also uses &lt;a href=&#34;https://en.wikipedia.org/wiki/Ephemeral_port&#34;&gt;ephemeral&lt;/a&gt;
ports to dial-out to these ports on other Ondat nodes. For this reason,
outgoing traffic should to other nodes be enabled.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;firewalls-and-vps-providers&#34;&gt;Firewalls and VPS providers&lt;/h2&gt;
&lt;p&gt;Some VPS providers (such as Digital Ocean) ship default firewall rulesets which
must be updated to allow Ondat to run. Some example rules are shown below -
modify to taste.&lt;/p&gt;
&lt;h3 id=&#34;ufw&#34;&gt;UFW&lt;/h3&gt;
&lt;p&gt;For distributions using UFW, such as RHEL and derivatives:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ufw default allow outgoing
ufw allow 5701:5711/tcp
ufw allow 5711/udp
ufw allow 25705:25960/tcp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;firewalld&#34;&gt;Firewalld&lt;/h3&gt;
&lt;p&gt;For distributions that enable firewalld to control iptables such as some installations of OpenShift.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;firewall-cmd --permanent  --new-service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
firewall-cmd --permanent  --service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos --add-port&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;5700-5800/tcp --add-port&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;25705-25960/tcp
firewall-cmd --add-service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos  --zone&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;public --permanent
firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;iptables&#34;&gt;Iptables&lt;/h3&gt;
&lt;p&gt;For those using plain iptables:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Inbound traffic&lt;/span&gt;
iptables -I INPUT -i lo -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit loopback traffic&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -m state --state ESTABLISHED,RELATED -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit established traffic&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -p tcp --dport 5701:5711 -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Ondat&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -p udp --dport &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;5711&lt;/span&gt; -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Ondat&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -p tcp --dport 25705:25960 -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Ondat&amp;#39;&lt;/span&gt; -j ACCEPT

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Outbound traffic&lt;/span&gt;
iptables -I OUTPUT -o lo -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit loopback traffic&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I OUTPUT -d 0.0.0.0/0 -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit outbound traffic&amp;#39;&lt;/span&gt; -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è  Make sure that the iptables rules you have added above come before any default DROP or REJECT rules.&lt;/p&gt;
&lt;/blockquote&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: PID Limits</title>
      <link>/docs/prerequisites/pidlimits/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/pidlimits/</guid>
      <description>
        
        
        &lt;p&gt;Ondat recommends that a &lt;a href=&#34;https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#pid&#34;&gt;PID
cgroup&lt;/a&gt;
limit of 32768 be used for Ondat pods.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Most environments fulfill this prerequisite by default. Check the
Ondat init container logs as shown below to ensure this is the case.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat pods running in Kubernetes are part of a PID cgroup that may limit
the maximum number of PIDs that all containers in the PID cgroup slice can
spawn. As the Linux kernel assigns a PID to processes and Light Weight
Processes (LWP) a low limit can be easily reached under certain circumstances.
The PID limit can be set by the Kubernetes distribution or by the container
runtime. Generally the limit is set to the machine wide default limit of 32768
but some environments can set this as low as 1024. A low PID limit may prevent
Ondat from spawning the required threads.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/storageos/init&#34;&gt;Ondat init container&lt;/a&gt; runs a script
that checks for the PID limit of the PID cGroup slice that the Ondat pod
runs in. If the
&lt;a href=&#34;https://github.com/storageos/init/blob/master/scripts/02-limits/limits.sh&#34;&gt;script&lt;/a&gt;
finds that the limit is less than 32768 it will log a warning. This warning can
be viewed using kubectl to check the init container logs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n storageos logs -l app.kubernetes.io/component&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;control-plane,app&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos -c init
WARNING: Effective max.pids limit &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;1024&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt; less than RECOMMENDED_MAX_PIDS_LIMIT &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;32768&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;setting-a-kubernetes-pid-limit&#34;&gt;Setting a Kubernetes PID limit&lt;/h2&gt;
&lt;p&gt;Kubernetes defaults to an unlimited &lt;code&gt;PodPidsLimit&lt;/code&gt;, which results in the usage of
the machine wide limit; typically 32768.&lt;/p&gt;
&lt;p&gt;For information on how to configure the Kubernetes PID limit see the Kubernetes
documentation
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;setting-a-cri-o-pid-limit&#34;&gt;Setting a CRI-O PID limit&lt;/h2&gt;
&lt;p&gt;Certain orchestrators or setups use CRI-O as the container runtime. Openshift
4.x currently has CRI-O set a PID limit of 1024 by default. To configure the
default CRI-O limit in Openshift 4.x see the RedHat documentation
&lt;a href=&#34;https://access.redhat.com/solutions/5305611&#34;&gt;here&lt;/a&gt;. To configure CRI-O more
generally see the CRI-O documentation
&lt;a href=&#34;https://github.com/cri-o/cri-o/blob/master/docs/crio.conf.5.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Best Practices</title>
      <link>/docs/best-practices/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/best-practices/</guid>
      <description>
        
        
        &lt;h2 id=&#34;etcd---in-cluster---replicas-and-availability-zones&#34;&gt;Etcd - In Cluster - Replicas and Availability Zones&lt;/h2&gt;
&lt;p&gt;We recommend running etcd with 5 replicas (etcd peers) and spreading them across availability zones when running etcd inside the cluster, this improves the resiliency of the etcd cluster. This is done by default when installing via the plugin or helm.&lt;/p&gt;
&lt;h2 id=&#34;etcd-low-latency-io&#34;&gt;Etcd low latency IO&lt;/h2&gt;
&lt;p&gt;It is recommended to run etcd on low-latency disks and keep other IO-intensive
applications separate from the etcd nodes. Etcd is very sensitive to IO latency.
Thus, the effect of disk contention can cause etcd downtime.&lt;/p&gt;
&lt;p&gt;Batch jobs such as backups, builds or application bundling can easily cause a
high usage of disks making etcd unstable. It is recommended to run such
workloads apart from the etcd servers.&lt;/p&gt;
&lt;h2 id=&#34;setup-of-storage-on-the-hosts&#34;&gt;Setup of storage on the hosts&lt;/h2&gt;
&lt;p&gt;We recommend creating a separate filesystem for Ondat to mitigate the risk
of filling the root filesystem on nodes. This has to be done for each node in
the cluster.&lt;/p&gt;
&lt;p&gt;Follow the &lt;a href=&#34;/docs/operations/managing-host-storage&#34;&gt;managing host storage&lt;/a&gt; best practices page for more
details.&lt;/p&gt;
&lt;h2 id=&#34;resource-reservations&#34;&gt;Resource reservations&lt;/h2&gt;
&lt;p&gt;Ondat resource consumption depends on the workloads and the Ondat
features in use.&lt;/p&gt;
&lt;p&gt;The recommended minimum memory reservation for the Ondat Pods is 512MB for
non-production environments. However it is recommended to prepare nodes so
Ondat can operate with at least with 1-2GB of memory. Ondat frees
memory when possible.&lt;/p&gt;
&lt;p&gt;For production environments, we recommend 4GB of Memory and 1 CPU as a minimum
and to test Ondat using realistic workloads and tune resources accordingly.&lt;/p&gt;
&lt;p&gt;Ondat Pods resource allocation will impact directly on the availability of
volumes in case of eviction or resource limit triggered restart. It is
recommended to not limit Ondat Pods.&lt;/p&gt;
&lt;p&gt;Ondat implements a storage engine, therefore limiting CPU consumption might
affect the I/O throughput of your volumes.&lt;/p&gt;
&lt;h2 id=&#34;setting-a-kubernetes-pid-limit&#34;&gt;Setting a Kubernetes PID limit&lt;/h2&gt;
&lt;p&gt;Ondat recommends that a PID cgroup limit of 32768 be set. Ondat is a
multi-threaded application and while most Kubernetes distributions set the PID
cgroup limit to 32768, some environments can set a limit as low as 1024. The
Ondat init container will print a log message warning if the PID cgroup
limit is too low. See our &lt;a href=&#34;/docs/prerequisites/pidlimits&#34;&gt;prerequisites&lt;/a&gt; for
more information.&lt;/p&gt;
&lt;h2 id=&#34;maintain-a-sufficient-number-of-nodes-for-replicas-to-be-created&#34;&gt;Maintain a sufficient number of nodes for replicas to be created&lt;/h2&gt;
&lt;p&gt;To ensure that a new replica can always be created, an additional node should
be available. To guarantee high availability, clusters using Volumes with 1
replica must have at least 3 storage nodes. When using Volumes with 2
replicas, at least 4 storage nodes, 3 replicas, 5 nodes, etc.&lt;/p&gt;
&lt;p&gt;Minimum number of storage nodes = 1 (primary) + N (replicas) + 1&lt;/p&gt;
&lt;p&gt;For more information, see the section on
&lt;a href=&#34;/docs/concepts/replication#number-of-nodes&#34;&gt;replication&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;ondat-api-usernamepassword&#34;&gt;Ondat API username/password&lt;/h2&gt;
&lt;p&gt;The API grants full access to Ondat functionality, therefore we recommend
that the default administrative password of &amp;lsquo;storageos&amp;rsquo; is reset to something
unique and strong.&lt;/p&gt;
&lt;p&gt;You can change the default parameters by encoding the &lt;code&gt;username&lt;/code&gt; and
&lt;code&gt;password&lt;/code&gt; values (in base64) into the &lt;code&gt;storageos-api&lt;/code&gt; secret.&lt;/p&gt;
&lt;p&gt;To generate a unique password, a technique such as the following, which
generates a pseudo-random 24 character string, may be used:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Generate strong password&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;cat -e /dev/urandom &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; tr -dc &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;a-zA-Z0-9-!@#$%^&amp;amp;*()_+~&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; fold -w &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;24&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; head -n 1&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Convert password to base64 representation for embedding in a K8S secret&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;BASE64PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; -n &lt;span style=&#34;color:#000&#34;&gt;$PASSWORD&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; base64&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that the Kubernetes secret containing a strong password &lt;em&gt;must&lt;/em&gt; be created
before bootstrapping the cluster. Multiple installation procedures use this
Secret to create an Ondat account when the cluster first starts.&lt;/p&gt;
&lt;h2 id=&#34;ondat-pod-placement&#34;&gt;Ondat Pod placement&lt;/h2&gt;
&lt;p&gt;Ondat must run on all nodes that will contribute storage capacity to the
cluster or that will host Pods which use Ondat volumes. For production
environments, it is recommended to avoid placing Ondat Pods on Master
nodes.&lt;/p&gt;
&lt;p&gt;Ondat is deployed with a DaemonSet controller, and therefore tolerates the
standard unschedulable (:NoSchedule) action. If that is the only taint placed
on master or cordoned nodes Ondat pods might start on them (see the
Kubernetes
&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34;&gt;docs&lt;/a&gt;
for more details). To avoid scheduling Ondat pods on master nodes, you can
add an arbitrary taint to them for which the Ondat DaemonSet won&amp;rsquo;t have a
toleration.&lt;/p&gt;
&lt;h2 id=&#34;dedicated-instance-groups&#34;&gt;Dedicated instance groups&lt;/h2&gt;
&lt;p&gt;Cloud environments give users the ability to quickly scale the number of nodes
in a cluster in response to their needs. Because of the ephemeral nature of the
cloud, Ondat recommends setting conservative downscaling policies.&lt;/p&gt;
&lt;p&gt;For production clusters, it recommended to use dedicated instance groups for
Stateful applications that allow the user to set different scaling policies and
define Ondat pools based on node selectors to collocate volumes.&lt;/p&gt;
&lt;p&gt;Losing a few nodes at the same time could cause the loss of data even when
volume replicas are being used.&lt;/p&gt;
&lt;h2 id=&#34;port-blocking&#34;&gt;Port blocking&lt;/h2&gt;
&lt;p&gt;Ondat exposes ports to operate. It is recommended that the &lt;a href=&#34;/docs/prerequisites/firewalls&#34;&gt;ports&lt;/a&gt; are not accessible from outside
the scope of your cluster.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Max AIO</title>
      <link>/docs/prerequisites/max-aio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/max-aio/</guid>
      <description>
        
        
        &lt;p&gt;As part of the dataplane operation, Ondat uses Linux AIO (Asynchronous
Input Output) contexts to serve I/O requests without blocking. Ondat
requires 4 AIO contexts per deployment (i.e. an Ondat volume deployment,
whether master or replica).&lt;/p&gt;
&lt;h2 id=&#34;max-aio-prerequisite&#34;&gt;Max AIO prerequisite&lt;/h2&gt;
&lt;p&gt;By default there is a maximum number of AIO contexts that can be allocated at
once.&lt;/p&gt;
&lt;p&gt;The current and maximum number of AIO requests is visible in the virtual
files &lt;code&gt;/proc/sys/fs/aio-nr&lt;/code&gt; and &lt;code&gt;/proc/sys/fs/aio-max-nr&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The default context limit has been set at 2^16 or 65536. This figure may vary
so do check your &lt;code&gt;/proc/sys/fs/aio-max-nr&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;aio-nr&lt;/code&gt; reaches &lt;code&gt;aio-max-nr&lt;/code&gt; the &lt;code&gt;io_setup&lt;/code&gt; syscall will fail with
EAGAIN. For more information see the Linux kernel docs
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/sysctl/fs.txt&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;why-is-this-relevant&#34;&gt;Why is this relevant?&lt;/h2&gt;
&lt;p&gt;As Ondat requires 4 AIO contexts per deployed volume, there is a limit to
the number of volumes that can be deployed per node. Trying to provision
additional deployments once the &lt;code&gt;aio-max-nr&lt;/code&gt; has been reached will fail as the
kernel will be unable to create enough new AIO contexts.&lt;/p&gt;
&lt;h2 id=&#34;increasing-your-aio-context-cap&#34;&gt;Increasing your AIO context cap&lt;/h2&gt;
&lt;p&gt;If your nodes &lt;code&gt;aio-max-nr&lt;/code&gt; is set too low you can either provision additional
nodes to reduce the number of deployments per node, or increase the &lt;code&gt;aio-max-nr&lt;/code&gt;
kernel parameter.&lt;/p&gt;
&lt;p&gt;You can do this by editing your &lt;code&gt;/etc/sysctl.conf&lt;/code&gt; file with the following
example line:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;fs.aio-max-nr &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1048576&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To activate the new settings, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sysctl -p /etc/sysctl.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Etcd in Kubernetes</title>
      <link>/docs/prerequisites/etcd/etcd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/etcd/etcd/</guid>
      <description>
        
        
        &lt;p&gt;Ondat requires an etcd cluster in order to function. For more information on
why etcd is required, see our &lt;a href=&#34;/docs/concepts/etcd&#34;&gt;etcd concepts&lt;/a&gt; page.&lt;/p&gt;
&lt;p&gt;Neither Ondat nor Kubernetes support using Kubernetes&#39; own internal etcd for Ondat.&lt;/p&gt;
&lt;p&gt;For most use-cases it is recommended to install the Ondat etcd operator that
will manage creation and maintenance of Ondat&amp;rsquo;s required etcd cluster. In some
circumstances, eg. when cloud storage technologies are not available,
it makes sense to install etcd on separate machines outside of
your Kubernetes cluster.&lt;/p&gt;
&lt;h2 id=&#34;installing-etcd-into-your-kubernetes-cluster&#34;&gt;Installing Etcd Into Your Kubernetes Cluster&lt;/h2&gt;
&lt;p&gt;This is our recommended way to host etcd in both testing and production
environments.&lt;/p&gt;
&lt;h2 id=&#34;configuring-storage-for-etcd&#34;&gt;Configuring Storage for Etcd&lt;/h2&gt;
&lt;p&gt;We highly recommend using cloud provider network attached disks for storing
etcd data, such as EBS volumes, Google Persistent Disks, Azure Disks, etc. This
allows the etcd operator to recover from node failures.&lt;/p&gt;
&lt;p&gt;For testing environments or where there are no resilient storage options available,
a node-local storage option can be used, such as
&lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt;.
This will store etcd data on the node hosting an etcd pod&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended when other, better
storage classes are not available, as this stores
all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which
makes it susceptible to state being lost on node failures.
In the case of &lt;code&gt;local-path&lt;/code&gt; storage, a minimum of 5 etcd nodes
is recommended to increase resilience.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;installing-etcd&#34;&gt;Installing Etcd&lt;/h2&gt;
&lt;p&gt;An etcd cluster can be created in three different ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Installing the etcd operator via our helm chart&lt;/li&gt;
&lt;li&gt;Installing Ondat (and the etcd operator) via our Plugin&lt;/li&gt;
&lt;li&gt;Manually deploying the etcd operator and applying an &lt;code&gt;etcdcluster&lt;/code&gt; custom resource&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;recommended-installing-the-etcd-operator-via-our-helm-chart&#34;&gt;&lt;strong&gt;Recommended:&lt;/strong&gt; Installing the etcd operator via our helm chart&lt;/h3&gt;
&lt;p&gt;For full instructions, visit &lt;a href=&#34;https://github.com/ondat/charts/tree/main/charts/ondat&#34;&gt;Ondat Helm
Chart&lt;/a&gt; repository.&lt;/p&gt;
&lt;h3 id=&#34;recommended-installing-ondat-and-the-etcd-operator-via-our-plugin&#34;&gt;&lt;strong&gt;Recommended:&lt;/strong&gt; Installing Ondat (and the etcd operator) via our Plugin&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl storageos install \
    --include-etcd \
    --etcd-storage-class &amp;lt;the storage class you want to use for etcd&amp;gt; \
    --etcd-tls-enabled
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;configurable-manually-applying-an-etcdcluster-custom-resource&#34;&gt;&lt;strong&gt;Configurable:&lt;/strong&gt; Manually applying an &lt;code&gt;etcdcluster&lt;/code&gt; custom resource&lt;/h3&gt;
&lt;p&gt;This installation method allows the most configuration of the etcd cluster, but
is error-prone and therefore not recommended in situations in which the Helm chart
or plugin can be used, instead.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Manually applying an &lt;code&gt;etcdcluster&lt;/code&gt; custom resource&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;recommended-installing-the-etcd-operator-via-our-helm-chart-1&#34;&gt;Recommended: Installing the etcd operator via our helm chart&lt;/h3&gt;
&lt;p&gt;For full instructions, visit &lt;a href=&#34;https://github.com/ondat/charts/tree/main/charts/ondat&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;recommended-installing-ondat-and-the-etcd-operator-via-our-plugin-1&#34;&gt;Recommended: Installing Ondat (and the etcd operator) via our Plugin&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl storageos install \
    --include-etcd \
    --etcd-storage-class &amp;lt;the storage class you want to use for etcd&amp;gt; \
    --etcd-tls-enabled
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;manually-applying-an-etcdcluster-custom-resource&#34;&gt;Manually applying an &lt;code&gt;etcdcluster&lt;/code&gt; custom resource&lt;/h3&gt;
&lt;p&gt;This installation method allows the most configuration of the etcd cluster, but
is error-prone and therefore not recommended in situations in which the Helm chart
or plugin can be used, instead.&lt;/p&gt;
&lt;p&gt;Find the verison of the etcd operator you want to install from
&lt;a href=&#34;https://github.com/storageos/etcd-cluster-operator/releases/&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Install the etcd operator:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;export ETCD_OPERATOR_VERSION=&amp;lt;set the version you want to use&amp;gt;
kubectl apply -f https://github.com/storageos/etcd-cluster-operator/releases/download/${ETCD_OPERATOR_VERSION}/storageos-etcd-cluster-operator.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then adapt the following sample to your needs and use &lt;code&gt;kubectl&lt;/code&gt; to  apply it:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;export ETCD_OPERATOR_VERSION=&amp;lt;set the version you want to use&amp;gt;
wget https://github.com/storageos/etcd-cluster-operator/releases/download/${ETCD_OPERATOR_VERSION}/storageos-etcd-cluster.yaml
vim storageos-etcd-cluster.yaml
kubectl apply -f storageos-etcd-cluster.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;installation-verification&#34;&gt;Installation Verification&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ kubectl -n storageos-etcd get pod,svc,pdb
NAME                                                     READY   STATUS    RESTARTS   AGE
pod/storageos-etcd-0-28m5t                               1/1     Running   0          18h
pod/storageos-etcd-1-2lpn9                               1/1     Running   0          18h
pod/storageos-etcd-2-dpdz6                               1/1     Running   0          18h
pod/storageos-etcd-3-7lsmz                               1/1     Running   0          18h
pod/storageos-etcd-4-q5xjd                               1/1     Running   0          18h
pod/storageos-etcd-controller-manager-6f5776c64f-dhp7r   1/1     Running   0          18h
pod/storageos-etcd-controller-manager-6f5776c64f-vvxrr   1/1     Running   0          18h
pod/storageos-etcd-proxy-96bf4bb5f-z5m7f                 1/1     Running   0          18h

NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE
service/storageos-etcd         ClusterIP   None            &amp;lt;none&amp;gt;        2379/TCP,2380/TCP   18h
service/storageos-etcd-proxy   ClusterIP   10.43.199.194   &amp;lt;none&amp;gt;        80/TCP              18h

NAME                                        MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
poddisruptionbudget.policy/storageos-etcd   3               N/A               2                     18h
&lt;/code&gt;&lt;/pre&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Etcd outside the cluster</title>
      <link>/docs/prerequisites/etcd/etcd-outside-the-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/etcd/etcd-outside-the-cluster/</guid>
      <description>
        
        
        &lt;p&gt;This page documents the process for installing etcd outside the Kubernetes
cluster.&lt;/p&gt;
&lt;p&gt;In some circumstances it can make sense to run etcd outside of Kubernetes. One
example is when running an on-premises Kubernetes cluster, if you do not
have access to reliable cloud disks to provide high availability to etcd data.&lt;/p&gt;
&lt;p&gt;For production installations running etcd outside the cluster, Ondat strongly
recommends running etcd on a minimum of 3 dedicated virtual machines. This
topology offers strong guarantees of resilience and uptime.&lt;/p&gt;
&lt;p&gt;Ondat doesn&amp;rsquo;t require a high performance etcd cluster as the throughput of
metadata to the cluster is low. However, we recommend a careful assessment of
IOPS capacity &lt;a href=&#34;/docs/operations/etcd/&#34;&gt;best practices&lt;/a&gt; to ensure that etcd
operates normally.&lt;/p&gt;
&lt;p&gt;You can choose between two installation options.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#installation---manual&#34;&gt;Manual Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#installation---ansible&#34;&gt;Ansible Installation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;installation---manual&#34;&gt;Installation - Manual&lt;/h3&gt;
&lt;p&gt;This section documents the steps required for manual installation of etcd
using standard package management commands and systemd manifests.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Repeat the following steps on all the nodes that will run etcd as a
systemd service.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Configure Etcd version and ports&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;3.4.9&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLIENT_PORT&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;2379&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;2380&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è &lt;strong&gt;If targeting Kubernetes Master nodes, you must change
&lt;code&gt;CLIENT_PORT&lt;/code&gt;, &lt;code&gt;PEERS_PORT&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download Etcd from CoreOS official site&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -L https://github.com/coreos/etcd/releases/download/v&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ETCD_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/etcd-v&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ETCD_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;-linux-amd64.tar.gz -o /tmp/etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ETCD_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;-linux-amd64.tar.gz
mkdir -p /tmp/etcd-v&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ETCD_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;-linux-amd64
tar -xzvf /tmp/etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ETCD_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;-linux-amd64.tar.gz -C /tmp/etcd-v&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ETCD_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;-linux-amd64 --strip-components&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;
rm /tmp/etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ETCD_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;-linux-amd64.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install Etcd binaries&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; /tmp/etcd-v&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ETCD_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;-linux-amd64
mv etcd /usr/local/sbin/etcd3
mv etcdctl /usr/local/sbin/etcdctl
chmod &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0755&lt;/span&gt; /usr/local/sbin/etcd3 /usr/local/sbin/etcdctl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set up persistent Etcd data directory&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir /var/lib/storageos-etcd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the systemd environment file&lt;/p&gt;
&lt;p&gt;On all nodes that will run etcd create a systemd environment file
&lt;code&gt;/etc/etcd.conf&lt;/code&gt; which has the IPs of all the nodes. The &lt;code&gt;NODE_IP&lt;/code&gt; will
need to change to correspond to the node IP where the environment file
resides. &lt;code&gt;NODE1_IP&lt;/code&gt;, &lt;code&gt;NODE2_IP&lt;/code&gt; and &lt;code&gt;NODE3_IP&lt;/code&gt; will remain the same across
all three files.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ cat &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;END &amp;gt; /etc/etcd.conf
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;# NODE_IP is the IP of the node where this file resides.
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;NODE_IP=10.64.10.228
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;# Node 1 IP
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;NODE1_IP=10.64.10.228
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;# Node 2 IP
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;NODE2_IP=10.64.14.233
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;# Node 3 IP  
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;NODE3_IP=10.64.12.111
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;CLIENT_PORT=${CLIENT_PORT}
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;PEERS_PORT=${PEERS_PORT}
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;END&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Verify that variables are expanded in the file&lt;/span&gt;
$ cat /etc/etcd.conf

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the systemd unit file for etcd3 service&lt;/p&gt;
&lt;p&gt;Create a systemd unit file &lt;code&gt;/etc/systemd/system/etcd3.service&lt;/code&gt; with the
following information:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;Unit&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;Description&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;etcd3
&lt;span style=&#34;color:#000&#34;&gt;Documentation&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;https://github.com/coreos/etcd
&lt;span style=&#34;color:#000&#34;&gt;Conflicts&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;etcd2.service

&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;Service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;Type&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;notify
&lt;span style=&#34;color:#000&#34;&gt;Restart&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;always
&lt;span style=&#34;color:#000&#34;&gt;RestartSec&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;5s
&lt;span style=&#34;color:#000&#34;&gt;LimitNOFILE&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;40000&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;TimeoutStartSec&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;EnvironmentFile&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;/etc/etcd.conf

&lt;span style=&#34;color:#000&#34;&gt;ExecStart&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;/usr/local/sbin/etcd3 --name etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --heartbeat-interval &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;500&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --election-timeout &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;5000&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --max-snapshots &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;10&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --max-wals &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;10&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --data-dir /var/lib/storageos-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --quota-backend-bytes &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;8589934592&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --snapshot-count &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;100000&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --auto-compaction-retention &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20000&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --auto-compaction-mode revision &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --initial-cluster-state new &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --initial-cluster-token etcd-token &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --listen-client-urls http://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLIENT_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;,http://127.0.0.1:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLIENT_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --advertise-client-urls http://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLIENT_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --listen-peer-urls http://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --initial-advertise-peer-urls http://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --initial-cluster etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE1_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;http://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE1_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;,etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE2_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;http://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE2_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;,etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE3_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;http://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE3_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;


&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;Install&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;WantedBy&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;üí° &lt;code&gt;$NODE_IP&lt;/code&gt; is the IP address of the machine you are installing etcd on.`&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è Note that setting the advertise-client-urls incorrectly will cause any
client connection to fail. Ondat will fail to communicate to Etcd.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è If enabling TLS, it is recomended to generate your own CA certificate
and key. You will need to distribute the keys and certificates for the
client auth on all etcd nodes. Moreover, the &lt;code&gt;ExecStart&lt;/code&gt; value should
look as below:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;    &lt;span style=&#34;color:#000&#34;&gt;ExecStart&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;/usr/local/sbin/etcd3 --name etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --heartbeat-interval &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;500&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --election-timeout &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;5000&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --max-snapshots &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;10&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --max-wals &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;10&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --data-dir /var/lib/storageos-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --quota-backend-bytes &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;8589934592&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --snapshot-count &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;100000&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --auto-compaction-retention &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20000&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --auto-compaction-mode revision &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --peer-auto-tls &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --client-cert-auth --trusted-ca-file&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;/path/to/client-cert.pem &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --cert-file&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;/path/to/ca.pem &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --key-file&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;/path/to/client-key.pem &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --initial-cluster-state new &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --initial-cluster-token etcd-token &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --listen-client-urls https://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLIENT_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --advertise-client-urls https://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLIENT_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --listen-peer-urls https://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --initial-advertise-peer-urls https://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --initial-cluster etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE1_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;https://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE1_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;,etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE2_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;https://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE2_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;,etcd-&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE3_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;https://&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NODE3_IP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PEERS_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reload and start the etc3 systemd service&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;systemctl daemon-reload
systemctl &lt;span style=&#34;color:#204a87&#34;&gt;enable&lt;/span&gt; etcd3.service
systemctl start  etcd3.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Installation Verification&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° The &lt;code&gt;etcdctl&lt;/code&gt; binary is installed at &lt;code&gt;/usr/local/bin&lt;/code&gt; on the nodes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ssh &lt;span style=&#34;color:#000&#34;&gt;$NODE&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Any node running the new etcd&lt;/span&gt;
$ &lt;span style=&#34;color:#000&#34;&gt;ETCDCTL_API&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt; etcdctl --endpoints&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;http://127.0.0.1:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CLIENT_PORT&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; member list &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# $NODE_IP - the IP of the node&lt;/span&gt;
66946cff1224bb5, started, etcd-b94bqkb9rf,  http://172.28.0.1:2380, http://172.28.0.1:2379
17e7256953f9319b, started, etcd-gjr25s4sdr, http://172.28.0.2:2380, http://172.28.0.2:2379
8b698843a4658823, started, etcd-rqdf9thx5p, http://172.28.0.3:2380, http://172.28.0.3:2379
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Read the &lt;a href=&#34;/docs/operations/etcd/&#34;&gt;etcd operations&lt;/a&gt;
page for our etcd recommendations.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;installation---ansible&#34;&gt;Installation - Ansible&lt;/h3&gt;
&lt;p&gt;For a repeatable and automated installation, use of a configuration management
tool such as ansible is recommended. Ondat provides an ansible playbook to
help you deploy etcd on standalone virtual machines.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Clone Ondat deployment repository&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/storageos/deploy.git
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; k8s/deploy-storageos/etcd-helpers/etcd-ansible-systemd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit the inventory file&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° The inventory file targets the nodes that will run etcd. The file
&lt;code&gt;hosts&lt;/code&gt; is an example of such an inventory file.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ cat hosts
&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;nodes&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;
centos-1 &lt;span style=&#34;color:#000&#34;&gt;ip&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;10.64.10.228&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;fqdn&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ip-10-64-10-228.eu-west-2.compute.internal&amp;#34;&lt;/span&gt;
centos-2 &lt;span style=&#34;color:#000&#34;&gt;ip&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;10.64.14.233&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;fqdn&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ip-10-64-14-233.eu-west-2.compute.internal&amp;#34;&lt;/span&gt;
centos-3 &lt;span style=&#34;color:#000&#34;&gt;ip&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;10.64.12.111&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;fqdn&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ip-10-64-12-111.eu-west-2.compute.internal&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Edit the inventory file&lt;/span&gt;
$ vi hosts &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Or your own inventory file&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è The ip or fqdn are used to expose the advertise-client-urls of Etcd.
Failing to provide valid ip/fqdn will cause any client connection to
fail. Ondat will fail to communicate to Etcd.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit the etcd configuration&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ö†Ô∏è  &lt;strong&gt;If targeting Kubernetes Master nodes, you must change
&lt;code&gt;etcd_port_client&lt;/code&gt;, &lt;code&gt;etcd_port_peers&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ cat group_vars/all
etcd_version: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;3.4.9&amp;#34;&lt;/span&gt;
etcd_port_client: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;2379&amp;#34;&lt;/span&gt;
etcd_port_peers: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;2380&amp;#34;&lt;/span&gt;
etcd_quota_bytes: &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;8589934592&lt;/span&gt;  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# 8 GB&lt;/span&gt;
etcd_auto_compaction_mode: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;revision&amp;#34;&lt;/span&gt;
etcd_auto_compaction_retention: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;1000&amp;#34;&lt;/span&gt;
members: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;{{ groups[&amp;#39;nodes&amp;#39;] }}&amp;#34;&lt;/span&gt;
installation_dir: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;/var/lib/storageos-etcd&amp;#34;&lt;/span&gt;
advertise_format: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;fqdn&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# fqdn || ip&lt;/span&gt;
backup_file: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;/tmp/backup.db&amp;#34;&lt;/span&gt;

tls:
  enabled: &lt;span style=&#34;color:#204a87&#34;&gt;false&lt;/span&gt;
  ca_common_name: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;eu-west-2.compute.internal&amp;#34;&lt;/span&gt;
  etcd_common_name: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;*.eu-west-2.compute.internal&amp;#34;&lt;/span&gt;
  cert_dir: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;/etc/etcdtls&amp;#34;&lt;/span&gt;
  ca_cert_file: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;etcd-ca.pem&amp;#34;&lt;/span&gt;
  etcd_server_cert_file: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;server.pem&amp;#34;&lt;/span&gt;
  etcd_server_key_file: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;server-key.pem&amp;#34;&lt;/span&gt;
  etcd_client_cert_file: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;etcd-client.crt&amp;#34;&lt;/span&gt;
  etcd_client_key_file: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;etcd-client.key&amp;#34;&lt;/span&gt;

$ vi group_vars/all
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;üí° Choose between using IP addressing or FQDN in the &lt;code&gt;advertise_format&lt;/code&gt;
parameter. It allows you to decide how Etcd advertises its address to
clients. This is particularly relevant when using TLS.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° If enabling TLS, it is recomended to generate your own CA certificate
and key. You can do it by generating the CA from the machine running
Ansible by: &lt;code&gt;ansible-playbook create_ca.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ansible-playbook -i hosts install.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Installation Verification&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° The playbook installs the &lt;code&gt;etcdctl&lt;/code&gt; binary on the nodes, at
&lt;code&gt;/usr/local/bin&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ssh &lt;span style=&#34;color:#000&#34;&gt;$NODE&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Any node running the new etcd&lt;/span&gt;
$ &lt;span style=&#34;color:#000&#34;&gt;ETCDCTL_API&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt; etcdctl --endpoints&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;127.0.0.1:2379 member list
66946cff1224bb5, started, etcd-b94bqkb9rf,  http://172.28.0.1:2380, http://172.28.0.1:2379
17e7256953f9319b, started, etcd-gjr25s4sdr, http://172.28.0.2:2380, http://172.28.0.2:2379
8b698843a4658823, started, etcd-rqdf9thx5p, http://172.28.0.3:2380, http://172.28.0.3:2379
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;bind-etcd-ips-to-kubernetes-service&#34;&gt;Bind Etcd IPs to Kubernetes Service&lt;/h2&gt;
&lt;p&gt;Kubernetes external services use a DNS name to reference external endpoints,
making them easy to reference from inside the cluster.  You can use the example
from the &lt;a href=&#34;https://github.com/storageos/deploy/tree/master/k8s/deploy-storageos/etcd-helpers/etcd-external-svc&#34;&gt;helper GitHub
repository&lt;/a&gt;
to deploy the external Service. Using an external service can make monitoring
of etcd from Prometheus easier.&lt;/p&gt;
&lt;h2 id=&#34;using-etcd-with-ondat&#34;&gt;Using Etcd with Ondat&lt;/h2&gt;
&lt;p&gt;During installation of Ondat the &lt;code&gt;kvBackend.address&lt;/code&gt; parameter in the
&lt;code&gt;storageoscluster&lt;/code&gt; custom resource is used to specify the address of the etcd
cluster.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Support</title>
      <link>/docs/support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/support/</guid>
      <description>
        
        
        &lt;p&gt;When you need support, raise a ticket via our &lt;a href=&#34;https://support.ondat.io/&#34;&gt;Help Desk
portal&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is important to select the priority of your ticket in accordance with the severity. This helps us to route and prioritise your ticket accordingly.&lt;/p&gt;
&lt;p&gt;Responses to tickets will be cc&amp;rsquo;d via email.&lt;/p&gt;
&lt;p&gt;For personal support and general enquiries, join our &lt;a href=&#34;https://slack.storageos.com&#34;&gt;public Slack channel&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;information-to-include-in-tickets&#34;&gt;Information to include in tickets&lt;/h2&gt;
&lt;p&gt;To help us provide effective support, we request that you provide as much information as possible when contacting us. The list below is a suggested
starting point. Additionally, include anything specific, such as log entries, that may help us debug your issue.&lt;/p&gt;
&lt;h3 id=&#34;platform&#34;&gt;Platform&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cloud provider/Bare metal&lt;/li&gt;
&lt;li&gt;OS distribution and version&lt;/li&gt;
&lt;li&gt;Kernel version&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat&#34;&gt;Ondat&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Version of Ondat&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storageos get nodes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storageos get volumes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storageos describe volume VOL_ID&lt;/code&gt; # in case of issues with a specific volume&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;orchestrator-related-kubernetes-openshift-etc&#34;&gt;Orchestrator related (Kubernetes, OpenShift, etc)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Version and installation method&lt;/li&gt;
&lt;li&gt;Managed or self managed?&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl -n storageos get pod&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl -n storageos logs -lapp=storageos -c storageos&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl -n storageos get storageclass&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Specific for your namespaces: &lt;code&gt;kubectl describe pvc PVC_NAME&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Specific for your namespaces: &lt;code&gt;kubectl describe pod POD_NAME&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;environment-changes&#34;&gt;Environment Changes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Details of any recent changes to your environment such as planned
maintenance, node reboots, network failures, etcd outage, etc.. This can
help speed up ticket triage and resolution considerably&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-support-bundle&#34;&gt;Ondat Support Bundle&lt;/h3&gt;
&lt;p&gt;Ondat provides the ability to generate a support bundle that aggregates cluster information. See &lt;a href=&#34;/docs/reference/bundles/support_bundle&#34;&gt;Support Bundle&lt;/a&gt; for a list of what is included.&lt;/p&gt;
&lt;p&gt;Ondat engineers might ask for a support bundle to be generated during support cases.&lt;/p&gt;
&lt;p&gt;The information in the bundle is used only for support purposes, and will be removed once it is no longer needed. If the information is sensitive and can&amp;rsquo;t be given to Ondat, make sure that the support engineers have as much information about your environment as possible.&lt;/p&gt;
&lt;p&gt;Refer to the &lt;a href=&#34;/docs/reference/bundles/support_bundle&#34;&gt;Support Bundle&lt;/a&gt; documentation page for details of how to generate a bundle.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
