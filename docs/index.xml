<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> â€“ Documentation</title>
    <link>/docs/</link>
    <description>Recent content in Documentation on </description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: CSI Allowed Topologies</title>
      <link>/docs/concepts/csi-allowed-topologies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/csi-allowed-topologies/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is available in release &lt;code&gt;v2.9.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat allows use of CSI&amp;rsquo;s Allowed Topology feature, for ensuring volumes
are located in specified lists of topologies, where &amp;lsquo;topology&amp;rsquo; is taken to
mean a description of a node&amp;rsquo;s location, some sub-division of a cluster.&lt;/p&gt;
&lt;p&gt;In Kubernetes topologies are defined by node labels. As it stands, the only
label Ondat supports for this purpose is &lt;code&gt;topology.kubernetes.io/zone&lt;/code&gt;, the
Kubernetes&#39; default label for representing &amp;ldquo;a logical failure domain&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;when-to-use-csi-allowed-topologies&#34;&gt;When to use CSI Allowed Topologies&lt;/h3&gt;
&lt;p&gt;CSI Allowed Topologies allows you to configure the &amp;ldquo;topologies&amp;rdquo; that a volume
is allowed to be placed in, ensuring localised access for given workloads and
availibility zones.&lt;/p&gt;
&lt;p&gt;As such, an example use case would be for a workload that has an affinity
for a given region of a cluster, ensuring that a deployment of that workload&amp;rsquo;s
volume is always available in that same region for lowered latency and
fault-tolerance.&lt;/p&gt;
&lt;h3 id=&#34;detailed-csi-allowed-topologies-behaviour&#34;&gt;Detailed CSI Allowed Topologies Behaviour&lt;/h3&gt;
&lt;p&gt;Where T is the set of allowed topologies, D is the set of volume deployments
(primary &amp;amp; replicas) and |T| and |D| are the sizes of those respective sets,
Ondat&amp;rsquo;s provisioning behaviour is this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When |T|&amp;gt;|D| - All deployments are created on nodes within |D| unique topologies within T.&lt;/li&gt;
&lt;li&gt;When |T|=|D| - All topologies in T contain exactly one deployment.&lt;/li&gt;
&lt;li&gt;When |T|&amp;lt;|D| - All topologies in T contain at least one deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So all allowed topologies will be populated with deployments if able, and if
there are more deployments than allowed topologies those deployments can be
placed on other toplogies.&lt;/p&gt;
&lt;h2 id=&#34;how-to-use&#34;&gt;How to use&lt;/h2&gt;
&lt;p&gt;You can enable by applying a &lt;code&gt;storageos.com/fixed-topology: &amp;quot;true&amp;quot;&lt;/code&gt; label to
any PVC that uses a StorageClass with an &lt;code&gt;allowedTopologies&lt;/code&gt; block.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For more information on how to enable CSI Allowed Topologies for your
volumes, review the &lt;a href=&#34;/docs/operations/csi-allowed-topologies&#34;&gt;Ondat CSI Allowed Topologies&lt;/a&gt;
operations page.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;useful-links&#34;&gt;Useful links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The CSI spec&amp;rsquo;s definition of the Topology Requirement feature: &lt;a href=&#34;https://github.com/container-storage-interface/spec/blob/master/spec.md#controller-service-rpc&#34;&gt;https://github.com/container-storage-interface/spec/blob/master/spec.md#controller-service-rpc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Docs on Kubernetes&#39; CSI&amp;rsquo;s implementation of the CSI Topology Requirement feature: &lt;a href=&#34;https://kubernetes-csi.github.io/docs/topology.html#sidecar-deployment&#34;&gt;https://kubernetes-csi.github.io/docs/topology.html#sidecar-deployment&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Please note that there are discrepencies between this implementation and the original spec. In these cases the Kubernetes implementation should be seen to supersede.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The description of the &lt;code&gt;topology.kubernetes.io/zone&lt;/code&gt; label, with information on how it&amp;rsquo;s set by cloud providers: &lt;a href=&#34;https://kubernetes.io/docs/reference/labels-annotations-taints/#topologykubernetesiozone&#34;&gt;https://kubernetes.io/docs/reference/labels-annotations-taints/#topologykubernetesiozone&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install</title>
      <link>/docs/reference/operator/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/operator/install/</guid>
      <description>
        
        
        &lt;p&gt;To install the operator follow the installation page for your orchestrator.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;/docs/install/kubernetes&#34;&gt;Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/install/rancher&#34;&gt;Rancher&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/install/openshift&#34;&gt;OpenShift&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Kubernetes</title>
      <link>/docs/install/kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/kubernetes/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a
&lt;a href=&#34;https://kubernetes.io/docs/setup/&#34;&gt;Kubernetes&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat
kubectl plugin&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm
Chart&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For users who are looking to deploy Ondat onto a managed/specific Kubernetes
distribution such AKS, EKS, GKE, RKE or DOKS, a recommendation would be to
review the &lt;a href=&#34;https://docs.ondat.io/docs/install/&#34;&gt;Install&lt;/a&gt; section and choose
the appropriate installation guide for your Kubernetes distribution.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h3 id=&#34;1---cluster-and-node-prerequisites&#34;&gt;1 - Cluster and Node Prerequisites&lt;/h3&gt;
&lt;p&gt;The minimum cluster requirements for a &lt;strong&gt;non-production installation&lt;/strong&gt; of ondat
are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux with a 64-bit architecture&lt;/li&gt;
&lt;li&gt;2 vCPU and 4GB of RAM per node.&lt;/li&gt;
&lt;li&gt;3 worker nodes in the cluster and sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control
(RBAC)&lt;/a&gt;
permissions to deploy and manage applications in the cluster&lt;/li&gt;
&lt;li&gt;Make sure the OS on your nodes are compatible with Ondat. See the &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat
Prerequisites&lt;/a&gt; for all supported
linux distributions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a comprehensive list of prerequisites and how to build a &lt;strong&gt;production
installation&lt;/strong&gt; of Ondat please refer to &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat
Prerequisites&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2---client-tools-prerequisites&#34;&gt;2 - Client Tools Prerequisites&lt;/h3&gt;
&lt;p&gt;The following CLI utilities are installed on your local machine and available
in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat can be installed either via Helm Chart or using our command-line tool.
Depending on which installation method you choose you will require either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3---installing-a-local-path-provisioner&#34;&gt;3 - Installing a Local Path Provisioner&lt;/h3&gt;
&lt;p&gt;Depending on the kubernetes distro you are using there may not be any CSI
driver deployed. Run the following commands against the cluster to deploy a
&lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; and
make it the default storageclass to provide local storage for Ondat&amp;rsquo;s embedded
&lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.22/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
kubectl patch storageclass local-path -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;metadata&amp;#34;: {&amp;#34;annotations&amp;#34;:{&amp;#34;storageclass.kubernetes.io/is-default-class&amp;#34;:&amp;#34;true&amp;#34;}}}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Verify that the Local Path Provisioner was successfully deployed and ensure
that that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt; status, run the following &lt;code&gt;kubectl&lt;/code&gt;
commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;installation-of-ondat&#34;&gt;Installation of Ondat&lt;/h2&gt;
&lt;h3 id=&#34;step-1---adding-a-cluster&#34;&gt;Step 1 - Adding a Cluster&lt;/h3&gt;
&lt;p&gt;The Ondat Portal is how you can license and get the commands for installing Ondat&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Either login or create an account on the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat Portal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Choose the &amp;lsquo;Install Ondat on your cluster&amp;rsquo; or &amp;lsquo;Add cluster&amp;rsquo; options in the UI&lt;/li&gt;
&lt;li&gt;Add a Name for your cluster and where it is going to be located.  This will
allow you to view the same prerequisites as are listed above&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-2---choosing-the-installation-method&#34;&gt;Step 2 - Choosing the Installation Method&lt;/h3&gt;
&lt;p&gt;You can use either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt;
or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt; to install Ondat onto your
cluster.  The most common way is to use Helm due to its popularity in the
Kubernetes community, but both are fully supported and described below.&lt;/p&gt;
&lt;h3 id=&#34;step-3a---installing-via-helm&#34;&gt;Step 3a - Installing via Helm&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install
Ondat using Helm. The command created will be unique for you and the screenshot
below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/HelmInstall.png&#34; alt=&#34;Helm Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The first two lines of the command adds the Ondat Helm repository and ensures a
updated local cache.  The remaining command installs Ondat via Helm with a set
of basic install parameters that are sufficient for a basic trial installation
and to connect the Ondat installation with your portal account for licensing.
The installation process may take a few minutes. The end of this guide contains
information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-3b---installing-via-kubectl-storageos-plugin&#34;&gt;Step 3b - Installing via kubectl-storageos plugin&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install
Ondat using the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin.  The command created will be unique
for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/PluginInstall.png&#34; alt=&#34;kubectl-storageos Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The command that is provided by the Portal is unique to you and uses the
&lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with a set of basic install parameters that
are sufficient for a basic trial installation and to connect the Ondat
installation with your portal account for licensing. The installation process
may take a few minutes. The end of this guide contains information on verifying
the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h3&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core
components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once all the components are up and running the output should look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/InstallSuccess.png&#34; alt=&#34;Install Success&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-5---applying-a-licence-to-the-cluster&#34;&gt;Step 5 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;p&gt;Newly installed Ondat clusters must be licensed within 24 hours. For details of
our Community Edition and pricing see &lt;a href=&#34;https://www.ondat.io/pricing&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To licence your cluster with the community edition:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Clusters page select &amp;lsquo;View Details&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Click on &amp;lsquo;Change Licence&amp;rsquo;&lt;/li&gt;
&lt;li&gt;In the following pop-up select the &amp;lsquo;Community Licence&amp;rsquo; option then click &amp;lsquo;Generate&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This process generates a licence and installs it for you. Now you are good to
go!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Namespaces</title>
      <link>/docs/reference/namespaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/namespaces/</guid>
      <description>
        
        
        &lt;p&gt;Ondat namespaces are an identical concept to Kubernetes namespaces. They
are intended to allow an Ondat cluster to be used by multiple teams across
multiple projects.&lt;/p&gt;
&lt;p&gt;It is not necessary to create Ondat namespaces manually, as Ondat maps
Kubernetes namespaces on a one-to-one basis when PersistentVolumeClaims using
the Ondat StorageClass are created.&lt;/p&gt;
&lt;p&gt;ðŸ’¡ Access to Namespaces is controlled through user or group level &lt;a href=&#34;/docs/concepts/policies&#34;&gt;policies&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Cluster Topologies</title>
      <link>/docs/concepts/cluster-topologies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/cluster-topologies/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Ondat makes it possible for cluster administrators to design and implement different cluster topologies, depending on types of workloads, use cases, priorities and needs. The topology approaches recommended below are idealised representations of possible Ondat clusters and can be mixed, modified and changed at execution time.&lt;/p&gt;
&lt;p&gt;Ondat performs file Input/Output (I/O) operations over the network, which is how the platform ensures that data is always available throughout your cluster. This also affords cluster administrators certain possibilities of organising their clusters in ways explained below.&lt;/p&gt;
&lt;h3 id=&#34;hyper-converged-cluster-topology&#34;&gt;Hyper-converged Cluster Topology&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/hyperconverged.png&#34; alt=&#34;Hyper-converged Cluster Topology&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Hyper-converged_infrastructure&#34;&gt;&lt;em&gt;hyper-converged&lt;/em&gt;&lt;/a&gt; cluster topology model leverages the available block storage attached to all the worker nodes in a Kubernetes cluster, creating a single storage pool that stores and present data for stateful workloads deployed and running.
&lt;ul&gt;
&lt;li&gt;This cluster topology gives the best flexibility to Ondat and Kubernetes schedulers, and provides maximum choice for optimal pod placement when pods are being assigned to nodes in a cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;No matter how or where workloads are deployed on worker nodes, Ondat will ensure that the data from workloads is stored, persistent and always accessible.&lt;/li&gt;
&lt;li&gt;New Ondat deployments will place workloads locally where possible using this hyper-converged cluster topology out of the box.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;centralised-cluster-topology&#34;&gt;Centralised Cluster Topology&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/centralised.png&#34; alt=&#34;Centralised Cluster Topology&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;centralised&lt;/em&gt; cluster topology model leverages the available block storage attached to only a &lt;em&gt;subset&lt;/em&gt; of worker nodes (creating a dedicated, storage-optimised &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/node-pools&#34;&gt;node pool&lt;/a&gt;) in a Kubernetes cluster, whilst the rest of the worker nodes are dedicated to running general and compute-intensive workloads,
&lt;ul&gt;
&lt;li&gt;Deployed workloads in centralised cluster that require data persistency will access a dedicated storage pool that is located on the declared subset of worker nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This cluster topology can be beneficial if, for example, cluster administers want to take advantage and effectively utilise high performance-optimised hardware components of a particular set of worker nodes for different types of workloads being deployed.&lt;/li&gt;
&lt;li&gt;The cluster topology can also aid in avoiding downtime issues that can arise from unaccounted resource/capacity planning and allocation for workloads, since storage-optimised nodes and compute-optimised workloads are compartmentalised.&lt;/li&gt;
&lt;li&gt;In addition, another suitable use case for this topology is for elastic worker node fleets with burst-able workloads. A fleet can be quickly expanded with new worker nodes for compute-intensive workloads on demand, whilst maintaining a centralised data storage pool that is not impacted by rapid auto cluster scaling.&lt;/li&gt;
&lt;li&gt;To configure this cluster topology for a new Ondat deployment, cluster administrators would need to apply an Ondat node label called &lt;code&gt;storageos.com/computeonly&lt;/code&gt; to nodes, which would inform Ondat that it &lt;em&gt;should not&lt;/em&gt; use the nodes to join a storage pool.
&lt;ul&gt;
&lt;li&gt;Review the &lt;a href=&#34;/docs/operations/compute-only/&#34;&gt;Centralised Cluster Topology&lt;/a&gt; operations page for more information on how to use this topology model for your clusters.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Command Line Interface (CLI) Utility</title>
      <link>/docs/reference/cli/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cli/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The Ondat CLI is a utility tool that is used to manage and configure Ondat resources and conduct Day-2 storage operations. The Ondat CLI is also useful for providing useful information on the state of an Ondat cluster and troubleshooting issues.
&lt;ul&gt;
&lt;li&gt;The project repository is open source and can be located on &lt;a href=&#34;https://github.com/storageos/go-cli&#34;&gt;GitHub&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that you have successfully &lt;a href=&#34;/docs/install/&#34;&gt;installed Ondat&lt;/a&gt; into your Kubernetes or Openshift cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-install-the-ondat-cli&#34;&gt;How To Install The Ondat CLI&lt;/h2&gt;
&lt;h3 id=&#34;option-1---run-the-ondat-cli-as-a-deployment-recommended&#34;&gt;Option 1 - Run The Ondat CLI As A Deployment (Recommended)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following command below against your Ondat cluster which will deploy the Ondat CLI using a &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34;&gt;Kubernetes deployment&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Create the deployment for the Ondat CLI.&lt;/span&gt;
kubectl create --filename -&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;EOF
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: apps/v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: Deployment
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  labels:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    app: storageos-cli
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    app.kubernetes.io/component: storageos-cli
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    app.kubernetes.io/part-of: storageos
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    kind: storageos
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  name: storageos-cli
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  namespace: storageos
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;spec:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  replicas: 1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  selector:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    matchLabels:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;      app: storageos-cli
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  template:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;      labels:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;        app: storageos-cli
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    spec:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;      containers:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;        - command:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            - /bin/sh
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            - -c
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            - while true; do sleep 3600; done
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;          env:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            - name: STORAGEOS_USERNAME
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;              valueFrom:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;                secretKeyRef:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;                  name: storageos-api
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;                  key: username
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;                  optional: false
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            - name: STORAGEOS_PASSWORD
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;              valueFrom:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;                secretKeyRef:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;                  name: storageos-api
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;                  key: password
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;                  optional: false
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            - name: STORAGEOS_ENDPOINTS
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;              value: storageos:5705
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;          image: storageos/cli:v2.9.0
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;          imagePullPolicy: Always
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;          name: cli
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;          ports:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            - containerPort: 5705
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;          resources:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            limits:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;              cpu: 100m
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;              memory: 128Mi
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            requests:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;              cpu: 50m
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;              memory: 32Mi
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;          securityContext:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            allowPrivilegeEscalation: false
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;            readOnlyRootFilesystem: true
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;execute-commands-through-the-ondat-cli-deployment&#34;&gt;Execute Commands Through The Ondat CLI Deployment&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Once the Ondat CLI deployment resource has been successfully created, get the pod name and take note of it for later reference.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Get the pod name of the Ondat CLI utility.&lt;/span&gt;
kubectl get pods --namespace storageos &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-cli&amp;#34;&lt;/span&gt;

storageos-cli-75874cd77f-b5dgp                       1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;              35m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;You can then use &lt;a href=&#34;https://kubernetes.io/docs/tasks/debug/debug-application/get-shell-running-container/&#34;&gt;&lt;code&gt;kubectl-exec&lt;/code&gt;&lt;/a&gt; to run Ondat CLI commands in the container as demonstrated below;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; storageos-cli-75874cd77f-b5dgp -- storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Deploying the Ondat CLI as a deployment is the recommended method as the Ondat support bundle generation tool can automatically detect a deployment called &lt;code&gt;cli&lt;/code&gt; and warn you if you do not have the CLI installed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;option-2---run-the-ondat-cli-on-a-workstation&#34;&gt;Option 2 - Run The Ondat CLI On A Workstation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;To be able to interact and manage your Ondat cluster, ensure that you define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt;, &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; and &lt;code&gt;STORAGEOS_ENDPOINTS&lt;/code&gt; environment variables that will be used to manage your Ondat cluster through the CLI.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;                    
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Enter the endpoint address of Ondat&amp;#39;s REST API to access the cluster through the CLI.&lt;/span&gt;
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# When using &amp;#34;kubectl port-forward&amp;#34; to access the cluster, change the endpoint to &amp;#34;localhost:5705&amp;#34;.&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos.storageos.svc:5705&amp;#34;&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Once you have defined the environment variables above, install the Ondat CLI on one of the supported operating systems listed below;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;linux&#34;&gt;Linux&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl --silent --show-error --location --output storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  https://github.com/storageos/go-cli/releases/download/v2.9.0/storageos_linux_amd64 &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo mv storageos /usr/local/bin/ &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;CLI version installed:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;macos-darwin&#34;&gt;macOS (Darwin)&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl --silent --show-error --location --output storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  https://github.com/storageos/go-cli/releases/download/v2.9.0/storageos_darwin_amd64 &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo mv storageos /usr/local/bin/ &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;CLI version installed:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;windows&#34;&gt;Windows&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# PowerShell&lt;/span&gt;
Invoke-WebRequest https://github.com/storageos/go-cli/releases/download/v2.9.0/storageos_windows_amd64.exe -OutFile storageos.exe &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; Write-Host &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Plugin version installed:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; .&lt;span style=&#34;color:#4e9a06&#34;&gt;\s&lt;/span&gt;torageos.exe version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;execute-commands-through-the-ondat-cli-binary&#34;&gt;Execute Commands Through The Ondat CLI Binary&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Once you have successfully installed the Ondat CLI, you can leverage &lt;a href=&#34;https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/&#34;&gt;&lt;code&gt;kubectl port-forward&lt;/code&gt;&lt;/a&gt; to establish a connection with your Ondat cluster in order to be able to execute commands.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Change the &amp;#34;STORAGEOS_ENDPOINTS&amp;#34; to point to &amp;#34;localhost:5705&amp;#34;.&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;localhost:5705&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Use port forwarding to access the Ondat REST API locally.&lt;/span&gt;
kubectl port-forward service/storageos &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;5705&lt;/span&gt; --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# In a new shell, execute Ondat CLI commands to confirm that you can now interact with your Ondat cluster.&lt;/span&gt;
storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;usage&#34;&gt;Usage&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Get the version of the CLI utility installed;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Get more information on the available commands in the CLI utility;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos &lt;span style=&#34;color:#204a87&#34;&gt;help&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;Storage &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; Cloud Native Applications.

By using this product, you are agreeing to the terms of the the StorageOS Ltd. End
User Subscription Agreement &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;EUSA&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt; found at: https://storageos.com/legal/#eusa

To be notified about stable releases and latest features, sign up at https://my.storageos.com.

Usage:
  storageos &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;command&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;

Available Commands:
  apply       Make changes to existing resources
  attach      Attach a volume to a node
  cordon      Marks a node as cordoned
  create      Create new resources
  delete      Delete resources in the cluster
  describe    Fetch extended details &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; resources
  detach      Detach a volume from its current location
  get         Fetch basic details &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; resources
  &lt;span style=&#34;color:#204a87&#34;&gt;help&lt;/span&gt;        Help about any &lt;span style=&#34;color:#204a87&#34;&gt;command&lt;/span&gt;
  nfs         Make changes and attach nfs volumes
  uncordon    Marks a node as uncordoned
  update      Make changes to existing resources
  version     View version information &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; the StorageOS CLI

Flags:
      --cache-dir string        &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; the directory used by the StorageOS CLI to cache data that can be used &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; future commands &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;/Users/rodney/Library/Caches/storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
  -c, --config string           specifies the config file path &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;/Users/rodney/Library/Application Support/storageos/config.yaml&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
      --endpoints stringArray   &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; the list of endpoints which are used when connecting to the StorageOS API &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;http://localhost:5705&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;])&lt;/span&gt;
  -h, --help                    &lt;span style=&#34;color:#204a87&#34;&gt;help&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; storageos
  -n, --namespace string        specifies the namespace to operate within &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; commands that require one &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
      --no-auth-cache           disable the CLI&lt;span style=&#34;color:#a40000&#34;&gt;&amp;#39;&lt;/span&gt;s caching of authentication sessions
  -o, --output string           specifies the output format &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;one of &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;json yaml text&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;])&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
      --password string         &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; the StorageOS account password to authenticate with &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
      --timeout duration        &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; the timeout duration to use &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; execution of the &lt;span style=&#34;color:#204a87&#34;&gt;command&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;default 15s&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
      --use-ids                 specify existing StorageOS resources by their unique identifiers instead of by their names
      --username string         &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; the StorageOS account username to authenticate as &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;

Additional &lt;span style=&#34;color:#204a87&#34;&gt;help&lt;/span&gt; topics:
  storageos config-file View &lt;span style=&#34;color:#204a87&#34;&gt;help&lt;/span&gt; information &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; using a configuration file
  storageos env         View documentation &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; configuration settings which can be &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; in the environment
  storageos exitcodes   View documentation &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; the &lt;span style=&#34;color:#204a87&#34;&gt;exit&lt;/span&gt; codes used by the StorageOS CLI

Use &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos [command] --help&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; more information about a command.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Components</title>
      <link>/docs/concepts/components/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/components/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Ondat is a software-defined storage platform for running stateful applications in Kubernetes.&lt;/p&gt;
&lt;p&gt;Fundamentally, Ondat uses the storage attached to the nodes in the Ondat cluster to create and present virtual volumes into containers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Space on the host is consumed from the mount point &lt;code&gt;/var/lib/storageos/data&lt;/code&gt; - so it is recommended that &lt;a href=&#34;https://en.wikipedia.org/wiki/Disk_storage&#34;&gt;disk devices&lt;/a&gt; are used exclusively for Ondat, as described in the &lt;a href=&#34;/docs/operations/managing-host-storage&#34;&gt;Managing Host Storage&lt;/a&gt; operations page.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat is agnostic to the underlying storage and runs equally well on bare metal, in virtual machines or on cloud providers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/ondat-deployment.png&#34; alt=&#34;Ondat cluster Components Diagram&#34;&gt;&lt;/p&gt;
&lt;p&gt;Read about &lt;a href=&#34;https://www.ondat.io/platform/platform-overview&#34;&gt;the cloud native storage principles behind Ondat&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-native-ondat-components&#34;&gt;Kubernetes-native Ondat Components&lt;/h2&gt;
&lt;p&gt;Ondat is architected as a series of containers that fulfil separate, discrete functions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Below is a list of core Ondat components with a description for each components responsibilities &amp;amp; tasks:&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-operator&#34;&gt;Ondat Operator&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/storageos/operator&#34;&gt;&lt;strong&gt;Ondat Operator&lt;/strong&gt;&lt;/a&gt; is responsible for the creation and maintenance of the Ondat cluster.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This operator is primarily responsible for ensuring that all the relevant applications are running in your cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-api-manager&#34;&gt;Ondat API Manager&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/storageos/api-manager&#34;&gt;&lt;strong&gt;Ondat API Manager&lt;/strong&gt;&lt;/a&gt; acts as a middle-man between various APIs. It has all the capabilities of a &lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/operator/&#34;&gt;Kubernetes operator&lt;/a&gt; and is also able to communicate with the Ondat control plane API.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This application handles typical operator tasks like labelling or removing nodes from Ondat when removed from the Kubernetes. It is continually monitoring the state of the cluster and moving it towards the desired state when necessary.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-data-plane&#34;&gt;Ondat Data Plane&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Ondat Data Plane&lt;/strong&gt; is responsible for all &lt;a href=&#34;https://en.wikipedia.org/wiki/Input/output&#34;&gt;I/O operations&lt;/a&gt; path related tasks;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Reading_%28computer%29&#34;&gt;Reading&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Read%E2%80%93write_memory&#34;&gt;Writing&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Data_compression&#34;&gt;Compression&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_%28computing%29&#34;&gt;Caching&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-control-plane&#34;&gt;Ondat Control Plane&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Ondat Control Plane&lt;/strong&gt; is responsible for monitoring and maintaining the state of volumes and nodes in the cluster.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Control Plane and the Data Plane run together in a single container, managed by a daemonset.&lt;/li&gt;
&lt;li&gt;The Control Plane works with a dedicated &lt;a href=&#34;https://etcd.io/&#34;&gt;&lt;code&gt;etcd&lt;/code&gt;&lt;/a&gt; instance to maintain state consensus in your cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-scheduler&#34;&gt;Ondat Scheduler&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Ondat Scheduler&lt;/strong&gt; is responsible for scheduling applications on the same node as an application&amp;rsquo;s
volumes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ondat uses a custom &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/&#34;&gt;Kubernetes scheduler&lt;/a&gt; to handle pod placement, ensuring that volumes are deployed on the same nodes as the relevant workloads as often as possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-csi-helper&#34;&gt;Ondat CSI Helper&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/storageos/external-provisioner&#34;&gt;&lt;strong&gt;CSI Helper&lt;/strong&gt;&lt;/a&gt; is responsible for registering Ondat with Kubernetes as a CSI driver.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is necessary because the internal persistent volume controller running in Kubernetes controller-manager does not have any direct interfaces to CSI drivers.&lt;/li&gt;
&lt;li&gt;It monitors PVC objects created by users and creates/deletes volumes for them.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-node-guard&#34;&gt;Ondat Node Guard&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Ondat Node Guard&lt;/strong&gt; is a key component of the &lt;a href=&#34;/docs/concepts/rolling-upgrades/&#34;&gt;Ondat Rolling Upgrade Protection for Orchestrators&lt;/a&gt; feature. It blocks certain nodes from being upgraded or drained thus avoiding data loss in the cluster.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Node Guard will detect if a volume is reconciling (for example, one that does not have enough synced replicas), at which point a node manager pod on the same node as the reconciling volume&amp;rsquo;s master and replicas become unready.&lt;/li&gt;
&lt;li&gt;Ondat uses a &lt;a href=&#34;https://kubernetes.io/docs/tasks/run-application/configure-pdb/&#34;&gt;PodDisruptionBudget (PDB)&lt;/a&gt; to stop more than &lt;code&gt;1&lt;/code&gt; node manager pod being unavailable at any point in time. This prevents the rolling upgrade from continuing until the PDB is satisfied and all volumes have fully reconciled.&lt;/li&gt;
&lt;li&gt;If the PDB is set to &lt;code&gt;1&lt;/code&gt; and a Control Plane volume on a node is not ready for a long period of time, this will stop the upgrade process. The &lt;code&gt;api-managercomponent&lt;/code&gt; will be able to dynamically set the PDB value if it can determine the health of the volume.&lt;/li&gt;
&lt;li&gt;If the &lt;code&gt;api-managercomponent&lt;/code&gt; knows that a volume will not be ready, it can increase the PDB &lt;code&gt;maxUnavailable&lt;/code&gt; value, allowing the upgrade to continue. The Node Guard container will log when it is available to upgrade, it will also log the reason if upgrade is not possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ The Node Guard container only monitors volumes that host a deployment on its node (for example, it doesnâ€™t care if a volume is unhealthy if the node it&amp;rsquo;s running on hosts none of the volumes primary and replicas)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ There is some latency between a volume becoming unhealthy and the Node Guard noticing, due to the polling nature of both the &lt;code&gt;api-managercomponent&lt;/code&gt; volume sync Kubernetes readiness endpoints)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;ondat-node-manager&#34;&gt;Ondat Node Manager&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Ondat Node Manager&lt;/strong&gt; is an out-of-band pod used for node management. It runs on all nodes that run the &lt;code&gt;StorageOS&lt;/code&gt; node container and is a separate pod so that it can be restarted independently of the node container.&lt;/p&gt;
&lt;h2 id=&#34;putting-it-all-together&#34;&gt;Putting It All Together&lt;/h2&gt;
&lt;p&gt;Ondat is deployed by the &lt;strong&gt;Ondat Operator&lt;/strong&gt;. In Kubernetes, the Ondat &lt;strong&gt;Control Plane&lt;/strong&gt; and &lt;strong&gt;Data Plane&lt;/strong&gt; are deployed in a single pod managed by a &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34;&gt;daemonset&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This daemonset runs on every node in the cluster that will consume or present storage.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;strong&gt;Ondat Scheduler&lt;/strong&gt;, &lt;strong&gt;CSI Helper&lt;/strong&gt;, &lt;strong&gt;Operator&lt;/strong&gt; and &lt;strong&gt;API Manager&lt;/strong&gt; run as separate &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/&#34;&gt;pods&lt;/a&gt; and are controlled as &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34;&gt;deployments&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ondat is designed to feel familiar to Kubernetes users. Storage is managed through standard &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/storage-classes/&#34;&gt;StorageClasses&lt;/a&gt; , &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;PersistentVolumeClaims&lt;/a&gt;, and &lt;a href=&#34;/docs/concepts/labels&#34;&gt;Ondat features&lt;/a&gt; are controlled by &lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/&#34;&gt;Kubernetes labels and selectors&lt;/a&gt;, prefixed with &lt;code&gt;storageos.com/&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;By default, volumes are cached to improve read performance and compressed to reduce network traffic.&lt;/li&gt;
&lt;li&gt;Any pod may mount an Ondat virtual volume from any node that is also running Ondat, regardless of whether the pod and volume are collocated on the same node. Therefore, applications may be started or restarted on any node and access volumes transparently.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Compression</title>
      <link>/docs/concepts/compression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/compression/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is disabled by default in release &lt;code&gt;v2.2.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;data-compression&#34;&gt;Data Compression&lt;/h3&gt;
&lt;p&gt;Ondat compression is handled on a per volume basis and is disabled in &lt;code&gt;v2.2.0&lt;/code&gt;, as performance is generally increased when compression is disabled due to &lt;a href=&#34;https://en.wikipedia.org/wiki/Data_structure_alignment&#34;&gt;block alignment&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This means that there is a trade off between volume performance and the space the volume occupies on the backend device.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat utilises the &lt;a href=&#34;https://en.wikipedia.org/wiki/LZ4_%28compression_algorithm%29&#34;&gt;LZ4 (compression algorithm)&lt;/a&gt; when writing to the backend store and when compressing Ondat &lt;a href=&#34;/docs/concepts/replication&#34;&gt;replication traffic&lt;/a&gt; before it is sent across the network.&lt;/p&gt;
&lt;p&gt;Ondat detects whether a block can be compressed or not by creating a heuristic that predicts the size of a compressed block.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the heuristic indicates that the compressed block is likely to be larger than the original block then the uncompressed block is stored.&lt;/li&gt;
&lt;li&gt;Block size increases post-compression if the compression dictionary is added to a block that cannot be compressed. By verifying whether blocks can be compressed, disk efficiency is increased and CPU resources are not wasted on attempts to compress incompressible blocks.&lt;/li&gt;
&lt;li&gt;Ondat&amp;rsquo;s patented on-disk format is used to tell whether individual blocks are compressed without overhead. As such volume compression can be dynamically enabled/disabled even while a volume is in use.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-to-enable-ondat-compression&#34;&gt;How To Enable Ondat Compression?&lt;/h3&gt;
&lt;p&gt;Compression can be enabled by setting the &lt;a href=&#34;/docs/concepts/labels&#34;&gt;Ondat Feature Label&lt;/a&gt; &amp;raquo; &lt;code&gt;storageos.com/nocompress=false&lt;/code&gt; on a volume at volume creation time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For more information on how to enable compression, review the &lt;a href=&#34;/docs/operations/compression&#34;&gt;Data Compression&lt;/a&gt; operations page.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-compression--data-encryption&#34;&gt;Ondat Compression &amp;amp; Data Encryption&lt;/h3&gt;
&lt;p&gt;When Ondat compression and &lt;a href=&#34;/docs/concepts/encryption&#34;&gt;data encryption&lt;/a&gt; are both enabled for a volume, blocks are &lt;strong&gt;compressed first&lt;/strong&gt; and then encrypted.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Data Encryption</title>
      <link>/docs/concepts/encryption/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/encryption/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is available in release &lt;code&gt;v2.4.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ End users can also leverage &lt;a href=&#34;https://www.ondat.io/trousseau&#34;&gt;Trousseau&lt;/a&gt; with Ondat&amp;rsquo;s volume encryption feature. Trousseau is an open source KMS plugin project that based on Kubernetes KMS provider design. The project allows users to store and access your secrets the Kubernetes native way with any external KMS. Trousseau&amp;rsquo;s repository can be located on &lt;a href=&#34;https://github.com/ondat/trousseau&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;data-encryption&#34;&gt;Data Encryption&lt;/h3&gt;
&lt;p&gt;Ondat supports &lt;a href=&#34;https://en.wikipedia.org/wiki/Data_at_rest&#34;&gt;data encryption-at-rest&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Data_in_transit&#34;&gt;data encryption-in-transit&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data encryption-in-transit is data as it is travelling between nodes. It is encrypted by default with &lt;a href=&#34;https://en.wikipedia.org/wiki/Mutual_authentication&#34;&gt;Mutual Authentication (mTLS)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Data encryption-at-rest is the data stored in your volumes as &lt;a href=&#34;/docs/concepts/volumes&#34;&gt;blob files&lt;/a&gt;. Encryption of these blob files is optional and can be enabled by adding a label to your volume definitions &lt;strong&gt;before they are provisioned&lt;/strong&gt; .&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on how to enable data encryption for Ondat volumes, review the &lt;a href=&#34;/docs/operations/encryption/&#34;&gt;Ondat Data Encryption&lt;/a&gt; operations page.&lt;/p&gt;
&lt;h3 id=&#34;how-are-ondat-volumes-encrypted&#34;&gt;How Are Ondat Volumes Encrypted?&lt;/h3&gt;
&lt;p&gt;Volumes are encrypted using &lt;code&gt;AES-256&lt;/code&gt; in the &lt;code&gt;XTS-AES&lt;/code&gt; mode with &lt;code&gt;512-bit&lt;/code&gt; keys, as
specified by &lt;a href=&#34;https://standards.ieee.org/ieee/1619/4205/&#34;&gt;&lt;code&gt;IEEE Standard 1619-2007&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is a non-zero performance impact of using encrypted volumes. A &lt;code&gt;10-25%&lt;/code&gt; cost in read/write throughput can be expected from &lt;code&gt;XTS-AES&lt;/code&gt;, dependent on workload.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Thin_provisioning&#34;&gt;Thin provisioning&lt;/a&gt; still applies to Ondat encrypted volumes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-are-ondat-encryption-keys-generated&#34;&gt;How Are Ondat Encryption Keys Generated?&lt;/h3&gt;
&lt;p&gt;On PVC creation, if data encryption-at-rest is enabled, Ondat will automatically generate &lt;strong&gt;up to two keys&lt;/strong&gt; as &lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/secret/&#34;&gt;Kubernetes secrets&lt;/a&gt;. Both keys are stored in the &lt;strong&gt;same namespace&lt;/strong&gt; as the PVC.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Firstly, if it doesn&amp;rsquo;t already exist, a &lt;strong&gt;namespace key&lt;/strong&gt; is generated. It is always named &lt;code&gt;storageos-namespace-key&lt;/code&gt; and &lt;strong&gt;only one exists per namespace&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Secondly a &lt;strong&gt;volume key&lt;/strong&gt; is created for each encrypted volume. It has a name in the format &lt;code&gt;storageos-volume-key-&amp;lt;random-id&amp;gt;&lt;/code&gt;, with no connection to the name of the volume.
&lt;ol&gt;
&lt;li&gt;The volume it is associated with can be determined by looking at the &lt;code&gt;storageos.com/pvc&lt;/code&gt; label on the secret.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;storageos.com/encryption-secret-name&lt;/code&gt; and &lt;code&gt;storageos.com/encryption-secret-namespace&lt;/code&gt; annotations are added to the PVC by an admission controller to map the PVC back to its secret.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;The encryption key is passed to Ondat as part of the CSI volume creation request and is used to encrypt the volume.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;how-are-encryption-keys-used&#34;&gt;How Are Encryption Keys Used?&lt;/h3&gt;
&lt;p&gt;The volume specific secret is needed whenever a volume is attached to a node for use by a pod.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When this happens, the Ondat node container&amp;rsquo;s &lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34;&gt;ServiceAccount&lt;/a&gt; reads the secret and passes it to the Ondat Control Plane.&lt;/li&gt;
&lt;li&gt;A volume missing its key or with a malformed key will be unable to attach.&lt;/li&gt;
&lt;li&gt;The key is stored in memory by Ondat only on the node that the volume is being used on. As a result, encryption and decryption are performed &lt;strong&gt;where the data is consumed, rather than where it is stored&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because of this, the use of encrypted volumes is transparent to the user. There is a complete integration between Kubernetes applications and Ondat volume encryption.&lt;/p&gt;
&lt;h3 id=&#34;encryption-key-management-best-practices&#34;&gt;Encryption Key Management Best Practices&lt;/h3&gt;
&lt;p&gt;Ondat saves volume encryption keys in Kubernetes secrets, thus - backups are imperative in case Kubernetes &lt;code&gt;etcd&lt;/code&gt; backing store is lost or damaged.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Ondat has no ability to decrypt a volume whose encryption keys have been lost.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Secrets in Kubernetes are not encrypted by default, they are stored in Kubernetes &lt;code&gt;etcd&lt;/code&gt; backing store in simple &lt;a href=&#34;https://en.wikipedia.org/wiki/Base64&#34;&gt;Base64&lt;/a&gt; encoding.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As Ondat encryption keys are stored as Kubernetes secrets, this means that anyone with access to Kubernetes &lt;code&gt;etcd&lt;/code&gt; backing store can read encryption keys and decrypt volumes, unless the cluster is using an external secrets store for key management.&lt;/li&gt;
&lt;li&gt;For more information on how to enable and configure encryption of Kubernetes secrets data at rest, review the &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/&#34;&gt;official Kubernetes documentation here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Secrets are not garbage-collected by Ondat, therefore - to clean up completely upon deletion of a volume it is necessary to also delete that volume&amp;rsquo;s secret. There is no benefit to doing this, however.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;managing-keys-with-a-key-management-service-kms-provider&#34;&gt;Managing Keys With A Key Management Service (KMS) Provider&lt;/h3&gt;
&lt;p&gt;As mentioned in the section above, Ondat volume encryption keys are stored within Kubernetes &lt;code&gt;etcd&lt;/code&gt; backing store as Kubernetes secrets. Whilst Kubernetes &lt;code&gt;etcd&lt;/code&gt; and secrets can also be encrypted, many security-focused organisations choose to use an &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kms-provider/&#34;&gt;external Key Management Service (KMS) provider for data encryption&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To address this from a Kubernetes limitations perspective and provide an agnostic solution, Ondat&amp;rsquo;s encryption design allows the user to leverage any supported &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kms-provider/#implementing-a-kms-plugin&#34;&gt;Kubernetes KMS plugin&lt;/a&gt; to envelop the secrets into a KMS provider encryption scheme.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ondat enables end users to transparently integrate any supported KMS plugin with Ondat encryption key management using the standard Kubernetes API and Kubernetes KMS provider framework. The architecture diagram below provides a high level overview of the process.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/gui-v2/kms-key-management.png&#34; alt=&#34;KMS Key Management&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The KMS plugin is deployed within the Kubernetes cluster.&lt;/li&gt;
&lt;li&gt;The KMS plugin is configured to act as a broker between the Kubernetes API server and the KMS server API endpoint.&lt;/li&gt;
&lt;li&gt;At volume creation, Ondat will create a Kubernetes secret using Kubernetes API calls&lt;/li&gt;
&lt;li&gt;The KMS plugin will handle the Kubernetes API Secret creation call and interface to the KMS server instance.&lt;/li&gt;
&lt;li&gt;The KMS server will return the secret using its encryption envelop scheme.&lt;/li&gt;
&lt;li&gt;The KMS plugin will store the encrypted secret within Kubernetes &lt;code&gt;etcd&lt;/code&gt; backing store.&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Feature Labels</title>
      <link>/docs/concepts/labels/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/labels/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Ondat Feature labels are &lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/&#34;&gt;Kubernetes Labels&lt;/a&gt; which provide a powerful and flexible way to control storage features.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Applying specific feature labels triggers &lt;a href=&#34;/docs/concepts/compression/&#34;&gt;compression&lt;/a&gt;, &lt;a href=&#34;/docs/concepts/replication/&#34;&gt;replication&lt;/a&gt;, &lt;a href=&#34;/docs/concepts/encryption/&#34;&gt;data encryption&lt;/a&gt; and other storage features. In order to use feature labels, end users are required to explicitly enable the features they want to use in their cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;types-of-ondat-feature-labels&#34;&gt;Types Of Ondat Feature Labels&lt;/h2&gt;
&lt;h3 id=&#34;ondat-volume-labels&#34;&gt;Ondat Volume Labels&lt;/h3&gt;
&lt;p&gt;Below are the list of available feature labels that can be used to define &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volumes/&#34;&gt;Volume resources&lt;/a&gt; and &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/storage-classes/#the-storageclass-resource&#34;&gt;StorageClass resources&lt;/a&gt; in an Ondat cluster.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ The &lt;strong&gt;encryption&lt;/strong&gt; and &lt;strong&gt;compression&lt;/strong&gt; labels can only applied at provisioning time, they can&amp;rsquo;t be changed during execution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature Name&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Label Reference&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Values&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;/docs/concepts/compression/&#34;&gt;&lt;strong&gt;Compression&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/nocompress&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enables or disables compression of data-at-rest and data-in-transit. Compression &lt;strong&gt;is not enabled by default&lt;/strong&gt; to maximise performance.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;/docs/concepts/encryption/&#34;&gt;&lt;strong&gt;Encryption&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/encryption&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Encrypts the contents of the volume. For each volume, a key is automatically generated, stored, and linked with the PVC.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;/docs/concepts/replication/#ondat-failure-modes&#34;&gt;&lt;strong&gt;Failure Mode&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/failure-mode&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;hard&lt;/code&gt;, &lt;code&gt;soft&lt;/code&gt;, &lt;code&gt;alwayson&lt;/code&gt;, or &lt;code&gt;threshold&lt;/code&gt; integers starting from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;5&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Sets the failure mode for a volume, either explicitly using a failure mode or implicitly using a replica threshold. The default failure mode is set to &lt;code&gt;hard&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;/docs/concepts/replication/&#34;&gt;&lt;strong&gt;Replication&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/replicas&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;integers&lt;/code&gt; starting from &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;5&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Sets the number of replicas, for example full copies of the data across nodes. Typically &lt;code&gt;1&lt;/code&gt; or &lt;code&gt;2&lt;/code&gt; replicas is sufficient (&lt;code&gt;2&lt;/code&gt; or &lt;code&gt;3&lt;/code&gt; instances of the data). Latency implications need to be assessed when using &lt;strong&gt;more than&lt;/strong&gt; &lt;code&gt;2&lt;/code&gt; replicas.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;/docs/concepts/tap/&#34;&gt;&lt;strong&gt;Topology-Aware Placement&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/topology-aware&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enables or disables Ondat Topology-Aware Placement.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;/docs/concepts/tap/#topology-domains&#34;&gt;&lt;strong&gt;Topology Domain Key&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/topology-key&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;custom region, read as a &lt;a href=&#34;https://en.wikipedia.org/wiki/String_%28computer_science%29&#34;&gt;string&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Define the failure domain for the node by using a custom key. If you don&amp;rsquo;t define a custom key, the label defaults to the &lt;code&gt;topology.kubernetes.io/zone&lt;/code&gt; value.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;/docs/concepts/rwx&#34;&gt;&lt;strong&gt;Squash Mode&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/nfs-squash&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;root&lt;/code&gt;, &lt;code&gt;rootuid&lt;/code&gt;, &lt;code&gt;all&lt;/code&gt;, &lt;code&gt;none&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Define the squash mode that will be used with Ondat Files - &lt;code&gt;ReadWriteMany&lt;/code&gt; (RWX) volumes to set the file ownership in the share. The default squash mode is set to &lt;code&gt;all&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;ondat-node-labels&#34;&gt;Ondat Node Labels&lt;/h3&gt;
&lt;p&gt;When Ondat is run within Kubernetes, the &lt;a href=&#34;https://github.com/storageos/api-manager&#34;&gt;Ondat API Manager&lt;/a&gt; syncs any &lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/&#34;&gt;Kubernetes node labels&lt;/a&gt; to the corresponding Ondat node. The Kubernetes node labels act as the &amp;ldquo;source of truth&amp;rdquo;, so labels should be applied to the Kubernetes nodes rather than to Ondat nodes. This is because the Kubernetes node labels overwrite the Ondat node labels on sync.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Below are the list of available feature labels that can be used to define &lt;a href=&#34;https://kubernetes.io/docs/concepts/architecture/nodes/&#34;&gt;Kubernetes Nodes&lt;/a&gt; in an Ondat Cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature Name&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Label Reference&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Values&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;/docs/concepts/nodes/#compute-only-mode&#34;&gt;&lt;strong&gt;Compute-only Nodes&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/computeonly&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Specifies whether a node should be &lt;code&gt;computeonly&lt;/code&gt; where it only acts as a client and does not host volume data locally, otherwise the node is hyper-converged (the default), where the node can operate in both client and server modes.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;ondat-pod-labels&#34;&gt;Ondat Pod Labels&lt;/h3&gt;
&lt;p&gt;Below are the list of available feature labels that can be used to define &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/&#34;&gt;Kubernetes Pods&lt;/a&gt; in an Ondat Cluster.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ For a pod to be fenced by Ondat, a recommendation will be to review the the &lt;a href=&#34;/docs/operations/fencing&#34;&gt;Ondat Fencing&lt;/a&gt; operations page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature Name&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Label Reference&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Values&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Feature Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;/docs/concepts/fencing/&#34;&gt;&lt;strong&gt;Pod Fencing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos.com/fenced&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Targets a pod to be fenced in case of node failure. The default value is &lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;how-to-use-ondat-feature-labels&#34;&gt;How To Use Ondat Feature Labels?&lt;/h2&gt;
&lt;p&gt;For more information about how to enable specific Ondat features, review the Ondat Feature Labels operations pages listed below;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/storageclasses&#34;&gt;How To Create Custom Storage Classes&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/compute-only&#34;&gt;How To Setup A Centralised Cluster Topology&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/replication&#34;&gt;How To Use Volume Replication&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/rwx/&#34;&gt;How To Use Ondat Files (ReadWriteMany - RWX Volumes)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/failure-modes/&#34;&gt;How To Use Failure Modes&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/fencing/&#34;&gt;How To Enable Fencing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/tap/&#34;&gt;How To Enable Topology-Aware Placement (TAP)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/encryption/&#34;&gt;How To Enable Data Encryption&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/compression&#34;&gt;How To Enable Data Compression&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Fencing</title>
      <link>/docs/concepts/fencing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/fencing/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is available in release &lt;code&gt;v2.4.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;what-is-ondat-fencing&#34;&gt;What Is Ondat Fencing?&lt;/h3&gt;
&lt;p&gt;In order to understand what Ondat Fencing for Kubernetes is and when it is needed, it is required to first understand the behaviour of &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&#34;&gt;Kubernetes StatefulSets&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;StatefulSets&lt;/em&gt; are the de facto Kubernetes controller to use for stateful applications. The StatefulSet controller offers guarantees around pod uniqueness, sticky identities and the persistence of PVCs beyond the lifetime of their pods.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As such, StatefulSets have different characteristics and provide different guarantees than &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34;&gt;Kubernetes Deployments&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Deployments&lt;/em&gt; guarantee the amount of healthy replicas by reconciling towards the deployment desired state. Attempts to align the number of healthy pods with the deployment&amp;rsquo;s desired state happen as fast as possible by aggressively initialising and terminating pods.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If one pod is terminating, another will be automatically scheduled to start even if the first pod is not yet completely terminated. Stateless applications benefit from this behaviour as one pod executes the same work as any other in the deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;StatefulSets, on the other hand, &lt;strong&gt;guarantee that every pod scheduled has a unique identity&lt;/strong&gt;, which is to say that only a single copy of a pod is running in the cluster at any one time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Whenever scheduling decisions are made, the StatefulSet controller ensures that only one copy of this pod is running at any time.&lt;/li&gt;
&lt;li&gt;If a pod is deleted, a new pod will not be scheduled until the first pod is fully terminated. This is an important guarantee as file systems need to be unmounted before they can be remounted in a new pod. Any &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes&#34;&gt;ReadWriteOnce (RWO)&lt;/a&gt; PVC defining a device requires this behaviour to ensure the consistency of the data and thus the PVC.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To protect data integrity, Kubernetes guarantees that there will never be more than one instance of a StatefulSet pod running at a time. It assumes that when a node is determined to be offline it may still be running the workload but partitioned from the network. Since Kubernetes is unable to verify that the pod has been stopped it errors on the side of caution and does not allow a replacement to start on another node.&lt;/p&gt;
&lt;p&gt;Kubernetes does reschedule pods from some controllers when nodes become unavailable. The default behaviour is that when a node becomes unavailable its status becomes &lt;code&gt;Unknown&lt;/code&gt; and after the &lt;code&gt;pod-eviction-timeout&lt;/code&gt; has passed pods are scheduled for deletion. By default, the &lt;code&gt;pod-eviction-timeout&lt;/code&gt; is &lt;code&gt;300&lt;/code&gt; seconds.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For this reason, Kubernetes requires manual intervention to initiate timely failover of a StatefulSet pod. The &lt;strong&gt;Ondat Fencing Controller&lt;/strong&gt; gives the capability to enable fast failover for workloads when a node goes offline.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on the rationale behind the design of StatefulSets, review the Kubernetes design proposal archive for &lt;a href=&#34;https://github.com/kubernetes/design-proposals-archive/blob/main/storage/pod-safety.md&#34;&gt;Pod Safety, Consistency Guarantees, and Storage Implications&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;ondat-fencing-controller&#34;&gt;Ondat Fencing Controller&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ The Ondat Fencing Controller is part of the Ondat API Manager which is deployed in high availability mode when Ondat is installed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ High Availability for StatefulSet applications can be achieved with the Ondat Fencing feature.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since Ondat is able to determine when a node is no longer able to access a volume and has protections in place to ensure that a partitioned or formerly partitioned node can stop writing data, it can work with Kubernetes to perform safe, fast failovers of pods, including those running in StatefulSets.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When Ondat detects that a node has gone offline or become partitioned, it marks the node offline and performs volume failover operations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/storageos/api-manager/tree/master/controllers/fencer&#34;&gt;Ondat Fencing Controller&lt;/a&gt; watches for these node failures and determines if there are any pods assigned to the failed node with the label &lt;code&gt;storageos.com/fenced=true&lt;/code&gt;, and if the pods have any PVCs backed by Ondat volumes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When a pod has Ondat volumes and if they are all healthy, the Ondat Fencing Controller deletes the pod to allow it to be rescheduled on another node. It also deletes the &lt;code&gt;VolumeAttachment&lt;/code&gt; object for the corresponding volumes so that they can be immediately attached to the new node.&lt;/li&gt;
&lt;li&gt;No changes are made to pods that have Ondat volumes that are unhealthy. This is usually because a volume was configured to not have any replicas, and the node with the single copy of the data is offline. In this case it is better to wait for the node to recover.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat Fencing works with both dynamically provisioned PVCs and PVCs referencing pre-provisioned volumes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In addition, the fencing feature is opt-in and pods must have the &lt;code&gt;storageos.com/fenced=true&lt;/code&gt; label set, and be using at least one Ondat volume, to enable fast failover.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information about how to enable Ondat fencing, review the &lt;a href=&#34;/docs/operations/fencing&#34;&gt;Ondat Fencing&lt;/a&gt; operations page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Kubectl Plugin</title>
      <link>/docs/reference/kubectl-plugin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/kubectl-plugin/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The Ondat kubectl plugin is a utility tool that accepts imperative and declarative modes which allows cluster administrators to seamlessly install, troubleshoot, upgrade or uninstall Ondat. The plugin can also be used to connect and manage Ondat clusters on the &lt;a href=&#34;https://docs.ondat.io/docs/ondat-portal/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.
&lt;ul&gt;
&lt;li&gt;The project repository is open source and can be located on &lt;a href=&#34;https://github.com/storageos/kubectl-storageos&#34;&gt;GitHub&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;install-the-ondat-kubectl-plugin&#34;&gt;Install The Ondat Kubectl Plugin&lt;/h3&gt;
&lt;h4 id=&#34;linux&#34;&gt;Linux&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl --silent --show-error --location --output kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  https://github.com/storageos/kubectl-storageos/releases/download/v1.3.1/kubectl-storageos_1.3.1_linux_amd64.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; tar --extract --file kubectl-storageos.tar.gz kubectl-storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x kubectl-storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo mv kubectl-storageos /usr/local/bin/ &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Plugin version installed:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; kubectl-storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;macos-darwin&#34;&gt;macOS (Darwin)&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl --silent --show-error --location --output kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  https://github.com/storageos/kubectl-storageos/releases/download/v1.3.1/kubectl-storageos_1.3.1_darwin_amd64.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; tar --extract --verbose --file kubectl-storageos.tar.gz kubectl-storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x kubectl-storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo mv kubectl-storageos /usr/local/bin/ &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Plugin version installed:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; kubectl-storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;windows&#34;&gt;Windows&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# PowerShell&lt;/span&gt;
Invoke-WebRequest https://github.com/storageos/kubectl-storageos/releases/download/v1.3.1/kubectl-storageos_1.3.1_windows_amd64.tar.gz -OutFile kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; tar -xf kubectl-storageos.tar.gz kubectl-storageos.exe &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; Remove-Item kubectl-storageos.tar.gz &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; Write-Host &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Plugin version installed:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; .&lt;span style=&#34;color:#4e9a06&#34;&gt;\k&lt;/span&gt;ubectl-storageos.exe version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;others&#34;&gt;Others&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;For more information on different binaries, supported architectures and checksum file verification, see the full page of &lt;a href=&#34;https://github.com/storageos/kubectl-storageos/releases&#34;&gt;releases&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;usage&#34;&gt;Usage&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Get the version of the plugin installed;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Get more information on the available commands in the plugin;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl storageos help
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;StorageOS kubectl plugin

Usage:
  kubectl-storageos [flags]
  kubectl-storageos [command]

Aliases:
  kubectl-storageos, kubectl storageos

Available Commands:
  bundle           Generate a support bundle
  completion       Generate completion script
  disable-portal   Disable StorageOS Portal Manager
  enable-portal    Enable StorageOS Portal Manager
  help             Help about any command
  install          Install StorageOS and (optionally) ETCD
  install-portal   Install StorageOS Portal Manager
  preflight        Test a k8s cluster for StorageOS pre-requisites
  uninstall        Uninstall StorageOS and (optionally) ETCD
  uninstall-portal Uninstall StorageOS Portal Manager
  upgrade          Ugrade StorageOS
  version          Show kubectl storageos version

Flags:
  -h, --help   help for kubectl-storageos

Use &amp;quot;kubectl-storageos [command] --help&amp;quot; for more information about a command.
&lt;/code&gt;&lt;/pre&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Metric Exporter</title>
      <link>/docs/concepts/metric-exporter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/metric-exporter/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is available in release &lt;code&gt;v2.8.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;prometheus-metrics-for-ondat-volumes&#34;&gt;Prometheus Metrics for Ondat Volumes&lt;/h3&gt;
&lt;p&gt;Following the &lt;a href=&#34;https://prometheus.io/docs/instrumenting/exporters/&#34;&gt;exporter pattern&lt;/a&gt;, we maintain and distribute our own &lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt; exporter for monitoring and alerting of Ondat volumes. The metrics our exporter publishes include data on volume health, capacity and traffic.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Ondat metric exporter repository is open source and can be located on &lt;a href=&#34;https://github.com/ondat/metrics-exporter&#34;&gt;GitHub&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To get started with installing and configuring the exporter in your Ondat cluster, review the &lt;a href=&#34;/docs/operations/metric-exporter/&#34;&gt;metric exporter&amp;rsquo;s&lt;/a&gt; operations page for more information.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ When setting up a &lt;a href=&#34;https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/getting-started.md&#34;&gt;ServiceMonitor&lt;/a&gt; resource, ensure that you create the rules in the same namespace as your Prometheus resource and have its &lt;code&gt;selector&lt;/code&gt; field match the labels of the services exposing metrics - review the &lt;a href=&#34;/docs/operations/metric-exporter/&#34;&gt;example ServiceMonitor resource&lt;/a&gt; manifest in the operations page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;alerting-rules-for-ondat-volumes&#34;&gt;Alerting Rules for Ondat Volumes&lt;/h3&gt;
&lt;p&gt;Ondat also distributes example alert rules for Ondat metrics using &lt;a href=&#34;https://prometheus.io/docs/alerting/latest/alertmanager/&#34;&gt;Alertmanager&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The alert rules manifest can be located in the &lt;a href=&#34;https://github.com/ondat/metrics-exporter/tree/main/alertmanager&#34;&gt;&lt;code&gt;alertmanager&lt;/code&gt; sub directory under the Ondat metric exporter&lt;/a&gt; repository.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;grafana-dashboard-for-ondat-volumes&#34;&gt;Grafana Dashboard for Ondat Volumes&lt;/h3&gt;
&lt;p&gt;In addition to the Ondat metric exporter project, we also distribute &lt;a href=&#34;https://grafana.com/grafana/dashboards/&#34;&gt;Grafana dashboards&lt;/a&gt; that allow end users to easily visualize and get insights into the status of Ondat volumes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The dashboards can be also located in the &lt;a href=&#34;https://github.com/ondat/metrics-exporter/tree/main/grafana&#34;&gt;&lt;code&gt;grafana&lt;/code&gt; sub directory under the Ondat metric exporter&lt;/a&gt; repository.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;contributing&#34;&gt;Contributing&lt;/h2&gt;
&lt;p&gt;If end users have suggestions/ideas for metrics that they would like Ondat to gather by default or improve the Grafana dashboards and Alertmanager integration, contributions are welcome.&lt;/p&gt;
&lt;p&gt;You can reach out to us on the &lt;a href=&#34;https://slack.storageos.com/&#34;&gt;Ondat community slack workspace&lt;/a&gt; or review the &lt;a href=&#34;https://github.com/ondat/metrics-exporter/blob/main/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt; in the Ondat metric exporter repository.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Nodes</title>
      <link>/docs/concepts/nodes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/nodes/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;An Ondat node is any machine (virtual or physical) that is running the Ondat &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34;&gt;daemonset&lt;/a&gt; pod. A node must be running a daemonset pod in order to consume and/or present storage.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nodes can be run in several modes, describe below;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hyper-converged-mode&#34;&gt;Hyper-converged Mode&lt;/h3&gt;
&lt;p&gt;By default Ondat nodes run in &lt;strong&gt;hyper-converged&lt;/strong&gt; mode. This means that the node hosts data from Ondat volumes and can present volumes to applications.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A hyper-converged node can store data from a volume and present volumes to applications regardless of whether the data for the volume consumed is placed on that node or is being served remotely.&lt;/li&gt;
&lt;li&gt;Remote volumes like this are handled by an internal protocol to present block device access to applications running on different nodes from the one to which their backing data store is attached.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat implements an extension of a Kubernetes Scheduler object that influences the placement of Pods on the same nodes as their data.&lt;/p&gt;
&lt;h3 id=&#34;compute-only-mode&#34;&gt;Compute-only Mode&lt;/h3&gt;
&lt;p&gt;Alternatively, a node can run in &lt;strong&gt;Compute-only&lt;/strong&gt; mode, which means no storage is consumed on the node itself and the node only presents volumes hosted by other nodes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Volumes presented to applications running on compute only nodes are therefore all remote.&lt;/li&gt;
&lt;li&gt;Compute only nodes can be very useful for topologies where nodes are ephemeral and should not host data, but the ephemeral nodes host applications that require Ondat volumes.&lt;/li&gt;
&lt;li&gt;The nodes that are not intended to hold data, but just to present Ondat volumes, can be set as compute-only.&lt;/li&gt;
&lt;li&gt;A node can be marked as compute only at any point in time by adding the label &lt;code&gt;storageos.com/computeonly=true&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More information on feature labels can be found under the &lt;a href=&#34;/docs/concepts/labels&#34;&gt;Ondat Feature Labels&lt;/a&gt; page.&lt;/p&gt;
&lt;h3 id=&#34;storage-mode&#34;&gt;Storage Mode&lt;/h3&gt;
&lt;p&gt;Finally, nodes can be set to storage mode. Nodes set to storage mode don&amp;rsquo;t present data locally - instead all data is accessed through the network.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This topology is enforced by tainting the relevant nodes to ensure that application workloads cannot be scheduled there.&lt;/li&gt;
&lt;li&gt;This mode is ideal for ensuring maximum stability of data access as the node is isolated from resource drains that may occur due to applications running alongside.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For redundancy purposes, in high load clusters it is ideal to have several nodes running in this mode.&lt;/p&gt;
&lt;h2 id=&#34;further-information&#34;&gt;Further Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Review the &lt;a href=&#34;/docs/concepts/cluster-topologies/&#34;&gt;Ondat Cluster Topologies&lt;/a&gt; feature page for more information on the supported cluster topologies that end users can leverage when designing storage-optimised clusters for their stateful applications.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Replication</title>
      <link>/docs/concepts/replication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/replication/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;h3 id=&#34;how-does-ondats-replication-work&#34;&gt;How Does Ondat&amp;rsquo;s Replication Work?&lt;/h3&gt;
&lt;p&gt;Ondat replicates volumes across nodes for data protection and high availability. Synchronous &lt;a href=&#34;https://en.wikipedia.org/wiki/Replication_%28computing%29&#34;&gt;replication&lt;/a&gt; ensures strong consistency for applications such as databases and message queues, incurring one network round trip on writes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The basic model for Ondat replication is of a master volume with distributed replicas. Each volume can be replicated between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;5&lt;/code&gt; times, which are provisioned to &lt;code&gt;0&lt;/code&gt; to &lt;code&gt;5&lt;/code&gt; nodes, up to the number of remaining nodes in the cluster.&lt;/li&gt;
&lt;li&gt;In this diagram, the master volume &lt;code&gt;D&lt;/code&gt; was created on node &lt;code&gt;1&lt;/code&gt;, and two replicas, &lt;code&gt;D2&lt;/code&gt; and &lt;code&gt;D3&lt;/code&gt; on nodes &lt;code&gt;3&lt;/code&gt; and &lt;code&gt;5&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/high-availability.png&#34; alt=&#34;Ondat Replication Diagram&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;[Step 1]&lt;/strong&gt; &amp;raquo; Data from the application is written to the master volume first (&lt;code&gt;D&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Step 2]&lt;/strong&gt; &amp;raquo; Data is then written in parallel to the replica volumes (&lt;code&gt;D2&lt;/code&gt; &amp;amp; &lt;code&gt;D3&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Step 3]&lt;/strong&gt; &amp;raquo; Master and replica volumes all acknowledge that data has been received and written&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Step 4]&lt;/strong&gt; &amp;raquo; A successful write operation is returned to the application.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For most applications, one replica is sufficient &lt;code&gt;storageos.com/replicas=1&lt;/code&gt;. All replication traffic on the wire is compressed using the &lt;a href=&#34;https://en.wikipedia.org/wiki/LZ4_%28compression_algorithm%29&#34;&gt;LZ4 (compression algorithm)&lt;/a&gt;, then streamed over &lt;code&gt;TCP/IP&lt;/code&gt; to target port &lt;code&gt;TCP/5703&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the master volume is lost, a replica is promoted to master (&lt;code&gt;D2&lt;/code&gt; or &lt;code&gt;D3&lt;/code&gt; above) and a new replica is created and synced on an available node (node &lt;code&gt;2&lt;/code&gt; or &lt;code&gt;4&lt;/code&gt;). This is transparent to the application and does not cause downtime.&lt;/li&gt;
&lt;li&gt;If a replica volume is lost and there are enough remaining nodes, a new replica is created and synced on an available node. While a new replica is created and being synced, the volume&amp;rsquo;s health will be marked as degraded.&lt;/li&gt;
&lt;li&gt;If the lost replica comes back online before the new replica has finished synchronising, then Ondat will calculate which of the two synchronising replicas has the smallest difference compared to the master volume and keep that replica.&lt;/li&gt;
&lt;li&gt;The same holds true if a master volume is lost and a replica is promoted to be the new master. If possible, a new replica will be created and begin to sync. Should the former master come back online it will be demoted to a replica and the replica will the smallest difference to the current master will be kept.&lt;/li&gt;
&lt;li&gt;While the replica count is controllable on a per-volume basis, some environments may prefer to set &lt;a href=&#34;/docs/concepts/labels&#34;&gt;default labels on the StorageClass&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondats-delta-sync-algorithm&#34;&gt;Ondat&amp;rsquo;s Delta Sync Algorithm&lt;/h3&gt;
&lt;p&gt;Ondat implements a delta sync between a volume master and its replicas.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This means that if a replica for a volume goes offline, that when the replica comes back online only the regions with changed blocks need to be synchronised.&lt;/li&gt;
&lt;li&gt;This optimisation reduces the time it takes for replicas to catch up, improving volume resilience.&lt;/li&gt;
&lt;li&gt;Additionally, it reduces network and I/O bandwidth which can reduce costs when running in public clouds.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-to-use-ondats-volume-replication&#34;&gt;How to use Ondat&amp;rsquo;s Volume Replication?&lt;/h3&gt;
&lt;p&gt;For more information on how to use the volume replication feature, review the &lt;a href=&#34;/docs/operations/replication&#34;&gt;Volume Replication&lt;/a&gt; operations page.&lt;/p&gt;
&lt;h3 id=&#34;ondat-topology-aware-placement-tap&#34;&gt;Ondat Topology-Aware Placement (TAP)&lt;/h3&gt;
&lt;p&gt;Ondat Topology-Aware Placement (TAP) is a feature that enforces placement of data across failure domains to guarantee high availability.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TAP uses default labels on nodes to define failure domains. For instance, an &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html&#34;&gt;Availability Zone (AZ)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on the Topology-Aware Placement feature, review the &lt;a href=&#34;/docs/concepts/tap&#34;&gt;Ondat Topology-Aware Placement&lt;/a&gt; feature page.&lt;/p&gt;
&lt;h2 id=&#34;ondat-failure-modes&#34;&gt;Ondat Failure Modes&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is available in release &lt;code&gt;v2.4.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat failure modes offer different guarantees with regards to a volume&amp;rsquo;s mode of operation in the face of replica failure. If the failure mode is not specified it defaults to &lt;code&gt;Hard&lt;/code&gt;. Volume failure modes can be dynamically updated at runtime.&lt;/p&gt;
&lt;h3 id=&#34;hard-failure-mode&#34;&gt;&lt;code&gt;hard&lt;/code&gt; Failure Mode&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;hard&lt;/code&gt; failure mode requires that the number of declared replicas matches the available number of replicas at all times.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If a replica fails Ondat will attempt creation of a new replica for 90 seconds. After 90s if the old replica is not available and a new replica cannot be provisioned, Ondat cannot guarantee that the data is stored on the number of multiple nodes requested by the user. Ondat will therefore set the volume to be read-only.&lt;/li&gt;
&lt;li&gt;If a volume has gone read-only there are two stages to making it read-write again. Firstly, sufficient replicas must be provisioned to match the desired replica count. Depending on your environment, additional nodes and/or disk capacity may be required for this. Secondly, the volume must be remounted - necessitating pod deletion/recreation in Kubernetes.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos.com/failure-mode: hard
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Number Of Nodes Required For A &lt;code&gt;hard&lt;/code&gt; Failure Mode Setup&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When a node fails, a new replica is provisioned and synced as described above. To ensure that a new replica can always be created, an additional node should be available.&lt;/li&gt;
&lt;li&gt;To guarantee high availability using &lt;code&gt;storageos.com/failure-mode: hard&lt;/code&gt;, clusters using volumes with &lt;code&gt;1&lt;/code&gt; replica must have at least &lt;code&gt;3&lt;/code&gt; storage nodes.&lt;/li&gt;
&lt;li&gt;When using volumes with &lt;code&gt;2&lt;/code&gt; replicas, at least &lt;code&gt;4&lt;/code&gt; storage nodes, &lt;code&gt;3&lt;/code&gt; replicas, &lt;code&gt;5&lt;/code&gt; nodes, and so on.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Minimum number of storage nodes = 1 (primary) + N (replicas) + 1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;soft-failure-mode&#34;&gt;&lt;code&gt;soft&lt;/code&gt; Failure Mode&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;soft&lt;/code&gt; failure mode allows a volume to continue serving I/O even when a replica goes offline and a new replica fails to provision.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;So long as there are &lt;code&gt;not less than max(1, N-1)&lt;/code&gt; available replicas where &lt;code&gt;N&lt;/code&gt; is the number of replicas for the volume.&lt;/li&gt;
&lt;li&gt;For example, if a volume with &lt;code&gt;2&lt;/code&gt; replicas loses &lt;code&gt;1&lt;/code&gt; replica, then I/O would continue to be served since &lt;code&gt;1&lt;/code&gt; replica remaining &lt;code&gt;&amp;gt;= max(1, 1)&lt;/code&gt;.
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ If a volume with &lt;code&gt;1&lt;/code&gt; replica loses &lt;code&gt;1&lt;/code&gt; replica, then I/O would halt after &lt;code&gt;90&lt;/code&gt; seconds since &lt;code&gt;0&lt;/code&gt;
replicas remaining &lt;code&gt;&amp;lt; max(1, 0)&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos.com/failure-mode: soft
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Number Of Nodes Required For A &lt;code&gt;soft&lt;/code&gt; Failure Mode Setup&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To ensure that a &lt;code&gt;storageos.com/failure-mode: soft&lt;/code&gt; volume is highly available, clusters using volumes with &lt;code&gt;1&lt;/code&gt; replica must have at least &lt;code&gt;2&lt;/code&gt; storage nodes.&lt;/li&gt;
&lt;li&gt;When using volumes with &lt;code&gt;2&lt;/code&gt; replicas, at least &lt;code&gt;3&lt;/code&gt; storage nodes, &lt;code&gt;3&lt;/code&gt; replicas, 3 nodes, etc.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Minimum number of storage nodes = 1 (primary) + N (replicas)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;threshold-failure-mode&#34;&gt;&lt;code&gt;threshold&lt;/code&gt; Failure Mode&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;threshold&lt;/code&gt; failure mode allows the user to set the minimum required number of online replicas for a volume.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For example for a volume with &lt;code&gt;2&lt;/code&gt; replicas, setting the threshold to &lt;code&gt;1&lt;/code&gt; would allow a single replica to be offline, whereas setting threshold to &lt;code&gt;0&lt;/code&gt; would allow &lt;code&gt;2&lt;/code&gt; replicas to be offline.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos.com/failure-mode: &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;0-5&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Number Of Nodes Required For A &lt;code&gt;threshold&lt;/code&gt; Failure Mode Setup&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The minimum number of nodes for a &lt;code&gt;threshold&lt;/code&gt; volume is determined by the threshold that is set.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Minimum number of storage nodes = 1 (primary) + T (threshold)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;alwayson-failure-mode&#34;&gt;&lt;code&gt;alwayson&lt;/code&gt; Failure Mode&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;alwayson&lt;/code&gt; failure mode allows all replicas for a volume to be offline and keeps the volume writeable. A volume with failure mode AlwaysOn will continue to serve I/O regardless of how many replicas it currently has.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This mode should be used with caution as it effectively allows for only a single copy of the data to be available.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos.com/failure-mode: alwayson
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Number Of Nodes Required For A &lt;code&gt;alwayson&lt;/code&gt; Failure Mode Setup&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;code&gt;storageos.com/failure-mode: alwayson&lt;/code&gt; volume is highly available albeit at the cost of reliability.&lt;/li&gt;
&lt;li&gt;The minimum node count here is &lt;code&gt;1&lt;/code&gt; as the loss of all replicas will be tolerated.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Minimum number of storage nodes = 1 (primary)&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on how to use failure mode labels on volumes, review the &lt;a href=&#34;/docs/operations/failure-modes&#34;&gt;Failure Modes&lt;/a&gt; operations page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Rolling Upgrades Protection For Orchestrators</title>
      <link>/docs/concepts/rolling-upgrades/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/rolling-upgrades/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is currently available as a Technical Preview from release &lt;code&gt;2.7.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;rolling-upgrades-protection&#34;&gt;Rolling Upgrades Protection&lt;/h3&gt;
&lt;p&gt;You can use our rolling upgrade protection feature to upgrade your cluster&amp;rsquo;s orchestrator without causing downtime or failure of Ondat.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the volumes containing the data for your stateful workloads do not wait to successfully synchronize in-between nodes upgrading, this can potentially cause data inconsistency and downtime. As such it is necessary to perform these upgrades intelligently.&lt;/li&gt;
&lt;li&gt;We are developing a solution to this problem for you. It is currently a Technical Preview but now, for example, Ondat can support a &lt;a href=&#34;/docs/install/anthos/&#34;&gt;Google Anthos&lt;/a&gt; one-click upgrade without any downtime.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To get started with Ondat&amp;rsquo;s Rolling Upgrades Protection for your cluster, review the &lt;a href=&#34;/docs/operations/using-rolling-upgrades&#34;&gt;Platform Upgrade&lt;/a&gt; page for more information.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat SaaS Platform Installation Guide</title>
      <link>/docs/ondat-portal/installation-portal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/ondat-portal/installation-portal/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure the kubectl storageos plugin is installed. Follow the &lt;a href=&#34;https://docs.ondat.io/docs/reference/kubectl-plugin/&#34;&gt;install guide for kubectl storageos&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ You must enable port 443 for egress in your ACLs if a VPC is used.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1-set-up-your-cluster&#34;&gt;Step 1: Set up your cluster&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Open &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Log into your account using your credentials&lt;/li&gt;
&lt;li&gt;In the main navigation, open the &lt;strong&gt;Cluster&lt;/strong&gt; tab&lt;/li&gt;
&lt;li&gt;On the &lt;strong&gt;Cluster&lt;/strong&gt; screen, click the &lt;strong&gt;Add Cluster&lt;/strong&gt; button&lt;/li&gt;
&lt;li&gt;Enter a name for the cluster and choose the &lt;strong&gt;Cluster Location&lt;/strong&gt; using the radio buttons&lt;/li&gt;
&lt;li&gt;Click &lt;strong&gt;Add Cluster&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-2-connect-cluster-to-the-ondat-saas-platform&#34;&gt;Step 2: Connect Cluster to the Ondat SaaS Platform&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: The CLI command will only be displayed &lt;strong&gt;once&lt;/strong&gt;
Note: Latest GA version of Ondat will be installed onto your cluster&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Make sure you follow all the prerequisites displayed on the screen. You can find more information &lt;a href=&#34;/docs/prerequisites/&#34;&gt;here&lt;/a&gt; for the prerequisites of using Ondat.&lt;/li&gt;
&lt;li&gt;Copy the cli command displayed on the screen&lt;/li&gt;
&lt;li&gt;Execute the cli command on your machine&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Shared Filesystems</title>
      <link>/docs/concepts/rwx/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/rwx/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is available in release &lt;code&gt;v2.3.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;what-are-ondat-shared-filesystems&#34;&gt;What Are Ondat Shared Filesystems?&lt;/h3&gt;
&lt;p&gt;Ondat provides support for &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes&#34;&gt;ReadWriteMany (RWX)&lt;/a&gt; persistent volumes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A RWX PVC can be used simultaneously by many Pods in the same Kubernetes namespace for read and write operations.&lt;/li&gt;
&lt;li&gt;Ondat RWX persistent volumes are based on a &lt;a href=&#34;https://en.wikipedia.org/wiki/Clustered_file_system&#34;&gt;shared filesystem&lt;/a&gt;, the protocol being used for this feature&amp;rsquo;s backend is &lt;a href=&#34;https://en.wikipedia.org/wiki/Network_File_System&#34;&gt;Network Files System (NFS)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;architecture-of-ondat-shared-filesystems&#34;&gt;Architecture Of Ondat Shared Filesystems&lt;/h3&gt;
&lt;p&gt;For each RWX persistent volume, the following components below are required:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ondat ReadWriteOnly (RWO) Volume&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Ondat provisions a standard &lt;a href=&#34;/docs/concepts/volumes&#34;&gt;volume&lt;/a&gt; that provides a block device for the file system of the NFS server.&lt;/li&gt;
&lt;li&gt;This means that every RWX Volume has its own RWO Volume - thus allowing RWX Volumes to leverage the synchronous &lt;a href=&#34;https://en.wikipedia.org/wiki/Replication_%28computing%29&#34;&gt;replication&lt;/a&gt; and automatic &lt;a href=&#34;https://en.wikipedia.org/wiki/Failover&#34;&gt;failover&lt;/a&gt; functionality of Ondat, providing the NFS server with high availability.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NFS-Ganesha Server&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;For each RWX volume, an &lt;a href=&#34;https://nfs-ganesha.github.io/&#34;&gt;NFS-Ganesha&lt;/a&gt; server is spawned by Ondat.&lt;/li&gt;
&lt;li&gt;The NFS server runs in user space on the bode containing the primary volume. Each NFS server uses its own &lt;em&gt;RWO&lt;/em&gt; volume to store data so the data of each Volume is isolated.&lt;/li&gt;
&lt;li&gt;Ondat binds an &lt;a href=&#34;https://en.wikipedia.org/wiki/Ephemeral_port&#34;&gt;ephemeral port&lt;/a&gt; to the host network interface for each NFS-Ganesha server.&lt;/li&gt;
&lt;li&gt;The NFS export is presented using &lt;a href=&#34;https://datatracker.ietf.org/doc/html/rfc7862&#34;&gt;&lt;code&gt;NFS v4.2&lt;/code&gt;&lt;/a&gt;. Ensure that you review the official &lt;a href=&#34;/docs/prerequisites/firewalls&#34;&gt;prerequisites&lt;/a&gt; page for more information on the port number range, that is for Ondat RWX persistent volumes to successfully run.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ondat API Manager&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The Ondat API Manager resource monitors Ondat RWX volumes to create and maintain a &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/&#34;&gt;Kubernetes service&lt;/a&gt; that points towards each RWX volume&amp;rsquo;s NFS export endpoint.&lt;/li&gt;
&lt;li&gt;The API Manager is responsible for updating the service endpoint when a RWX volume failover occurs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;how-are-ondat-readwritemany-rwx-persistentvolumeclaims-pvcs-provisioned&#34;&gt;How are Ondat ReadWriteMany (RWX) PersistentVolumeClaims (PVCs) Provisioned?&lt;/h3&gt;
&lt;p&gt;The sequence in which a RWX PVC is provisioned and used demonstrated in the steps below:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A &lt;code&gt;PersistentVolumeClaim&lt;/code&gt; (PVC) is created with &lt;code&gt;ReadWriteMany&lt;/code&gt; (RWX) access mode using any Ondat &lt;code&gt;StorageClass&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Ondat dynamically provisions the &lt;code&gt;PersistentVolume&lt;/code&gt; (PV).&lt;/li&gt;
&lt;li&gt;A new Ondat &lt;code&gt;ReadWriteOnly&lt;/code&gt; (RWO) Volume is provisioned internally (not visible in Kubernetes).&lt;/li&gt;
&lt;li&gt;When the RWX PVC is consumed by a pod, an NFS-Ganesha server is instantiated on the same node as the primary volume.&lt;/li&gt;
&lt;li&gt;The NFS-Ganesha server then uses the RWO Ondat volume as its backend disk.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;Ondat API Manager&lt;/em&gt; publishes the host IP and port for the NFS service endpoint, by creating a Kubernetes service that points to the NFS-Ganesha server export endpoint.&lt;/li&gt;
&lt;li&gt;Ondat issues a NFS mount on the Node where the Pod using the PVC is scheduled.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For more information on how to get started with Ondat Shared Filesystems, review the &lt;a href=&#34;/docs/operations/rwx&#34;&gt;How To Create ReadWriteMany (RWX) Volumes&lt;/a&gt; operations page.&lt;/p&gt;
&lt;h3 id=&#34;high-availability-for-ondat-shared-filesystems&#34;&gt;High Availability For Ondat Shared Filesystems&lt;/h3&gt;
&lt;p&gt;Ondat RWX volumes failover in the same way as standard Ondat RWO volumes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The replica volume is promoted upon detection of node failure and the NFS-Ganesha server is started on the node containing the promoted replica.&lt;/li&gt;
&lt;li&gt;The Ondat API Manager updates the endpoint of the Volume&amp;rsquo;s NFS service, causing traffic to be routed to the URL of the new NFS-Ganesha server.&lt;/li&gt;
&lt;li&gt;The NFS client in the application node (where the user&amp;rsquo;s pod is running) automatically reconnects.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;further-information&#34;&gt;Further Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;All &lt;a href=&#34;/docs/concepts/labels/&#34;&gt;Ondat Feature Labels&lt;/a&gt; that work on RWO volumes will also work on RWX volumes.&lt;/li&gt;
&lt;li&gt;A Ondat RWX volume is matched one-to-one with a PVC. Therefore the Ondat RWX volume can only be accessed by pods in the &lt;strong&gt;same&lt;/strong&gt; Kubernetes namespace.&lt;/li&gt;
&lt;li&gt;Ondat RWX volumes support volume resize.
&lt;ul&gt;
&lt;li&gt;For more information on how to resize a volume, review the &lt;a href=&#34;/docs/operations/resize&#34;&gt;Volume Resize&lt;/a&gt; operations page.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;As it&amp;rsquo;s backed by an NFS instance, the resource consumption of a RWX volume can grow.
&lt;ul&gt;
&lt;li&gt;This consumption scales linearly with the volume&amp;rsquo;s throughput.&lt;/li&gt;
&lt;li&gt;If given insufficient resources the NFS server&amp;rsquo;s IO can be blocked and it can fail.&lt;/li&gt;
&lt;li&gt;The resources in question are the speed of the underlying disk and CPU time of the machine hosting the volume&amp;rsquo;s primary replica.&lt;/li&gt;
&lt;li&gt;Our attachments are unlikely to cause any issue outside of NFS. We have happily tested up to 800 consumers for volumes hosted on small hosts, for very low-throughput applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Snapshots</title>
      <link>/docs/concepts/snapshots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/snapshots/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is available in release &lt;code&gt;v2.8.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The Ondat Snapshot feature can be used in conjunction with a backup tooling provider e.g. &lt;a href=&#34;https://www.kasten.io/product/&#34;&gt;Kasten K10&lt;/a&gt; or &lt;a href=&#34;https://cloudcasa.io/&#34;&gt;CloudCasa&lt;/a&gt; to snapshot, backup and restore Kubernetes applications.
Kasten K10 and CloudCasa have been tested and validated with our feature.&lt;/p&gt;
&lt;p&gt;The snapshot functionality is useful for:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Disaster_recovery&#34;&gt;Disaster Recovery (DR)&lt;/a&gt; scenarios.&lt;/li&gt;
&lt;li&gt;Rolling back unwanted changes.&lt;/li&gt;
&lt;li&gt;Auditing purposes.&lt;/li&gt;
&lt;li&gt;Migrating applications between clusters.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;what-are-snapshots-backups--restores&#34;&gt;What Are Snapshots, Backups &amp;amp; Restores?&lt;/h3&gt;
&lt;p&gt;A â€œ&lt;strong&gt;snapshot&lt;/strong&gt;â€ is a point-in-time copy of a PVC. Snapshots are modelled via the &lt;code&gt;VolumeSnapshot&lt;/code&gt; and &lt;code&gt;VolumeSnapshotContent&lt;/code&gt; Kubernetes API objects.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Snapshots have limited use as they live within the cluster and cannot be used to restore the PVC if the node holding the snapshot is lost.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A â€œ&lt;strong&gt;backup&lt;/strong&gt;â€ is the process of materialising a new PVC, whose data source is a previously created snapshot and then extracting the data to a location outside of the cluster.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Ondat Snapshots feature integrates with Kasten K10 or CloudCasa to provide backup functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A â€œ&lt;strong&gt;restore&lt;/strong&gt;â€ is the process of restoring an application from a given backup.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Ondat Snapshots feature integrates with Kasten K10 or CloudCasa to provide restore functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-does-it-work&#34;&gt;How Does It Work?&lt;/h3&gt;
&lt;p&gt;The Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volume-snapshots/&#34;&gt;Volume Snapshots&lt;/a&gt; feature provides users with a set of custom resource definitions (CRD) and APIs to create and manage volume snapshots. Storage providers can then implement the necessary &lt;a href=&#34;https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/&#34;&gt;Container Storage Interface (CSI)&lt;/a&gt; APIs to integrate with this feature.&lt;/p&gt;
&lt;p&gt;This is exactly what weâ€™ve done at Ondat. Additional backup tooling solutions (e.g. Kasten K10 or Cloudcasa) can then be utilised to orchestrate and automate snapshotting, backups and restores.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For Kasten K10 users, review the &lt;a href=&#34;/docs/operations/backups-and-restores-with-kastenk10/&#34;&gt;How To Backup &amp;amp; Restore Using Ondat Snapshots with Kasten K10&lt;/a&gt; operations page to get started.&lt;/li&gt;
&lt;li&gt;For CloudCasa users, review the &lt;a href=&#34;/docs/operations/backups-and-restores-with-ondat-snapshots-and-cloudcasa/&#34;&gt;How To Backup &amp;amp; Restore Using Ondat Snapshots with CloudCasa&lt;/a&gt; operations page to get started.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ The Ondat Snapshots feature is not fully CSI compliant yet. As of today, the feature can only be used with Kasten K10 or CloudCasa, and with restoration from an external backup.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;current-scope--limitations&#34;&gt;Current Scope &amp;amp; Limitations&lt;/h3&gt;
&lt;p&gt;The Ondat Snapshots feature has the following limitations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The feature has been designed to work with Kasten K10 &amp;amp; CloudCasa only. This is not a fully CSI compliant implementation of the specification yet.&lt;/li&gt;
&lt;li&gt;Restoring via Kasten 10 from a â€œlocal snapshotâ€ is not supported with the Ondat Snapshot feature. Users may only restore applications using a Kasten K10
â€œExternal backupâ€.&lt;/li&gt;
&lt;li&gt;Snapshotting &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes&#34;&gt;ReadWriteMany (RWX)&lt;/a&gt; volumes is not supported. This is because it is next to impossible to ensure that a NFS mounted volume is in a suitable state for snapshotting.
&lt;ol&gt;
&lt;li&gt;For RWX volumes, the user only has access to the filesystem on the NFS client. It is not possible to run &lt;a href=&#34;https://man7.org/linux/man-pages/man8/fsfreeze.8.html&#34;&gt;&lt;code&gt;fsfreeze&lt;/code&gt;&lt;/a&gt; on this mount point &amp;ndash; NFS does not support it. Thus the user can not &lt;a href=&#34;https://en.wikipedia.org/wiki/Quiesce&#34;&gt;quiesce&lt;/a&gt; the filesystem and we can not take a &amp;ldquo;consistent&amp;rdquo; snapshot.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Topology-Aware Placement (TAP)</title>
      <link>/docs/concepts/tap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/tap/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is available in release &lt;code&gt;v2.5.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat Topology-Aware Placement (TAP) is a feature that enforces placement of data across failure domains to guarantee high availability.&lt;/p&gt;
&lt;p&gt;Ondat TAP uses default &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#built-in-node-labels&#34;&gt;labels on nodes&lt;/a&gt; to define failure domains - for instance, an &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html&#34;&gt;Availability Zone&lt;/a&gt;. However, the key label used to segment failure domains can be defined by the user per node. Lastly, Ondat TAP is an opt-in feature per volume.&lt;/p&gt;
&lt;h3 id=&#34;how-does-ondat-topology-aware-placement-work&#34;&gt;How does Ondat Topology-Aware Placement Work?&lt;/h3&gt;
&lt;p&gt;Ondat&amp;rsquo;s Topology-Aware Placement attempts to distribute sensitive data across different failure domains. Hence, a primary volume and its replicas are scattered across failure domains - that is implemented following a &lt;a href=&#34;https://en.wikipedia.org/wiki/Best-effort_delivery&#34;&gt;best effort algorithm&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In case that Ondat TAP rules can&amp;rsquo;t be fulfilled the placement algorithm will attempt a best approach placement (even if new replicas are in the same failure domain).&lt;/li&gt;
&lt;li&gt;The best effort placement allows the system to place replicas on the same failure domains when a full domain has failed catastrophically. Hence, the system self heals as fast as possible without waiting for the nodes on the failed domain to recover.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is the user&amp;rsquo;s responsibility to rebalance the data when the failed domain has recovered its availability. That can be achieved by recreating the replicas of a volume.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Future versions of Ondat will facilitate the procedure by allowing a volume drain.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;advantages-of-using-ondat-topology-aware-placement-tap&#34;&gt;Advantages of using Ondat Topology-Aware Placement (TAP)&lt;/h3&gt;
&lt;p&gt;Deploying a stateful application on a clusters with multiple nodes without Ondat TAP enabled can result in suboptimal placement for &lt;a href=&#34;https://en.wikipedia.org/wiki/High_availability&#34;&gt;high availability.&lt;/a&gt; Not enabling Ondat TAP can cause following problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unschedulable pods due to resource, affinity, and taint issues when a full failure domain experiences a failure.&lt;/li&gt;
&lt;li&gt;Volume replicas placed within the same zone as a primary volume.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/tap.png&#34; alt=&#34;Ondat Topology-Aware Placement&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;how-to-use-ondat-topology-aware-placement&#34;&gt;How to use Ondat Topology-Aware Placement?&lt;/h3&gt;
&lt;p&gt;Topology-Aware Placement can be enabled by applying the label &lt;code&gt;storageos.com/topology-aware=true&lt;/code&gt; to a PVC or as a parameter of its StorageClass.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For more information on how to enable Ondat Topology-Aware Placement for your volumes, review the &lt;a href=&#34;/docs/operations/tap&#34;&gt;Ondat Topology-Aware Placement&lt;/a&gt; operations page.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;understanding-topology-domains&#34;&gt;Understanding Topology Domains&lt;/h3&gt;
&lt;p&gt;A topology domain is a set of nodes. The domain is identified by a label, which can be defined by the user.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The default label that Ondat uses to segment nodes in failure domains is &amp;raquo; &lt;code&gt;topology.kubernetes.io/zone&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;However, you can define your own topology key by setting the key string in the &lt;a href=&#34;/docs/concepts/labels/&#34;&gt;Ondat feature label&lt;/a&gt; &amp;raquo; &lt;code&gt;storageos.com/topology-key&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-failure-modes--topology-aware-placement&#34;&gt;Ondat Failure Modes &amp;amp; Topology-Aware Placement&lt;/h3&gt;
&lt;p&gt;Failure modes are a complimentary feature of the Topology-Aware Placement functionality. Failure modes allow you to define how many replicas of a volume can become unavailable before the volume is marked as read-only.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For more information on how to Failure Modes work , review the &lt;a href=&#34;/docs/concepts/replication&#34;&gt;Ondat Topology-Aware Placement&lt;/a&gt; feature page.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, assuming that your cluster has three topology zones, &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt;, and your deployment has a master and two replicas, Ondat will attempt to place one volume in each topology zone.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If zone &lt;code&gt;A&lt;/code&gt; fails, I/O operations to your volume will stop completely - if the Failure Mode is &lt;code&gt;hard&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If the Failure Mode is &lt;code&gt;soft&lt;/code&gt; - I/O operations will continue while volume failover is in progress, and a new replica will be placed in an operational zone.&lt;/li&gt;
&lt;li&gt;Note that if zone &lt;code&gt;A&lt;/code&gt; recovers, the cluster will &lt;strong&gt;not&lt;/strong&gt; automatically rebalance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;soft&lt;/code&gt; failure mode will not tolerate the failure of multiple replicas at once, and will suspend I/O operations in this case.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you wish to tolerate more than one failed replica, then you can set this as an integer using the &lt;code&gt;&amp;lt;integer&amp;gt;&lt;/code&gt; label.&lt;/li&gt;
&lt;li&gt;If individual nodes within a topology zone fail, the replicas will fail over to other nodes within that zone. Once nodes in the zone are exhausted, placement will revert to best-effort.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Upgrade</title>
      <link>/docs/upgrade/upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/upgrade/upgrade/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide provides instructions on how to upgrade Ondat.&lt;/p&gt;
&lt;h2 id=&#34;upgrading-an-ondat-v2-cluster&#34;&gt;Upgrading An Ondat &lt;code&gt;v2&lt;/code&gt; Cluster&lt;/h2&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Ensure that you have read the &lt;a href=&#34;/docs/prerequisites/pidlimits&#34;&gt;PIDs prerequisite introduced in Ondat
v2.3&lt;/a&gt; and that you have checked the init
container logs to ensure your environments PID limits are set correctly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Pull down the new Ondat container image &lt;code&gt;storageos/node:v2.8.2&lt;/code&gt; onto the
nodes beforehand so that the cluster spins up faster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Speak with our support team &lt;a href=&#34;/docs/support/&#34;&gt;here&lt;/a&gt; so we can assist you
with your upgrade.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---backup-ondat-deployment-manifests&#34;&gt;Step 1 - Backup Ondat Deployment Manifests&lt;/h3&gt;
&lt;p&gt;Make sure that you keep a backup of all the Ondat YAML files. You can also
backup the &lt;code&gt;StatefulSet&lt;/code&gt; yaml files to keep track of the replicas.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod -n storageos -o yaml &amp;gt; storageos_operator.yaml
kubectl get storageoscluster -n storageos -o yaml &amp;gt; storageos_cr.yaml
kubectl get statefulset --all-namespaces &amp;gt; statefulset-sizes.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2---scale-down-stateful-applications-to-zero&#34;&gt;Step 2 - Scale Down Stateful Applications To Zero&lt;/h3&gt;
&lt;p&gt;Scale all of the stateful applications that use Ondat volumes to 0.&lt;/p&gt;
&lt;h3 id=&#34;step-3---upgrade-ondat&#34;&gt;Step 3 - Upgrade Ondat&lt;/h3&gt;
&lt;p&gt;Run the following command using the kubectl storageos plugin.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure you are using the latest version of the kubectl storageos plugin.
You can make use of the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;installation guide&lt;/a&gt;
and get the latest version
&lt;a href=&#34;https://github.com/storageos/kubectl-storageos&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos upgrade
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Please use the &lt;code&gt;--etcd-tls-enabled&lt;/code&gt; if using TLS with your ETCD.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ If you are using a namespace other than &lt;code&gt;storageos&lt;/code&gt; for your Ondat
install, please use &lt;code&gt;--uninstall-stos-operator-namespace&lt;/code&gt; argument because it
uninstalls the cluster first and then reinstalls it with the new version.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ If at any point something goes wrong with the upgrade process, backups of
all the relevant Kubernetes manifests can be found in &lt;code&gt;~/.kube/storageos/&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;step-4---scale-up-stateful-applications&#34;&gt;Step 4 - Scale Up Stateful Applications&lt;/h3&gt;
&lt;p&gt;Once the Ondat upgrade is complete and the core components are back online,
scale up the stateful applications that use Ondat volumes back up to their
respective replica count.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Volumes</title>
      <link>/docs/concepts/volumes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/volumes/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Ondat volumes are a logical construct which represent a writeable volume and exhibit standard POSIX semantics. Ondat presents volumes as mounts into containers via the &lt;a href=&#34;https://en.wikipedia.org/wiki/LIO_(SCSI_target)&#34;&gt;Linux-IO (LIO)&lt;/a&gt; subsystem.&lt;/p&gt;
&lt;p&gt;Conceptually, Ondat volumes have a frontend presentation, which is what the application sees, and a backend presentation, which is the actual on-disk format. Depending on the configuration, frontend and backend components may be on the same or different hosts.&lt;/p&gt;
&lt;p&gt;Volumes are formatted using the linux standard &lt;code&gt;ext4&lt;/code&gt; filesystem by default. Kubernetes users may change the default filesystem type to &lt;code&gt;ext2&lt;/code&gt;, &lt;code&gt;ext3&lt;/code&gt;, &lt;code&gt;ext4&lt;/code&gt;, or &lt;code&gt;xfs&lt;/code&gt; by setting the &lt;code&gt;fsType&lt;/code&gt; parameter in their &lt;code&gt;StorageClass&lt;/code&gt; - review the &lt;a href=&#34;/docs/reference/filesystems#persistent-volume-filesystems&#34;&gt;Supported Filesystems&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Different filesystems may be supported in the future.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat volumes are represented on disk in two parts.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Actual volume data is written to blob files in &lt;code&gt;/var/lib/storageos/data/dev[\d+]&lt;/code&gt;. Inside these directories, each Ondat block device gets two blob files of the form &lt;code&gt;vol.xxxxxx.y.blob&lt;/code&gt;, where &lt;code&gt;x&lt;/code&gt; is the inode number for the device, and &lt;code&gt;y&lt;/code&gt; is an index between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;We provide two blob files in order to ensure that certain operations which require locking do not impede in-flight writes to the volume.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In systems which have multiple &lt;code&gt;/var/lib/storageos/data/dev[\d+]&lt;/code&gt; directories, two blob files are created per block device.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This allows us to load-balance writes across multiple devices. In cases where dev directories are added after a period of runtime, later directories are favoured for writes until the data is distributed evenly across the blob files.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Metadata is kept in directories named &lt;code&gt;/var/lib/storageos/data/db[\d+]&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We maintain an index of all blocks written to the blob file inside the metadata store, including checksums. These checksums allow us to detect &lt;a href=&#34;https://en.wikipedia.org/wiki/Data_degradation&#34;&gt;bit rot&lt;/a&gt;, and return errors on reads, rather than serve bad data.&lt;/li&gt;
&lt;li&gt;In future versions we may implement recovery from replicas for volumes with one or more replicas defined.&lt;/li&gt;
&lt;li&gt;Ondat metadata requires approximately &lt;code&gt;2.7 GiB&lt;/code&gt; of storage per &lt;code&gt;1 TiB&lt;/code&gt; of allocated blocks in the associated volume. This size is consistent irrespective of data compression defined on the volume.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To ensure deterministic performance, individual Ondat volumes must fit on a single node.&lt;/p&gt;
&lt;h3 id=&#34;minimum-ondat-volume-size&#34;&gt;Minimum Ondat Volume Size&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The minimum volume size Ondat supports is &lt;code&gt;1 GiB&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ondat-volume-resizing&#34;&gt;Ondat Volume Resizing&lt;/h3&gt;
&lt;p&gt;Ondat supports offline resize of volumes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This means that a volume cannot be resized while it is in use. Furthermore, in order for a resize operation to take place the volume must not be attached to a node. This is to ensure that the volume is not in use.&lt;/li&gt;
&lt;li&gt;This means that if a Kubernetes pod is currently consuming a volume that a resize request has been issued for, the resize will not be actioned until the pod is terminated and the volume is detached from the node.&lt;/li&gt;
&lt;li&gt;The Ondat Control Plane will then attach the volume to the node that holds the master deployment and resize the underlying block device and then run &lt;a href=&#34;https://man7.org/linux/man-pages/man8/resize2fs.8.html&#34;&gt;resize2fs&lt;/a&gt; to expand the filesystem.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on how to resize a volume, review the &lt;a href=&#34;/docs/operations/resize&#34;&gt;Volume Resize&lt;/a&gt; operations page.&lt;/p&gt;
&lt;h3 id=&#34;ondat-volume-encryption&#34;&gt;Ondat Volume Encryption&lt;/h3&gt;
&lt;p&gt;Volumes can be configured on creation to have &lt;a href=&#34;https://en.wikipedia.org/wiki/Data_at_rest&#34;&gt;data encryption-at-rest&lt;/a&gt;. Data is encrypted with XTS-AES and decrypted upon use.&lt;/p&gt;
&lt;p&gt;For more information on how to enable data encryption for Ondat volumes, review the &lt;a href=&#34;/docs/concepts/encryption&#34;&gt;Ondat Data Encryption&lt;/a&gt; feature page.&lt;/p&gt;
&lt;h3 id=&#34;trim&#34;&gt;TRIM&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ This feature is available in release &lt;code&gt;v2.4.0&lt;/code&gt; or greater.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat volumes support &lt;a href=&#34;https://en.wikipedia.org/wiki/Trim_%28computing%29&#34;&gt;TRIM/UNMAP&lt;/a&gt; which allows the space allocated to deleted blocks to be reclaimed from the backend blob files that back each volume when a TRIM call is made.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support for TRIM is enabled by default for all uncompressed volumes, volumes are created without compression enabled by default.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on how to TRIM a filesystem, review the &lt;a href=&#34;/docs/operations/trim&#34;&gt;TRIM&lt;/a&gt; operations page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Platform Upgrade</title>
      <link>/docs/upgrade/using-rolling-upgrades/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/upgrade/using-rolling-upgrades/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to enable protection for your orchestrator&amp;rsquo;s rolling upgrades using the &lt;a href=&#34;/docs/concepts/rolling-upgrades/#node-guard&#34;&gt;Node Guard&lt;/a&gt; and &lt;a href=&#34;/docs/concepts/rolling-upgrades/#node-manager&#34;&gt;Node Manager&lt;/a&gt;. This feature helps prevent your persistent storage volumes from becoming unhealthy during the rolling downtime of an orchestrator upgrade.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ This feature is currently in tech preview, we only recommend using this feature on your test clusters.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure you have met the requirements of &lt;a href=&#34;https://kubernetes.io/docs/tasks/run-application/configure-pdb/&#34;&gt;configuring a Pod Disruption Budget (PDB)&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ If your volume does not have any replicas, the rolling upgrades feature will not start on any StorageOS node until you have one or more replicas on all your volumes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ This feature supports the following platforms: Google Anthos, and Google GKE with future support to be expanded to Amazon EKS, Openshift, and Rancher.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Using Ondat for the internal registry is not recommended. OpenShift requires the internal registry to be available but Ondat volumes may become unavailable during the upgrade.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ For Openshift: The PDB feature is only stable in Kubernetes v1.21+ and Openshift v4.8+.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---enable-node-manager--node-guard&#34;&gt;Step 1 - Enable Node Manager &amp;amp; Node Guard&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Add the following lines to the &lt;code&gt;StorageOSCluster&lt;/code&gt; spec:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeManagerFeatures&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeGuard&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Alternatively, you can run the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get storageoscluster -n storageos storageoscluster -o yaml &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; sed -e &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;s|^spec:$|spec:\n  nodeManagerFeatures:\n    nodeGuard: &amp;#34;&amp;#34;|&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; kubectl apply -f - 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;You will see new pods getting created, one pod per node in a cluster called Node Manager. If you enable the Node Guard during the first installation, Node Guard might fall into a temporary &lt;code&gt;CrashLoopBackoff&lt;/code&gt; loop until all cluster components are up and running.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Node Guard has a few configuration options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MINIMUM_REPLICAS&lt;/code&gt;: minimum replica number of any volume. Default: 1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;WATCH_ALL_VOLUMES&lt;/code&gt;: watch all volumes on every node, otherwise Node Guard watches volumes and their replicas on the node where it is running. Extra safety option with a performance impact. Default: false&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeManagerFeatures&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeGuard&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;MINIMUM_REPLICAS=2,WATCH_ALL_VOLUMES=true&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2---rolling-upgrades-is-ready&#34;&gt;Step 2 - Rolling Upgrades Is Ready&lt;/h3&gt;
&lt;p&gt;Congratulations, you are now ready to start the rolling upgrade process of your orchestrator!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ GKE and AKS take care of the pod disruption budget for one hour. After this period, they drain the node, which would destroy the volume.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ EKS takes care of PDB for 50 mins, after this period upgrade would fail unless it was forced.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Node Guard has a one-day termination period by default. The final termination period heavily depends on the platform you use. During the termination period, you should SSH into the node to create a backup in the worst-case scenario.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Volumes are healthy, all in sync but &lt;code&gt;storageos-node-manager&lt;/code&gt; pod is hanging on the &lt;code&gt;Terminating&lt;/code&gt; state.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The long termination period of Node Manager tries to keep failed node - and volumes on it - up and running as long as possible. This gives a chance to create a backup from an accidentally deleted machine. In case, Node Guard isn&amp;rsquo;t able to determine volume statuses, because of a network issue or missing StorageOS service, you have to delete pod manually by executing the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl delete pods -n storageos storageos-node-manager-XYZ --grace-period&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt; --force
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;A node has been removed accidentally or not in the official &lt;code&gt;graceful termination&lt;/code&gt; way before drain, and two Node Manager pods - one in &lt;code&gt;Pending&lt;/code&gt; and the other in &lt;code&gt;Terminating&lt;/code&gt; states - are hanging on the same node.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Node Manager deployment tolerates almost every issue on the target node to protect your data. On the other hand, Node Manager doesn&amp;rsquo;t tolerate itself on the same node. If a node goes down before Kubernetes was able to properly delete StorageOS Node daemonset, after the termination phase it re-schedules Node Manager pod to ensure the right number of replicas. But the pod isn&amp;rsquo;t able to be scheduled, because of the toleration. Meantime Kubernetes isn&amp;rsquo;t able to remove the pod in &lt;code&gt;Terminating&lt;/code&gt; state, because Kubelet isn&amp;rsquo;t responding.&lt;/p&gt;
&lt;p&gt;The only way to solve this situation is to delete the node from Kubernetes cluster by executing the command below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl delete node XYZ
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Kubernetes has introduced Non-Graceful Node Shutdown Alpha in 1.24. This new feature allows cluster admins to mark failing nodes as &lt;code&gt;NoExecute&lt;/code&gt; or &lt;code&gt;NoScedule&lt;/code&gt;. Both options should solve the scheduling issue of Node Manager pod by decreasing the number of daemonset instances to the right number at Kubernetes API level, but in the absence of Kubelet termination of pods would still hangin.&lt;/p&gt;
&lt;/blockquote&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Policies</title>
      <link>/docs/reference/policies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/policies/</guid>
      <description>
        
        
        &lt;p&gt;Ondat policies are a way to control user and group access to Ondat
&lt;a href=&#34;/docs/concepts/namespaces&#34;&gt;Namespaces&lt;/a&gt;. To grant a user or group
access to a namespace, a policy needs to be created mapping the user or group
to the namespace.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Users always have access to the default namespace&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For more information on how to use policies, see the
&lt;a href=&#34;/docs/operations/policies&#34;&gt;Policies operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Amazon Elastic Kubernetes Service (EKS)</title>
      <link>/docs/install/aws/amazon-web-services-eks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/aws/amazon-web-services-eks/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://aws.amazon.com/eks/&#34;&gt;Amazon EKS&lt;/a&gt; cluster using either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm Chart&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h3 id=&#34;1---cluster-and-node-prerequisites&#34;&gt;1 - Cluster and Node Prerequisites&lt;/h3&gt;
&lt;p&gt;The minimum cluster requirements for a &lt;strong&gt;non-production installation&lt;/strong&gt; of Ondat are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux with a 64-bit architecture.&lt;/li&gt;
&lt;li&gt;2 vCPU and 4GB of RAM per node.&lt;/li&gt;
&lt;li&gt;3 worker nodes in the cluster and sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/li&gt;
&lt;li&gt;Make sure your EKS clusters use &lt;a href=&#34;https://cloud-images.ubuntu.com/docs/aws/eks/&#34;&gt;Ubuntu for EKS&lt;/a&gt; as the default node operating system with an optimised kernel.  This installation guide takes you through that process as it is not easily available in the AWS Console.&lt;/li&gt;
&lt;li&gt;For more information on the Linux distributions that are supported, and how to update Amazon Linux with the correct Kernal Modules, see &lt;a href=&#34;/docs/prerequisites/systemconfiguration/&#34;&gt;System Configuration&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a comprehensive list of prerequisites and how to build a &lt;strong&gt;production installation&lt;/strong&gt; of Ondat please refer to &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat Prerequisites&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2---client-tools-prerequisites&#34;&gt;2 - Client Tools Prerequisites&lt;/h3&gt;
&lt;p&gt;The following CLI utilities are installed on your local machine and available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/cli/&#34;&gt;aws&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://eksctl.io/&#34;&gt;eksctl&lt;/a&gt;, at least version &lt;code&gt;&amp;gt;=0.83.0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat can be installed either via Helm Chart or using our command-line tool.  Depending on which installation method you choose you will require either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3---creating-a-cluster-with-the-correct-linux-distribution&#34;&gt;3 - Creating a cluster with the correct Linux distribution&lt;/h3&gt;
&lt;p&gt;In this example, we have used &lt;a href=&#34;https://eksctl.io/introduction/&#34;&gt;eksctl&lt;/a&gt; to create a cluster with 3 nodes of size &lt;code&gt;i3en.xlarge&lt;/code&gt; running Ubuntu for EKS in the &lt;code&gt;eu-west-2&lt;/code&gt; region. We have provided &lt;code&gt;20 GB&lt;/code&gt; of disk space for each node. With a default installation Ondat will store data locally in the node&amp;rsquo;s file system under the path &lt;code&gt;/var/lib/storageos&lt;/code&gt; on each node in &lt;a href=&#34;/docs/concepts/nodes/#hyperconverged-mode&#34;&gt;hyperconverged mode&lt;/a&gt;.  In a production infrastructure, we would create multiple Elastic Block Store (EBS) Volumes tweaked for performance or use ephemeral SSD storage and &lt;a href=&#34;/docs/concepts/volumes/&#34;&gt;mount our volumes under data device directories&lt;/a&gt; with some additions to user data. We would also implement some form of snapshots or backup of these underlying volumes to ensure continuity in a disaster scenario.&lt;/p&gt;
&lt;h4 id=&#34;3a---creating-the-clusteryaml-file&#34;&gt;3a - Creating the cluster.yaml file&lt;/h4&gt;
&lt;p&gt;Create the following &lt;code&gt;cluster.yaml&lt;/code&gt; file that will be used to create your cluster. Make the following updates:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The file to use the &lt;code&gt;region&lt;/code&gt; and &lt;code&gt;availabilityZones&lt;/code&gt; that you need&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;&amp;lt;key-name&amp;gt;&lt;/code&gt; field in the publicKeyName parameter - make sure you update this to match your ssh key name.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# cluster.yaml&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;---&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;eksctl.io/v1alpha5&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ClusterConfig&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ondat-cluster&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;region&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;eu-west-2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;1.22&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;addons&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;aws-ebs-csi-driver&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;iam&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;withOIDC&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;managedNodeGroups&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ondat-ng-2a&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;availabilityZones&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;eu-west-2a&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;minSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;maxSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;desiredCapacity&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;instanceType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i3en.xlarge&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;amiFamily&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Ubuntu2004&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ssh&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;allow&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;publicKeyName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;&amp;lt;key-name&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;labels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;{&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ondat&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;node}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;gp3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeEncrypted&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;disableIMDSv1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;iam&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;withAddonPolicies&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ebs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;preBootstrapCommands&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkdir -p /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;echo &amp;#34;/dev/nvme1n1 /var/lib/storageos ext4 defaults,discard 0 1&amp;#34; &amp;gt;&amp;gt; /etc/fstab&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkfs.ext4 /dev/nvme1n1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mount /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ondat-ng-2b&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;availabilityZones&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;eu-west-2b&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;minSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;maxSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;desiredCapacity&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;instanceType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i3en.xlarge&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;amiFamily&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Ubuntu2004&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ssh&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;allow&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;publicKeyName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;&amp;lt;key-name&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;labels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;{&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ondat&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;node}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;gp3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeEncrypted&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;disableIMDSv1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;iam&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;withAddonPolicies&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ebs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;preBootstrapCommands&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkdir -p /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;echo &amp;#34;/dev/nvme1n1 /var/lib/storageos ext4 defaults,discard 0 1&amp;#34; &amp;gt;&amp;gt; /etc/fstab&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkfs.ext4 /dev/nvme1n1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mount /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ondat-ng-2c&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;availabilityZones&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;eu-west-2c&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;minSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;maxSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;desiredCapacity&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;instanceType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;i3en.xlarge&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;amiFamily&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Ubuntu2004&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ssh&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;allow&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;publicKeyName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;&amp;lt;key-name&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;labels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;{&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ondat&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;node}&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeSize&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeType&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;gp3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeEncrypted&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;disableIMDSv1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;iam&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;withAddonPolicies&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ebs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;preBootstrapCommands&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkdir -p /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;echo &amp;#34;/dev/nvme1n1 /var/lib/storageos ext4 defaults,discard 0 1&amp;#34; &amp;gt;&amp;gt; /etc/fstab&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mkfs.ext4 /dev/nvme1n1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;mount /var/lib/storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;3b---creating-the-cluster&#34;&gt;3b - Creating the cluster&lt;/h4&gt;
&lt;p&gt;Once you have created the yaml file above, run the following eksctl command to create your cluster.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;eksctl create cluster --config-file&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;cluster.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;âš ï¸ With the above configuration, volumes will be deleted when the nodes they are attached to are terminated. Be sure to keep snapshots, for example by using &lt;a href=&#34;https://aws.amazon.com/blogs/storage/automating-amazon-ebs-snapshot-and-ami-management-using-amazon-dlm/&#34;&gt;Data Lifecycle Manager&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;4---connecting-to-your-cluster&#34;&gt;4 - Connecting to your cluster&lt;/h3&gt;
&lt;p&gt;First, provision your &lt;code&gt;kubeconfig&lt;/code&gt; for &lt;code&gt;kubectl&lt;/code&gt; and test that you can connect to Kubernetes.  You will need to update the script with the region where your cluster is.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;AWS_REGION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;eu-west-2&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Insert your preferred region here&lt;/span&gt;
aws eks update-kubeconfig --region AWS_REGION --name ondat-cluster
kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you receive the message &lt;code&gt;No resources found&lt;/code&gt; or see nodes marked as &lt;code&gt;NotReady&lt;/code&gt;, wait for 2-3 minutes in order for your nodes to transition to &lt;code&gt;Ready&lt;/code&gt; and check again to ensure they are running before proceeding through the next steps.&lt;/p&gt;
&lt;h3 id=&#34;5---creating-a-storageclass-for-etcd-to-use&#34;&gt;5 - Creating a StorageClass for etcd to use&lt;/h3&gt;
&lt;p&gt;If you used the &lt;code&gt;eksctl&lt;/code&gt; cluster configuration defined above, the gp3 storage class is already available so you can skip to the next step. Otherwise you can set up the EBS CSI Driver as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is important to note that the Ondat etcd usage of disk depends on the size of the Kubernetes cluster. However, it is recommended that the disks have at least 800 IOPS at any point in time. The best cost-effective storage class that fulfils such requirements is gp3. If gp2 is used, it is paramount to use a volume bigger than 256Gi as it will have enough IOPS even when the burstable credits are exhausted.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To use a gp3 storage class in Kubernetes it is required to install the Amazon CSI Driver. Follow [this guide] (&lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html&#34;&gt;https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html&lt;/a&gt;) to install. Follow the steps below:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/csi-iam-role.html&#34;&gt;Create IAM permissions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install the CSI driver&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/managing-ebs-csi.html&#34;&gt;Using EKS addon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/aws-ebs-csi-driver/blob/master/docs/install.md&#34;&gt;Using self-managed add on&lt;/a&gt; (AWS clusters, but not in EKS)&lt;/li&gt;
&lt;li&gt;Install the &lt;code&gt;gp3&lt;/code&gt; &lt;code&gt;StorageClass&lt;/code&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;EOF
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: StorageClass
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: storage.k8s.io/v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  name: gp3
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;allowVolumeExpansion: true
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;provisioner: ebs.csi.aws.com
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;volumeBindingMode: WaitForFirstConsumer
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;parameters:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  type: gp3
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;installation-of-ondat&#34;&gt;Installation of Ondat&lt;/h2&gt;
&lt;h3 id=&#34;step-1---adding-a-cluster&#34;&gt;Step 1 - Adding a Cluster&lt;/h3&gt;
&lt;p&gt;The Ondat Portal is how you can license and get the commands for installing Ondat:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Either login or create an account on the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat Portal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Choose the &amp;lsquo;Install Ondat on your cluster&amp;rsquo; or &amp;lsquo;Add cluster&amp;rsquo; options the UI&lt;/li&gt;
&lt;li&gt;Add a Name for your cluster and where it is going to be located&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-2---choosing-the-installation-method&#34;&gt;Step 2 - Choosing the Installation Method&lt;/h3&gt;
&lt;p&gt;You can use either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt; to install Ondat onto your cluster.  The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below&lt;/p&gt;
&lt;h3 id=&#34;step-3a---installing-via-helm&#34;&gt;Step 3a - Installing via Helm&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/HelmInstall.png&#34; alt=&#34;Helm Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The first two lines of the command adds the Ondat Helm repository and ensures a updated local cache.  The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-3b---installing-via-kubectl-storageos-plugin&#34;&gt;Step 3b - Installing via kubectl-storageos plugin&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin.  The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/PluginInstall.png&#34; alt=&#34;kubectl-storageos Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The command that is provided by the Portal is unique to you and uses the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h3&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once all the components are up and running the output should look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/InstallSuccess.png&#34; alt=&#34;Install Success&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-5---applying-a-licence-to-the-cluster&#34;&gt;Step 5 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;p&gt;Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see our &lt;a href=&#34;https://www.ondat.io/pricing&#34;&gt;pricing page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To licence your cluster with the community edition:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Clusters page select &amp;lsquo;View Details&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Click on &amp;lsquo;Change Licence&amp;rsquo;&lt;/li&gt;
&lt;li&gt;In the following pop-up select the &amp;lsquo;Community Licence&amp;rsquo; option then click &amp;lsquo;Generate&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This process generates a licence and installs it for you. Now you are good to go!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Google Kubernetes Engine (GKE)</title>
      <link>/docs/install/gcp/google-kubernetes-engine-gke/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/gcp/google-kubernetes-engine-gke/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://cloud.google.com/kubernetes-engine&#34;&gt;Google Kubernetes Engine (GKE)&lt;/a&gt; cluster using either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm Chart&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ For users who are looking to deploy Ondat onto a &lt;a href=&#34;https://cloud.google.com/anthos&#34;&gt;Google Anthos&lt;/a&gt; cluster, use the &lt;a href=&#34;https://docs.ondat.io/docs/install/anthos/&#34;&gt;Google Anthos Installation guide&lt;/a&gt; for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h3 id=&#34;1---cluster-and-node-prerequisites&#34;&gt;1 - Cluster and Node Prerequisites&lt;/h3&gt;
&lt;p&gt;The minimum cluster requirements for a &lt;strong&gt;non-production installation&lt;/strong&gt; of ondat are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux with a 64-bit architecture.&lt;/li&gt;
&lt;li&gt;2 vCPU and 4GB of RAM per node.&lt;/li&gt;
&lt;li&gt;3 worker nodes in the cluster and sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/li&gt;
&lt;li&gt;Make sure your GKE cluster uses &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/node-images#ubuntu&#34;&gt;&lt;code&gt;ubuntu_containerd&lt;/code&gt;&lt;/a&gt; as the default node operating system. This node operating system image has the required kernel modules available for Ondat to run successfully.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a comprehensive list of prerequisites and how to build a &lt;strong&gt;production installation&lt;/strong&gt; of Ondat please refer to &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat Prerequisites&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2---client-tools-prerequisites&#34;&gt;2 - Client Tools Prerequisites&lt;/h3&gt;
&lt;p&gt;The following CLI utilities are installed on your local machine and available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat can be installed either via Helm Chart or using our command-line tool.  Depending on which installation method you choose you will require either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installation-of-ondat&#34;&gt;Installation of Ondat&lt;/h2&gt;
&lt;h3 id=&#34;step-1---adding-a-cluster&#34;&gt;Step 1 - Adding a Cluster&lt;/h3&gt;
&lt;p&gt;The Ondat Portal is how you can license and get the commands for installing Ondat.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Either login or create an account on the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat Portal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Choose the &amp;lsquo;Install Ondat on your cluster&amp;rsquo; or &amp;lsquo;Add cluster&amp;rsquo; options in the UI&lt;/li&gt;
&lt;li&gt;Add a Name for your cluster and where it is going to be located. This will allow you to view the same prerequisites listed above.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-2---choosing-the-installation-method&#34;&gt;Step 2 - Choosing the Installation Method&lt;/h3&gt;
&lt;p&gt;You can use either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt; to install Ondat onto your cluster.  The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below.&lt;/p&gt;
&lt;h3 id=&#34;step-3a---installing-via-helm&#34;&gt;Step 3a - Installing via Helm&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/HelmInstall.png&#34; alt=&#34;Helm Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The first two lines of the command adds the Ondat Helm repository and ensures a updated local cache.  The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-3b---installing-via-kubectl-storageos-plugin&#34;&gt;Step 3b - Installing via kubectl-storageos plugin&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin.  The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/PluginInstall.png&#34; alt=&#34;kubectl-storageos Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The command that is provided by the Portal is unique to you and uses the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h3&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once all the components are up and running the output should look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/InstallSuccess.png&#34; alt=&#34;Install Success&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-5---applying-a-licence-to-the-cluster&#34;&gt;Step 5 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;p&gt;Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see &lt;a href=&#34;https://www.ondat.io/pricing&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To licence your cluster with the community edition:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Clusters page select &amp;lsquo;View Details&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Click on &amp;lsquo;Change Licence&amp;rsquo;&lt;/li&gt;
&lt;li&gt;In the following pop-up select the &amp;lsquo;Community Licence&amp;rsquo; option then click &amp;lsquo;Generate&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This process generates a licence and installs it for you. Now you are good to go!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: OpenShift via OperatorHub</title>
      <link>/docs/install/openshift/openshift-operatorhub/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/openshift/openshift-operatorhub/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto an &lt;a href=&#34;/docs/platforms/openshift&#34;&gt;Openshift&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure the
&lt;a href=&#34;/docs/prerequisites/&#34;&gt;prerequisites for Ondat&lt;/a&gt; are
satisfied before proceeding. Including the deployment of an etcd cluster and
configuration of CRI-O PID limits.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ If you have installed OpenShift in AWS ensure that the requisite ports are
opened for the worker nodes&#39; security group.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ For OpenShift upgrades, refer to the
&lt;a href=&#34;/docs/platforms/openshift#openshift-upgrades&#34;&gt;OpenShift platform page&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat v2 supports OpenShift v4. For more information, see the &lt;a href=&#34;/docs/platforms/openshift&#34;&gt;OpenShift platform&lt;/a&gt; page.&lt;/p&gt;
&lt;h2 id=&#34;installation-of-ondat-via-operatorhub&#34;&gt;installation of Ondat via OperatorHub&lt;/h2&gt;
&lt;h4 id=&#34;step-1-operatorhub&#34;&gt;Step 1: Operatorhub&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Select the &lt;code&gt;OperatorHub&lt;/code&gt; from the Catalog sub menu and search for StorageOS&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Choose between using the RedHat Marketplace or the Community Operators
installation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select StorageOS and click &lt;strong&gt;Install&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select the relevant install options.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure the &lt;code&gt;Approval Strategy&lt;/code&gt; is set to &lt;strong&gt;Manual&lt;/strong&gt;. This option makes sure that the StorageOS
Operator doesn&amp;rsquo;t upgrade versions without explicit approval.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the approval procedure by clicking on the operator name.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On &lt;strong&gt;Subscription Details&lt;/strong&gt;, click the approval link.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On &lt;strong&gt;Review Manual Install&lt;/strong&gt; panel in the &lt;strong&gt;Components&lt;/strong&gt; tab, click &lt;strong&gt;Approve&lt;/strong&gt; to confirm the installation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Ondat Operator is installed along the required CRDs.&lt;/p&gt;
&lt;h4 id=&#34;step-2-authentication&#34;&gt;Step 2: Authentication&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a Secret in the &lt;code&gt;openshift-operators&lt;/code&gt; project and select the YAML option to create a secret containing the &lt;code&gt;username&lt;/code&gt; and an
&lt;code&gt;password&lt;/code&gt; key. The username and password defined in the secret will be
used to authenticate when using the Ondat CLI and GUI. Take note of
which project you created the secret in.&lt;/p&gt;
&lt;p&gt;Input the secret as YAML for simplicity.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;v1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Secret&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos-api&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;openshift-operators&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;kubernetes.io/storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# echo -n &amp;#39;&amp;lt;secret&amp;gt;&amp;#39; | base64&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;username&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;c3RvcmFnZW9z&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;password&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;c3RvcmFnZW9z&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go to the &lt;strong&gt;Operators&lt;/strong&gt;-&amp;gt;&lt;strong&gt;Installed Operators&lt;/strong&gt; and verify that the StorageOS Operator is installed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go to the &lt;strong&gt;StorageOS Cluster&lt;/strong&gt; section.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &lt;strong&gt;Create StorageOSCluster&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ An Ondat Cluster is defined using a Custom Resource Definition&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the Custom Resource&lt;/p&gt;
&lt;p&gt;The StorageOS cluster resource describes the Ondat cluster that will be
created. Parameters such as the &lt;code&gt;secretRefName&lt;/code&gt;, the &lt;code&gt;secretRefNamespace&lt;/code&gt; and
the &lt;code&gt;kvBackend.address&lt;/code&gt; are mandatory.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Additional &lt;code&gt;spec&lt;/code&gt; parameters are available on the &lt;a href=&#34;/docs/reference/operator/configuration&#34;&gt;Operator configuration&lt;/a&gt; page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;apiVersion: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos.com/v1&amp;#34;&lt;/span&gt;
kind: StorageOSCluster
metadata:
  name: storageos
  namespace: openshift-operators
spec:
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Ondat Pods are in kube-system by default&lt;/span&gt;
  secretRefName: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-api&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Reference the Secret created in the previous step&lt;/span&gt;
  secretRefNamespace: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;openshift-operators&amp;#34;&lt;/span&gt;  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Namespace of the Secret created in the previous step&lt;/span&gt;
  k8sDistro: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;openshift&amp;#34;&lt;/span&gt;
  kvBackend:
    address: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;storageos-etcd-client.etcd:2379&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Example address, change for your etcd endpoint&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# address: &amp;#39;10.42.15.23:2379,10.42.12.22:2379,10.42.13.16:2379&amp;#39; # You can set ETCD server ips&lt;/span&gt;
  resources:
    requests:
      memory: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;512Mi&amp;#34;&lt;/span&gt;
      cpu: &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# nodeSelectorTerms:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#   - matchExpressions:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#     - key: &amp;#34;node-role.kubernetes.io/worker&amp;#34; # Compute node label will vary according to your installation&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       operator: In&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       values:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       - &amp;#34;true&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the StorageOS Cluster resource status is &lt;strong&gt;Running&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It can take up to a minute to report the Ondat Pods ready.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the StorageOS Pods in the &lt;code&gt;kube-system&lt;/code&gt; project&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A Status of 3/3 in the &lt;strong&gt;Ready&lt;/strong&gt; column for the Daemonset Pods indicates that Ondat is
bootstrapped successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;license-cluster&#34;&gt;License cluster&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a license, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;
&lt;h2 id=&#34;first-ondat-volume&#34;&gt;First Ondat volume&lt;/h2&gt;
&lt;p&gt;If this is your first installation you may wish to follow the &lt;a href=&#34;/docs/operations/firstpvc&#34;&gt;Ondat volume guide&lt;/a&gt; for an example of how
to mount an Ondat volume in a Pod.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Azure Kubernetes Service (AKS)</title>
      <link>/docs/install/azure/microsoft-azure-aks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/azure/microsoft-azure-aks/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://azure.microsoft.com/en-gb/services/kubernetes-service/&#34;&gt;Microsoft AKS&lt;/a&gt; cluster using either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm Chart&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h3 id=&#34;1---cluster-and-node-prerequisites&#34;&gt;1 - Cluster and Node Prerequisites&lt;/h3&gt;
&lt;p&gt;The minimum cluster requirements for a &lt;strong&gt;non-production installation&lt;/strong&gt; of ondat are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux with a 64-bit architecture&lt;/li&gt;
&lt;li&gt;2 vCPU and 8GB of memory&lt;/li&gt;
&lt;li&gt;3 worker nodes in the cluster and sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster&lt;/li&gt;
&lt;li&gt;Make sure your AKS cluster uses &lt;a href=&#34;https://ubuntu.com/&#34;&gt;Ubuntu&lt;/a&gt; as the default node operating system with an optimised kernel. Any Ubuntu-based node operating system with a kernel version greater than &lt;code&gt;4.15.0-1029-azure&lt;/code&gt; is compatible with Ondat&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a comprehensive list of prerequisites and how to build a &lt;strong&gt;production installation&lt;/strong&gt; of Ondat please refer to &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat Prerequisites&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2---client-tools-prerequisites&#34;&gt;2 - Client Tools Prerequisites&lt;/h3&gt;
&lt;p&gt;The following CLI utilities are installed on your local machine and available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat can be installed either via Helm Chart or using our command-line tool.  Depending on which installation method you choose you will require either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installation-of-ondat&#34;&gt;Installation of Ondat&lt;/h2&gt;
&lt;h3 id=&#34;step-1---adding-a-cluster&#34;&gt;Step 1 - Adding a Cluster&lt;/h3&gt;
&lt;p&gt;The Ondat Portal is how you can license and get the commands for installing Ondat&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Either login or create an account on the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat Portal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Choose the &amp;lsquo;Install Ondat on your cluster&amp;rsquo; or &amp;lsquo;Add cluster&amp;rsquo; options in the UI&lt;/li&gt;
&lt;li&gt;Add a Name for your cluster and where it is going to be located.  This will allow you to view the same prerequisites as are listed above&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-2---choosing-the-installation-method&#34;&gt;Step 2 - Choosing the Installation Method&lt;/h3&gt;
&lt;p&gt;You can use either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt; to install Ondat onto your cluster.  The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below&lt;/p&gt;
&lt;h3 id=&#34;step-3a---installing-via-helm&#34;&gt;Step 3a - Installing via Helm&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/HelmInstall.png&#34; alt=&#34;Helm Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The first two lines of the command adds the Ondat Helm repository and ensures a updated local cache.  The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-3b---installing-via-kubectl-storageos-plugin&#34;&gt;Step 3b - Installing via kubectl-storageos plugin&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin.  The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/PluginInstall.png&#34; alt=&#34;kubectl-storageos Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The command that is provided by the Portal is unique to you and uses the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h3&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once all the components are up and running the output should look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/InstallSuccess.png&#34; alt=&#34;Install Success&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-5---applying-a-licence-to-the-cluster&#34;&gt;Step 5 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;p&gt;Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see &lt;a href=&#34;https://www.ondat.io/pricing&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To licence your cluster with the community edition:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Clusters page select &amp;lsquo;View Details&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Click on &amp;lsquo;Change Licence&amp;rsquo;&lt;/li&gt;
&lt;li&gt;In the following pop-up select the &amp;lsquo;Community Licence&amp;rsquo; option then click &amp;lsquo;Generate&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This process generates a licence and installs it for you. Now you are good to go!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: DigitalOcean Kubernetes (DOKS)</title>
      <link>/docs/install/digitalocean/digitalocean-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/digitalocean/digitalocean-kubernetes/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://www.digitalocean.com/products/kubernetes&#34;&gt;DigitalOcean Managed Kubernetes (DOKS)&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm Chart&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h3 id=&#34;1---cluster-and-node-prerequisites&#34;&gt;1 - Cluster and Node Prerequisites&lt;/h3&gt;
&lt;p&gt;The minimum cluster requirements for a &lt;strong&gt;non-production installation&lt;/strong&gt; of ondat are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux with a 64-bit architecture.&lt;/li&gt;
&lt;li&gt;2 vCPU and 4GB of RAM per node.&lt;/li&gt;
&lt;li&gt;3 worker nodes in the cluster and sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/li&gt;
&lt;li&gt;Make sure your DOKS cluster version is greater than or equal to &lt;code&gt;v1.21.10&lt;/code&gt; or &lt;code&gt;v1.22.7&lt;/code&gt; as they will have the required kernel modules available for Ondat to run successfully.&lt;/li&gt;
&lt;li&gt;Ensure the following firewall ports are open: &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/firewalls/#firewalls-and-vps-providers&#34;&gt;Firewalls and VPS providers&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a comprehensive list of prerequisites and how to build a &lt;strong&gt;production installation&lt;/strong&gt; of Ondat please refer to &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat Prerequisites&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2---client-tools-prerequisites&#34;&gt;2 - Client Tools Prerequisites&lt;/h3&gt;
&lt;p&gt;The following CLI utilities are installed on your local machine and available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat can be installed either via Helm Chart or using our command-line tool.  Depending on which installation method you choose you will require either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installation-of-ondat&#34;&gt;Installation of Ondat&lt;/h2&gt;
&lt;h3 id=&#34;step-1---adding-a-cluster&#34;&gt;Step 1 - Adding a Cluster&lt;/h3&gt;
&lt;p&gt;The Ondat Portal is how you can license and get the commands for installing Ondat&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Either login or create an account on the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat Portal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Choose the &amp;lsquo;Install Ondat on your cluster&amp;rsquo; or &amp;lsquo;Add cluster&amp;rsquo; options in the UI&lt;/li&gt;
&lt;li&gt;Add a Name for your cluster and where it is going to be located.  This will allow you to view the same prerequisites as are listed above&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-2---choosing-the-installation-method&#34;&gt;Step 2 - Choosing the Installation Method&lt;/h3&gt;
&lt;p&gt;You can use either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt; to install Ondat onto your cluster.  The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below&lt;/p&gt;
&lt;h3 id=&#34;step-3a---installing-via-helm&#34;&gt;Step 3a - Installing via Helm&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/HelmInstall.png&#34; alt=&#34;Helm Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The first two lines of the command adds the Ondat Helm repository and ensures a updated local cache.  The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-3b---installing-via-kubectl-storageos-plugin&#34;&gt;Step 3b - Installing via kubectl-storageos plugin&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin.  The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/PluginInstall.png&#34; alt=&#34;kubectl-storageos Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The command that is provided by the Portal is unique to you and uses the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h3&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once all the components are up and running the output should look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/InstallSuccess.png&#34; alt=&#34;Install Success&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-5---applying-a-licence-to-the-cluster&#34;&gt;Step 5 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;p&gt;Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see &lt;a href=&#34;https://www.ondat.io/pricing&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To licence your cluster with the community edition:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Clusters page select &amp;lsquo;View Details&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Click on &amp;lsquo;Change Licence&amp;rsquo;&lt;/li&gt;
&lt;li&gt;In the following pop-up select the &amp;lsquo;Community Licence&amp;rsquo; option then click &amp;lsquo;Generate&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This process generates a licence and installs it for you. Now you are good to go!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Google Anthos</title>
      <link>/docs/install/gcp/anthos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/gcp/anthos/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://cloud.google.com/anthos&#34;&gt;Google Anthos&lt;/a&gt; cluster using the &lt;a href=&#34;https://docs.ondat.io/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h3 id=&#34;1---cluster-and-node-prerequisites&#34;&gt;1 - Cluster and Node Prerequisites&lt;/h3&gt;
&lt;p&gt;The minimum requirements for the nodes are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux with a 64-bit architecture.&lt;/li&gt;
&lt;li&gt;2 vCPU and 4GB of RAM per node.&lt;/li&gt;
&lt;li&gt;3 worker nodes in the cluster and sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/li&gt;
&lt;li&gt;Make sure your Google Anthos cluster uses &lt;a href=&#34;https://cloud.google.com/anthos/clusters/docs/on-prem/1.8/concepts/using-containerd&#34;&gt;&lt;code&gt;ubuntu_containerd&lt;/code&gt;&lt;/a&gt; as the default node operating system. This node operating system image has the required kernel modules available for Ondat to run successfully.&lt;/li&gt;
&lt;li&gt;For a comprehensive list of prerequisites please refer to &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat Prerequisites&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2---client-tools-prerequisites&#34;&gt;2 - Client Tools Prerequisites&lt;/h3&gt;
&lt;p&gt;The following CLI utilities are install on your local machine and available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat can be installed either via Helm Chart or using our command-line tool.  Depending on which installation method you choose you will require either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---choosing-where-your-cluster-is-located&#34;&gt;Step 1 - Choosing where your cluster is located&lt;/h3&gt;
&lt;p&gt;The Ondat Portal is how you can license and get the commands for installing Ondat:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Either login or create an account on the Ondat Portal &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;https://portal.ondat.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Choose the &amp;lsquo;Install Ondat on your cluster&amp;rsquo; or &amp;lsquo;Add cluster&amp;rsquo; options in the UI&lt;/li&gt;
&lt;li&gt;Add a Name for your cluster and where it is going to be located.  This will allow you to view the same prerequisites as are listed above&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-2---choosing-the-installation-method&#34;&gt;Step 2 - Choosing the Installation Method&lt;/h3&gt;
&lt;p&gt;You can use either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt; to install Ondat onto your cluster.  The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below.&lt;/p&gt;
&lt;h3 id=&#34;step-3a---installing-via-helm&#34;&gt;Step 3a - Installing via Helm&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/HelmInstall.png&#34; alt=&#34;Helm Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The first two lines of the command adds the Ondat Helm repository and ensures a updated local cache.  The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-3b---installing-via-kubectl-storageos-plugin&#34;&gt;Step 3b - Installing via kubectl-storageos plugin&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin.  The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/PluginInstall.png&#34; alt=&#34;kubectl-storageos Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The command that is provided by the Portal is unique to you and uses the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h3&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once all the components are up and running the output should look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/InstallSuccess.png&#34; alt=&#34;Install Success&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-5---applying-a-licence-to-the-cluster&#34;&gt;Step 5 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;p&gt;Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see &lt;a href=&#34;https://www.ondat.io/pricing&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To licence your cluster with the community edition:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Clusters page select &amp;lsquo;View Details&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Click on &amp;lsquo;Change Licence&amp;rsquo;&lt;/li&gt;
&lt;li&gt;In the following pop-up select the &amp;lsquo;Community Licence&amp;rsquo; option then click &amp;lsquo;Generate&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This process generates a licence and installs it for you. Now you are good to go!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Overview</title>
      <link>/docs/introduction/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/introduction/overview/</guid>
      <description>
        
        
        &lt;p&gt;Over the past several months, we&amp;rsquo;ve been hard at work on Ondat V2, which
contains some significant enhancements over our v1 product. We&amp;rsquo;ve built V2
based on our observations of trends in the industry, as well as our own
experience.&lt;/p&gt;
&lt;p&gt;Many of our customers want to run big clusters - in the tens or hundreds of
nodes. In these sorts of big environments, the challenges multiply. Not only do
we need to scale well, but we also need to be more failure tolerant. Bigger
environments typically suffer higher failure rates (more nodes = greater chance
of something failing), but are also subject to all sorts of transient
conditions such as network partitions.&lt;/p&gt;
&lt;p&gt;The second trend we&amp;rsquo;ve seen become increasingly common is the desire to run
multiple clusters, and consume storage between them in some way - sometimes to
implement novel topologies such as a centralised storage cluster with
satellites consuming the storage, and sometimes to replicate data between those
clusters for HA or DR purposes.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve built V2 with these architectures and design patterns in mind. Not only
does it scale well, but it contains the foundations we need to implement a rich
set of multi-cluster functionality.&lt;/p&gt;
&lt;h2 id=&#34;-upgraded-control-plane&#34;&gt;ðŸš€ Upgraded Control Plane&lt;/h2&gt;
&lt;p&gt;At the heart of the V2 release is an upgraded control plane. We&amp;rsquo;ve changed a
lot here. Firstly, our usage of etcd is vastly improved. We&amp;rsquo;ve learnt a lot
about the subtleties of distributed consensus in the last year, particularly in
noisy or unpredictable environments. Not only is Ondat V2 much lighter on
your etcd cluster, but it&amp;rsquo;s a lot more tolerant of transient failure conditions
that are often found in cloud environments, or clusters under heavy load.&lt;/p&gt;
&lt;p&gt;We spent some time describing and testing our internal state machine using the
&lt;a href=&#34;https://en.wikipedia.org/wiki/TLA+&#34;&gt;TLA+&lt;/a&gt; formal verification language. This
allows us to have a much higher degree of confidence that our algorithms will
behave correctly, particularly under hard-to-test edge cases and failure
conditions.&lt;/p&gt;
&lt;p&gt;Additionally, we&amp;rsquo;ve changed the way volumes behave with respect to centralised
scheduling. Each volume group (consisting of a master and 0 or more replicas)
now behaves as a strongly consistent unit allowing it to take action
independent of the activities of the rest of the cluster. Other state can be
distributed around the cluster using eventually consistent mechanisms. This
approach inherently scales better and allows Ondat V2 to effectively manage
many more nodes and volumes than before.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve implemented TLS on all endpoints. Not only does this give you encrypted
traffic between nodes in your storage cluster, it also protects all endpoints
with strong, public key based authentication. Today&amp;rsquo;s IT environments can&amp;rsquo;t
rely on firewalls to keep bad actors out - they must implement security at all
layers within the stack - defense in depth. While we recognise that this brings
a welcome relief to many security conscious administrators, we also know that
managing certificate authorities (CAs) can be an unwelcome source of
complexity. For this reason, Ondat V2 implements an internal CA by default,
to manage this complexity for you. If you&amp;rsquo;d prefer to integrate your own CA, we
support that too - it&amp;rsquo;s up to you.&lt;/p&gt;
&lt;p&gt;Finally - our logging has undergone a complete transformation in this edition. We
know that systems engineers and operators don&amp;rsquo;t just value headline features,
but that observability and diagnostics are equally important. All logs are now
decorated with rich context to help you understand what is happening within
your cluster, and we&amp;rsquo;ll output in json by default, for easy ingestion into log
aggregators such as Elasticsearch.&lt;/p&gt;
&lt;h2 id=&#34;-upgraded-data-plane&#34;&gt;ðŸš€ Upgraded Data Plane&lt;/h2&gt;
&lt;p&gt;Not to be outdone, our data plane contains some significant improvements.&lt;/p&gt;
&lt;p&gt;Firstly, we&amp;rsquo;ve completely re-written our sync algorithm (see &lt;a href=&#34;/docs/concepts/volumes&#34;&gt;Delta Sync&lt;/a&gt;, used when seeding or catching up replicas
that have been offline or partitioned. Our new algorithm uses a &lt;a href=&#34;https://en.wikipedia.org/wiki/Hash_list&#34;&gt;Hash
List&lt;/a&gt; to sync only changed sections of
a volume (similar in some ways to what rsync does). Ondat maintains these
hashes during normal operation, meaning that when resyncing a failed replica,
for example after a node reboot, we can very quickly and efficiently catch this
replica up, rather than needing to promote and build a new one from scratch.
This improves resiliency within your cluster, and prevents using excessive
network bandwidth during failover conditions - at a time when it might be
needed the most.&lt;/p&gt;
&lt;p&gt;Secondly, a new threading model, with dynamic pool sizing, means that Ondat
is faster, a lot faster. In our tests we observed improvements across the
board, with improvements in throughput of up to 135% for some scenarios.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: OpenShift via Marketplace</title>
      <link>/docs/install/openshift/openshift-marketplace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/openshift/openshift-marketplace/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto an &lt;a href=&#34;/docs/platforms/openshift&#34;&gt;Openshift&lt;/a&gt; cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure the &lt;a href=&#34;/docs/prerequisites/&#34;&gt;prerequisites for Ondat&lt;/a&gt; are satisfied before proceeding. Including the deployment of an etcd cluster and configuration of CRI-O PID limits.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ If you have installed OpenShift in AWS ensure that the requisite ports are opened for the worker nodes&#39; security group.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ For OpenShift upgrades, refer to the &lt;a href=&#34;/docs/platforms/openshift#openshift-upgrades&#34;&gt;OpenShift platform page&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat v2 supports OpenShift v4. For more information, see the &lt;a href=&#34;/docs/platforms/openshift&#34;&gt;OpenShift platform&lt;/a&gt; page.&lt;/p&gt;
&lt;h2 id=&#34;installation-of-ondat-via-red-hat-marketplace&#34;&gt;installation of Ondat via Red Hat Marketplace&lt;/h2&gt;
&lt;h4 id=&#34;step-1-red-hat-markerplace&#34;&gt;Step 1: Red Hat Markerplace&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ The installation of Ondat using the Red Hat Marketplace requires the
Openshift cluster to be registered to the Marketplace Portal, including the
roll out of the &lt;code&gt;PullSecret&lt;/code&gt; in your cluster. Failure to do so will result in a
image pull authentication failure with the Red Hat registry.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Select the &lt;code&gt;OperatorHub&lt;/code&gt; from the Catalog sub menu and search for StorageOS.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Choose the RedHat Marketplace option.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select StorageOS and click &lt;strong&gt;Purchase&lt;/strong&gt;. Note that Openshift needs to be
registered with the Red Hat Marketplace portal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select the relevant install option.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Project Edition is suitable for production workloads, Developer Edition
for personal experimentation and evaluation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Specify the product configuration to fit your needs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to your software within Red Hat Marketplace and install the
StorageOS software as specified in the image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the Operator. Set the update approval strategy to &lt;strong&gt;Automatic&lt;/strong&gt; to
ensure that you always have the latest version of StorageOS installed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Ondat Operator is installed into your specified cluster.&lt;/p&gt;
&lt;h4 id=&#34;step-2-authentication&#34;&gt;Step 2: Authentication&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a Secret in the &lt;code&gt;openshift-operators&lt;/code&gt; project and select the YAML option to create a secret containing the &lt;code&gt;username&lt;/code&gt; and an
&lt;code&gt;password&lt;/code&gt; key. The username and password defined in the secret will be
used to authenticate when using the Ondat CLI and GUI. Take note of
which project you created the secret in.&lt;/p&gt;
&lt;p&gt;Input the secret as YAML for simplicity.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;v1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;Secret&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos-api&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;openshift-operators&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;kubernetes.io/storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# echo -n &amp;#39;&amp;lt;secret&amp;gt;&amp;#39; | base64&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;username&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;c3RvcmFnZW9z&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;password&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;c3RvcmFnZW9z&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to StorageOS on your &lt;strong&gt;Installed Operators&lt;/strong&gt; tab.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Verify that the StorageOS Operator is installed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open to the &lt;strong&gt;StorageOS Cluster&lt;/strong&gt; tab and click &lt;strong&gt;Create StorageOSCluster&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ A StorageOSCluster is defined using a Custom Resource(CR) Definition.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the CR Definition:&lt;/p&gt;
&lt;p&gt;The Ondat cluster resource describes the Ondat cluster that will be
created. Parameters such as the &lt;code&gt;secretRefName&lt;/code&gt;, the &lt;code&gt;secretRefNamespace&lt;/code&gt; and
the &lt;code&gt;kvBackend.address&lt;/code&gt; are mandatory.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Additional &lt;code&gt;spec&lt;/code&gt; parameters are available on the &lt;a href=&#34;/docs/reference/operator/configuration&#34;&gt;Operator configuration&lt;/a&gt; page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;apiVersion: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos.com/v1&amp;#34;&lt;/span&gt;
kind: StorageOSCluster
metadata:
  name: storageos
  namespace: openshift-operators
spec:
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Ondat Pods are in kube-system by default&lt;/span&gt;
  secretRefName: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-api&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Reference the Secret created in the previous step&lt;/span&gt;
  secretRefNamespace: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;openshift-operators&amp;#34;&lt;/span&gt;  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Namespace of the Secret created in the previous step&lt;/span&gt;
  k8sDistro: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;openshift&amp;#34;&lt;/span&gt;
  kvBackend:
    address: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;storageos-etcd-client.etcd:2379&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Example address, change for your etcd endpoint&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# address: &amp;#39;10.42.15.23:2379,10.42.12.22:2379,10.42.13.16:2379&amp;#39; # You can set ETCD server ips&lt;/span&gt;
  resources:
    requests:
      memory: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;512Mi&amp;#34;&lt;/span&gt;
      cpu: &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# nodeSelectorTerms:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#   - matchExpressions:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#     - key: &amp;#34;node-role.kubernetes.io/worker&amp;#34; # Compute node label will vary according to your installation&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       operator: In&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       values:&lt;/span&gt;
  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#       - &amp;#34;true&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the StorageOS Cluster status is &lt;strong&gt;Running&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ It can take up to a minute to report the Ondat Pods ready.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the StorageOS Pods in the &lt;code&gt;kube-system&lt;/code&gt; project.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ A Status of 3/3 in the &lt;strong&gt;Ready&lt;/strong&gt; column for the Daemonset Pods indicates that Ondat is
bootstrapped successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;license-cluster&#34;&gt;License cluster&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a license, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;
&lt;h2 id=&#34;first-ondat-volume&#34;&gt;First Ondat volume&lt;/h2&gt;
&lt;p&gt;If this is your first installation you may wish to follow the &lt;a href=&#34;/docs/operations/firstpvc&#34;&gt;Ondat volume guide&lt;/a&gt; for an example of how
to mount an Ondat volume in a Pod.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Rancher Kubernetes Engine (RKE)</title>
      <link>/docs/install/rancher/rancher/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/rancher/rancher/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://rancher.com/products/rke&#34;&gt;Rancher Kubernetes Engine (RKE)&lt;/a&gt; cluster using either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm Chart&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h3 id=&#34;1---cluster-and-node-prerequisites&#34;&gt;1 - Cluster and Node Prerequisites&lt;/h3&gt;
&lt;p&gt;The minimum requirements for the nodes are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux with a 64-bit architecture&lt;/li&gt;
&lt;li&gt;2 vCPU and 4GB of RAM per node.&lt;/li&gt;
&lt;li&gt;3 worker nodes in the cluster and sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster&lt;/li&gt;
&lt;li&gt;Make sure your RKE cluster uses a Linux distribution that is officially supported by Rancher as your node operating system and has the required LinuxIO related kernel modules are available for Ondat to run successfully. A strong recommendation would be to review &lt;a href=&#34;https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/&#34;&gt;SUSE Rancher Support Matrix&lt;/a&gt; documentation to ensure that you are using a supported Linux distribution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a comprehensive list of prerequisites and how to build a &lt;strong&gt;production installation&lt;/strong&gt; of Ondat please refer to &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat Prerequisites&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2---installing-a-local-path-provisioner&#34;&gt;2 - Installing a Local Path Provisioner&lt;/h3&gt;
&lt;p&gt;By default, a newly provisioned RKE cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; and make it the default storageclass to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.22/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
kubectl patch storageclass local-path -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;metadata&amp;#34;: {&amp;#34;annotations&amp;#34;:{&amp;#34;storageclass.kubernetes.io/is-default-class&amp;#34;:&amp;#34;true&amp;#34;}}}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Verify that the Local Path Provisioner was successfully deployed and ensure that that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt; status, run the following &lt;code&gt;kubectl&lt;/code&gt; commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3---client-tools-prerequisites&#34;&gt;3 - Client Tools Prerequisites&lt;/h3&gt;
&lt;p&gt;The following CLI utilities are installed on your local machine and available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat can be installed either via Helm Chart or using our command-line tool.  Depending on which installation method you choose you will require either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installation-of-ondat&#34;&gt;Installation of Ondat&lt;/h2&gt;
&lt;h3 id=&#34;step-1---adding-a-cluster&#34;&gt;Step 1 - Adding a Cluster&lt;/h3&gt;
&lt;p&gt;The Ondat Portal is how you can license and get the commands for installing Ondat&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Either login or create an account on the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat Portal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Choose the &amp;lsquo;Install Ondat on your cluster&amp;rsquo; or &amp;lsquo;Add cluster&amp;rsquo; options in the UI&lt;/li&gt;
&lt;li&gt;Add a Name for your cluster and where it is going to be located.  This will allow you to view the same prerequisites as are listed above&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-2---choosing-the-installation-method&#34;&gt;Step 2 - Choosing the Installation Method&lt;/h3&gt;
&lt;p&gt;You can use either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt; to install Ondat onto your cluster.  The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below.&lt;/p&gt;
&lt;h3 id=&#34;step-3a---installing-via-helm&#34;&gt;Step 3a - Installing via Helm&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/HelmInstall.png&#34; alt=&#34;Helm Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The first two lines of the command adds the Ondat Helm repository and ensures a updated local cache.  The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-3b---installing-via-kubectl-storageos-plugin&#34;&gt;Step 3b - Installing via kubectl-storageos plugin&lt;/h3&gt;
&lt;p&gt;The Ondat Portal UI will display the following cmd that can be used to install Ondat using the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin.  The command created will be unique for you and the screenshot below is just for reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/PluginInstall.png&#34; alt=&#34;kubectl-storageos Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;The command that is provided by the Portal is unique to you and uses the &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing.  The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.&lt;/p&gt;
&lt;h3 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h3&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once all the components are up and running the output should look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/install/InstallSuccess.png&#34; alt=&#34;Install Success&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-5---applying-a-licence-to-the-cluster&#34;&gt;Step 5 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;p&gt;Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see &lt;a href=&#34;https://www.ondat.io/pricing&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To licence your cluster with the community edition:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Clusters page select &amp;lsquo;View Details&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Click on &amp;lsquo;Change Licence&amp;rsquo;&lt;/li&gt;
&lt;li&gt;In the following pop-up select the &amp;lsquo;Community Licence&amp;rsquo; option then click &amp;lsquo;Generate&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This process generates a licence and installs it for you. Now you are good to go!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Rancher Kubernetes Engine (RKE) via Marketplace</title>
      <link>/docs/install/rancher/rancher-marketplace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/rancher/rancher-marketplace/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://rancher.com/products/rke&#34;&gt;Rancher Kubernetes Engine (RKE)&lt;/a&gt; cluster using either the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt; or &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm Chart&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h3 id=&#34;1---cluster-and-node-prerequisites&#34;&gt;1 - Cluster and Node Prerequisites&lt;/h3&gt;
&lt;p&gt;The minimum cluster requirements for a &lt;strong&gt;non-production installation&lt;/strong&gt; of ondat are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux with a 64-bit architecture.&lt;/li&gt;
&lt;li&gt;2 vCPU and 4GB of RAM per node.&lt;/li&gt;
&lt;li&gt;3 worker nodes in the cluster and sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/li&gt;
&lt;li&gt;Make sure your RKE cluster uses a Linux distribution that is officially supported by Rancher as your node operating system and has the required LinuxIO related kernel modules are available for Ondat to run successfully. A strong recommendation would be to review &lt;a href=&#34;https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/&#34;&gt;SUSE Rancher Support Matrix&lt;/a&gt; documentation to ensure that you are using a supported Linux distribution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a comprehensive list of prerequisites and how to build a &lt;strong&gt;production installation&lt;/strong&gt; of Ondat please refer to &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/&#34;&gt;Ondat Prerequisites&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2---installing-a-local-path-provisioner&#34;&gt;2 - Installing a Local Path Provisioner&lt;/h3&gt;
&lt;p&gt;By default, a newly provisioned RKE cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; and make it the default storageclass to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.22/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
kubectl patch storageclass local-path -p &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;{&amp;#34;metadata&amp;#34;: {&amp;#34;annotations&amp;#34;:{&amp;#34;storageclass.kubernetes.io/is-default-class&amp;#34;:&amp;#34;true&amp;#34;}}}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Verify that the Local Path Provisioner was successfully deployed and ensure that that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt; status, run the following &lt;code&gt;kubectl&lt;/code&gt; commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3---client-tools-prerequisites&#34;&gt;3 - Client Tools Prerequisites&lt;/h3&gt;
&lt;p&gt;The following CLI utilities are installed on your local machine and available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ondat can be installed either via Helm Chart or using our command-line tool.  Depending on which installation method you choose you will require either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;Helm 3 CLI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;installing-ondat-using-ranchers-apps--marketplace&#34;&gt;Installing Ondat Using Rancher&amp;rsquo;s Apps &amp;amp; Marketplace&lt;/h3&gt;
&lt;h4 id=&#34;step-1---setup-an-etcd-cluster&#34;&gt;Step 1 - Setup An etcd Cluster&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ensure that you have an &lt;code&gt;etcd&lt;/code&gt; cluster deployed first before installing Ondat through the Helm chart located on Apps &amp;amp; Marketplace. There are two different methods listed below with instructions on how to deploy an &lt;code&gt;etcd&lt;/code&gt; cluster;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/etcd/#testing---installing-etcd-into-your-kubernetes-cluster&#34;&gt;Embedded Deployment&lt;/a&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster operator into your RKE cluster, recommended for &lt;strong&gt;non production&lt;/strong&gt; environments.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/etcd/#production---etcd-on-external-virtual-machines&#34;&gt;External Deployment&lt;/a&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster in dedicated virtual machines, recommended for &lt;strong&gt;production&lt;/strong&gt; environments.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you have an &lt;code&gt;etcd&lt;/code&gt; cluster up and running, ensure that you note down the list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values that will be used when configuring Ondat in &lt;strong&gt;Step 3&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For example, &lt;code&gt;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---locate-ondat-operator-helm-chart&#34;&gt;Step 2 - Locate Ondat Operator Helm Chart&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;In the Rancher UI, under the RKE cluster where Ondat will be deployed - select the &lt;strong&gt;Menu&lt;/strong&gt; button in the top-left corner of the page and then select &lt;strong&gt;Apps &amp;amp; Marketplace&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Under &lt;strong&gt;Apps &amp;amp; Marketplace&lt;/strong&gt;, a &lt;strong&gt;Charts&lt;/strong&gt; page will be displayed where you can locate the &lt;a href=&#34;https://github.com/rancher/partner-charts/tree/main/charts/ondat-operator/ondat-operator&#34;&gt;Ondat Operator Helm chart&lt;/a&gt; by searching for &amp;ldquo;&lt;strong&gt;Ondat&lt;/strong&gt;&amp;rdquo; in the search filter box.&lt;/li&gt;
&lt;li&gt;Once you have located the Ondat Operator Helm chart, select the chart. This will direct you to a page showing you more information about the Ondat Operator and how to install it.&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;step-3---customising--installing-the-helm-chart&#34;&gt;Step 3 - Customising &amp;amp; Installing The Helm Chart&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Upon selecting the &lt;strong&gt;Install&lt;/strong&gt; button in the previous step, you will be directed to a page to configure the &lt;strong&gt;Application Metadata&lt;/strong&gt;. Define the namespace and application name where Ondat will be deployed and click &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Parameter&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Namespace&lt;/td&gt;
&lt;td&gt;&lt;code&gt;storageos&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Namespace name for the deployment.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Name&lt;/td&gt;
&lt;td&gt;&lt;code&gt;ondat-operator&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Application name for the deployment.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The next page will allow you to configure the Ondat Operator through Helm chart values. Under &lt;strong&gt;Edit Options&lt;/strong&gt;, you are provided with 3 configurable sections called;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Questions&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Container Images&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;StorageOS Cluster&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select the &lt;strong&gt;StorageOS Cluster&lt;/strong&gt; section. This will show you a form with configurable parameters that have predefined values for an Ondat deployment. Below are following parameters that will need to be populated before beginning the installation;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Parameter&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Password&lt;/td&gt;
&lt;td&gt;&lt;code&gt;$STORAGEOS_PASSWORD&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Password of the StorageOS administrator account. Must be at least 8 characters long, for example &amp;gt; &lt;code&gt;storageos&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;External &lt;code&gt;etcd&lt;/code&gt; address(es)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;$ETCD_ENDPOINTS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;List of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values. Prefer multiple direct endpoints over a single load-balanced endpoint, for example &amp;gt; &lt;code&gt;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ &lt;strong&gt;Advanced Users&lt;/strong&gt; - For users who are looking to make further customisations to the Helm chart through additional configurable parameters or import your own &lt;code&gt;StorageOSCluster&lt;/code&gt; custom resource manifest, review the Ondat Operator &lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/component-charts/ondat-operator/README.md&#34;&gt;README.md&lt;/a&gt; document, &lt;a href=&#34;/docs/reference/operator/configuration&#34;&gt;Operator Configuration&lt;/a&gt; and  &lt;a href=&#34;/docs/reference/operator/examples&#34;&gt;Operator Examples&lt;/a&gt; reference pages for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the parameters have been successfully populated, select &lt;strong&gt;Install&lt;/strong&gt; to deploy Ondat.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# only if the etcd cluster was deployed inside the RKE cluster.&lt;/span&gt;
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;applying-a-licence-to-the-cluster&#34;&gt;Applying a Licence to the Cluster&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Configuration</title>
      <link>/docs/reference/operator/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/operator/configuration/</guid>
      <description>
        
        
        &lt;h2 id=&#34;storageoscluster-resource-configuration&#34;&gt;StorageOSCluster Resource Configuration&lt;/h2&gt;
&lt;p&gt;The following table lists the configurable spec parameters of the StorageOSCluster custom resource and their default values.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Parameter&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Description&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Default&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.deploymentStrategy&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI helper deployment strategy (&lt;code&gt;statefulset&lt;/code&gt; or &lt;code&gt;deployment&lt;/code&gt;)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;statefulset&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.enable&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable CSI setup&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.enableControllerPublishCreds&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable CSI controller publish credentials&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.enableNodePublishCreds&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable CSI node publish credentials&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;csi.enableProvisionCreds&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable CSI provision credentials&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;debug&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Enable debug mode for all the cluster nodes&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;disableTelemetry&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Disable telemetry reports&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.apiManagerContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ondat API Manager container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/api-manager:v1.0.0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.csiClusterDriverRegistrarContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI Cluster Driver Registrar Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;quay.io/k8scsi/csi-cluster-driver-registrar:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.csiExternalAttacherContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI External Attacher Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;quay.io/k8scsi/csi-attacher:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.csiExternalProvisionerContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI External Provisioner Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/csi-provisioner:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;Ã¬mages.csiLivenessProbeContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI Liveness Probe Container Image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;quay.io/k8scsi/livenessprobe:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.csiNodeDriverRegistrarContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI Node Driver Registrar Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;quay.io/k8scsi/csi-node-driver-registrar:v1.0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.hyperkubeContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Deprecated field - HyperKube Container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Default dependent on Scheduler version&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.initContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ondat init container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/init:2.1.0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.kubeSchedulerContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Kube scheduler container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Default dependent on Scheduler version&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.nfsContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ondat nfs container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/nfs:1.0.0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;images.nodeContainer&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Ondat node container image&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos/node:v2.7.0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;k8sDistro&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The name of the Kubernetes distribution is use, e.g. &lt;code&gt;rancher&lt;/code&gt; or &lt;code&gt;eks&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;kvBackend.address&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Comma-separated list of addresses of external key-value store. (&lt;code&gt;1.2.3.4:2379,2.3.4.5:2379&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;kvBackend.backend&lt;/code&gt; (v2 deprecated)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Name of the key-value store to use. Set to &lt;code&gt;etcd&lt;/code&gt; for external key-value store.&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;embedded&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;nodeSelectorTerms&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Set node selector for storageos pod placement&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;resources&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Set resource requirements for the containers&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;secretRefName&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Reference name of storageos secret within the namespace&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.annotations&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Annotations of the Service used by the cluster&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.externalPort&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;External port of the Service used by the cluster&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;5705&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.internalPort&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Internal port of the Service used by the cluster&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;5705&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.name&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Name of the Service used by the cluster&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;service.type&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Type of the Service used by the cluster&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;ClusterIP&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;sharedDir&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Path to be shared with kubelet container when deployed as a pod&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;/var/lib/kubelet/plugins/kubernetes.io~storageos&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageClassName&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The name of the default StorageClass created for Ondat volumes&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;storageos&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;tlsEtcdSecretRefName&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Secret containing etcd client certificates&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;tolerations&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Set pod tolerations for storageos pod placement&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

      </description>
    </item>
    
    <item>
      <title>Docs:  Dashboard Page Reference</title>
      <link>/docs/ondat-portal/dashboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/ondat-portal/dashboard/</guid>
      <description>
        
        
        &lt;p&gt;The &lt;strong&gt;Dashboard&lt;/strong&gt; gives you an unified and summarised view of the application you have deployed. If there are any persistent volumes in error this will be indicated on the dashboard as a red side line next to the application name and will also give you the number of affected volumes.&lt;/p&gt;
&lt;p&gt;Your deployed application can be one of the following types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Replica&lt;/strong&gt; - ensures that one or more pods are running at any given time, according to configuration. Usually, &lt;code&gt;ReplicaSets&lt;/code&gt; are managed by Deployments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;StatefulSet&lt;/strong&gt; - represents a stateful application that both manages one or more pods, ensures that they are running at any given time and provides certain guarantees about the order and uniqueness of the pods.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deployment&lt;/strong&gt; - provides a desired state for one or more sets of pods without guaranteeing order or uniqueness.&lt;/p&gt;
&lt;p&gt;To view more details about each application, go to the &lt;strong&gt;Applications&lt;/strong&gt; tab.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Rancher Kubernetes Engine 2 (RKE2)</title>
      <link>/docs/install/rancher/rancher-gov/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/rancher/rancher-gov/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a &lt;a href=&#34;https://docs.rke2.io/&#34;&gt;Rancher Kubernetes Engine 2 (RKE2)&lt;/a&gt;, also known as RKE Government, cluster using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure the following CLI utilities are installed on your local machine and are available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure you have a running RKE2 cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure your RKE2 cluster uses a Linux distribution that is officially supported by RKE2 as your node operating system and the required LinuxIO related kernel modules are available for Ondat to run successfully. A strong recommendation would be to review &lt;a href=&#34;https://docs.rke2.io/install/requirements/#operating-systems&#34;&gt;RKE2 Operating System Requirements&lt;/a&gt; documentation to ensure that you are using a supported Linux distribution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---install-local-path-provisioner&#34;&gt;Step 1 - Install Local Path Provisioner&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;By default, a newly provisioned RKE2 cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;âš ï¸ The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;step-2---conducting-preflight-checks&#34;&gt;Step 2 - Conducting Preflight Checks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following command to conduct preflight checks against the RKE2 cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-3---installing-ondat&#34;&gt;Step 3 - Installing Ondat&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command to install Ondat.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-storage-class&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-4---verifying-ondat-installation&#34;&gt;Step 4 - Verifying Ondat Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-5---applying-a-licence-to-the-cluster&#34;&gt;Step 5 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs:  Applications Page Reference</title>
      <link>/docs/ondat-portal/applications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/ondat-portal/applications/</guid>
      <description>
        
        
        &lt;p&gt;The &lt;strong&gt;Applications&lt;/strong&gt; tab displays all of your applications. For a detailed explanation of the view, refer to the table below:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Column&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Description&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Possible Values&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;App Name&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The name of the app&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;String&lt;/code&gt; (can contain special characters)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Kind&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the kind of application.&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Replica&lt;/strong&gt; &lt;br /&gt;  &lt;strong&gt;StatefulSet&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Deployment&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Pods&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;The number of pods for your application&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;Integer&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Pod Status&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the number of pods that are ready/syncing or with unknown/failed status&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Ready&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Syncing&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Unknown&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Failed&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;PV Amount&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the amount of PVs taken up by the app&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;Integer&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;PVs Size&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the size of all Persistent volumes as a percentage of all available storage on all pods&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Available GB on the pods&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;PVs Status&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Indicates the number of PVs that are ready/syncing or with unknown/failed status&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Ready&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Syncing&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Unknown&lt;/strong&gt; &lt;br /&gt; &lt;strong&gt;Failed&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;detailed-view-of-the-application&#34;&gt;Detailed View of the Application&lt;/h2&gt;
&lt;p&gt;To view more details of your application, click &lt;strong&gt;View Details&lt;/strong&gt; and you will be given an overview of the status of the app.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Operator examples</title>
      <link>/docs/reference/operator/examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/operator/examples/</guid>
      <description>
        
        
        &lt;p&gt;Before deploying an Ondat cluster, create a Secret to define the Ondat
API Username and Password in base64 encoding.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;END
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: Secret
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  name: &amp;#34;storageos-api&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  namespace: &amp;#34;default&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  labels:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    app: &amp;#34;storageos&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;type: &amp;#34;kubernetes.io/storageos&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;data:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  username: c3RvcmFnZW9z
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  password: c3RvcmFnZW9z
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;END&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This example contains a default password, for production installations, use a
unique, strong password.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure that the encoding of the credentials doesn&amp;rsquo;t have special characters such as &amp;lsquo;\n&amp;rsquo;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;You can define a base64 value by &lt;code&gt;echo -n &amp;quot;mystring&amp;quot; | base64&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Create a &lt;code&gt;cluster-config.yaml&lt;/code&gt; according to your needs from the examples below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create -f cluster-config.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that Ondat will be deployed in &lt;code&gt;spec.namespace&lt;/code&gt; (storageos by
default), irrespective of what NameSpace the CR is defined in.&lt;/p&gt;
&lt;p&gt;Â  &lt;!-- this is a blank line --&gt;&lt;/p&gt;
&lt;h1 id=&#34;examples&#34;&gt;Examples&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;You can checkout all the parameters configurable in the
&lt;a href=&#34;/docs/reference/operator/configuration&#34;&gt;configuration&lt;/a&gt;
page.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;All examples must reference the &lt;code&gt;storageos-api&lt;/code&gt; Secret.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;secretRefName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-api&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Reference to the Secret created in the previous step&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;installing-with-an-external-etcd&#34;&gt;Installing with an external etcd&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kvBackend&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;address&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;10.43.93.95:2379&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# IP of the SVC that exposes ETCD&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# address: &amp;#39;10.42.15.23:2379,10.42.12.22:2379,10.42.13.16:2379&amp;#39; # You can specify individual IPs of the etcd servers&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If using Etcd with mTLS, it is required to create the secret with the TLS
material on the same namespace as the StorageOSCluster resource. Reference it&amp;rsquo;s
name with the following parameter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# External mTLS secured etcd cluster specific properties&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;tlsEtcdSecretRefName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-etcd-secret&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Secret containing etcd client certificates, within the StorageOSCluster CR namespace&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Follow the &lt;a href=&#34;/docs/operations/etcd/storageos-secret-info&#34;&gt;etcd operations&lt;/a&gt; page to setup the
secret with the Etcd client certificate, client key and CA.&lt;/p&gt;
&lt;h2 id=&#34;installing-to-a-subset-of-nodes&#34;&gt;Installing to a subset of nodes&lt;/h2&gt;
&lt;p&gt;In this case we select nodes that are workers. To make sure that Ondat doesn&amp;rsquo;t start in Master nodes.&lt;/p&gt;
&lt;p&gt;You can see the labels in the nodes by &lt;code&gt;kubectl get node --show-labels&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nodeSelectorTerms&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;matchExpressions&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;key&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;node-role.kubernetes.io/worker&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;operator&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;In&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;values&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# OpenShift uses &amp;#34;node-role.kubernetes.io/compute=true&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Rancher uses &amp;#34;node-role.kubernetes.io/worker=true&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Kops uses &amp;#34;node-role.kubernetes.io/node=&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Different provisioners and Kubernetes distributions use node labels
differently to specify master vs workers. Node Taints are not enough to
make sure Ondat doesn&amp;rsquo;t start in a node. The &lt;code&gt;JOIN&lt;/code&gt; variable is defined
by the operator by selecting all the nodes that match the &lt;code&gt;nodeSelectorTerms&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;specifying-a-shared-directory-for-use-with-kubelet-as-a-container&#34;&gt;Specifying a shared directory for use with kubelet as a container&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sharedDir&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;/var/lib/kubelet/plugins/kubernetes.io~storageos&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;defining-pod-resource-requests-and-reservations&#34;&gt;Defining pod resource requests and reservations&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;512Mi&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#   cpu: &amp;#34;1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# limits:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#   memory: &amp;#34;4Gi&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We have the following limits for all of our components:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;         &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;api-manager&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;         &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;           &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;250m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;200Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;           &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;10m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;provisioner&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;securityContext&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;privileged&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;5m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;30Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;attacher&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;50m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;1m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;30Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;resizer&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;50m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;1m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;30Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos-scheduler&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;           &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;limits&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;100m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;200Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;10m&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;             &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;memory&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;50Mi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;specifying-custom-tolerations&#34;&gt;Specifying custom Tolerations&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;tolerations&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;key&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;key1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;operator&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Equal&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;value&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;value1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;effect&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;EffectToTolerate&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;key&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;key2&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;operator&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Exists&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Custom tolerations specified in the StorageOSCluster definition are added to
all Ondat components; the Ondat daemonset, CSI helper and scheduler.&lt;/p&gt;
&lt;p&gt;In the above example a toleration &lt;code&gt;key1=value1:EffectToTolerate&lt;/code&gt; would be
tolerated and &lt;code&gt;key2&lt;/code&gt; would be tolerated regardless of the value and effect. For
more information about tolerations see the &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/&#34;&gt;Kubernetes
documentation&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Supported Platforms and Orchestrators</title>
      <link>/docs/introduction/platforms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/introduction/platforms/</guid>
      <description>
        
        
        &lt;h2 id=&#34;os&#34;&gt;OS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linux X86_64&lt;/li&gt;
&lt;li&gt;Kernels satisfying our module &lt;a href=&#34;/docs/prerequisites/systemconfiguration&#34;&gt;prerequisites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.x kernels have a limitation of 256 active volumes per node&lt;/li&gt;
&lt;li&gt;4.x kernels have a limitation of 4096 active volumes per node&lt;/li&gt;
&lt;li&gt;We are distribution agnostic as long as our prerequisites are met&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;orchestrators&#34;&gt;Orchestrators&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 1.19 to 1.23&lt;/li&gt;
&lt;li&gt;OpenShift 4.0+&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Air-Gapped Install</title>
      <link>/docs/install/advanced/airgap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/advanced/airgap/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto clusters that don&amp;rsquo;t have direct access to the internet - i.e., &lt;a href=&#34;https://en.wikipedia.org/wiki/Air_gap_%28networking%29&#34;&gt;air-gapped&lt;/a&gt; environments. Air-gapped environments require cluster administrators to explicitly ensure that Ondat components are locally available before the installation.&lt;/p&gt;
&lt;p&gt;ðŸ’¡ This guide is recommended for &lt;strong&gt;advanced users&lt;/strong&gt; who have experience and permissions to be able to manage air-gapped deployments in their environment. The full procedure for this deployment method is estimated to take ~60 minutes to complete.&lt;/p&gt;
&lt;p&gt;Below is a quick summary of the procedure that will be covered in this guide:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install the Ondat kubectl plugin.&lt;/li&gt;
&lt;li&gt;Generate the Ondat deployment manifests for your use case.&lt;/li&gt;
&lt;li&gt;Push Ondat container images to your private registry.&lt;/li&gt;
&lt;li&gt;Modify the Ondat deployment manifests.&lt;/li&gt;
&lt;li&gt;Install Ondat onto your air-gapped cluster.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Make sure you have met the minimum resource requirements for Ondat so your set up would be successful. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/li&gt;
&lt;li&gt;Make sure the following CLI utility is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:
&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Make sure you have a running Kubernetes cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/li&gt;
&lt;li&gt;Make sure your Kubernetes cluster uses a Linux distribution that is officially supported by Ondat as your node operating system.&lt;/li&gt;
&lt;li&gt;Make sure that the node operating system have the required LinuxIO related kernel modules are available for Ondat to run successfully.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;step-1---install-ondat-kubectl-plugin&#34;&gt;Step 1 - Install Ondat Kubectl Plugin&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that the Ondat kubectl plugin is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-2---conducting-preflight-checks&#34;&gt;Step 2 - Conducting Preflight Checks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to conduct preflight checks against the Kubernetes cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-3---generate-ondat-deployment-manifests&#34;&gt;Step 3 - Generate Ondat Deployment Manifests&lt;/h3&gt;
&lt;h4 id=&#34;option-a---using-an-embedded-etcd-deployment&#34;&gt;Option A - Using An Embedded &lt;code&gt;etcd&lt;/code&gt; Deployment&lt;/h4&gt;
&lt;h5 id=&#34;install-local-path-provisioner&#34;&gt;Install Local Path Provisioner&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Different Kubernetes distributions may include a CSI driver as part of the deployment. Cluster administrators can leverage the CSI driver provided by their distribution if they donâ€™t want to use a Local Path Provisioner. If so, ensure that the  &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt;  environment variable points to the correct value for your Kubernetes distributionâ€™s default StorageClass name.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Download the Local Path Provisioner.&lt;/span&gt;
wget https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Get the list of images and push them to your private registry.&lt;/span&gt;
grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;image:&amp;#34;&lt;/span&gt; local-path-storage.yaml

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Modify the manifest and add the private registry URL to pull the images.&lt;/span&gt;
vi local-path-storage.yaml

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Deploy the Local Path Provisioner.&lt;/span&gt;
kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non-production&lt;/strong&gt; clusters, as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to its state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;generate-manifests&#34;&gt;Generate Manifests&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance. In addition, define and export a &lt;code&gt;KUBERNETES_VERSION&lt;/code&gt; environment variable, where the value will be the exact version of your Kubernetes cluster where Ondat is going to be deployed - for example, &lt;code&gt;v1.23.5&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v1.23.5&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with the &lt;code&gt;--dry-run&lt;/code&gt; flag to generate the Ondat deployment Kubernetes manifests in a directory, called &lt;code&gt;storageos-dry-run&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --dry-run &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-storage-class&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --k8s-version&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To review the list of manifests generated in the newly created &lt;code&gt;storageos-dry-run&lt;/code&gt; directory, run the following commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-dry-run/
ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;option-b---using-an-external-etcd-deployment&#34;&gt;Option B - Using An External &lt;code&gt;etcd&lt;/code&gt; Deployment&lt;/h4&gt;
&lt;h5 id=&#34;setup-an--etcd--cluster&#34;&gt;Setup An  &lt;code&gt;etcd&lt;/code&gt;  Cluster&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that you have an  &lt;code&gt;etcd&lt;/code&gt;  cluster deployed first before installing Ondat. For instructions on how to set up an external  &lt;code&gt;etcd&lt;/code&gt;  cluster, review the  &lt;a href=&#34;/docs/prerequisites/etcd/#production---etcd-on-external-virtual-machines&#34;&gt;&lt;code&gt;etcd&lt;/code&gt;  documentation&lt;/a&gt;  page.&lt;/li&gt;
&lt;li&gt;Once you have an  &lt;code&gt;etcd&lt;/code&gt;  cluster up and running, ensure that you note down the list of  &lt;code&gt;etcd&lt;/code&gt;  endpoints as comma-separated values that will be used when configuring Ondat.
&lt;ul&gt;
&lt;li&gt;For example,  &lt;code&gt;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;generate-manifests-1&#34;&gt;Generate Manifests&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance. In addition, define and export a &lt;code&gt;KUBERNETES_VERSION&lt;/code&gt; environment variable, where the value will be the exact version of your Kubernetes cluster where Ondat is going to be deployed - for example, &lt;code&gt;v1.23.5&lt;/code&gt;. Lastly, define and export a &lt;code&gt;ETCD_ENDPOINTS&lt;/code&gt; environment variable, where the value will be a list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v1.23.5&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with the &lt;code&gt;--dry-run&lt;/code&gt; flag to generate the Ondat deployment Kubernetes manifests in a directory, called &lt;code&gt;storageos-dry-run&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --dry-run &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --skip-etcd-endpoints-validation &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-endpoints&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --k8s-version&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To review the list of manifests generated in the newly created &lt;code&gt;storageos-dry-run&lt;/code&gt; directory, run the following commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-dry-run/
ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-4---push-ondat-images-to-private-registry&#34;&gt;Step 4 - Push Ondat Images To Private Registry&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Get the list of all the container images required for Ondat to be deployed successfully and push them to your private registry which will be accessible through your air-gapped environment.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;grep --extended-regexp &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;RELATED|image:&amp;#34;&lt;/span&gt; *.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You will also need to pull the kubernetes scheduler image for your release and push that to your private registry.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v1.23.5&amp;#34;&lt;/span&gt;
docker pull k8s.gcr.io/kube-scheduler:&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-5---modify-deployment-manifests&#34;&gt;Step 5 - Modify Deployment Manifests&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;etcd-operator&lt;/code&gt;&lt;/strong&gt; - Modify the &lt;code&gt;2-etcd-operator.yaml&lt;/code&gt; manifest and apply the following changes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Locate the &lt;code&gt;storageos-etcd-controller-manager&lt;/code&gt;  &lt;code&gt;Deployment&lt;/code&gt; YAML, navigate to &lt;code&gt;manager&lt;/code&gt; container and locate the &lt;code&gt;args&lt;/code&gt; section.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In this section, add a flag called &lt;code&gt;--etcd-repository=&lt;/code&gt; where the value will be your &lt;code&gt;$PRIVATE_REGISTRY_URL/quay.io/coreos/etcd&lt;/code&gt;. For example;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Before modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;containers&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;args&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;enable-leader-election&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;proxy-url=storageos-proxy.storageos-etcd.svc&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# After modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;containers&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;args&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;enable-leader-election&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;proxy-url=storageos-proxy.storageos-etcd.svc&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- --&lt;span style=&#34;color:#000&#34;&gt;etcd-repository=$PRIVATE_REGISTRY_URL/quay.io/coreos/etcd  &lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;etcd-cluster&lt;/code&gt;&lt;/strong&gt; - Modify the &lt;code&gt;3-etcd-cluster.yaml&lt;/code&gt; manifest and apply the following changes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Locate the &lt;code&gt;storageos-etcd&lt;/code&gt;  &lt;code&gt;CustomResource&lt;/code&gt; YAML, navigate to the &lt;code&gt;storage&lt;/code&gt; section and set the &lt;code&gt;storage&lt;/code&gt; size value from &lt;code&gt;1Gi&lt;/code&gt; to &lt;code&gt;256Gi&lt;/code&gt;. For example;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Before modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeClaimTemplate&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;1Gi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# After modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeClaimTemplate&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;256Gi&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;storageos-operator&lt;/code&gt;&lt;/strong&gt; - Modify the &lt;code&gt;0-storageos-operator.yaml&lt;/code&gt; manifest and apply the following changes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Locate the &lt;code&gt;storageos-operator&lt;/code&gt; &lt;code&gt;Deployment&lt;/code&gt; YAML, navigate to the &lt;code&gt;manager&lt;/code&gt; and &lt;code&gt;kube-rbac-proxy&lt;/code&gt; containers.  Proceed to change the existing image registry URLs to point to your private registry URLs where the Ondat images reside. For example;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Before modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manager&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/operator:v2.7.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kube-rbac-proxy&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/brancz/kube-rbac-proxy:v0.10.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# After modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;manager&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/operator:v2.7.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;kube-rbac-proxy&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/brancz/kube-rbac-proxy:v0.10.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Locate the &lt;code&gt;storageos-related-images&lt;/code&gt; &lt;code&gt;ConfigMap&lt;/code&gt; YAML, navigate to the environment variables that are prefixed with &lt;code&gt;RELATED_IMAGE_&lt;/code&gt;. Proceed to change the existing image registry URLs to point to your private registry URLs where the Ondat images reside. For example;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Before modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ConfigMap&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_API_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/api-manager:v1.2.9&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_ATTACHER_V3&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/k8scsi/csi-attacher:v3.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_PROVISIONER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/csi-provisioner:v2.1.1-patched&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_RESIZER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/k8scsi/csi-resizer:v1.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_LIVENESS_PROBE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/k8scsi/livenessprobe:v2.2.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_NODE_DRIVER_REGISTRAR&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;quay.io/k8scsi/csi-node-driver-registrar:v2.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_NODE_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/node-manager:v0.0.6&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_PORTAL_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/portal-manager:v1.0.2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_STORAGEOS_INIT&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/init:v2.1.2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_STORAGEOS_NODE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/node:v2.7.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_NODE_GUARD&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;storageos/node-guard:v0.0.4&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# After modification.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;ConfigMap&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_API_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/api-manager:v1.2.9&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_ATTACHER_V3&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/k8scsi/csi-attacher:v3.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_PROVISIONER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/csi-provisioner:v2.1.1-patched&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_EXTERNAL_RESIZER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/k8scsi/csi-resizer:v1.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_LIVENESS_PROBE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/livenessprobe:v2.2.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_CSIV1_NODE_DRIVER_REGISTRAR&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/k8scsi/csi-node-driver-registrar:v2.1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_NODE_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/node-manager:v0.0.6&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_PORTAL_MANAGER&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/portal-manager:v1.0.2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_STORAGEOS_INIT&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/init:v2.1.2&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_STORAGEOS_NODE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/node:v2.7.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;RELATED_IMAGE_NODE_GUARD&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$PRIVATE_REGISTRY_URL/node-guard:v0.0.4&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;storageos-cluster&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ &lt;strong&gt;Optional&lt;/strong&gt; - For users who are looking to make further customisations to their &lt;code&gt;StorageOSCluster&lt;/code&gt; custom resource in the &lt;code&gt;1-storageos-cluster.yaml&lt;/code&gt; manifest, review the &lt;a href=&#34;https://docs.ondat.io/docs/reference/operator/configuration&#34;&gt;Operator Configuration&lt;/a&gt; and &lt;a href=&#34;https://docs.ondat.io/docs/reference/operator/examples&#34;&gt;Operator Examples&lt;/a&gt; reference pages for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;step-6---installing-ondat&#34;&gt;Step 6 - Installing Ondat&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl&lt;/code&gt; command to install Ondat with the generated manifests in the &lt;code&gt;storageos-dry-run&lt;/code&gt; directory.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Apply the Operators and CustomResourceDefinitions (CRDs) first.&lt;/span&gt;
find . -name &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*-operator.yaml&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; xargs -I&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt; kubectl apply --filename &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Apply the Custom Resources next.&lt;/span&gt;
find . -name &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*-cluster.yaml&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; xargs -I&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt; kubectl apply --filename &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The installation process may take a few minutes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-7---verifying-ondat-installation&#34;&gt;Step 7 - Verifying Ondat Installation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# only if the etcd cluster was deployed inside the Kubernetes cluster.&lt;/span&gt;
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-8---applying-a-licence-to-the-cluster&#34;&gt;Step 8 - Applying a Licence to the Cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Declarative Install</title>
      <link>/docs/install/advanced/declarative-install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/advanced/declarative-install/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This guide will demonstrate how to install Ondat onto a Kubernetes cluster declaratively. Ondat can be installed declaratively onto a Kubernetes cluster through two different methods;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using the &lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;Ondat kubectl plugin&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Using the &lt;a href=&#34;https://github.com/ondat/charts&#34;&gt;Ondat Helm chart&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main &lt;a href=&#34;/docs/prerequisites/&#34;&gt;Ondat prerequisites&lt;/a&gt; page for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure the following CLI utility is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/#kubectl&#34;&gt;kubectl&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure to add an &lt;a href=&#34;/docs/operations/licensing/&#34;&gt;Ondat licence&lt;/a&gt; after installing. You can request a licence via the &lt;a href=&#34;https://portal.ondat.io/&#34;&gt;Ondat SaaS Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure you have a running Kubernetes cluster with a minimum of 5 worker nodes and the sufficient &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role-Based Access Control (RBAC)&lt;/a&gt; permissions to deploy and manage applications in the cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Make sure your Kubernetes cluster uses a Linux distribution that is officially supported by Ondat as your node operating system and has the required LinuxIO related kernel modules are available for Ondat to run successfully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;
&lt;h3 id=&#34;option-a---using-ondat-kubectl-plugin&#34;&gt;Option A - Using Ondat Kubectl Plugin&lt;/h3&gt;
&lt;h4 id=&#34;step-1---install-ondat-kubectl-plugin&#34;&gt;Step 1 - Install Ondat Kubectl Plugin&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that the Ondat kubectl plugin is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubectl-plugin/&#34;&gt;kubectl-storageos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---install-local-path-provisioner&#34;&gt;Step 2 - Install Local Path Provisioner&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Different Kubernetes distributions may include a CSI driver as part of the deployment. Cluster administrators can leverage the CSI driver provided by their distribution if they don&amp;rsquo;t want to use a Local Path Provisioner. If so, ensure that the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable points to the correct value for your Kubernetes distribution&amp;rsquo;s default StorageClass name.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters, as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;step-3---conducting-preflight-checks&#34;&gt;Step 3 - Conducting Preflight Checks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following command to conduct preflight checks against the Kubernetes cluster to validate that Ondat prerequisites have been met before attempting an installation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos preflight
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-4---generate-ondat-yaml-kubernetes-manifests&#34;&gt;Step 4 - Generate Ondat YAML Kubernetes Manifests&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_USERNAME&lt;/code&gt; and &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variables that will be used to manage your Ondat instance. In addition, define and export a &lt;code&gt;KUBERNETES_VERSION&lt;/code&gt; environment variable, where the value will be the exact version of your Kubernetes cluster where Ondat is going to be deployed - for example, &lt;code&gt;v1.23.5&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v1.23.5&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl-storageos&lt;/code&gt; plugin command with the &lt;code&gt;--dry-run&lt;/code&gt; flag to generate the Ondat YAML Kubernetes manifests in a directory, called &lt;code&gt;storageos-dry-run&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl storageos install &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --dry-run &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --include-etcd &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-tls-enabled &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --etcd-storage-class&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --k8s-version&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$KUBERNETES_VERSION&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-username&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --admin-password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To review the list of manifests generated in the newly created &lt;code&gt;storageos-dry-run&lt;/code&gt; directory run the following commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-dry-run/
ls storageos-dry-run/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;step-4---installing-ondat&#34;&gt;Step 4 - Installing Ondat&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;kubectl&lt;/code&gt; command to install Ondat with the generated manifests in the &lt;code&gt;storageos-dry-run&lt;/code&gt; directory. The manifests  can also be used in your &lt;a href=&#34;https://www.weave.works/technologies/gitops/&#34;&gt;GitOps&lt;/a&gt; workflow to deploy Ondat, enabling you to have a fully declarative approach towards managing your infrastructure deployments.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ &lt;strong&gt;Advanced Users&lt;/strong&gt; - For users who are looking to make further customisations to their &lt;code&gt;StorageOSCluster&lt;/code&gt; custom resource manifest, review the &lt;a href=&#34;/docs/reference/operator/configuration&#34;&gt;Operator Configuration&lt;/a&gt; and  &lt;a href=&#34;/docs/reference/operator/examples&#34;&gt;Operator Examples&lt;/a&gt; reference pages for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Apply the Operators and CustomResourceDefinitions (CRDs) first.&lt;/span&gt;
find . -name &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*-operator.yaml&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; xargs -I&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt; kubectl apply --filename &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Apply the Custom Resources next.&lt;/span&gt;
find . -name &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;*-cluster.yaml&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; xargs -I&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt; kubectl apply --filename &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-5---verifying-ondat-installation&#34;&gt;Step 5 - Verifying Ondat Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;option-b---using-ondats-helm-chart&#34;&gt;Option B - Using Ondat&amp;rsquo;s Helm Chart&lt;/h3&gt;
&lt;h4 id=&#34;step-1---install-helm&#34;&gt;Step 1 - Install Helm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that the &lt;a href=&#34;https://helm.sh/&#34;&gt;Helm 3&lt;/a&gt; CLI utility is installed on your local machine and is available in your &lt;code&gt;$PATH&lt;/code&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34;&gt;helm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---setup-an-etcd-cluster-external-etcd&#34;&gt;Step 2 - Setup An &lt;code&gt;etcd&lt;/code&gt; Cluster (External etcd)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you are installing &lt;code&gt;etcd&lt;/code&gt; externally, ensure that you have deployed the cluster before installing Ondat through the Helm chart. There are two different methods listed below with instructions on how to deploy an &lt;code&gt;etcd&lt;/code&gt; cluster;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/etcd/#testing---installing-etcd-into-your-kubernetes-cluster&#34;&gt;Embedded Deployment&lt;/a&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster operator into your Kubernetes cluster, recommended for &lt;strong&gt;non production&lt;/strong&gt; environments.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/etcd/#production---etcd-on-external-virtual-machines&#34;&gt;External Deployment&lt;/a&gt; - deploy an &lt;code&gt;etcd&lt;/code&gt; cluster in dedicated virtual machines, recommended for &lt;strong&gt;production&lt;/strong&gt; environments.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you have an &lt;code&gt;etcd&lt;/code&gt; cluster up and running, ensure that you note down the list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values that will be used when configuring Ondat in &lt;strong&gt;Step 4&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For example, &lt;code&gt;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-2---setup-a-storageclass-for-etcd-internal-etcd&#34;&gt;Step 2 - Setup a &lt;code&gt;StorageClass&lt;/code&gt; for &lt;code&gt;etcd&lt;/code&gt; (Internal etcd)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you are installing &lt;code&gt;etcd&lt;/code&gt; inside the cluster, ensure that you have at least 3 (recommend 5) nodes ready to ensure high availability. It is recommended that these nodes are placed in different physical or virtual locations (ie. Datacenters or availability zones) for maximum resilience.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Before installing Ondat with &lt;code&gt;etcd&lt;/code&gt;, create the &lt;code&gt;StorageClass&lt;/code&gt; that you want to use for &lt;code&gt;etcd&lt;/code&gt;. Note that this cannot be &lt;code&gt;storageos&lt;/code&gt; as Ondat depends on etcd to function. The following procedure will install a local path &lt;code&gt;StorageClass&lt;/code&gt; that will work in all configurations, ideally there is another more resilient option (eg. Gp3 on AWS) available that can be used instead.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a &lt;a href=&#34;https://github.com/rancher/local-path-provisioner&#34;&gt;Local Path Provisioner&lt;/a&gt; to provide local storage for Ondat&amp;rsquo;s embedded &lt;code&gt;etcd&lt;/code&gt; cluster operator deployment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Different Kubernetes distributions may include a CSI driver as part of the deployment. Cluster administrators can leverage the CSI driver provided by their distribution if they don&amp;rsquo;t want to use a Local Path Provisioner. If so, ensure that the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable points to the correct value for your Kubernetes distribution&amp;rsquo;s default StorageClass name.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply --filename&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable so that value is &lt;code&gt;local-path&lt;/code&gt;, which is the default StorageClass name for the Local Path Provisioner.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a  &lt;code&gt;RUNNING&lt;/code&gt;  status, run the following  &lt;code&gt;kubectl&lt;/code&gt;  commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;local-path-storage
kubectl get storageclass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters, as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;step-3---configure-ondats-helm-chart-repository&#34;&gt;Step 3 - Configure Ondat&amp;rsquo;s Helm Chart Repository&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Add the Ondat Helm chart repository, update the local Helm repository index using the following &lt;code&gt;helm repo&lt;/code&gt; commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo add ondat https://ondat.github.io/charts
helm repo update
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check to confirm that the Ondat Helm chart repository is available using the following &lt;code&gt;helm&lt;/code&gt; commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo list
helm search repo &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ondat&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;step-4---customising--installing-ondats-operator-helm-chart&#34;&gt;Step 4 - Customising &amp;amp; Installing Ondat&amp;rsquo;s Operator Helm Chart&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;There are two ways to conduct an installation with Helm, &lt;strong&gt;declaratively&lt;/strong&gt; by creating a custom &lt;code&gt;values.yaml&lt;/code&gt; (recommended method) or &lt;strong&gt;interactively&lt;/strong&gt; by using the &lt;code&gt;--set&lt;/code&gt; flags to overwrite specific values for the deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ &lt;strong&gt;Advanced Users&lt;/strong&gt; - For users who are looking to make further customisations to the Helm chart through additional configurable parameters or manually create your own &lt;code&gt;StorageOSCluster&lt;/code&gt; custom resource manifest, review the Ondat chart &lt;a href=&#34;https://github.com/ondat/charts/blob/main/README.md&#34;&gt;README.md&lt;/a&gt; document, &lt;a href=&#34;/docs/reference/operator/configuration&#34;&gt;Operator Configuration&lt;/a&gt; and  &lt;a href=&#34;/docs/reference/operator/examples&#34;&gt;Operator Examples&lt;/a&gt; reference pages for more information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;declarative-recommended&#34;&gt;Declarative (Recommended)&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Make a copy of the &lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/umbrella-charts/ondat/values.yaml&#34;&gt;&lt;code&gt;values.yaml&lt;/code&gt;&lt;/a&gt; configuration file, rename it to &lt;code&gt;custom-values.yaml&lt;/code&gt;, then ensure that the following configurable parameters have been populated before beginning the installation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/umbrella-charts/ondat/values.yaml#L23&#34;&gt;&lt;code&gt;ondat-operator.cluster.admin.password&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Password to authenticate to the StorageOS API with. This must be at least&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# 8 characters long.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;password&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# for example -&amp;gt; storageos&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If an external etcd installation is being used&lt;/strong&gt;, add &lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/umbrella-charts/ondat/values.yaml&#34;&gt;&lt;code&gt;ondat-operator.cluster.kvBackend.address&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Key-Value store backend.&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kvBackend&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;address&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# for example -&amp;gt; 203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If an internal etcd installation is being used&lt;/strong&gt;, set &lt;a href=&#34;https://github.com/ondat/charts/blob/main/charts/umbrella-charts/ondat/values.yaml&#34;&gt;&lt;code&gt;etcd-cluster-operator.cluster.storageclass&lt;/code&gt;&lt;/a&gt;, set this to the StorageClass installed earlier&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Storageclass for etcd backing storage&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# NOTE: We CANNOT use storageos here as this is the egg to Ondat&amp;#39;s chicken&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storageclass&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;local-path&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;âš ï¸ The &lt;code&gt;local-path&lt;/code&gt; StorageClass is only recommended for &lt;strong&gt;non production&lt;/strong&gt; clusters, as this stores all the data of the &lt;code&gt;etcd&lt;/code&gt; peers locally, which makes it susceptible to state being lost on node failures.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the parameters above have been defined, run the following  &lt;code&gt;helm install&lt;/code&gt;  command to install Ondat using the Helm chart. Ensure that you use the &lt;code&gt;--values=&lt;/code&gt; flag with your &lt;code&gt;custom-values.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install ondat ondat/ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --create-namespace &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --values&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;custom-values.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes. If you are installing etcd internally, the Ondat pods may initially fail to connect and enter an &lt;code&gt;Error&lt;/code&gt; state - they will retry automatically until etcd becomes available.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;interactive&#34;&gt;Interactive&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Define and export the &lt;code&gt;STORAGEOS_PASSWORD&lt;/code&gt; environment variable that will be used to manage your Ondat instance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;If you are using an internal etcd cluster&lt;/strong&gt;, define and export a &lt;code&gt;ETCD_STORAGECLASS&lt;/code&gt; environment variable, where the value will be the StorageClass to use for etcd volumes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;local-path&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;If you are using an external etcd cluster&lt;/strong&gt;, define and export a &lt;code&gt;ETCD_ENDPOINTS&lt;/code&gt; environment variable, where the value will be a list of &lt;code&gt;etcd&lt;/code&gt; endpoints as comma-separated values noted down earlier in &lt;strong&gt;Step 2&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the following  &lt;code&gt;helm install&lt;/code&gt;  command to install Ondat using the Helm chart.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Internal Etcd&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install ondat ondat/ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --create-namespace &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set ondat-operator.cluster.admin.password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set etcd-cluster-operator.cluster.storageclass&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_STORAGECLASS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;External etcd&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install ondat ondat/ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;ondat &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --create-namespace &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set ondat-operator.cluster.admin.password&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set ondat-operator.cluster.kvBackend.address&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ETCD_ENDPOINTS&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;  --set etcd-cluster-operator.cluster.create&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;false&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;The installation process may take a few minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;step-5---verifying-ondat-installation-1&#34;&gt;Step 5 - Verifying Ondat Installation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run the following &lt;code&gt;kubectl&lt;/code&gt; commands to inspect Ondat&amp;rsquo;s resources (the core components should all be in a &lt;code&gt;RUNNING&lt;/code&gt; status)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
kubectl get all --namespace&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# only if the etcd cluster was deployed inside the Kubernetes cluster.&lt;/span&gt;
kubectl get storageclasses &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;applying-a-licence-to-the-cluster&#34;&gt;Applying a Licence to the Cluster&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To obtain a licence, follow the instructions on our &lt;a href=&#34;/docs/operations/licensing&#34;&gt;licensing operations&lt;/a&gt; page.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing Ondat with the EKS Terraform Blueprints</title>
      <link>/docs/install/aws/terraform-aws-eks-blueprints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/install/aws/terraform-aws-eks-blueprints/</guid>
      <description>
        
        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/aws-ia/terraform-aws-eks-blueprints&#34;&gt;Amazon EKS Blueprints for Terraform&lt;/a&gt; is a collection of Terraform modules that aim to make it easier and faster for customers to adopt Amazon EKS. It can be used by AWS customers, partners, and internal AWS teams to configure and manage complete EKS clusters that are fully bootstrapped with the operational software that is needed to deploy and operate workloads.&lt;/p&gt;
&lt;p&gt;Ondat has published an official add-on to the EKS Blueprints that allows the deployment of Ondat.  Access the add-on via the following GitHub repo: &lt;a href=&#34;https://github.com/ondat/terraform-eksblueprints-ondat-addon/tree/main/blueprints/getting-started&#34;&gt;terraform-eksblueprints-ondat-addon&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For further information, see the following material:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ondat.io/blog/ondat-is-now-available-via-amazon-eks-blueprints&#34;&gt;Ondat is now available via Amazon EKS Blueprints&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: System Configuration</title>
      <link>/docs/prerequisites/systemconfiguration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/systemconfiguration/</guid>
      <description>
        
        
        &lt;p&gt;Ondat requires certain standard kernel modules to function. In particular it requires &lt;a href=&#34;http://linux-iscsi.org/wiki/Main_Page&#34;&gt;Linux-IO&lt;/a&gt;, an open-source implementation of the SCSI target, on all nodes that will execute Ondat (usually the workers).  A variety of Linux distributions are made available by AWS/Azure/GCP and other hyperscalers for use within their kubernetes platforms, however note that not all of them ship with Linux-IO.&lt;/p&gt;
&lt;h2 id=&#34;supported-distributions&#34;&gt;Supported Distributions&lt;/h2&gt;
&lt;p&gt;Current (non-EOL) versions of the following distributions are supported by default:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SUSE Linux Enterprise Server&lt;/li&gt;
&lt;li&gt;Red Hat Enterprise Linux&lt;/li&gt;
&lt;li&gt;CentOS&lt;/li&gt;
&lt;li&gt;Debian&lt;/li&gt;
&lt;li&gt;Ubuntu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following distributions include the prerequisite modules but are not yet tested exhaustively by the Ondat team:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bottlerocket&lt;/li&gt;
&lt;li&gt;Google ContainerOS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following distributions are currently not supported:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Linux (lacks &lt;code&gt;target_core_mod&lt;/code&gt; and &lt;code&gt;target_core_user&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This has been &lt;a href=&#34;https://github.com/amazonlinux/amazon-linux-2022/issues/88&#34;&gt;raised with AWS&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ If you require help with a specific issue with a listed distribution, &lt;a href=&#34;https://github.com/ondat/documentation/issues&#34;&gt;raise an issue on GitHub&lt;/a&gt; or reach out to us on our &lt;a href=&#34;https://slack.storageos.com&#34;&gt;Community Slack&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;kernel-modules&#34;&gt;Kernel Modules&lt;/h2&gt;
&lt;p&gt;We require the following modules to be loaded:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;target_core_mod&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tcm_loop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;configfs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;target_core_user&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;uio&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ Other applications utilising &lt;a href=&#34;http://linux-iscsi.org/wiki/LIO&#34;&gt;TCMU&lt;/a&gt; cannot be run concurrently with Ondat. Doing so may result in corruption of data. On startup, Ondat will detect if other applications are using TCMU.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In most modern distributions, including those listed above, the modules are distributed as part of the Linux kernel package and are included by default. In some older distributions, they were part of a kernel extras package that needed to be installed separately.&lt;/p&gt;
&lt;h2 id=&#34;installing-the-required-kernel-modules&#34;&gt;Installing the required Kernel Modules&lt;/h2&gt;
&lt;p&gt;The script &lt;a href=&#34;https://github.com/storageos/init/blob/master/scripts/01-lio/enable-lio.sh&#34;&gt;enable-lio.sh&lt;/a&gt; from Ondat&amp;rsquo;s init container can be used to ensure that all kernel-level dependencies are installed, any errors will indicate which components are missing.&lt;/p&gt;
&lt;p&gt;For example, in Ubuntu versions prior to 22.04 several modules were not included in the base kernel configuration. Run the following command to install &lt;code&gt;linux-modules-extra&lt;/code&gt; to obtain these additional modules required for Ondat:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;sudo apt-get update
sudo apt-get install -y linux-modules-extra-&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;uname -r&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;automatic-configuration&#34;&gt;Automatic Configuration&lt;/h2&gt;
&lt;p&gt;Once required kernel modules are installed on the system, for convenience we provide a container that will ensure the appropriate modules are loaded and ready for use at runtime. You will need to run the init container prior to starting Ondat.  Our installation guides for Kubernetes and OpenShift include this step.&lt;/p&gt;
&lt;h2 id=&#34;manual-configuration&#34;&gt;Manual Configuration&lt;/h2&gt;
&lt;p&gt;For those wishing to manage their own kernel configuration, rather than using the init container, perform the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ensure kernel modules are all loaded per list above&lt;/li&gt;
&lt;li&gt;Ensure configfs is loaded and mounted at &lt;code&gt;/sys/kernel/config&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Release Notes</title>
      <link>/docs/release-notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/release-notes/</guid>
      <description>
        
        
        &lt;p&gt;We recommend always using &amp;ldquo;tagged&amp;rdquo; versions of Ondat rather than &amp;ldquo;latest&amp;rdquo;,
and to perform upgrades only after reading the release notes.&lt;/p&gt;
&lt;p&gt;The latest tagged release is &lt;code&gt;2.8.3&lt;/code&gt;. For
installation instructions see our
&lt;a href=&#34;/docs/install/&#34;&gt;Install&lt;/a&gt; page.&lt;/p&gt;
&lt;p&gt;The latest CLI release is &lt;code&gt;2.8.3&lt;/code&gt;, available from
&lt;a href=&#34;https://github.com/storageos/go-cli/releases&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;upgrading&#34;&gt;Upgrading&lt;/h1&gt;
&lt;p&gt;To upgrade from version 1.x to 2.x, contact Ondat &lt;a href=&#34;/docs/support&#34;&gt;support&lt;/a&gt; for assistance.&lt;/p&gt;
&lt;h2 id=&#34;283---release-2022-09-14&#34;&gt;2.8.3 - Release 2022-09-14&lt;/h2&gt;
&lt;h3 id=&#34;new&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Added support for AWS Bottlerocket&lt;/li&gt;
&lt;li&gt;Added check for whether the block device directory (usually &lt;code&gt;/var/lib/storageos/volumes&lt;/code&gt;) supports creation of devices, and enable it if it is not already&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The scheduler extender, that attempts to place workloads on the same nodes as volumes, can now be disabled&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Increased the LIO_DEVICE_TIMEOUT_SECS to 300 seconds (5 minutes) and the LIO_RETRY_LOOP_DURATION_SECS to 240 seconds (4 minutes). This provides additional flexibility for environments experiencing resource contention&lt;/li&gt;
&lt;li&gt;Added environment variables so time-outs can be adjusted and tuned&lt;/li&gt;
&lt;li&gt;Fixed spelling mistake in alert log messages&lt;/li&gt;
&lt;li&gt;Improved the clarity of the log messages which alert users that IO to the backend disk (fdatasync, preadv, pwritev and fallocate) is running unusually slowly&lt;/li&gt;
&lt;li&gt;Fixed an issue wherein creating a Ondat block device could erroneously fail because we&amp;rsquo;d fail to wait for the underlying kernel device to be available&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The following fixes apply to k8s clusters running v1.23, v1.24 and v1.25, the bugs did not apply to older cluster versions
&lt;ul&gt;
&lt;li&gt;api-manager will now have permissions to use &lt;code&gt;podsecuritypolicies&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;api-manager now has the expected resource limits&lt;/li&gt;
&lt;li&gt;api-manager will no longer run as root&lt;/li&gt;
&lt;li&gt;api-manager pods will now be spread across nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The control plane will now crash loop less when its pod is restarted&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;282---release-2022-08-12&#34;&gt;2.8.2 - Release 2022-08-12&lt;/h2&gt;
&lt;h3 id=&#34;fixed-1&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fixed a bug that would cause the Data Plane to crash due to a timing issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;281---release-2022-08-02&#34;&gt;2.8.1 - Release 2022-08-02&lt;/h2&gt;
&lt;h3 id=&#34;new-1&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;k8s&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Operator:
&lt;ul&gt;
&lt;li&gt;Install snapshot controller and related CRDs if not present&lt;/li&gt;
&lt;li&gt;Pod Disruption Budget support for k8s v1.25&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Improve logging on kubectl plugin&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Warn that filesystem might go read-only after a failed write or sync SCSI command. The log of interest is: &lt;code&gt;&amp;quot;SCSI command failed - if the block device is mounted the filesystem may go read-only&amp;quot;.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Log when the average IO service time from the mount node is greater than 2 seconds. We log the following message on a per volume basis with exponential backoff: &lt;code&gt;&amp;quot;it is taking unsually long to send and receive IO from the presentation node&amp;quot;&lt;/code&gt;. Metrics are included in the log message.
&lt;ul&gt;
&lt;li&gt;Note: this measurement is tracking the time it takes to send the IO over the network to the master and any replicas and for the IO to be committed and the response sent back to the mount node.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Log when the average IO service time from the master node to its replica is greater than 2 seconds. We log the following message, on a per replica basis with exponential backoff: &amp;ldquo;it is taking unsually long to send and receive IO from the master deployment to its replica&amp;rdquo;. Metrics are included in the log message. Note: this measurement is tracking the time it takes to send the IO over the network to the replica and for the IO to be committed and the response sent back to the mount node.&lt;/li&gt;
&lt;li&gt;Log when it takes more than 1 second to commit a write, read, sync or unmap to disk. Logs of interest are of the format &lt;code&gt;&amp;quot;X operation took longer than Yms to complete completion_time=Zms&amp;quot;.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatically round up storage requests to align with blocksize, instead of rejecting requests&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-2&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;k8s&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fixed an issue where Portal Manager would not work if installed in a namespace that was not &lt;code&gt;storageos&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fixed an issue where CSI requests would occasionally not be serviced&lt;/li&gt;
&lt;li&gt;Fixed an issue on GKE where some pods would not be scheduled if there was no resource quota&lt;/li&gt;
&lt;li&gt;Fixed a bug where the operator would attempt to delete snapshot related CRs when the CRD did not exist&lt;/li&gt;
&lt;li&gt;Fixed an issue where default containers were not correctly marked&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduced the amount of crash loop backoffs when installing via the helm chart&lt;/li&gt;
&lt;li&gt;Reduced the impact of ListVolumes on etcd (significantly, in the case of clusters with lots of volumes)&lt;/li&gt;
&lt;li&gt;Fixed an issue where formatting would timeout due to large TRIM writes being sent across the network&lt;/li&gt;
&lt;li&gt;Fixed an issue where volume deployments would all be scheduled on the same nodes when deploying multiple PVC at the same time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fix &lt;code&gt;Convert&amp;lt;&amp;gt;&lt;/code&gt; and add support for &lt;code&gt;uint16_t&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Fix &lt;code&gt;Volume::GetConsumerCount&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Improve error message when a write/unmap SCSI command is not committed to the backend disk: &lt;code&gt;&amp;quot;a consumer IO was not committed to rdbplugin because its transaction ID lost. This could mean there are two consumers with the same transaction ID (bad); the CP has forgotten to increment the consumer count in between remounts of the volume (bad) or it could indicate that a retry of this IO operation has overtaken a previous IO attempt (normally indicative of a very slow/flaky network and/or disk).&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;280---release-2022-06-29&#34;&gt;2.8.0 - Release 2022-06-29&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ For Ondat 2.8.0, we recommend having at least a 5 node cluster when running etcd within Kubernetes, as we recommend running etcd with 5 replicas.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;new-2&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;k8s&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Etcd in Production: We have added support for putting ETCD in your cluster in a production environment&lt;/li&gt;
&lt;li&gt;Modified CSI provisioner to work with Snapshots&lt;/li&gt;
&lt;li&gt;Ondat volumes metrics exporter: we have added a Prometheus endpoint to allow users to view metrics for Ondat Volumes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have relaxed some Ondat specific security checks for the ReadWriteOnce node volumes that we were doing in the control plane ahead of the new volume mode ReadWriteOncePod which is being introduced in k8s 1.22. This will align the Ondat RWO volumes with the spec and we will in a future release also implement support for &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;RWOP&lt;/a&gt; for users that wish to implement these existing controls.
&lt;ul&gt;
&lt;li&gt;Please note that the relaxation of these security checks could mean that Deployment objects using RWO volumes (if a rolling strategy is used for example) will be able to mount the volume concurrently on the same node, for this reason we suggest users are creating workloads using stateful sets or use RWX volumes for these deployments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Snapshot GA: we added the Snapshot feature to allow users to back up their Ondat data outside of their Kubernetes clusters in conjunction with a backup solution&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Portal Manager&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatic licencing: we added a feature to allow automatic deployment of licence to your cluster when you connect to our Ondat SaaS Platform&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-3&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;k8s&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fixed a bug where the StorageOS operator would occasionally restart&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;270---released-2022-04-11&#34;&gt;2.7.0 - Released 2022-04-11&lt;/h2&gt;
&lt;h3 id=&#34;new-3&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;k8s &amp;amp; Orchestrator Rolling Upgrade&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tech Preview: Kubernetes rolling upgrade for AWS EKS, Google Anthos, Google GKE, Microsoft Azure, Openshift and Rancher
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ This is a tech preview, we only recommend using this feature on your test clusters&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Operator&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Updated memory limit&lt;/li&gt;
&lt;li&gt;Introduced topology spread constraint with &lt;code&gt;ScheduledAnyway&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;API Manager&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adds a feature so when a PVC is not found scheduling will not be blocked&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set &lt;code&gt;Only_Numeric_Owners&lt;/code&gt; to true on NFSv4 setting on Ganesha&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Removed support for FUSE. Ondat now only supports TCMU. &lt;code&gt;target_core_user&lt;/code&gt; must now be used. Read &lt;a href=&#34;https://docs.ondat.io/docs/prerequisites/systemconfiguration/&#34;&gt;System Configuration&lt;/a&gt; for more information&lt;/li&gt;
&lt;li&gt;Rewrote the RPC interface between the Control Plane and the Data Plane. All of the old &lt;code&gt;ctl&lt;/code&gt; tools have been removed&lt;/li&gt;
&lt;li&gt;Removed the 32-bit mappings and uses the UUIDs passed by the CP directly to address presentations and deployments
&lt;blockquote&gt;
&lt;p&gt;âš ï¸ If you decide to upgrade to 2.7.0 and want to downgrade, you can only roll back to 2.6.0, not earlier versions. Roll back instruction can be found &lt;a href=&#34;/docs/operations/downgrade-ondat-2.7-to-2.6&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-4&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;Operator&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fixed a bug that sometimes caused the operator to enter a deadlock state after Ondat cluster CR object deletion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fixed an issue where Ondat was not able to unmount volumes in rare instances, then occasionally causing volumes to become unhealthy&lt;/li&gt;
&lt;li&gt;Fixed an issue that caused replicas to go into the â€œunknownâ€ state during failover in somne rare instances&lt;/li&gt;
&lt;li&gt;Fixed an issue to now display output all dataplane logs even if they don&amp;rsquo;t have the expected syntax&lt;/li&gt;
&lt;li&gt;Fixed an issue so Ondat would speculatively configure the replica in the dataplane before we advertise ourselves to the master&lt;/li&gt;
&lt;li&gt;Fix an issue where goroutines attempting to dial remote nodes could be blocked&lt;/li&gt;
&lt;li&gt;Fix an issue so Ondat volume would remain mounted and online during temporary network issues when pod is on remote, master and replica&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data Plane&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fix non-null terminated buffer which could lead to garbled logs&lt;/li&gt;
&lt;li&gt;Fix client-server network to improve robustness&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;260---released-2022-02-14&#34;&gt;2.6.0 - Released 2022-02-14&lt;/h2&gt;
&lt;h3 id=&#34;new-4&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;Portal Manager:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initial release of the Portal Manager, which supports the connection to Ondat
SaaS Platform.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubectl Plugin:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have added a &lt;code&gt;--dry-run&lt;/code&gt; flag into install command, so you can view the
installation manifests written locally to &lt;code&gt;./storageos-dry-run/&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;We have added capability for conducting an airgapped installation. The new
options can also be used outside of an airgapped cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Operator:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have defined the resource requests and resource limits for the Ondat
components (csi-attacher, csi-provisioner, csi-resizer, api-manager,
cluster-operator and ondat-scheduler).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ondat supports Kubernetes v1.23&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Components&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have added a new component called Node Guard that once enabled allows
you to do rolling upgrades to the orchestrator without any downtime. This
component is disabled by default and we do not recommend using the feature
for production workloads as it is a technical preview feature.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;250---released-2021-12-06&#34;&gt;2.5.0 - Released 2021-12-06&lt;/h2&gt;
&lt;h3 id=&#34;fixed-5&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;Dataplane:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deadlock with unordered UNMAP commands.&lt;/li&gt;
&lt;li&gt;Spurious log message when detaching a volume - you would often see a spurious
warning message â€œmissing fs configuration for presentation_id=2001&amp;quot;. We&amp;rsquo;ve
fixed the issue that led to this log message, by ensuring deletion of LUN
(Logical Unit Number).&lt;/li&gt;
&lt;li&gt;Stop potential shutdown hangs - &lt;code&gt;directfs initiator&lt;/code&gt; could restart
connections after shutdown has been requested. This race condition has been
removed.&lt;/li&gt;
&lt;li&gt;Misleading log message when &lt;code&gt;SetVolumeConsumerCount&lt;/code&gt; is called - log message
now only sent in correct scenarios.&lt;/li&gt;
&lt;li&gt;Volume backup tool in disaster recovery scenarios - the volume backup tool is
used to extract volume data in disaster recovery scenarios. There was an
issue that prevented the tool from running whilst the Dataplane was running.
This has been fixed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;new-5&#34;&gt;New&lt;/h3&gt;
&lt;p&gt;Dataplane:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faster replica syncing - new replicas can be provisioned faster and rejoining
replicas sync faster. Non-contiguous data regions are collated into the same
RPC. Ondat now syncs multiple regions concurrently maximising the network
bandwidth.&lt;/li&gt;
&lt;li&gt;Improved network performance - Up to 2.3 times faster speed and even higher
on high-latency networks.&lt;/li&gt;
&lt;li&gt;Improved error-handling mechanism for synchronise cache commands - we have
ensured error messages are propagated when SYNCHRONIZE_CACHE_16 commands
fail.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Control Plane:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/tap&#34;&gt;Topology-Aware Placement&lt;/a&gt; is a feature
that enforces placement of data across failure domains to guarantee high
availability.&lt;/li&gt;
&lt;li&gt;Track logs from control plane to data plane with extra details.&lt;/li&gt;
&lt;li&gt;The command-line tool can now display the availability zone of each of the volume&amp;rsquo;s
deployments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;New &lt;a href=&#34;/docs/reference/kubectl-plugin&#34;&gt;kubectl plugin&lt;/a&gt; to
manage Ondat.&lt;/li&gt;
&lt;li&gt;Upgrades to the operator and improved development speed - StorageOS cluster
status now reflects cluster deployment status. Users can now change log-level
port to new operator and we have given users increased flexibility for users
to configure StorageOS images.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;244---released-2021-09-08&#34;&gt;2.4.4 - Released 2021-09-08&lt;/h2&gt;
&lt;h3 id=&#34;fixed-6&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;controlplane: Fix an issue with timeouts when opening gRPC connections to
other nodes in the cluster.&lt;/li&gt;
&lt;li&gt;controlplane: Changes to GUI licensing workflow - See our &lt;a href=&#34;/docs/reference/licence&#34;&gt;Licensing
page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;dataplane: Fix an issue where failed IO network connections could be
erroneously restarted while we are trying to shutdown.&lt;/li&gt;
&lt;li&gt;k8s: Leader election requires ability to patch events.&lt;/li&gt;
&lt;li&gt;k8s: Node label sync could fail to apply updated label.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v242---released-2021-07-15&#34;&gt;v2.4.2 - Released 2021-07-15&lt;/h2&gt;
&lt;h3 id=&#34;fixed-7&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;controlplane: Improve error message when unable to set the cluster-wide log
level on an individual node.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Fix rare assert when retrying some writes under certain conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Log format string safety improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Backuptool reliability improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Allow api-manager to patch events for leader election.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v241---released-2021-06-30&#34;&gt;v2.4.1 - Released 2021-06-30&lt;/h2&gt;
&lt;h3 id=&#34;new-6&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cluster-wide log level configuration via Custom Resource.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-8&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;controlplane: Improve error message during failed &lt;code&gt;--label&lt;/code&gt; argument parsing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane: Double-check the OS performs the NFS mount as directed, and
unmount on error.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane: Improved FSM and sync CC logging.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Log message quality, quantity and visibility improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane: Volume backup tool error reporting improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s: Pod scheduler fixes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v240---released-2021-05-27&#34;&gt;v2.4.0 - Released 2021-05-27&lt;/h2&gt;
&lt;p&gt;This release adds production-grade &lt;a href=&#34;/docs/reference/encryption&#34;&gt;encryption at rest&lt;/a&gt; for Ondat volumes, as well as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/docs/concepts/fencing&#34;&gt;Fencing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/operations/trim&#34;&gt;TRIM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/concepts/replication#failure-modes&#34;&gt;Failure modes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/reference/kubernetes-object-sync&#34;&gt;Kubernetes object sync&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: v2.4.0 &lt;em&gt;requires&lt;/em&gt; Kubernetes 1.17 or newer.&lt;/p&gt;
&lt;h3 id=&#34;new-7&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Volume encryption-at-rest.&lt;/li&gt;
&lt;li&gt;Fencing support.&lt;/li&gt;
&lt;li&gt;Block trim support.&lt;/li&gt;
&lt;li&gt;Kubernetes label sync.&lt;/li&gt;
&lt;li&gt;Kubernetes node and namespace delete sync.&lt;/li&gt;
&lt;li&gt;Failure tolerance threshold support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-9&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;controlplane/api: Compression is not disabled by default when provisioning
volumes via the API.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/api: Spec has incorrect response body for partial bundle.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/csi: Error incorrectly returned when concurrent namespace
creation requests occur.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: GetDiagnostics RPC response does not indicate if
node timed out collecting some data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: Invalid character &amp;lsquo;\u0080&amp;rsquo; looking for beginning of
value via CLI when a node is down.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnosticutil: Include attachment type in unpacking local
volumes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnotics: Node timing out during local diagnostics is missing
logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/healthcheck: Combined sources fires callback in initialisation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/volumerpc: &amp;ldquo;Got unknown replica state 0&amp;rdquo; discards results.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Check blob writes don&amp;rsquo;t exceed internal limit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Checking the return code of InitiatorAddConnection().&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Director signal hander thread is not joined.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Don&amp;rsquo;t block I/O when many retries are in progress.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: gRPC API robustness improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Initiator needs to include the node UUID in Endpoint.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Low-level I/O engines don&amp;rsquo;t propagate IO failures via Wait().&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Log available contextual information where possible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Ensure BackingStore is not deleted twice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Serialise LIO create/delete operations to avoid kernel bug.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Dataplane shutdown time can exceed 10 seconds.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Fix non-threadsafe access on TCMU device object.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fix: Don&amp;rsquo;t hold lock unecessarily in Rdb::Reap.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: First ip octet should not be 0, 127, 169 or 224.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Keygen should only operate on Ondat PVCs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add perm to allow VolumeAttachment finalizer removal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Fix apiManagerContainer tag in v1 deploy CRD.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Fix docker credentials check.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Fix ServiceAccountName in the OLM bundle.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Set webhook service-for label to be unique.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;controlplane/api: Make version provided consistent for NFS/Host attach
handler.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/attachtracker: Cleanup NFS mounts at shutdown.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/build: Migrate to go modules for dependency management.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/build: Use sentry prod-url if build branch has &amp;ldquo;release&amp;rdquo; prefix.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/cli: Colour for significant feedback.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/cli: Update node must set compute only separately to other
labels.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/cli: Warn user that updating labels action can be reverted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/csi: Bound request handlers with timeout similar to HTTP API.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/csi: Remove error obfuscation and clarify log messages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/csi: Stop logging not found.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/dataplane: Remove UUID mappings during failed presentation
creation rollback.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/dataplaneevents: Decorate logs with extra event details.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: Asymmetrically encrypt bundles.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: Collect FSM state.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnostics: Support single node bundle collection.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnosticutil: Decorate log entries with well-known field
corresponding to node id/name.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnosticutil: Parallelise unpacking of disjoint data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/diagnosticutil: Unpack gathered NFS config data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/fsm: Perform state match check before version check.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/k8s: Use secret store.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/log: Fix race condition writing logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/log: Handle originator timestamps from dataplane logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/meta: Error checking code uses Go 1.13 error features.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/rpc: Make CP gRPC calls to the DP configuration endpoints
idempotent.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/sentry: Prevent some unnecessary alerts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/slog: Clean up error logging in RPC provision stack.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/states: Add the &amp;ldquo;from&amp;rdquo; state as a log field for state transition
msgs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/store/etcd: Decorate lock logs with associated ID fields.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/ui: Warn user that updating labels action will be reverted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/vendor: Bump service repository.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;controlplane/volume: Encryption support in kubernetes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fs: Don&amp;rsquo;t return from PresentationCreate RPC until the device is
fully created.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fs: Each LUN should have it&amp;rsquo;s own HBA.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/fs: Improve device ready check.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/internals: Improve DP stats implementation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/internals: Major director refactor.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/log: Logs should output originating timestamps.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/log: Move to log3 API exclusively.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/log: Remove log2.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/log: Set log_level and log_filter via the supctl tool.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/rdb: Handle unaligned I/O in RdbPlugin.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/rdb: Implement low-level &amp;ldquo;delete block&amp;rdquo; functionality.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/rdb: rocksdb Get() should use an iterator.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/story: Support for block unmapping.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/story: Add backuptool binary to export volume data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/story: Volume encryption-at-rest.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/sync: Add retries for failed sync IOs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/sync: VolumeHash performance improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dataplane/sys: Find and check OS pids.max on startup.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Don&amp;rsquo;t attempt service creation if the owning PVC doesn&amp;rsquo;t
exist.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Compare SC and PVC creation time during label sync.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add action to ensure modules tidy &amp;amp; vendored.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add defaults from StorageClass.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add fencing controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add flag and support for cert validity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add flags to disable label sync controllers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add namespace delete controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add node delete controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add OpenTelemetry tracing with Jaeger backend.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add PVC label sync controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add PVC mutating controller.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add support for failure-mode label.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Add support for volume encryption.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Allow multiple mutators.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Build and tests should use vendored deps.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Bump controller-runtime to v0.6.4.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Encrypt only provisioned PVCs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Fix tracing example.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Introduce StorageClass to PVC annotation mutator.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Log API reason.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Migrate namespace delete to operator toolkit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Migrate node delete to operator toolkit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Migrate to kubebuilder v3.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Node label sync.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Node label update must include current reserved labels.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Pass context to API consistently.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Rename leader election config map.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: RFC 3339 and flags to configure level &amp;amp; format.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Run shared volume controller with manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Set initial sync delay.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Set Pod scheduler.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Standardise on ObjectKeys for all API function signatures.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Ondat API interface and mocks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Update dependencies and go version 1.16.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Update to new external object sync.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Use composite client in admission controllers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/api-manager: Use Object interface.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Changes to the StorageOSCluster CR get applied to Ondat.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Increase provisioner timeout from 15 to 30s.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Reduce CSI provisioner worker pool.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Set priority class for helper pods.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add pod anti-affinity to api-manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add pvc mutator config.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add rbac for api-manager fencing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add RBAC for encryption key management.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add RBAC needed for csi-resizer v1.0.0.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add webhook resource migration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Add workflow to push image to RedHat registry.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Bump csi-provisioner to v2.1.1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Call APIManagerWebhookServiceTest test.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Delete CSI expand secret when cluster is deleted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Docker login to avoid toomanyrequests error.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Move pod scheduler webhook to api-manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: RBAC to allow sync functions move to api-manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Remove pool from StorageClass, not used in v2.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Remove some other v1.14 specific logic.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Set the default container for kubectl logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Update code owners.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Update CSI sidecar images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s/cluster-operator: Validate minimum Kubernetes version.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v234---released-2021-03-24&#34;&gt;v2.3.4 - Released 2021-03-24&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;controlplane/build: Use Sentry prod-url for release branches (CP-4600).&lt;/li&gt;
&lt;li&gt;controlplane/csi: Improve CSI handler timeout (CP-4585).&lt;/li&gt;
&lt;li&gt;controlplane/dataplane: UUID mapping cleanup on failed volume creation (CP-4588).&lt;/li&gt;
&lt;li&gt;controlplane/slog: Improve RPC error logging (CP-4616).&lt;/li&gt;
&lt;li&gt;dataplane: Allocate fewer aio contexts per volume (DP-305)&lt;/li&gt;
&lt;li&gt;dataplane: Defer fallocate(2) until first write (DP-312).&lt;/li&gt;
&lt;li&gt;dataplane: Don&amp;rsquo;t fail replica sync if inter-node connection establishment is slow (DP-319, DP-280).&lt;/li&gt;
&lt;li&gt;dataplane: Improve logging around gRPC context cancellations (DP-315).&lt;/li&gt;
&lt;li&gt;dataplane: Improve rollback for failed volume creation (DP-308).&lt;/li&gt;
&lt;li&gt;dataplane: New support tool to cleanup orphaned volume storage (DP-307).&lt;/li&gt;
&lt;li&gt;dataplane: supctl can reap named volumes (DP-309).&lt;/li&gt;
&lt;li&gt;k8s: API token reset failures should trigger re-authentication directly (#38).&lt;/li&gt;
&lt;li&gt;k8s: Increase lint timeout to reduce CI errors (#305).&lt;/li&gt;
&lt;li&gt;k8s: Remove PriorityClass from helper pods (#312).&lt;/li&gt;
&lt;li&gt;k8s: Toleration defaults for helper pods (#311).&lt;/li&gt;
&lt;li&gt;k8s: Use ubi-minimal base image directly (#307).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v233---released-2021-02-12&#34;&gt;v2.3.3 - Released 2021-02-12&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Support CSI ListVolumes() API, addressing volume attach problems seen by some
customers.&lt;/li&gt;
&lt;li&gt;Quality-of-life fixes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;new-8&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;operator: Use CSI attacher v3 for k8s 1.17+.&lt;/li&gt;
&lt;li&gt;controlplane/csi: ListVolumes support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-10&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;api-manager: Reset API after token refresh error.&lt;/li&gt;
&lt;li&gt;operator: Set scheduler when PVCs use default StorageClass.&lt;/li&gt;
&lt;li&gt;operator: Update base container image.&lt;/li&gt;
&lt;li&gt;controlplane/volumerpc: &amp;ldquo;Got unknown replica state 0&amp;rdquo; discards results.&lt;/li&gt;
&lt;li&gt;controlplane/healthcheck: Combined sources fires callback in initialisation.&lt;/li&gt;
&lt;li&gt;controlplane/fsm: Perform state match check before version check.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v232---released-2020-11-25&#34;&gt;v2.3.2 - Released 2020-11-25&lt;/h2&gt;
&lt;h3 id=&#34;fixed-11&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;controlplane/rejoin: Failure to delete data causes re-advertise loop.&lt;/li&gt;
&lt;li&gt;controlplane/rejoin: Handle timeout waiting for progress report.&lt;/li&gt;
&lt;li&gt;dataplane/log: Change buffering of &lt;code&gt;symmetra&lt;/code&gt; output to prevent stalls.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v231---released-2020-11-16&#34;&gt;v2.3.1 - Released 2020-11-16&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Allows access to &lt;code&gt;ReadWriteMany&lt;/code&gt; shared volumes when running containers as a
non-root user.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-12&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;nfs: root squash to uid=0 is now configured on all shared volumes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v230---released-2020-10-31&#34;&gt;v2.3.0 - Released 2020-10-31&lt;/h2&gt;
&lt;p&gt;This release adds production-grade shared file support to v2, previously a
technology preview in v1.&lt;/p&gt;
&lt;h3 id=&#34;breaking&#34;&gt;Breaking&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;v2.3.0&lt;/code&gt; operator is no longer able to run Ondat v1.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;new-9&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Adds support for &lt;code&gt;ReadWriteMany&lt;/code&gt; shared volumes.  See
&lt;a href=&#34;/docs/concepts/rwx&#34;&gt;ReadWriteMany&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Adds &lt;code&gt;api-manager&lt;/code&gt; deployment to support shared volumes.  See &lt;a href=&#34;https://github.com/storageos/api-manager&#34;&gt;the api
manager&lt;/a&gt; GitHub repository for more
information.&lt;/li&gt;
&lt;li&gt;Kubernetes 1.19 support.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved-1&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;dataplane: Reduce replication thread usage by having the replication processes
share the main thread pool.  This helps ensure that there isn&amp;rsquo;t a spike in
thread usage when a node recovers and begins re-syncing its volumes.  This is
particularly relevant on CRIO-based orchestrators such as Openshift where the
default maximum allowed PID limit (which also governs the thread limit) is
low.&lt;/li&gt;
&lt;li&gt;dataplane: Detect and log the effective maximum PID limit on startup.&lt;/li&gt;
&lt;li&gt;dataplane: Internal device presentation mappings are now ephemeral and are not
persisted across reboots.&lt;/li&gt;
&lt;li&gt;dataplane: Disabled default verbose logging for fdatasync/flushWAL timers.&lt;/li&gt;
&lt;li&gt;dataplane: Log both volume inode and UUID in replication error messages for
easier correlation.&lt;/li&gt;
&lt;li&gt;dataplane: On startup, ensure any remnant devices that may have been left
after an unclean shutdown have been properly cleared.&lt;/li&gt;
&lt;li&gt;dataplane: Signal when all startup tasks complete.  This ensures no IO can be
initiated before this time.&lt;/li&gt;
&lt;li&gt;ha: Implement a backoff when attempting to repoint an attached volume after
the master has failed.&lt;/li&gt;
&lt;li&gt;ha: Replicas can now rejoin after an asymmetric partition. This can occur when
the master has not lost communication to the replica, but the replica can&amp;rsquo;t
communicate with the master.  Previously the replica would not be able to
rejoin until the master determined it had failed.&lt;/li&gt;
&lt;li&gt;ha: A master that was partitioned can now re-join to the new master as a
replica.&lt;/li&gt;
&lt;li&gt;api: node label changes update target node prior to committing new state.&lt;/li&gt;
&lt;li&gt;api: Validation errors now include more information on the failure and how to
resolve.&lt;/li&gt;
&lt;li&gt;csi: Volume resize error messages (e.g. capacity exceeded) now passed through
in CSI response.&lt;/li&gt;
&lt;li&gt;csi: Volume attachment is now verified prior to mount for more instructive
error message.&lt;/li&gt;
&lt;li&gt;csi: Returns &lt;code&gt;RESOURCE EXHAUSTED&lt;/code&gt; error when attempting to exceed maximum of
250 Ondat volume attachments per node.&lt;/li&gt;
&lt;li&gt;diagnostics: Multiple improvements to bundle collection and collected data.&lt;/li&gt;
&lt;li&gt;ui: Allow collection of partial diagnostics bundles.&lt;/li&gt;
&lt;li&gt;ui: Tolerate clock skew when authenticating via the UI.&lt;/li&gt;
&lt;li&gt;licensing: Read-through cache added.  Licence updates will take up to 60s to
propagate to all nodes.&lt;/li&gt;
&lt;li&gt;cli: Set replicas output formatting.&lt;/li&gt;
&lt;li&gt;init: Checks the effective maximum PID limit and warns if less than the
Ondat recommended PID limit (32,768).  CRIO-based distributions such as
Openshift have a much lower default value (1024).  Consult
&lt;a href=&#34;/docs/prerequisites/pidlimits&#34;&gt;prerequisites&lt;/a&gt; for more
information.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-13&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;dataplane: Fixes &lt;code&gt;transport endpoint is not connected&lt;/code&gt; on startup after an
unclean shutdown.&lt;/li&gt;
&lt;li&gt;csi: Volume unmount requests now succeed when the mountpoint has
already been removed by the orchestrator.&lt;/li&gt;
&lt;li&gt;csi: Volume detach requests now succeed when the volume has already been
deleted.  Previously the volume would be stuck in &lt;code&gt;Terminating&lt;/code&gt; status.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v220---released-2020-08-18&#34;&gt;v2.2.0 - Released 2020-08-18&lt;/h2&gt;
&lt;p&gt;This release focuses on performance. We analysed existing performance
characteristics across a variety of real-world use cases and ended up with
improvements across the board. Of particular note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sequential reads have improved by up to 130%&lt;/li&gt;
&lt;li&gt;Sequential writes have improved by up to 737%&lt;/li&gt;
&lt;li&gt;Random reads have improved by up to 45%&lt;/li&gt;
&lt;li&gt;Random writes have improved by up to 135%&lt;/li&gt;
&lt;li&gt;I/O for large block sizes (128K) has improved by up to 353%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are extremely proud of our performance and we love to talk about it. Have a
look at the &lt;a href=&#34;/docs/introduction/self-eval#Benchmarking&#34;&gt;Benchmarking&lt;/a&gt; section of the
self-evaluation guide and consider sharing
your results. Our PRE engineers are available to discuss in our &lt;a href=&#34;https://storageos.slack.com&#34;&gt;slack
channel&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;new-10&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Data engine revamp focused on provable consistency and performance. Key
characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Metadata is stored in an optimised index, lowering I/O latency and improving
performance for all workloads.&lt;/li&gt;
&lt;li&gt;Large block reads/writes are now be handled in a single operation.
Applications like Kafka will go much faster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On-disk compression is now disabled by default as in most scenarios this
offers better performance. To enable on-disk compression for a specific
workload, see &lt;a href=&#34;/docs/concepts/compression&#34;&gt;compression&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved-2&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;dataplane: The number of I/O threads are now determined by the number of
processing cores available.  This improves scalability and performance on
larger servers.&lt;/li&gt;
&lt;li&gt;ha: Improve partition tolerance behaviour when a volume master that has lost
its connection to etcd rejoins.&lt;/li&gt;
&lt;li&gt;ha: Allow replicas in unhealthy states to be remediated and re-used while
maintaining partition tolerance.&lt;/li&gt;
&lt;li&gt;ha: When a master fails and the new master is not yet available, introduce a
back-off to the redirection logic to avoid spamming the logs with connection
failure errors.&lt;/li&gt;
&lt;li&gt;ha: Ignore health advertisements for local node. Local nodes are handled
directly.&lt;/li&gt;
&lt;li&gt;node delete: Only refuse to delete a node if the node health can be
authoritatively verified to be in use.&lt;/li&gt;
&lt;li&gt;api: Increase HTTP server write timeout.&lt;/li&gt;
&lt;li&gt;cli/ui: Allow partial diagnostic bundle downloads.&lt;/li&gt;
&lt;li&gt;ui: Namespace dropdown can now be scrolled.&lt;/li&gt;
&lt;li&gt;ui: Add &amp;ldquo;Job title&amp;rdquo; to UI licence form.&lt;/li&gt;
&lt;li&gt;logging: Log version at startup at INFO level.&lt;/li&gt;
&lt;li&gt;logging: Lower verbosity of SCSI warnings that do not apply to Ondat.&lt;/li&gt;
&lt;li&gt;diagnostics: Include logs that have been rotated.&lt;/li&gt;
&lt;li&gt;diagnostics: Bundle collection across providers is now done in parallel.&lt;/li&gt;
&lt;li&gt;build: Update base image to RHEL 8.2.&lt;/li&gt;
&lt;li&gt;operator: Removed DB migration utility required for v1.3 -&amp;gt; v1.4 upgrades.&lt;/li&gt;
&lt;li&gt;operator: Automatically refreshes Ondat API token without failing
requests when the token expires.&lt;/li&gt;
&lt;li&gt;operator: Updated CSI attacher and provisioner to latest upstream.&lt;/li&gt;
&lt;li&gt;operator: Remove &lt;code&gt;cluster.local&lt;/code&gt; suffix on Pod scheduler service address.
This allows the scheduler to work in clusters with custom DNS configuration.&lt;/li&gt;
&lt;li&gt;operator: Defaults are now set for most CSI configuration options in the
StorageOSCluster custom resource.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-14&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;csi: When unmount request is received for a volume that has already been
unmounted, return success.&lt;/li&gt;
&lt;li&gt;csi: Verify volume is attached on the node before mounting it.&lt;/li&gt;
&lt;li&gt;xfs: Support older RHEL kernels which have an XFS library that does not
allow reflinks/dedupe.&lt;/li&gt;
&lt;li&gt;dataplane: Reserve 1GiB of capacity on the target disk to allow manual cleanup
operations, rather than filling target disk to capacity.&lt;/li&gt;
&lt;li&gt;operator: In some cases &lt;code&gt;/var/lib/storageos&lt;/code&gt; could fail to unmount cleanly
after a restart. This resulted in multiple entries in &lt;code&gt;/proc/mounts&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v210---released-2020-06-26&#34;&gt;v2.1.0 - Released 2020-06-26&lt;/h2&gt;
&lt;h3 id=&#34;new-11&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;csi: Volume expansion now supported in offline mode. To expand a volume, stop
any workloads accessing the volume, then edit the PVC to increase the
capacity. For more information, see our &lt;a href=&#34;/docs/operations/resize&#34;&gt;Volume Resize&lt;/a&gt; operations page and the &lt;a href=&#34;https://kubernetes-csi.github.io/docs/volume-expansion.html&#34;&gt;&lt;code&gt;CSI Volume Expansion&lt;/code&gt;&lt;/a&gt;
page.&lt;/li&gt;
&lt;li&gt;api: Volume configuration including replica count can now be updated while
the volume is in use. Other updateable fields include labels and
description.&lt;/li&gt;
&lt;li&gt;failover: Before determining that a node is offline and performing recovery
operations, the I/O path is also verified. This provides more robust failure
detection and ensures that nodes that are still responding to I/O do not get
replaced. This I/O path verification is in addition to the gossip-based
failure detection.&lt;/li&gt;
&lt;li&gt;operator: Default tolerations are now set for the Ondat node container.
This helps ensure that the Ondat node container does not get evicted when
the node is running low on resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved-3&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;api: Added checks to prevent deletion of a node with active volumes, or if it
is the master of at least one volume. This helps prevent orphaned volumes.&lt;/li&gt;
&lt;li&gt;cli: Add an &lt;code&gt;--offline-delete&lt;/code&gt; flag to allow removal of volumes whose master
and replica nodes are offline. This allows cleanup of orphaned volumes.&lt;/li&gt;
&lt;li&gt;ui: Add an offline volume delete option.&lt;/li&gt;
&lt;li&gt;ui: Volumes can now be detached from the UI.&lt;/li&gt;
&lt;li&gt;cli: Labels are no longer truncated.&lt;/li&gt;
&lt;li&gt;api: When a new node is added to the cluster, its capacity is available to use
immediately.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-15&#34;&gt;Fixed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ui: Favicon was missing.&lt;/li&gt;
&lt;li&gt;ui: Duplicate volumes could be shown on the node details page.&lt;/li&gt;
&lt;li&gt;operator: During uninstall a ClusterRoleBinding was not removed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;v200---released-2020-05-05&#34;&gt;v2.0.0 - Released 2020-05-05&lt;/h2&gt;
&lt;h3 id=&#34;new-12&#34;&gt;New&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;operator: Ondat containers now run in the &lt;code&gt;kube-system&lt;/code&gt; namespace by
default to allow the &lt;code&gt;system-node-critical&lt;/code&gt; priority class to be set. This
instructs Kubernetes to start Ondat before application Pods, and to evict
Ondat only after application Pods have finished. This setting was
previously recommended in documentation; it is now the default.&lt;/li&gt;
&lt;li&gt;operator: Ondat CSI helper containers now run as privileged. This ensures
that the CSI endpoint can be seen on systems with SELinux enabled.&lt;/li&gt;
&lt;li&gt;ui: replication progress for new or re-joining replicas is now displayed.&lt;/li&gt;
&lt;li&gt;ui: show warning for unlicensed clusters.&lt;/li&gt;
&lt;li&gt;cli: new commands:
&lt;ul&gt;
&lt;li&gt;licence management&lt;/li&gt;
&lt;li&gt;get policy&lt;/li&gt;
&lt;li&gt;create namespace&lt;/li&gt;
&lt;li&gt;create policy&lt;/li&gt;
&lt;li&gt;describe user&lt;/li&gt;
&lt;li&gt;describe namespace&lt;/li&gt;
&lt;li&gt;describe policy&lt;/li&gt;
&lt;li&gt;delete user&lt;/li&gt;
&lt;li&gt;delete namespace&lt;/li&gt;
&lt;li&gt;delete policy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;licence: removed the default licence expiry date added for &lt;code&gt;v2.0.0-rc.1&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;improved-4&#34;&gt;Improved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;dataplane: improved retry behaviour for network I/O.&lt;/li&gt;
&lt;li&gt;cli: &amp;ldquo;get volumes&amp;rdquo; for all namespaces should be done in parallel.&lt;/li&gt;
&lt;li&gt;cli: help text document config file&lt;/li&gt;
&lt;li&gt;ui: link node name and get to node details on the volume details page.&lt;/li&gt;
&lt;li&gt;ui: node details add available capacity spinner.&lt;/li&gt;
&lt;li&gt;ui: node list remove capacity values / address port.&lt;/li&gt;
&lt;li&gt;ui: node list show master/replica counts.&lt;/li&gt;
&lt;li&gt;ui: node list remove edit action.&lt;/li&gt;
&lt;li&gt;ui: format entity labels.&lt;/li&gt;
&lt;li&gt;ui: node details link volumes.&lt;/li&gt;
&lt;li&gt;ui: align buttons for licences.&lt;/li&gt;
&lt;li&gt;ui: k8s warning in &amp;ldquo;create volume&amp;rdquo; modal.&lt;/li&gt;
&lt;li&gt;ui: node list remove &amp;ldquo;API&amp;rdquo; from &amp;ldquo;API Address&amp;rdquo;&lt;/li&gt;
&lt;li&gt;ui: add some details about the Licence on the licence page.&lt;/li&gt;
&lt;li&gt;api: include valid for duration in login response.&lt;/li&gt;
&lt;li&gt;licence: restrict nodes which are unregistered after 24 hours.&lt;/li&gt;
&lt;li&gt;scheduler: return error for namespace/volume not found&lt;/li&gt;
&lt;li&gt;dataplane: start gRPC threads separately from rest of the supervisor.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fixed-16&#34;&gt;Fixed&lt;/h3&gt;
&lt;p&gt;&amp;laquo;&amp;laquo;&amp;laquo;&amp;lt; HEAD&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ui: centre licence types.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ui: capacity in ui is per namespace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cli: fail gracefully if missing some output details (i.e. no node exists for ID).
=======&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ui: centre licence types.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ui: capacity in ui is per namespace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cli: fail gracefully if missing some output details (i.e. no node exists for ID).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;main&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;v200-rc1---released-2020-03-31&#34;&gt;v2.0.0-rc.1 - Released 2020-03-31&lt;/h2&gt;
&lt;p&gt;Initial release of version 2.x. See &lt;a href=&#34;https://storageos.com/storageos-2-0-release-blog&#34;&gt;Ondat v2.0 Release
Blog&lt;/a&gt; for details.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Availability of IPv6</title>
      <link>/docs/prerequisites/ipv6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/ipv6/</guid>
      <description>
        
        
        &lt;h2 id=&#34;availability-of-ipv6-address-family&#34;&gt;Availability of IPv6 Address Family&lt;/h2&gt;
&lt;p&gt;Certain Ondat components need to be able to listen on a standard
dual-stack socket of type AF_INET6. The IPv6 address family must be supported
on the server so that this socket can be allocated. Ondat does not require
IPv6 to be configured on the server - no addressing or routing needs to be in
place, however Ondat does need this functionality to be enabled in the
kernel.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Firewalls</title>
      <link>/docs/prerequisites/firewalls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/firewalls/</guid>
      <description>
        
        
        &lt;h2 id=&#34;port-list&#34;&gt;Port list&lt;/h2&gt;
&lt;p&gt;Ondat daemons listen on specific ports, which we require to be accessible
between all nodes in the cluster:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Port Number&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;TCP/UDP&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5701&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;gRPC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5703&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;DirectFS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5704&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Dataplane Supervisor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5705&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;REST API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5710&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;gRPC API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5711&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP &amp;amp; UDP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Gossip service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25705-25960&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TCP&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;RWX Volume Endpoints&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Ondat also uses &lt;a href=&#34;https://en.wikipedia.org/wiki/Ephemeral_port&#34;&gt;ephemeral&lt;/a&gt;
ports to dial-out to these ports on other Ondat nodes. For this reason,
outgoing traffic should to other nodes be enabled.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;firewalls-and-vps-providers&#34;&gt;Firewalls and VPS providers&lt;/h2&gt;
&lt;p&gt;Some VPS providers (such as Digital Ocean) ship default firewall rulesets which
must be updated to allow Ondat to run. Some example rules are shown below -
modify to taste.&lt;/p&gt;
&lt;h3 id=&#34;ufw&#34;&gt;UFW&lt;/h3&gt;
&lt;p&gt;For distributions using UFW, such as RHEL and derivatives:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ufw default allow outgoing
ufw allow 5701:5711/tcp
ufw allow 5711/udp
ufw allow 25705:25960/tcp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;firewalld&#34;&gt;Firewalld&lt;/h3&gt;
&lt;p&gt;For distributions that enable firewalld to control iptables such as some installations of OpenShift.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;firewall-cmd --permanent  --new-service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
firewall-cmd --permanent  --service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos --add-port&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;5700-5800/tcp --add-port&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;25705-25960/tcp
firewall-cmd --add-service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos  --zone&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;public --permanent
firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;iptables&#34;&gt;Iptables&lt;/h3&gt;
&lt;p&gt;For those using plain iptables:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Inbound traffic&lt;/span&gt;
iptables -I INPUT -i lo -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit loopback traffic&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -m state --state ESTABLISHED,RELATED -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit established traffic&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -p tcp --dport 5701:5711 -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Ondat&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -p udp --dport &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;5711&lt;/span&gt; -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Ondat&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -p tcp --dport 25705:25960 -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Ondat&amp;#39;&lt;/span&gt; -j ACCEPT

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Outbound traffic&lt;/span&gt;
iptables -I OUTPUT -o lo -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit loopback traffic&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I OUTPUT -d 0.0.0.0/0 -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit outbound traffic&amp;#39;&lt;/span&gt; -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;âš ï¸  Make sure that the iptables rules you have added above come before any default DROP or REJECT rules.&lt;/p&gt;
&lt;/blockquote&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: PID Limits</title>
      <link>/docs/prerequisites/pidlimits/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/pidlimits/</guid>
      <description>
        
        
        &lt;p&gt;Ondat recommends that a &lt;a href=&#34;https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#pid&#34;&gt;PID
cgroup&lt;/a&gt;
limit of 32768 be used for Ondat pods.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ðŸ’¡ Most environments fulfill this prerequisite by default. Check the
Ondat init container logs as shown below to ensure this is the case.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ondat pods running in Kubernetes are part of a PID cgroup that may limit
the maximum number of PIDs that all containers in the PID cgroup slice can
spawn. As the Linux kernel assigns a PID to processes and Light Weight
Processes (LWP) a low limit can be easily reached under certain circumstances.
The PID limit can be set by the Kubernetes distribution or by the container
runtime. Generally the limit is set to the machine wide default limit of 32768
but some environments can set this as low as 1024. A low PID limit may prevent
Ondat from spawning the required threads.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/storageos/init&#34;&gt;Ondat init container&lt;/a&gt; runs a script
that checks for the PID limit of the PID cGroup slice that the Ondat pod
runs in. If the
&lt;a href=&#34;https://github.com/storageos/init/blob/master/scripts/02-limits/limits.sh&#34;&gt;script&lt;/a&gt;
finds that the limit is less than 32768 it will log a warning. This warning can
be viewed using kubectl to check the init container logs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n storageos logs -l app.kubernetes.io/component&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;control-plane,app&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos -c init
WARNING: Effective max.pids limit &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;1024&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt; less than RECOMMENDED_MAX_PIDS_LIMIT &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;32768&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;setting-a-kubernetes-pid-limit&#34;&gt;Setting a Kubernetes PID limit&lt;/h2&gt;
&lt;p&gt;Kubernetes defaults to an unlimited &lt;code&gt;PodPidsLimit&lt;/code&gt;, which results in the usage of
the machine wide limit; typically 32768.&lt;/p&gt;
&lt;p&gt;For information on how to configure the Kubernetes PID limit see the Kubernetes
documentation
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;setting-a-cri-o-pid-limit&#34;&gt;Setting a CRI-O PID limit&lt;/h2&gt;
&lt;p&gt;Certain orchestrators or setups use CRI-O as the container runtime. Openshift
4.x currently has CRI-O set a PID limit of 1024 by default. To configure the
default CRI-O limit in Openshift 4.x see the RedHat documentation
&lt;a href=&#34;https://access.redhat.com/solutions/5305611&#34;&gt;here&lt;/a&gt;. To configure CRI-O more
generally see the CRI-O documentation
&lt;a href=&#34;https://github.com/cri-o/cri-o/blob/master/docs/crio.conf.5.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ondat Best Practices</title>
      <link>/docs/best-practices/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/best-practices/</guid>
      <description>
        
        
        &lt;h2 id=&#34;etcd---in-cluster---replicas-and-availability-zones&#34;&gt;Etcd - In Cluster - Replicas and Availability Zones&lt;/h2&gt;
&lt;p&gt;We recommend running etcd with 5 replicas (etcd peers) and spreading them across availability zones when running etcd inside the cluster, this improves the resiliency of the etcd cluster. This is done by default when installing via the plugin or helm.&lt;/p&gt;
&lt;h2 id=&#34;etcd-low-latency-io&#34;&gt;Etcd low latency IO&lt;/h2&gt;
&lt;p&gt;It is recommended to run etcd on low-latency disks and keep other IO-intensive
applications separate from the etcd nodes. Etcd is very sensitive to IO latency.
Thus, the effect of disk contention can cause etcd downtime.&lt;/p&gt;
&lt;p&gt;Batch jobs such as backups, builds or application bundling can easily cause a
high usage of disks making etcd unstable. It is recommended to run such
workloads apart from the etcd servers.&lt;/p&gt;
&lt;h2 id=&#34;setup-of-storage-on-the-hosts&#34;&gt;Setup of storage on the hosts&lt;/h2&gt;
&lt;p&gt;We recommend creating a separate filesystem for Ondat to mitigate the risk
of filling the root filesystem on nodes. This has to be done for each node in
the cluster.&lt;/p&gt;
&lt;p&gt;Follow the &lt;a href=&#34;/docs/operations/managing-host-storage&#34;&gt;managing host storage&lt;/a&gt; best practices page for more
details.&lt;/p&gt;
&lt;h2 id=&#34;resource-reservations&#34;&gt;Resource reservations&lt;/h2&gt;
&lt;p&gt;Ondat resource consumption depends on the workloads and the Ondat
features in use.&lt;/p&gt;
&lt;p&gt;The recommended minimum memory reservation for the Ondat Pods is 512MB for
non-production environments. However it is recommended to prepare nodes so
Ondat can operate with at least with 1-2GB of memory. Ondat frees
memory when possible.&lt;/p&gt;
&lt;p&gt;For production environments, we recommend 4GB of Memory and 1 CPU as a minimum
and to test Ondat using realistic workloads and tune resources accordingly.&lt;/p&gt;
&lt;p&gt;Ondat Pods resource allocation will impact directly on the availability of
volumes in case of eviction or resource limit triggered restart. It is
recommended to not limit Ondat Pods.&lt;/p&gt;
&lt;p&gt;Ondat implements a storage engine, therefore limiting CPU consumption might
affect the I/O throughput of your volumes.&lt;/p&gt;
&lt;h2 id=&#34;setting-a-kubernetes-pid-limit&#34;&gt;Setting a Kubernetes PID limit&lt;/h2&gt;
&lt;p&gt;Ondat recommends that a PID cgroup limit of 32768 be set. Ondat is a
multi-threaded application and while most Kubernetes distributions set the PID
cgroup limit to 32768, some environments can set a limit as low as 1024. The
Ondat init container will print a log message warning if the PID cgroup
limit is too low. See our &lt;a href=&#34;/docs/prerequisites/pidlimits&#34;&gt;prerequisites&lt;/a&gt; for
more information.&lt;/p&gt;
&lt;h2 id=&#34;maintain-a-sufficient-number-of-nodes-for-replicas-to-be-created&#34;&gt;Maintain a sufficient number of nodes for replicas to be created&lt;/h2&gt;
&lt;p&gt;To ensure that a new replica can always be created, an additional node should
be available. To guarantee high availability, clusters using Volumes with 1
replica must have at least 3 storage nodes. When using Volumes with 2
replicas, at least 4 storage nodes, 3 replicas, 5 nodes, etc.&lt;/p&gt;
&lt;p&gt;Minimum number of storage nodes = 1 (primary) + N (replicas) + 1&lt;/p&gt;
&lt;p&gt;For more information, see the section on
&lt;a href=&#34;/docs/concepts/replication#number-of-nodes&#34;&gt;replication&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;ondat-api-usernamepassword&#34;&gt;Ondat API username/password&lt;/h2&gt;
&lt;p&gt;The API grants full access to Ondat functionality, therefore we recommend
that the default administrative password of &amp;lsquo;storageos&amp;rsquo; is reset to something
unique and strong.&lt;/p&gt;
&lt;p&gt;You can change the default parameters by encoding the &lt;code&gt;username&lt;/code&gt; and
&lt;code&gt;password&lt;/code&gt; values (in base64) into the &lt;code&gt;storageos-api&lt;/code&gt; secret.&lt;/p&gt;
&lt;p&gt;To generate a unique password, a technique such as the following, which
generates a pseudo-random 24 character string, may be used:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Generate strong password&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;cat -e /dev/urandom &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; tr -dc &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;a-zA-Z0-9-!@#$%^&amp;amp;*()_+~&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; fold -w &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;24&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; head -n 1&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Convert password to base64 representation for embedding in a K8S secret&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;BASE64PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; -n &lt;span style=&#34;color:#000&#34;&gt;$PASSWORD&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; base64&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that the Kubernetes secret containing a strong password &lt;em&gt;must&lt;/em&gt; be created
before bootstrapping the cluster. Multiple installation procedures use this
Secret to create an Ondat account when the cluster first starts.&lt;/p&gt;
&lt;h2 id=&#34;ondat-pod-placement&#34;&gt;Ondat Pod placement&lt;/h2&gt;
&lt;p&gt;Ondat must run on all nodes that will contribute storage capacity to the
cluster or that will host Pods which use Ondat volumes. For production
environments, it is recommended to avoid placing Ondat Pods on Master
nodes.&lt;/p&gt;
&lt;p&gt;Ondat is deployed with a DaemonSet controller, and therefore tolerates the
standard unschedulable (:NoSchedule) action. If that is the only taint placed
on master or cordoned nodes Ondat pods might start on them (see the
Kubernetes
&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/&#34;&gt;docs&lt;/a&gt;
for more details). To avoid scheduling Ondat pods on master nodes, you can
add an arbitrary taint to them for which the Ondat DaemonSet won&amp;rsquo;t have a
toleration.&lt;/p&gt;
&lt;h2 id=&#34;dedicated-instance-groups&#34;&gt;Dedicated instance groups&lt;/h2&gt;
&lt;p&gt;Cloud environments give users the ability to quickly scale the number of nodes
in a cluster in response to their needs. Because of the ephemeral nature of the
cloud, Ondat recommends setting conservative downscaling policies.&lt;/p&gt;
&lt;p&gt;For production clusters, it recommended to use dedicated instance groups for
Stateful applications that allow the user to set different scaling policies and
define Ondat pools based on node selectors to collocate volumes.&lt;/p&gt;
&lt;p&gt;Losing a few nodes at the same time could cause the loss of data even when
volume replicas are being used.&lt;/p&gt;
&lt;h2 id=&#34;port-blocking&#34;&gt;Port blocking&lt;/h2&gt;
&lt;p&gt;Ondat exposes ports to operate. It is recommended that the &lt;a href=&#34;/docs/prerequisites/firewalls&#34;&gt;ports&lt;/a&gt; are not accessible from outside
the scope of your cluster.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Max AIO</title>
      <link>/docs/prerequisites/max-aio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/max-aio/</guid>
      <description>
        
        
        &lt;p&gt;As part of the dataplane operation, Ondat uses Linux AIO (Asynchronous
Input Output) contexts to serve I/O requests without blocking. Ondat
requires 4 AIO contexts per deployment (i.e. an Ondat volume deployment,
whether master or replica).&lt;/p&gt;
&lt;h2 id=&#34;max-aio-prerequisite&#34;&gt;Max AIO prerequisite&lt;/h2&gt;
&lt;p&gt;By default there is a maximum number of AIO contexts that can be allocated at
once.&lt;/p&gt;
&lt;p&gt;The current and maximum number of AIO requests is visible in the virtual
files &lt;code&gt;/proc/sys/fs/aio-nr&lt;/code&gt; and &lt;code&gt;/proc/sys/fs/aio-max-nr&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The default context limit has been set at 2^16 or 65536. This figure may vary
so do check your &lt;code&gt;/proc/sys/fs/aio-max-nr&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;aio-nr&lt;/code&gt; reaches &lt;code&gt;aio-max-nr&lt;/code&gt; the &lt;code&gt;io_setup&lt;/code&gt; syscall will fail with
EAGAIN. For more information see the Linux kernel docs
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/sysctl/fs.txt&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;why-is-this-relevant&#34;&gt;Why is this relevant?&lt;/h2&gt;
&lt;p&gt;As Ondat requires 4 AIO contexts per deployed volume, there is a limit to
the number of volumes that can be deployed per node. Trying to provision
additional deployments once the &lt;code&gt;aio-max-nr&lt;/code&gt; has been reached will fail as the
kernel will be unable to create enough new AIO contexts.&lt;/p&gt;
&lt;h2 id=&#34;increasing-your-aio-context-cap&#34;&gt;Increasing your AIO context cap&lt;/h2&gt;
&lt;p&gt;If your nodes &lt;code&gt;aio-max-nr&lt;/code&gt; is set too low you can either provision additional
nodes to reduce the number of deployments per node, or increase the &lt;code&gt;aio-max-nr&lt;/code&gt;
kernel parameter.&lt;/p&gt;
&lt;p&gt;You can do this by editing your &lt;code&gt;/etc/sysctl.conf&lt;/code&gt; file with the following
example line:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;fs.aio-max-nr &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1048576&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To activate the new settings, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sysctl -p /etc/sysctl.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
  </channel>
</rss>
