[{"body":"To install the operator follow the installation page for your orchestrator.\n Kubernetes Rancher OpenShift  ","excerpt":"To install the operator follow the installation page for your orchestrator.\n Kubernetes Rancher ‚Ä¶","ref":"/docs/reference/operator/install/","title":"Install"},{"body":"What is Ondat So you run workloads, either in-house developed or using Consumer Off The Shelf (COTS) platforms. You also recognise that operationally, you want to run them on Kubernetes as my ‚Äúcloud operating system‚Äù of choice. This gives you freedom to deploy and operate your workloads anywhere Kubernetes runs based on business criteria such as cost, locality, compliance needs and risk appetite.\nYou have been running stateless workloads in such a way for years, now your developers/suppliers have decided to move the application state (database/message queue/ flat files/ key-value store‚Ä¶) into your Kubernetes clusters as well. They are proposing to do this to reduce operational toil as they can leverage ‚ÄúOperators‚Äù to deliver domain specific knowledge in the running of these components.\nState now matters in your Kubernetes cluster, but hang on, how do we deliver the same operational paradigm that we are used to for these stateful workloads?\nThe answer is Ondat.\nIn the first wave of Kubernetes adoption, the focus was on stateless workloads. These workloads did not care if a pod or node was killed. They can just move to another node in the cluster and restart with minimal fuss. What happens when we suddenly have data and state, well the obvious answer is that you need network attached storage which can be re-pointed to react in the same way as we have come to expect as for our stateless workloads.\nThis is Ondat, delivering a data mesh for block storage using Kubernetes native constructs to power stateful applications. Ondat couples any storage to any Kubernetes cluster and, with the simple application of Kubernetes labels, also delivers advanced features such as: Encryption at a per Kubernetes volume level, allowing for safe multi-tenant operations. Topology aware placement of volumes to align with your availability zones and physical architecture to ensure your data compliance. Replication of data at a Kubernetes Volume making sure that the data you need is protected to deliver the business resilience required.\nUsing Ondat, any storage on any node in your Kubernetes cluster can be delivered to the applications that need it anywhere in the cluster. Intelligent placement makes sure that your workload is always optimised, and by deploying the Ondat data mesh your Kubernetes platforms are responsive to your business applications with compute and storage able to grow independently as your workloads change.\nThis is Ondat, a data mesh to deliver the reality of stateful workloads to any Kubernetes platform, delivering the next generation of stateful workloads to your customers.\n","excerpt":"What is Ondat So you run workloads, either in-house developed or using Consumer Off The Shelf (COTS) ‚Ä¶","ref":"/docs/introduction/","title":"Introduction"},{"body":"Overview This guide will demonstrate how to install Ondat onto a Kubernetes cluster using the Ondat kubectl plugin or Helm Chart\nFor users who are looking to deploy Ondat onto a managed/specific Kubernetes distribution such AKS, EKS, GKE, RKE or DOKS, a recommendation would be to review the Install section and choose the appropriate installation guide for your Kubernetes distribution.\nPrerequisites 1 - Cluster and Node Prerequisites The minimum cluster requirements for a non-production installation of ondat are as follows:\n Linux with a 64-bit architecture 2 vCPU and 4GB of RAM per node. 3 worker nodes in the cluster and sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster Make sure the OS on your nodes are compatible with Ondat. See the Ondat Prerequisites for all supported linux distributions.  For a comprehensive list of prerequisites and how to build a production installation of Ondat please refer to Ondat Prerequisites\n2 - Client Tools Prerequisites The following CLI utilities are installed on your local machine and available in your $PATH:\n kubectl  Ondat can be installed either via Helm Chart or using our command-line tool. Depending on which installation method you choose you will require either:\n kubectl-storageos CLI Helm 3 CLI  3 - Installing a Local Path Provisioner Depending on the kubernetes distro you are using there may not be any CSI driver deployed. Run the following commands against the cluster to deploy a Local Path Provisioner and make it the default storageclass to provide local storage for Ondat\u0026rsquo;s embedded etcd cluster operator deployment.\nkubectl apply --filename=\u0026#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.22/deploy/local-path-storage.yaml\u0026#34; kubectl patch storageclass local-path -p \u0026#39;{\u0026#34;metadata\u0026#34;: {\u0026#34;annotations\u0026#34;:{\u0026#34;storageclass.kubernetes.io/is-default-class\u0026#34;:\u0026#34;true\u0026#34;}}}\u0026#39; Verify that the Local Path Provisioner was successfully deployed and ensure that that the deployment is in a RUNNING status, run the following kubectl commands.\nkubectl get pod --namespace=local-path-storage kubectl get storageclass Installation of Ondat Step 1 - Adding a Cluster The Ondat Portal is how you can license and get the commands for installing Ondat\n Either login or create an account on the Ondat Portal Choose the \u0026lsquo;Install Ondat on your cluster\u0026rsquo; or \u0026lsquo;Add cluster\u0026rsquo; options in the UI Add a Name for your cluster and where it is going to be located. This will allow you to view the same prerequisites as are listed above  Step 2 - Choosing the Installation Method You can use either the kubectl-storageos CLI or Helm 3 CLI to install Ondat onto your cluster. The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below.\nStep 3a - Installing via Helm The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.\nThe first two lines of the command adds the Ondat Helm repository and ensures a updated local cache. The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 3b - Installing via kubectl-storageos plugin The Ondat Portal UI will display the following cmd that can be used to install Ondat using the kubectl-storageos plugin. The command created will be unique for you and the screenshot below is just for reference.\nThe command that is provided by the Portal is unique to you and uses the kubectl-storageos plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 4 - Verifying Ondat Installation Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status)\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd kubectl get storageclasses | grep \u0026#34;storageos\u0026#34; Once all the components are up and running the output should look like this:\nStep 5 - Applying a Licence to the Cluster Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see here.\nTo licence your cluster with the community edition:\n On the Clusters page select \u0026lsquo;View Details\u0026rsquo; Click on \u0026lsquo;Change Licence\u0026rsquo; In the following pop-up select the \u0026lsquo;Community Licence\u0026rsquo; option then click \u0026lsquo;Generate\u0026rsquo;  This process generates a licence and installs it for you. Now you are good to go!\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a Kubernetes cluster using the Ondat ‚Ä¶","ref":"/docs/install/kubernetes/","title":"Kubernetes"},{"body":"Ondat namespaces are an identical concept to Kubernetes namespaces. They are intended to allow an Ondat cluster to be used by multiple teams across multiple projects.\nIt is not necessary to create Ondat namespaces manually, as Ondat maps Kubernetes namespaces on a one-to-one basis when PersistentVolumeClaims using the Ondat StorageClass are created.\nüí° Access to Namespaces is controlled through user or group level policies.\n","excerpt":"Ondat namespaces are an identical concept to Kubernetes namespaces. They are intended to allow an ‚Ä¶","ref":"/docs/reference/namespaces/","title":"Namespaces"},{"body":"Overview Ondat makes it possible for cluster administrators to design and implement different cluster topologies, depending on types of workloads, use cases, priorities and needs. The topology approaches recommended below are idealised representations of possible Ondat clusters and can be mixed, modified and changed at execution time.\nOndat performs file Input/Output (I/O) operations over the network, which is how the platform ensures that data is always available throughout your cluster. This also affords cluster administrators certain possibilities of organising their clusters in ways explained below.\nHyper-converged Cluster Topology  The hyper-converged cluster topology model leverages the available block storage attached to all the worker nodes in a Kubernetes cluster, creating a single storage pool that stores and present data for stateful workloads deployed and running.  This cluster topology gives the best flexibility to Ondat and Kubernetes schedulers, and provides maximum choice for optimal pod placement when pods are being assigned to nodes in a cluster.   No matter how or where workloads are deployed on worker nodes, Ondat will ensure that the data from workloads is stored, persistent and always accessible. New Ondat deployments will place workloads locally where possible using this hyper-converged cluster topology out of the box.  Centralised Cluster Topology  The centralised cluster topology model leverages the available block storage attached to only a subset of worker nodes (creating a dedicated, storage-optimised node pool) in a Kubernetes cluster, whilst the rest of the worker nodes are dedicated to running general and compute-intensive workloads,  Deployed workloads in centralised cluster that require data persistency will access a dedicated storage pool that is located on the declared subset of worker nodes.   This cluster topology can be beneficial if, for example, cluster administers want to take advantage and effectively utilise high performance-optimised hardware components of a particular set of worker nodes for different types of workloads being deployed. The cluster topology can also aid in avoiding downtime issues that can arise from unaccounted resource/capacity planning and allocation for workloads, since storage-optimised nodes and compute-optimised workloads are compartmentalised. In addition, another suitable use case for this topology is for elastic worker node fleets with burst-able workloads. A fleet can be quickly expanded with new worker nodes for compute-intensive workloads on demand, whilst maintaining a centralised data storage pool that is not impacted by rapid auto cluster scaling. To configure this cluster topology for a new Ondat deployment, cluster administrators would need to apply an Ondat node label called storageos.com/computeonly to nodes, which would inform Ondat that it should not use the nodes to join a storage pool.  Review the Centralised Cluster Topology operations page for more information on how to use this topology model for your clusters.    ","excerpt":"Overview Ondat makes it possible for cluster administrators to design and implement different ‚Ä¶","ref":"/docs/concepts/cluster-topologies/","title":"Ondat Cluster Topologies"},{"body":"Overview  The Ondat CLI is a utility tool that is used to manage and configure Ondat resources and conduct Day-2 storage operations. The Ondat CLI is also useful for providing useful information on the state of an Ondat cluster and troubleshooting issues.  The project repository is open source and can be located on GitHub.    Prerequisites  Ensure that you have successfully installed Ondat into your Kubernetes or Openshift cluster.  How To Install The Ondat CLI Option 1 - Run The Ondat CLI As A Deployment (Recommended)  Run the following command below against your Ondat cluster which will deploy the Ondat CLI using a Kubernetes deployment.  # Create the deployment for the Ondat CLI. kubectl create --filename -\u0026lt;\u0026lt;EOF apiVersion: apps/v1 kind: Deployment metadata: labels: app: storageos-cli app.kubernetes.io/component: storageos-cli app.kubernetes.io/part-of: storageos kind: storageos name: storageos-cli namespace: storageos spec: replicas: 1 selector: matchLabels: app: storageos-cli template: metadata: labels: app: storageos-cli spec: containers: - command: - /bin/sh - -c - while true; do sleep 3600; done env: - name: STORAGEOS_USERNAME valueFrom: secretKeyRef: name: storageos-api key: username optional: false - name: STORAGEOS_PASSWORD valueFrom: secretKeyRef: name: storageos-api key: password optional: false - name: STORAGEOS_ENDPOINTS value: storageos:5705 image: storageos/cli:v2.8.3 imagePullPolicy: Always name: cli ports: - containerPort: 5705 resources: limits: cpu: 100m memory: 128Mi requests: cpu: 50m memory: 32Mi securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true EOF Execute Commands Through The Ondat CLI Deployment  Once the Ondat CLI deployment resource has been successfully created, get the pod name and take note of it for later reference.  # Get the pod name of the Ondat CLI utility. kubectl get pods --namespace storageos | grep \u0026#34;storageos-cli\u0026#34; storageos-cli-75874cd77f-b5dgp 1/1 Running 0 35m  You can then use kubectl-exec to run Ondat CLI commands in the container as demonstrated below;  kubectl --namespace=storageos exec storageos-cli-75874cd77f-b5dgp -- storageos version  üí° Deploying the Ondat CLI as a deployment is the recommended method as the Ondat support bundle generation tool can automatically detect a deployment called cli and warn you if you do not have the CLI installed.\n Option 2 - Run The Ondat CLI On A Workstation  To be able to interact and manage your Ondat cluster, ensure that you define and export the STORAGEOS_USERNAME, STORAGEOS_PASSWORD and STORAGEOS_ENDPOINTS environment variables that will be used to manage your Ondat cluster through the CLI.  export STORAGEOS_USERNAME=\u0026#34;storageos\u0026#34; export STORAGEOS_PASSWORD=\u0026#34;storageos\u0026#34; # Enter the endpoint address of Ondat\u0026#39;s REST API to access the cluster through the CLI. # When using \u0026#34;kubectl port-forward\u0026#34; to access the cluster, change the endpoint to \u0026#34;localhost:5705\u0026#34;. export STORAGEOS_ENDPOINTS=\u0026#34;storageos.storageos.svc:5705\u0026#34;  Once you have defined the environment variables above, install the Ondat CLI on one of the supported operating systems listed below;  Linux curl --silent --show-error --location --output storageos \\  https://github.com/storageos/go-cli/releases/download/v2.8.3/storageos_linux_amd64 \\  \u0026amp;\u0026amp; chmod +x storageos \\  \u0026amp;\u0026amp; sudo mv storageos /usr/local/bin/ \\  \u0026amp;\u0026amp; echo \u0026#34;CLI version installed:\u0026#34; \\  \u0026amp;\u0026amp; storageos version macOS (Darwin) curl --silent --show-error --location --output storageos \\  https://github.com/storageos/go-cli/releases/download/v2.8.3/storageos_darwin_amd64 \\  \u0026amp;\u0026amp; chmod +x storageos \\  \u0026amp;\u0026amp; sudo mv storageos /usr/local/bin/ \\  \u0026amp;\u0026amp; echo \u0026#34;CLI version installed:\u0026#34; \\  \u0026amp;\u0026amp; storageos version Windows # PowerShell Invoke-WebRequest https://github.com/storageos/go-cli/releases/download/v2.8.3/storageos_windows_amd64.exe -OutFile storageos.exe ` ; Write-Host \u0026#34;Plugin version installed:\u0026#34; ` ; .\\storageos.exe version Execute Commands Through The Ondat CLI Binary  Once you have successfully installed the Ondat CLI, you can leverage kubectl port-forward to establish a connection with your Ondat cluster in order to be able to execute commands.  # Change the \u0026#34;STORAGEOS_ENDPOINTS\u0026#34; to point to \u0026#34;localhost:5705\u0026#34;. export STORAGEOS_ENDPOINTS=\u0026#34;localhost:5705\u0026#34; # Use port forwarding to access the Ondat REST API locally. kubectl port-forward service/storageos 5705 --namespace=storageos # In a new shell, execute Ondat CLI commands to confirm that you can now interact with your Ondat cluster. storageos version Usage  Get the version of the CLI utility installed;  storageos version  Get more information on the available commands in the CLI utility;  storageos help Storage for Cloud Native Applications. By using this product, you are agreeing to the terms of the the StorageOS Ltd. End User Subscription Agreement (EUSA) found at: https://storageos.com/legal/#eusa To be notified about stable releases and latest features, sign up at https://my.storageos.com. Usage: storageos [command] Available Commands: apply Make changes to existing resources attach Attach a volume to a node cordon Marks a node as cordoned create Create new resources delete Delete resources in the cluster describe Fetch extended details for resources detach Detach a volume from its current location get Fetch basic details for resources help Help about any command nfs Make changes and attach nfs volumes uncordon Marks a node as uncordoned update Make changes to existing resources version View version information for the StorageOS CLI Flags: --cache-dir string set the directory used by the StorageOS CLI to cache data that can be used for future commands (default \u0026#34;/Users/rodney/Library/Caches/storageos\u0026#34;) -c, --config string specifies the config file path (default \u0026#34;/Users/rodney/Library/Application Support/storageos/config.yaml\u0026#34;) --endpoints stringArray set the list of endpoints which are used when connecting to the StorageOS API (default [http://localhost:5705]) -h, --help help for storageos -n, --namespace string specifies the namespace to operate within for commands that require one (default \u0026#34;default\u0026#34;) --no-auth-cache disable the CLI\u0026#39;s caching of authentication sessions -o, --output string specifies the output format (one of [json yaml text]) (default \u0026#34;text\u0026#34;) --password string set the StorageOS account password to authenticate with (default \u0026#34;storageos\u0026#34;) --timeout duration set the timeout duration to use for execution of the command (default 15s) --use-ids specify existing StorageOS resources by their unique identifiers instead of by their names --username string set the StorageOS account username to authenticate as (default \u0026#34;storageos\u0026#34;) Additional help topics: storageos config-file View help information for using a configuration file storageos env View documentation for configuration settings which can be set in the environment storageos exitcodes View documentation for the exit codes used by the StorageOS CLI Use \u0026#34;storageos [command] --help\u0026#34; for more information about a command. ","excerpt":"Overview  The Ondat CLI is a utility tool that is used to manage and configure Ondat resources and ‚Ä¶","ref":"/docs/reference/cli/","title":"Ondat Command Line Interface (CLI) Utility"},{"body":"Overview Ondat is a software-defined storage platform for running stateful applications in Kubernetes.\nFundamentally, Ondat uses the storage attached to the nodes in the Ondat cluster to create and present virtual volumes into containers.\n Space on the host is consumed from the mount point /var/lib/storageos/data - so it is recommended that disk devices are used exclusively for Ondat, as described in the Managing Host Storage operations page.  Ondat is agnostic to the underlying storage and runs equally well on bare metal, in virtual machines or on cloud providers.\nRead about the cloud native storage principles behind Ondat.\nKubernetes-native Ondat Components Ondat is architected as a series of containers that fulfil separate, discrete functions.\n Below is a list of core Ondat components with a description for each components responsibilities \u0026amp; tasks:  Ondat Operator The Ondat Operator is responsible for the creation and maintenance of the Ondat cluster.\n This operator is primarily responsible for ensuring that all the relevant applications are running in your cluster.  Ondat API Manager The Ondat API Manager acts as a middle-man between various APIs. It has all the capabilities of a Kubernetes operator and is also able to communicate with the Ondat control plane API.\n This application handles typical operator tasks like labelling or removing nodes from Ondat when removed from the Kubernetes. It is continually monitoring the state of the cluster and moving it towards the desired state when necessary.  Ondat Data Plane The Ondat Data Plane is responsible for all I/O operations path related tasks;\n Reading, Writing, Compression, Caching.  Ondat Control Plane The Ondat Control Plane is responsible for monitoring and maintaining the state of volumes and nodes in the cluster.\n The Control Plane and the Data Plane run together in a single container, managed by a daemonset. The Control Plane works with a dedicated etcd instance to maintain state consensus in your cluster.  Ondat Scheduler The Ondat Scheduler is responsible for scheduling applications on the same node as an application\u0026rsquo;s volumes.\n Ondat uses a custom Kubernetes scheduler to handle pod placement, ensuring that volumes are deployed on the same nodes as the relevant workloads as often as possible.  Ondat CSI Helper The CSI Helper is responsible for registering Ondat with Kubernetes as a CSI driver.\n It is necessary because the internal persistent volume controller running in Kubernetes controller-manager does not have any direct interfaces to CSI drivers. It monitors PVC objects created by users and creates/deletes volumes for them.  Ondat Node Guard The Ondat Node Guard is a key component of the Ondat Rolling Upgrade Protection for Orchestrators feature. It blocks certain nodes from being upgraded or drained thus avoiding data loss in the cluster.\n The Node Guard will detect if a volume is reconciling (for example, one that does not have enough synced replicas), at which point a node manager pod on the same node as the reconciling volume\u0026rsquo;s master and replicas become unready. Ondat uses a PodDisruptionBudget (PDB) to stop more than 1 node manager pod being unavailable at any point in time. This prevents the rolling upgrade from continuing until the PDB is satisfied and all volumes have fully reconciled. If the PDB is set to 1 and a Control Plane volume on a node is not ready for a long period of time, this will stop the upgrade process. The api-managercomponent will be able to dynamically set the PDB value if it can determine the health of the volume. If the api-managercomponent knows that a volume will not be ready, it can increase the PDB maxUnavailable value, allowing the upgrade to continue. The Node Guard container will log when it is available to upgrade, it will also log the reason if upgrade is not possible.   ‚ö†Ô∏è The Node Guard container only monitors volumes that host a deployment on its node (for example, it doesn‚Äôt care if a volume is unhealthy if the node it\u0026rsquo;s running on hosts none of the volumes primary and replicas)\n  ‚ö†Ô∏è There is some latency between a volume becoming unhealthy and the Node Guard noticing, due to the polling nature of both the api-managercomponent volume sync Kubernetes readiness endpoints)\n Ondat Node Manager The Ondat Node Manager is an out-of-band pod used for node management. It runs on all nodes that run the StorageOS node container and is a separate pod so that it can be restarted independently of the node container.\nPutting It All Together Ondat is deployed by the Ondat Operator. In Kubernetes, the Ondat Control Plane and Data Plane are deployed in a single pod managed by a daemonset.\n This daemonset runs on every node in the cluster that will consume or present storage.  The Ondat Scheduler, CSI Helper, Operator and API Manager run as separate pods and are controlled as deployments.\nOndat is designed to feel familiar to Kubernetes users. Storage is managed through standard StorageClasses , PersistentVolumeClaims, and Ondat features are controlled by Kubernetes labels and selectors, prefixed with storageos.com/.\n By default, volumes are cached to improve read performance and compressed to reduce network traffic. Any pod may mount an Ondat virtual volume from any node that is also running Ondat, regardless of whether the pod and volume are collocated on the same node. Therefore, applications may be started or restarted on any node and access volumes transparently.  ","excerpt":"Overview Ondat is a software-defined storage platform for running stateful applications in ‚Ä¶","ref":"/docs/concepts/components/","title":"Ondat Components"},{"body":"Overview  üí° This feature is disabled by default in release v2.2.0 or greater.\n Data Compression Ondat compression is handled on a per volume basis and is disabled in v2.2.0, as performance is generally increased when compression is disabled due to block alignment.\n This means that there is a trade off between volume performance and the space the volume occupies on the backend device.  Ondat utilises the LZ4 (compression algorithm) when writing to the backend store and when compressing Ondat replication traffic before it is sent across the network.\nOndat detects whether a block can be compressed or not by creating a heuristic that predicts the size of a compressed block.\n If the heuristic indicates that the compressed block is likely to be larger than the original block then the uncompressed block is stored. Block size increases post-compression if the compression dictionary is added to a block that cannot be compressed. By verifying whether blocks can be compressed, disk efficiency is increased and CPU resources are not wasted on attempts to compress incompressible blocks. Ondat\u0026rsquo;s patented on-disk format is used to tell whether individual blocks are compressed without overhead. As such volume compression can be dynamically enabled/disabled even while a volume is in use.  How To Enable Ondat Compression? Compression can be enabled by setting the Ondat Feature Label \u0026raquo; storageos.com/nocompress=false on a volume at volume creation time.\n For more information on how to enable compression, review the Data Compression operations page.  Ondat Compression \u0026amp; Data Encryption When Ondat compression and data encryption are both enabled for a volume, blocks are compressed first and then encrypted.\n","excerpt":"Overview  üí° This feature is disabled by default in release v2.2.0 or greater.\n Data Compression ‚Ä¶","ref":"/docs/concepts/compression/","title":"Ondat Compression"},{"body":"Overview  üí° This feature is available in release v2.4.0 or greater.\n  üí° End users can also leverage Trousseau with Ondat\u0026rsquo;s volume encryption feature. Trousseau is an open source KMS plugin project that based on Kubernetes KMS provider design. The project allows users to store and access your secrets the Kubernetes native way with any external KMS. Trousseau\u0026rsquo;s repository can be located on GitHub.\n Data Encryption Ondat supports data encryption-at-rest and data encryption-in-transit.\n Data encryption-in-transit is data as it is travelling between nodes. It is encrypted by default with Mutual Authentication (mTLS). Data encryption-at-rest is the data stored in your volumes as blob files. Encryption of these blob files is optional and can be enabled by adding a label to your volume definitions before they are provisioned .  For more information on how to enable data encryption for Ondat volumes, review the Ondat Data Encryption operations page.\nHow Are Ondat Volumes Encrypted? Volumes are encrypted using AES-256 in the XTS-AES mode with 512-bit keys, as specified by IEEE Standard 1619-2007.\n There is a non-zero performance impact of using encrypted volumes. A 10-25% cost in read/write throughput can be expected from XTS-AES, dependent on workload. Thin provisioning still applies to Ondat encrypted volumes.  How Are Ondat Encryption Keys Generated? On PVC creation, if data encryption-at-rest is enabled, Ondat will automatically generate up to two keys as Kubernetes secrets. Both keys are stored in the same namespace as the PVC.\n Firstly, if it doesn\u0026rsquo;t already exist, a namespace key is generated. It is always named storageos-namespace-key and only one exists per namespace. Secondly a volume key is created for each encrypted volume. It has a name in the format storageos-volume-key-\u0026lt;random-id\u0026gt;, with no connection to the name of the volume.  The volume it is associated with can be determined by looking at the storageos.com/pvc label on the secret. The storageos.com/encryption-secret-name and storageos.com/encryption-secret-namespace annotations are added to the PVC by an admission controller to map the PVC back to its secret.   The encryption key is passed to Ondat as part of the CSI volume creation request and is used to encrypt the volume.  How Are Encryption Keys Used? The volume specific secret is needed whenever a volume is attached to a node for use by a pod.\n When this happens, the Ondat node container\u0026rsquo;s ServiceAccount reads the secret and passes it to the Ondat Control Plane. A volume missing its key or with a malformed key will be unable to attach. The key is stored in memory by Ondat only on the node that the volume is being used on. As a result, encryption and decryption are performed where the data is consumed, rather than where it is stored.  Because of this, the use of encrypted volumes is transparent to the user. There is a complete integration between Kubernetes applications and Ondat volume encryption.\nEncryption Key Management Best Practices Ondat saves volume encryption keys in Kubernetes secrets, thus - backups are imperative in case Kubernetes etcd backing store is lost or damaged.\n ‚ö†Ô∏è Ondat has no ability to decrypt a volume whose encryption keys have been lost.\n Secrets in Kubernetes are not encrypted by default, they are stored in Kubernetes etcd backing store in simple Base64 encoding.\n As Ondat encryption keys are stored as Kubernetes secrets, this means that anyone with access to Kubernetes etcd backing store can read encryption keys and decrypt volumes, unless the cluster is using an external secrets store for key management. For more information on how to enable and configure encryption of Kubernetes secrets data at rest, review the official Kubernetes documentation here. Secrets are not garbage-collected by Ondat, therefore - to clean up completely upon deletion of a volume it is necessary to also delete that volume\u0026rsquo;s secret. There is no benefit to doing this, however.  Managing Keys With A Key Management Service (KMS) Provider As mentioned in the section above, Ondat volume encryption keys are stored within Kubernetes etcd backing store as Kubernetes secrets. Whilst Kubernetes etcd and secrets can also be encrypted, many security-focused organisations choose to use an external Key Management Service (KMS) provider for data encryption.\nTo address this from a Kubernetes limitations perspective and provide an agnostic solution, Ondat\u0026rsquo;s encryption design allows the user to leverage any supported Kubernetes KMS plugin to envelop the secrets into a KMS provider encryption scheme.\n Ondat enables end users to transparently integrate any supported KMS plugin with Ondat encryption key management using the standard Kubernetes API and Kubernetes KMS provider framework. The architecture diagram below provides a high level overview of the process.   The KMS plugin is deployed within the Kubernetes cluster. The KMS plugin is configured to act as a broker between the Kubernetes API server and the KMS server API endpoint. At volume creation, Ondat will create a Kubernetes secret using Kubernetes API calls The KMS plugin will handle the Kubernetes API Secret creation call and interface to the KMS server instance. The KMS server will return the secret using its encryption envelop scheme. The KMS plugin will store the encrypted secret within Kubernetes etcd backing store.  ","excerpt":"Overview  üí° This feature is available in release v2.4.0 or greater.\n  üí° End users can also leverage ‚Ä¶","ref":"/docs/concepts/encryption/","title":"Ondat Data Encryption"},{"body":"Overview Ondat Feature labels are Kubernetes Labels which provide a powerful and flexible way to control storage features.\n Applying specific feature labels triggers compression, replication, data encryption and other storage features. In order to use feature labels, end users are required to explicitly enable the features they want to use in their cluster.  Types Of Ondat Feature Labels Ondat Volume Labels Below are the list of available feature labels that can be used to define Volume resources and StorageClass resources in an Ondat cluster.\n üí° The encryption and compression labels can only applied at provisioning time, they can\u0026rsquo;t be changed during execution.\n    Feature Name Label Reference Values Feature Description     Compression storageos.com/nocompress true / false Enables or disables compression of data-at-rest and data-in-transit. Compression is not enabled by default to maximise performance.   Encryption storageos.com/encryption true / false Encrypts the contents of the volume. For each volume, a key is automatically generated, stored, and linked with the PVC.   Failure Mode storageos.com/failure-mode hard, soft, alwayson, or threshold integers starting from 0 to 5 Sets the failure mode for a volume, either explicitly using a failure mode or implicitly using a replica threshold. The default failure mode is set to hard.   Replication storageos.com/replicas integers starting from 0 to 5 Sets the number of replicas, for example full copies of the data across nodes. Typically 1 or 2 replicas is sufficient (2 or 3 instances of the data). Latency implications need to be assessed when using more than 2 replicas.   Topology-Aware Placement storageos.com/topology-aware true / false Enables or disables Ondat Topology-Aware Placement.   Topology Domain Key storageos.com/topology-key custom region, read as a string Define the failure domain for the node by using a custom key. If you don\u0026rsquo;t define a custom key, the label defaults to the topology.kubernetes.io/zone value.   Squash Mode storageos.com/nfs-squash root, rootuid, all, none Define the squash mode that will be used with Ondat Files - ReadWriteMany (RWX) volumes to set the file ownership in the share. The default squash mode is set to all.    Ondat Node Labels When Ondat is run within Kubernetes, the Ondat API Manager syncs any Kubernetes node labels to the corresponding Ondat node. The Kubernetes node labels act as the \u0026ldquo;source of truth\u0026rdquo;, so labels should be applied to the Kubernetes nodes rather than to Ondat nodes. This is because the Kubernetes node labels overwrite the Ondat node labels on sync.\n Below are the list of available feature labels that can be used to define Kubernetes Nodes in an Ondat Cluster.     Feature Name Label Reference Values Feature Description     Compute-only Nodes storageos.com/computeonly true / false Specifies whether a node should be computeonly where it only acts as a client and does not host volume data locally, otherwise the node is hyper-converged (the default), where the node can operate in both client and server modes.    Ondat Pod Labels Below are the list of available feature labels that can be used to define Kubernetes Pods in an Ondat Cluster.\n üí° For a pod to be fenced by Ondat, a recommendation will be to review the the Ondat Fencing operations page for more information.\n    Feature Name Label Reference Values Feature Description     Pod Fencing storageos.com/fenced true / false Targets a pod to be fenced in case of node failure. The default value is false    How To Use Ondat Feature Labels? For more information about how to enable specific Ondat features, review the Ondat Feature Labels operations pages listed below;\n How To Create Custom Storage Classes. How To Setup A Centralised Cluster Topology. How To Use Volume Replication. How To Use Ondat Files (ReadWriteMany - RWX Volumes). How To Use Failure Modes. How To Enable Fencing. How To Enable Topology-Aware Placement (TAP). How To Enable Data Encryption. How To Enable Data Compression.  ","excerpt":"Overview Ondat Feature labels are Kubernetes Labels which provide a powerful and flexible way to ‚Ä¶","ref":"/docs/concepts/labels/","title":"Ondat Feature Labels"},{"body":"Overview  üí° This feature is available in release v2.4.0 or greater.\n What Is Ondat Fencing? In order to understand what Ondat Fencing for Kubernetes is and when it is needed, it is required to first understand the behaviour of Kubernetes StatefulSets.\nStatefulSets are the de facto Kubernetes controller to use for stateful applications. The StatefulSet controller offers guarantees around pod uniqueness, sticky identities and the persistence of PVCs beyond the lifetime of their pods.\n As such, StatefulSets have different characteristics and provide different guarantees than Kubernetes Deployments.  Deployments guarantee the amount of healthy replicas by reconciling towards the deployment desired state. Attempts to align the number of healthy pods with the deployment\u0026rsquo;s desired state happen as fast as possible by aggressively initialising and terminating pods.\n If one pod is terminating, another will be automatically scheduled to start even if the first pod is not yet completely terminated. Stateless applications benefit from this behaviour as one pod executes the same work as any other in the deployment.  StatefulSets, on the other hand, guarantee that every pod scheduled has a unique identity, which is to say that only a single copy of a pod is running in the cluster at any one time.\n Whenever scheduling decisions are made, the StatefulSet controller ensures that only one copy of this pod is running at any time. If a pod is deleted, a new pod will not be scheduled until the first pod is fully terminated. This is an important guarantee as file systems need to be unmounted before they can be remounted in a new pod. Any ReadWriteOnce (RWO) PVC defining a device requires this behaviour to ensure the consistency of the data and thus the PVC.  To protect data integrity, Kubernetes guarantees that there will never be more than one instance of a StatefulSet pod running at a time. It assumes that when a node is determined to be offline it may still be running the workload but partitioned from the network. Since Kubernetes is unable to verify that the pod has been stopped it errors on the side of caution and does not allow a replacement to start on another node.\nKubernetes does reschedule pods from some controllers when nodes become unavailable. The default behaviour is that when a node becomes unavailable its status becomes Unknown and after the pod-eviction-timeout has passed pods are scheduled for deletion. By default, the pod-eviction-timeout is 300 seconds.\n For this reason, Kubernetes requires manual intervention to initiate timely failover of a StatefulSet pod. The Ondat Fencing Controller gives the capability to enable fast failover for workloads when a node goes offline.  For more information on the rationale behind the design of StatefulSets, review the Kubernetes design proposal archive for Pod Safety, Consistency Guarantees, and Storage Implications.\nOndat Fencing Controller  üí° The Ondat Fencing Controller is part of the Ondat API Manager which is deployed in high availability mode when Ondat is installed.\n  üí° High Availability for StatefulSet applications can be achieved with the Ondat Fencing feature.\n Since Ondat is able to determine when a node is no longer able to access a volume and has protections in place to ensure that a partitioned or formerly partitioned node can stop writing data, it can work with Kubernetes to perform safe, fast failovers of pods, including those running in StatefulSets.\n When Ondat detects that a node has gone offline or become partitioned, it marks the node offline and performs volume failover operations.  The Ondat Fencing Controller watches for these node failures and determines if there are any pods assigned to the failed node with the label storageos.com/fenced=true, and if the pods have any PVCs backed by Ondat volumes.\n When a pod has Ondat volumes and if they are all healthy, the Ondat Fencing Controller deletes the pod to allow it to be rescheduled on another node. It also deletes the VolumeAttachment object for the corresponding volumes so that they can be immediately attached to the new node. No changes are made to pods that have Ondat volumes that are unhealthy. This is usually because a volume was configured to not have any replicas, and the node with the single copy of the data is offline. In this case it is better to wait for the node to recover.  Ondat Fencing works with both dynamically provisioned PVCs and PVCs referencing pre-provisioned volumes.\n In addition, the fencing feature is opt-in and pods must have the storageos.com/fenced=true label set, and be using at least one Ondat volume, to enable fast failover.  For more information about how to enable Ondat fencing, review the Ondat Fencing operations page.\n","excerpt":"Overview  üí° This feature is available in release v2.4.0 or greater.\n What Is Ondat Fencing? In order ‚Ä¶","ref":"/docs/concepts/fencing/","title":"Ondat Fencing"},{"body":"Overview  The Ondat kubectl plugin is a utility tool that accepts imperative and declarative modes which allows cluster administrators to seamlessly install, troubleshoot, upgrade or uninstall Ondat. The plugin can also be used to connect and manage Ondat clusters on the Ondat SaaS Platform.  The project repository is open source and can be located on GitHub.    Install The Ondat Kubectl Plugin Linux curl --silent --show-error --location --output kubectl-storageos.tar.gz \\  https://github.com/storageos/kubectl-storageos/releases/download/v1.3.1/kubectl-storageos_1.3.1_linux_amd64.tar.gz \\  \u0026amp;\u0026amp; tar --extract --file kubectl-storageos.tar.gz kubectl-storageos \\  \u0026amp;\u0026amp; chmod +x kubectl-storageos \\  \u0026amp;\u0026amp; sudo mv kubectl-storageos /usr/local/bin/ \\  \u0026amp;\u0026amp; rm kubectl-storageos.tar.gz \\  \u0026amp;\u0026amp; echo \u0026#34;Plugin version installed:\u0026#34; \\  \u0026amp;\u0026amp; kubectl-storageos version macOS (Darwin) curl --silent --show-error --location --output kubectl-storageos.tar.gz \\  https://github.com/storageos/kubectl-storageos/releases/download/v1.3.1/kubectl-storageos_1.3.1_darwin_amd64.tar.gz \\  \u0026amp;\u0026amp; tar --extract --verbose --file kubectl-storageos.tar.gz kubectl-storageos \\  \u0026amp;\u0026amp; chmod +x kubectl-storageos \\  \u0026amp;\u0026amp; sudo mv kubectl-storageos /usr/local/bin/ \\  \u0026amp;\u0026amp; rm kubectl-storageos.tar.gz \\  \u0026amp;\u0026amp; echo \u0026#34;Plugin version installed:\u0026#34; \\  \u0026amp;\u0026amp; kubectl-storageos version Windows # PowerShell Invoke-WebRequest https://github.com/storageos/kubectl-storageos/releases/download/v1.3.1/kubectl-storageos_1.3.1_windows_amd64.tar.gz -OutFile kubectl-storageos.tar.gz ` ; tar -xf kubectl-storageos.tar.gz kubectl-storageos.exe ` ; Remove-Item kubectl-storageos.tar.gz ` ; Write-Host \u0026#34;Plugin version installed:\u0026#34; ` ; .\\kubectl-storageos.exe version Others  For more information on different binaries, supported architectures and checksum file verification, see the full page of releases.  Usage  Get the version of the plugin installed;  kubectl storageos version  Get more information on the available commands in the plugin;  kubectl storageos help StorageOS kubectl plugin Usage: kubectl-storageos [flags] kubectl-storageos [command] Aliases: kubectl-storageos, kubectl storageos Available Commands: bundle Generate a support bundle completion Generate completion script disable-portal Disable StorageOS Portal Manager enable-portal Enable StorageOS Portal Manager help Help about any command install Install StorageOS and (optionally) ETCD install-portal Install StorageOS Portal Manager preflight Test a k8s cluster for StorageOS pre-requisites uninstall Uninstall StorageOS and (optionally) ETCD uninstall-portal Uninstall StorageOS Portal Manager upgrade Ugrade StorageOS version Show kubectl storageos version Flags: -h, --help help for kubectl-storageos Use \u0026quot;kubectl-storageos [command] --help\u0026quot; for more information about a command. ","excerpt":"Overview  The Ondat kubectl plugin is a utility tool that accepts imperative and declarative modes ‚Ä¶","ref":"/docs/reference/kubectl-plugin/","title":"Ondat Kubectl Plugin"},{"body":"Overview  üí° This feature is available in release v2.8.0 or greater.\n Prometheus Metrics for Ondat Volumes Following the exporter pattern, we maintain and distribute our own Prometheus exporter for monitoring and alerting of Ondat volumes. The metrics our exporter publishes include data on volume health, capacity and traffic.\n The Ondat metric exporter repository is open source and can be located on GitHub.  To get started with installing and configuring the exporter in your Ondat cluster, review the metric exporter\u0026rsquo;s operations page for more information.\n ‚ö†Ô∏è When setting up a ServiceMonitor resource, ensure that you create the rules in the same namespace as your Prometheus resource and have its selector field match the labels of the services exposing metrics - review the example ServiceMonitor resource manifest in the operations page for more information.\n Alerting Rules for Ondat Volumes Ondat also distributes example alert rules for Ondat metrics using Alertmanager.\n The alert rules manifest can be located in the alertmanager sub directory under the Ondat metric exporter repository.  Grafana Dashboard for Ondat Volumes In addition to the Ondat metric exporter project, we also distribute Grafana dashboards that allow end users to easily visualize and get insights into the status of Ondat volumes.\n The dashboards can be also located in the grafana sub directory under the Ondat metric exporter repository.  Contributing If end users have suggestions/ideas for metrics that they would like Ondat to gather by default or improve the Grafana dashboards and Alertmanager integration, contributions are welcome.\nYou can reach out to us on the Ondat community slack workspace or review the contributing guidelines in the Ondat metric exporter repository.\n","excerpt":"Overview  üí° This feature is available in release v2.8.0 or greater.\n Prometheus Metrics for Ondat ‚Ä¶","ref":"/docs/concepts/metric-exporter/","title":"Ondat Metric Exporter"},{"body":"Overview An Ondat node is any machine (virtual or physical) that is running the Ondat daemonset pod. A node must be running a daemonset pod in order to consume and/or present storage.\n Nodes can be run in several modes, describe below;  Hyper-converged Mode By default Ondat nodes run in hyper-converged mode. This means that the node hosts data from Ondat volumes and can present volumes to applications.\n A hyper-converged node can store data from a volume and present volumes to applications regardless of whether the data for the volume consumed is placed on that node or is being served remotely. Remote volumes like this are handled by an internal protocol to present block device access to applications running on different nodes from the one to which their backing data store is attached.  Ondat implements an extension of a Kubernetes Scheduler object that influences the placement of Pods on the same nodes as their data.\nCompute-only Mode Alternatively, a node can run in Compute-only mode, which means no storage is consumed on the node itself and the node only presents volumes hosted by other nodes.\n Volumes presented to applications running on compute only nodes are therefore all remote. Compute only nodes can be very useful for topologies where nodes are ephemeral and should not host data, but the ephemeral nodes host applications that require Ondat volumes. The nodes that are not intended to hold data, but just to present Ondat volumes, can be set as compute-only. A node can be marked as compute only at any point in time by adding the label storageos.com/computeonly=true.  More information on feature labels can be found under the Ondat Feature Labels page.\nStorage Mode Finally, nodes can be set to storage mode. Nodes set to storage mode don\u0026rsquo;t present data locally - instead all data is accessed through the network.\n This topology is enforced by tainting the relevant nodes to ensure that application workloads cannot be scheduled there. This mode is ideal for ensuring maximum stability of data access as the node is isolated from resource drains that may occur due to applications running alongside.  For redundancy purposes, in high load clusters it is ideal to have several nodes running in this mode.\nFurther Information  Review the Ondat Cluster Topologies feature page for more information on the supported cluster topologies that end users can leverage when designing storage-optimised clusters for their stateful applications.  ","excerpt":"Overview An Ondat node is any machine (virtual or physical) that is running the Ondat daemonset pod. ‚Ä¶","ref":"/docs/concepts/nodes/","title":"Ondat Nodes"},{"body":"Overview How Does Ondat\u0026rsquo;s Replication Work? Ondat replicates volumes across nodes for data protection and high availability. Synchronous replication ensures strong consistency for applications such as databases and message queues, incurring one network round trip on writes.\n The basic model for Ondat replication is of a master volume with distributed replicas. Each volume can be replicated between 0 and 5 times, which are provisioned to 0 to 5 nodes, up to the number of remaining nodes in the cluster. In this diagram, the master volume D was created on node 1, and two replicas, D2 and D3 on nodes 3 and 5.   [Step 1] \u0026raquo; Data from the application is written to the master volume first (D). [Step 2] \u0026raquo; Data is then written in parallel to the replica volumes (D2 \u0026amp; D3). [Step 3] \u0026raquo; Master and replica volumes all acknowledge that data has been received and written [Step 4] \u0026raquo; A successful write operation is returned to the application.  For most applications, one replica is sufficient storageos.com/replicas=1. All replication traffic on the wire is compressed using the LZ4 (compression algorithm), then streamed over TCP/IP to target port TCP/5703.\n If the master volume is lost, a replica is promoted to master (D2 or D3 above) and a new replica is created and synced on an available node (node 2 or 4). This is transparent to the application and does not cause downtime. If a replica volume is lost and there are enough remaining nodes, a new replica is created and synced on an available node. While a new replica is created and being synced, the volume\u0026rsquo;s health will be marked as degraded. If the lost replica comes back online before the new replica has finished synchronising, then Ondat will calculate which of the two synchronising replicas has the smallest difference compared to the master volume and keep that replica. The same holds true if a master volume is lost and a replica is promoted to be the new master. If possible, a new replica will be created and begin to sync. Should the former master come back online it will be demoted to a replica and the replica will the smallest difference to the current master will be kept. While the replica count is controllable on a per-volume basis, some environments may prefer to set default labels on the StorageClass.  Ondat\u0026rsquo;s Delta Sync Algorithm Ondat implements a delta sync between a volume master and its replicas.\n This means that if a replica for a volume goes offline, that when the replica comes back online only the regions with changed blocks need to be synchronised. This optimisation reduces the time it takes for replicas to catch up, improving volume resilience. Additionally, it reduces network and I/O bandwidth which can reduce costs when running in public clouds.  How to use Ondat\u0026rsquo;s Volume Replication? For more information on how to use the volume replication feature, review the Volume Replication operations page.\nOndat Topology-Aware Placement (TAP) Ondat Topology-Aware Placement (TAP) is a feature that enforces placement of data across failure domains to guarantee high availability.\n TAP uses default labels on nodes to define failure domains. For instance, an Availability Zone (AZ).  For more information on the Topology-Aware Placement feature, review the Ondat Topology-Aware Placement feature page.\nOndat Failure Modes  üí° This feature is available in release v2.4.0 or greater.\n Ondat failure modes offer different guarantees with regards to a volume\u0026rsquo;s mode of operation in the face of replica failure. If the failure mode is not specified it defaults to Hard. Volume failure modes can be dynamically updated at runtime.\nhard Failure Mode hard failure mode requires that the number of declared replicas matches the available number of replicas at all times.\n If a replica fails Ondat will attempt creation of a new replica for 90 seconds. After 90s if the old replica is not available and a new replica cannot be provisioned, Ondat cannot guarantee that the data is stored on the number of multiple nodes requested by the user. Ondat will therefore set the volume to be read-only. If a volume has gone read-only there are two stages to making it read-write again. Firstly, sufficient replicas must be provisioned to match the desired replica count. Depending on your environment, additional nodes and/or disk capacity may be required for this. Secondly, the volume must be remounted - necessitating pod deletion/recreation in Kubernetes.  storageos.com/failure-mode: hard Number Of Nodes Required For A hard Failure Mode Setup\n When a node fails, a new replica is provisioned and synced as described above. To ensure that a new replica can always be created, an additional node should be available. To guarantee high availability using storageos.com/failure-mode: hard, clusters using volumes with 1 replica must have at least 3 storage nodes. When using volumes with 2 replicas, at least 4 storage nodes, 3 replicas, 5 nodes, and so on. Minimum number of storage nodes = 1 (primary) + N (replicas) + 1  soft Failure Mode soft failure mode allows a volume to continue serving I/O even when a replica goes offline and a new replica fails to provision.\n So long as there are not less than max(1, N-1) available replicas where N is the number of replicas for the volume. For example, if a volume with 2 replicas loses 1 replica, then I/O would continue to be served since 1 replica remaining \u0026gt;= max(1, 1).  ‚ö†Ô∏è If a volume with 1 replica loses 1 replica, then I/O would halt after 90 seconds since 0 replicas remaining \u0026lt; max(1, 0).\n   storageos.com/failure-mode: soft Number Of Nodes Required For A soft Failure Mode Setup\n To ensure that a storageos.com/failure-mode: soft volume is highly available, clusters using volumes with 1 replica must have at least 2 storage nodes. When using volumes with 2 replicas, at least 3 storage nodes, 3 replicas, 3 nodes, etc. Minimum number of storage nodes = 1 (primary) + N (replicas)  threshold Failure Mode threshold failure mode allows the user to set the minimum required number of online replicas for a volume.\n For example for a volume with 2 replicas, setting the threshold to 1 would allow a single replica to be offline, whereas setting threshold to 0 would allow 2 replicas to be offline.  storageos.com/failure-mode: (0-5) Number Of Nodes Required For A threshold Failure Mode Setup\n The minimum number of nodes for a threshold volume is determined by the threshold that is set. Minimum number of storage nodes = 1 (primary) + T (threshold)  alwayson Failure Mode alwayson failure mode allows all replicas for a volume to be offline and keeps the volume writeable. A volume with failure mode AlwaysOn will continue to serve I/O regardless of how many replicas it currently has.\n This mode should be used with caution as it effectively allows for only a single copy of the data to be available.  storageos.com/failure-mode: alwayson Number Of Nodes Required For A alwayson Failure Mode Setup\n A storageos.com/failure-mode: alwayson volume is highly available albeit at the cost of reliability. The minimum node count here is 1 as the loss of all replicas will be tolerated. Minimum number of storage nodes = 1 (primary).  For more information on how to use failure mode labels on volumes, review the Failure Modes operations page.\n","excerpt":"Overview How Does Ondat\u0026rsquo;s Replication Work? Ondat replicates volumes across nodes for data ‚Ä¶","ref":"/docs/concepts/replication/","title":"Ondat Replication"},{"body":"Overview  üí° This feature is currently available as a Technical Preview from release 2.7.0 or greater.\n Rolling Upgrades Protection You can use our rolling upgrade protection feature to upgrade your cluster\u0026rsquo;s orchestrator without causing downtime or failure of Ondat.\n If the volumes containing the data for your stateful workloads do not wait to successfully synchronize in-between nodes upgrading, this can potentially cause data inconsistency and downtime. As such it is necessary to perform these upgrades intelligently. We are developing a solution to this problem for you. It is currently a Technical Preview but now, for example, Ondat can support a Google Anthos one-click upgrade without any downtime.  To get started with Ondat\u0026rsquo;s Rolling Upgrades Protection for your cluster, review the Platform Upgrade page for more information.\n","excerpt":"Overview  üí° This feature is currently available as a Technical Preview from release 2.7.0 or ‚Ä¶","ref":"/docs/concepts/rolling-upgrades/","title":"Ondat Rolling Upgrades Protection For Orchestrators"},{"body":"Overview This guide will demonstrate how to install the Ondat SaaS Platform.\nPrerequisite  ‚ö†Ô∏è Make sure the kubectl storageos plugin is installed. Follow the install guide for kubectl storageos.\n  ‚ö†Ô∏è Make sure to add an Ondat licence after installing. You can request a licence via the Ondat SaaS Platform.\n  ‚ö†Ô∏è You must enable port 443 for egress in your ACLs if a VPC is used.\n Procedure Step 1: Set up your cluster  Open Ondat SaaS Platform Log into your account using your credentials In the main navigation, open the Cluster tab On the Cluster screen, click the Add Cluster button Enter a name for the cluster and choose the Cluster Location using the radio buttons Click Add Cluster  Step 2: Connect Cluster to the Ondat SaaS Platform  Note: The CLI command will only be displayed once Note: Latest GA version of Ondat will be installed onto your cluster\n  Make sure you follow all the prerequisites displayed on the screen. You can find more information here for the prerequisites of using Ondat. Copy the cli command displayed on the screen Execute the cli command on your machine  ","excerpt":"Overview This guide will demonstrate how to install the Ondat SaaS Platform.\nPrerequisite  ‚ö†Ô∏è Make ‚Ä¶","ref":"/docs/ondat-portal/installation-portal/","title":"Ondat SaaS Platform Installation Guide"},{"body":"Overview  üí° This feature is available in release v2.3.0 or greater.\n What Are Ondat Shared Filesystems? Ondat provides support for ReadWriteMany (RWX) persistent volumes.\n A RWX PVC can be used simultaneously by many Pods in the same Kubernetes namespace for read and write operations. Ondat RWX persistent volumes are based on a shared filesystem, the protocol being used for this feature\u0026rsquo;s backend is Network Files System (NFS).  Architecture Of Ondat Shared Filesystems For each RWX persistent volume, the following components below are required:\n Ondat ReadWriteOnly (RWO) Volume  Ondat provisions a standard volume that provides a block device for the file system of the NFS server. This means that every RWX Volume has its own RWO Volume - thus allowing RWX Volumes to leverage the synchronous replication and automatic failover functionality of Ondat, providing the NFS server with high availability.   NFS-Ganesha Server  For each RWX volume, an NFS-Ganesha server is spawned by Ondat. The NFS server runs in user space on the bode containing the primary volume. Each NFS server uses its own RWO volume to store data so the data of each Volume is isolated. Ondat binds an ephemeral port to the host network interface for each NFS-Ganesha server. The NFS export is presented using NFS v4.2. Ensure that you review the official prerequisites page for more information on the port number range, that is for Ondat RWX persistent volumes to successfully run.   Ondat API Manager  The Ondat API Manager resource monitors Ondat RWX volumes to create and maintain a Kubernetes service that points towards each RWX volume\u0026rsquo;s NFS export endpoint. The API Manager is responsible for updating the service endpoint when a RWX volume failover occurs.    How are Ondat ReadWriteMany (RWX) PersistentVolumeClaims (PVCs) Provisioned? The sequence in which a RWX PVC is provisioned and used demonstrated in the steps below:\n A PersistentVolumeClaim (PVC) is created with ReadWriteMany (RWX) access mode using any Ondat StorageClass. Ondat dynamically provisions the PersistentVolume (PV). A new Ondat ReadWriteOnly (RWO) Volume is provisioned internally (not visible in Kubernetes). When the RWX PVC is consumed by a pod, an NFS-Ganesha server is instantiated on the same node as the primary volume. The NFS-Ganesha server then uses the RWO Ondat volume as its backend disk. The Ondat API Manager publishes the host IP and port for the NFS service endpoint, by creating a Kubernetes service that points to the NFS-Ganesha server export endpoint. Ondat issues a NFS mount on the Node where the Pod using the PVC is scheduled.  For more information on how to get started with Ondat Shared Filesystems, review the How To Create ReadWriteMany (RWX) Volumes operations page.\nHigh Availability For Ondat Shared Filesystems Ondat RWX volumes failover in the same way as standard Ondat RWO volumes.\n The replica volume is promoted upon detection of node failure and the NFS-Ganesha server is started on the node containing the promoted replica. The Ondat API Manager updates the endpoint of the Volume\u0026rsquo;s NFS service, causing traffic to be routed to the URL of the new NFS-Ganesha server. The NFS client in the application node (where the user\u0026rsquo;s pod is running) automatically reconnects.  Further Information  All Ondat Feature Labels that work on RWO volumes will also work on RWX volumes. A Ondat RWX volume is matched one-to-one with a PVC. Therefore the Ondat RWX volume can only be accessed by pods in the same Kubernetes namespace. Ondat RWX volumes support volume resize.  For more information on how to resize a volume, review the Volume Resize operations page.   As it\u0026rsquo;s backed by an NFS instance, the resource consumption of a RWX volume can grow.  This consumption scales linearly with the volume\u0026rsquo;s throughput. If given insufficient resources the NFS server\u0026rsquo;s IO can be blocked and it can fail. The resources in question are the speed of the underlying disk and CPU time of the machine hosting the volume\u0026rsquo;s primary replica. Our attachments are unlikely to cause any issue outside of NFS. We have happily tested up to 800 consumers for volumes hosted on small hosts, for very low-throughput applications.    ","excerpt":"Overview  üí° This feature is available in release v2.3.0 or greater.\n What Are Ondat Shared ‚Ä¶","ref":"/docs/concepts/rwx/","title":"Ondat Shared Filesystems"},{"body":"Overview  üí° This feature is available in release v2.8.0 or greater.\n The Ondat Snapshot feature can be used in conjunction with a backup tooling provider e.g. Kasten K10 or CloudCasa to snapshot, backup and restore Kubernetes applications. Kasten K10 and CloudCasa have been tested and validated with our feature.\nThe snapshot functionality is useful for:\n Disaster Recovery (DR) scenarios. Rolling back unwanted changes. Auditing purposes. Migrating applications between clusters.  What Are Snapshots, Backups \u0026amp; Restores? A ‚Äúsnapshot‚Äù is a point-in-time copy of a PVC. Snapshots are modelled via the VolumeSnapshot and VolumeSnapshotContent Kubernetes API objects.\n Snapshots have limited use as they live within the cluster and cannot be used to restore the PVC if the node holding the snapshot is lost.  A ‚Äúbackup‚Äù is the process of materialising a new PVC, whose data source is a previously created snapshot and then extracting the data to a location outside of the cluster.\n The Ondat Snapshots feature integrates with Kasten K10 or CloudCasa to provide backup functionality.  A ‚Äúrestore‚Äù is the process of restoring an application from a given backup.\n The Ondat Snapshots feature integrates with Kasten K10 or CloudCasa to provide restore functionality.  How Does It Work? The Kubernetes Volume Snapshots feature provides users with a set of custom resource definitions (CRD) and APIs to create and manage volume snapshots. Storage providers can then implement the necessary Container Storage Interface (CSI) APIs to integrate with this feature.\nThis is exactly what we‚Äôve done at Ondat. Additional backup tooling solutions (e.g. Kasten K10 or Cloudcasa) can then be utilised to orchestrate and automate snapshotting, backups and restores.\n For Kasten K10 users, review the How To Backup \u0026amp; Restore Using Ondat Snapshots with Kasten K10 operations page to get started. For CloudCasa users, review the How To Backup \u0026amp; Restore Using Ondat Snapshots with CloudCasa operations page to get started.   ‚ö†Ô∏è The Ondat Snapshots feature is not fully CSI compliant yet. As of today, the feature can only be used with Kasten K10 or CloudCasa, and with restoration from an external backup.\n Current Scope \u0026amp; Limitations The Ondat Snapshots feature has the following limitations:\n The feature has been designed to work with Kasten K10 \u0026amp; CloudCasa only. This is not a fully CSI compliant implementation of the specification yet. Restoring via Kasten 10 from a ‚Äúlocal snapshot‚Äù is not supported with the Ondat Snapshot feature. Users may only restore applications using a Kasten K10 ‚ÄúExternal backup‚Äù. Snapshotting ReadWriteMany (RWX) volumes is not supported. This is because it is next to impossible to ensure that a NFS mounted volume is in a suitable state for snapshotting.  For RWX volumes, the user only has access to the filesystem on the NFS client. It is not possible to run fsfreeze on this mount point \u0026ndash; NFS does not support it. Thus the user can not quiesce the filesystem and we can not take a \u0026ldquo;consistent\u0026rdquo; snapshot.    ","excerpt":"Overview  üí° This feature is available in release v2.8.0 or greater.\n The Ondat Snapshot feature can ‚Ä¶","ref":"/docs/concepts/snapshots/","title":"Ondat Snapshots"},{"body":"Overview  üí° This feature is available in release v2.5.0 or greater.\n Ondat Topology-Aware Placement (TAP) is a feature that enforces placement of data across failure domains to guarantee high availability.\nOndat TAP uses default labels on nodes to define failure domains - for instance, an Availability Zone. However, the key label used to segment failure domains can be defined by the user per node. Lastly, Ondat TAP is an opt-in feature per volume.\nHow does Ondat Topology-Aware Placement Work? Ondat\u0026rsquo;s Topology-Aware Placement attempts to distribute sensitive data across different failure domains. Hence, a primary volume and its replicas are scattered across failure domains - that is implemented following a best effort algorithm.\n In case that Ondat TAP rules can\u0026rsquo;t be fulfilled the placement algorithm will attempt a best approach placement (even if new replicas are in the same failure domain). The best effort placement allows the system to place replicas on the same failure domains when a full domain has failed catastrophically. Hence, the system self heals as fast as possible without waiting for the nodes on the failed domain to recover.  It is the user\u0026rsquo;s responsibility to rebalance the data when the failed domain has recovered its availability. That can be achieved by recreating the replicas of a volume.\n üí° Future versions of Ondat will facilitate the procedure by allowing a volume drain.\n Advantages of using Ondat Topology-Aware Placement (TAP) Deploying a stateful application on a clusters with multiple nodes without Ondat TAP enabled can result in suboptimal placement for high availability. Not enabling Ondat TAP can cause following problems:\n Unschedulable pods due to resource, affinity, and taint issues when a full failure domain experiences a failure. Volume replicas placed within the same zone as a primary volume.  How to use Ondat Topology-Aware Placement? Topology-Aware Placement can be enabled by applying the label storageos.com/topology-aware=true to a PVC or as a parameter of its StorageClass.\n For more information on how to enable Ondat Topology-Aware Placement for your volumes, review the Ondat Topology-Aware Placement operations page.  Understanding Topology Domains A topology domain is a set of nodes. The domain is identified by a label, which can be defined by the user.\n The default label that Ondat uses to segment nodes in failure domains is \u0026raquo; topology.kubernetes.io/zone. However, you can define your own topology key by setting the key string in the Ondat feature label \u0026raquo; storageos.com/topology-key.  Ondat Failure Modes \u0026amp; Topology-Aware Placement Failure modes are a complimentary feature of the Topology-Aware Placement functionality. Failure modes allow you to define how many replicas of a volume can become unavailable before the volume is marked as read-only.\n For more information on how to Failure Modes work , review the Ondat Topology-Aware Placement feature page.  For example, assuming that your cluster has three topology zones, A, B and C, and your deployment has a master and two replicas, Ondat will attempt to place one volume in each topology zone.\n If zone A fails, I/O operations to your volume will stop completely - if the Failure Mode is hard. If the Failure Mode is soft - I/O operations will continue while volume failover is in progress, and a new replica will be placed in an operational zone. Note that if zone A recovers, the cluster will not automatically rebalance.  The soft failure mode will not tolerate the failure of multiple replicas at once, and will suspend I/O operations in this case.\n If you wish to tolerate more than one failed replica, then you can set this as an integer using the \u0026lt;integer\u0026gt; label. If individual nodes within a topology zone fail, the replicas will fail over to other nodes within that zone. Once nodes in the zone are exhausted, placement will revert to best-effort.  ","excerpt":"Overview  üí° This feature is available in release v2.5.0 or greater.\n Ondat Topology-Aware Placement ‚Ä¶","ref":"/docs/concepts/tap/","title":"Ondat Topology-Aware Placement (TAP)"},{"body":"Overview This guide provides instructions on how to upgrade Ondat.\nUpgrading An Ondat v2 Cluster Prerequisites  ‚ö†Ô∏è Ensure that you have read the PIDs prerequisite introduced in Ondat v2.3 and that you have checked the init container logs to ensure your environments PID limits are set correctly.\n  üí° Pull down the new Ondat container image storageos/node:v2.8.2 onto the nodes beforehand so that the cluster spins up faster.\n  üí° Speak with our support team here so we can assist you with your upgrade.\n Procedure Step 1 - Backup Ondat Deployment Manifests Make sure that you keep a backup of all the Ondat YAML files. You can also backup the StatefulSet yaml files to keep track of the replicas.\nkubectl get pod -n storageos -o yaml \u0026gt; storageos_operator.yaml kubectl get storageoscluster -n storageos -o yaml \u0026gt; storageos_cr.yaml kubectl get statefulset --all-namespaces \u0026gt; statefulset-sizes.yaml Step 2 - Scale Down Stateful Applications To Zero Scale all of the stateful applications that use Ondat volumes to 0.\nStep 3 - Upgrade Ondat Run the following command using the kubectl storageos plugin.\n Make sure you are using the latest version of the kubectl storageos plugin. You can make use of the installation guide and get the latest version here.\n kubectl storageos upgrade  üí° Please use the --etcd-tls-enabled if using TLS with your ETCD.\n  üí° If you are using a namespace other than storageos for your Ondat install, please use --uninstall-stos-operator-namespace argument because it uninstalls the cluster first and then reinstalls it with the new version.\n  üí° If at any point something goes wrong with the upgrade process, backups of all the relevant Kubernetes manifests can be found in ~/.kube/storageos/.\n Step 4 - Scale Up Stateful Applications Once the Ondat upgrade is complete and the core components are back online, scale up the stateful applications that use Ondat volumes back up to their respective replica count.\n","excerpt":"Overview This guide provides instructions on how to upgrade Ondat.\nUpgrading An Ondat v2 Cluster ‚Ä¶","ref":"/docs/upgrade/upgrade/","title":"Ondat Upgrade"},{"body":"Overview Ondat volumes are a logical construct which represent a writeable volume and exhibit standard POSIX semantics. Ondat presents volumes as mounts into containers via the Linux-IO (LIO) subsystem.\nConceptually, Ondat volumes have a frontend presentation, which is what the application sees, and a backend presentation, which is the actual on-disk format. Depending on the configuration, frontend and backend components may be on the same or different hosts.\nVolumes are formatted using the linux standard ext4 filesystem by default. Kubernetes users may change the default filesystem type to ext2, ext3, ext4, or xfs by setting the fsType parameter in their StorageClass - review the Supported Filesystems page for more information.\n üí° Different filesystems may be supported in the future.\n Ondat volumes are represented on disk in two parts.\n Actual volume data is written to blob files in /var/lib/storageos/data/dev[\\d+]. Inside these directories, each Ondat block device gets two blob files of the form vol.xxxxxx.y.blob, where x is the inode number for the device, and y is an index between 0 and 1. We provide two blob files in order to ensure that certain operations which require locking do not impede in-flight writes to the volume.  In systems which have multiple /var/lib/storageos/data/dev[\\d+] directories, two blob files are created per block device.\n This allows us to load-balance writes across multiple devices. In cases where dev directories are added after a period of runtime, later directories are favoured for writes until the data is distributed evenly across the blob files.  Metadata is kept in directories named /var/lib/storageos/data/db[\\d+].\n We maintain an index of all blocks written to the blob file inside the metadata store, including checksums. These checksums allow us to detect bit rot, and return errors on reads, rather than serve bad data. In future versions we may implement recovery from replicas for volumes with one or more replicas defined. Ondat metadata requires approximately 2.7 GiB of storage per 1 TiB of allocated blocks in the associated volume. This size is consistent irrespective of data compression defined on the volume.  To ensure deterministic performance, individual Ondat volumes must fit on a single node.\nMinimum Ondat Volume Size  The minimum volume size Ondat supports is 1 GiB.  Ondat Volume Resizing Ondat supports offline resize of volumes.\n This means that a volume cannot be resized while it is in use. Furthermore, in order for a resize operation to take place the volume must not be attached to a node. This is to ensure that the volume is not in use. This means that if a Kubernetes pod is currently consuming a volume that a resize request has been issued for, the resize will not be actioned until the pod is terminated and the volume is detached from the node. The Ondat Control Plane will then attach the volume to the node that holds the master deployment and resize the underlying block device and then run resize2fs to expand the filesystem.  For more information on how to resize a volume, review the Volume Resize operations page.\nOndat Volume Encryption Volumes can be configured on creation to have data encryption-at-rest. Data is encrypted with XTS-AES and decrypted upon use.\nFor more information on how to enable data encryption for Ondat volumes, review the Ondat Data Encryption feature page.\nTRIM  üí° This feature is available in release v2.4.0 or greater.\n Ondat volumes support TRIM/UNMAP which allows the space allocated to deleted blocks to be reclaimed from the backend blob files that back each volume when a TRIM call is made.\n Support for TRIM is enabled by default for all uncompressed volumes, volumes are created without compression enabled by default.  For more information on how to TRIM a filesystem, review the TRIM operations page.\n","excerpt":"Overview Ondat volumes are a logical construct which represent a writeable volume and exhibit ‚Ä¶","ref":"/docs/concepts/volumes/","title":"Ondat Volumes"},{"body":"Overview This guide will demonstrate how to enable protection for your orchestrator\u0026rsquo;s rolling upgrades using the Node Guard and Node Manager. This feature helps prevent your persistent storage volumes from becoming unhealthy during the rolling downtime of an orchestrator upgrade.\n ‚ö†Ô∏è This feature is currently in tech preview, we only recommend using this feature on your test clusters.\n Prerequisites  ‚ö†Ô∏è Make sure you have met the requirements of configuring a Pod Disruption Budget (PDB).\n  ‚ö†Ô∏è If your volume does not have any replicas, the rolling upgrades feature will not start on any StorageOS node until you have one or more replicas on all your volumes.\n  ‚ö†Ô∏è This feature supports the following platforms: Google Anthos, and Google GKE with future support to be expanded to Amazon EKS, Openshift, and Rancher.\n  ‚ö†Ô∏è Using Ondat for the internal registry is not recommended. OpenShift requires the internal registry to be available but Ondat volumes may become unavailable during the upgrade.\n  ‚ö†Ô∏è For Openshift: The PDB feature is only stable in Kubernetes v1.21+ and Openshift v4.8+.\n Procedure Step 1 - Enable Node Manager \u0026amp; Node Guard  Add the following lines to the StorageOSCluster spec:  nodeManagerFeatures:nodeGuard:\u0026#34;\u0026#34; Alternatively, you can run the following command:  kubectl get storageoscluster -n storageos storageoscluster -o yaml | sed -e \u0026#39;s|^spec:$|spec:\\n nodeManagerFeatures:\\n nodeGuard: \u0026#34;\u0026#34;|\u0026#39; | kubectl apply -f -  You will see new pods getting created, one pod per node in a cluster called Node Manager. If you enable the Node Guard during the first installation, Node Guard might fall into a temporary CrashLoopBackoff loop until all cluster components are up and running.  Node Guard has a few configuration options:\n MINIMUM_REPLICAS: minimum replica number of any volume. Default: 1 WATCH_ALL_VOLUMES: watch all volumes on every node, otherwise Node Guard watches volumes and their replicas on the node where it is running. Extra safety option with a performance impact. Default: false  nodeManagerFeatures:nodeGuard:\u0026#34;MINIMUM_REPLICAS=2,WATCH_ALL_VOLUMES=true\u0026#34;Step 2 - Rolling Upgrades Is Ready Congratulations, you are now ready to start the rolling upgrade process of your orchestrator!\n ‚ö†Ô∏è GKE and AKS take care of the pod disruption budget for one hour. After this period, they drain the node, which would destroy the volume.\n  ‚ö†Ô∏è EKS takes care of PDB for 50 mins, after this period upgrade would fail unless it was forced.\n  ‚ö†Ô∏è Node Guard has a one-day termination period by default. The final termination period heavily depends on the platform you use. During the termination period, you should SSH into the node to create a backup in the worst-case scenario.\n Troubleshooting  Volumes are healthy, all in sync but storageos-node-manager pod is hanging on the Terminating state.  The long termination period of Node Manager tries to keep failed node - and volumes on it - up and running as long as possible. This gives a chance to create a backup from an accidentally deleted machine. In case, Node Guard isn\u0026rsquo;t able to determine volume statuses, because of a network issue or missing StorageOS service, you have to delete pod manually by executing the following command:\nkubectl delete pods -n storageos storageos-node-manager-XYZ --grace-period=0 --force  A node has been removed accidentally or not in the official graceful termination way before drain, and two Node Manager pods - one in Pending and the other in Terminating states - are hanging on the same node.  Node Manager deployment tolerates almost every issue on the target node to protect your data. On the other hand, Node Manager doesn\u0026rsquo;t tolerate itself on the same node. If a node goes down before Kubernetes was able to properly delete StorageOS Node daemonset, after the termination phase it re-schedules Node Manager pod to ensure the right number of replicas. But the pod isn\u0026rsquo;t able to be scheduled, because of the toleration. Meantime Kubernetes isn\u0026rsquo;t able to remove the pod in Terminating state, because Kubelet isn\u0026rsquo;t responding.\nThe only way to solve this situation is to delete the node from Kubernetes cluster by executing the command below:\nkubectl delete node XYZ  ‚ö†Ô∏è Kubernetes has introduced Non-Graceful Node Shutdown Alpha in 1.24. This new feature allows cluster admins to mark failing nodes as NoExecute or NoScedule. Both options should solve the scheduling issue of Node Manager pod by decreasing the number of daemonset instances to the right number at Kubernetes API level, but in the absence of Kubelet termination of pods would still hangin.\n ","excerpt":"Overview This guide will demonstrate how to enable protection for your orchestrator\u0026rsquo;s rolling ‚Ä¶","ref":"/docs/upgrade/using-rolling-upgrades/","title":"Platform Upgrade"},{"body":"Ondat policies are a way to control user and group access to Ondat Namespaces. To grant a user or group access to a namespace, a policy needs to be created mapping the user or group to the namespace.\n üí° Users always have access to the default namespace\n For more information on how to use policies, see the Policies operations page.\n","excerpt":"Ondat policies are a way to control user and group access to Ondat Namespaces. To grant a user or ‚Ä¶","ref":"/docs/reference/policies/","title":"Policies"},{"body":"Overview This guide will demonstrate how to install Ondat onto a Amazon EKS cluster using either the Ondat kubectl plugin or Helm Chart.\nPrerequisites 1 - Cluster and Node Prerequisites The minimum cluster requirements for a non-production installation of Ondat are as follows:\n Linux with a 64-bit architecture. 2 vCPU and 4GB of RAM per node. 3 worker nodes in the cluster and sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster. Make sure your EKS clusters use Ubuntu for EKS as the default node operating system with an optimised kernel. This installation guide takes you through that process as it is not easily available in the AWS Console. For more information on the Linux distributions that are supported, and how to update Amazon Linux with the correct Kernal Modules, see System Configuration.  For a comprehensive list of prerequisites and how to build a production installation of Ondat please refer to Ondat Prerequisites\n2 - Client Tools Prerequisites The following CLI utilities are installed on your local machine and available in your $PATH:\n kubectl aws eksctl, at least version \u0026gt;=0.83.0  Ondat can be installed either via Helm Chart or using our command-line tool. Depending on which installation method you choose you will require either:\n kubectl-storageos CLI Helm 3 CLI  3 - Creating a cluster with the correct Linux distribution In this example, we have used eksctl to create a cluster with 3 nodes of size i3en.xlarge running Ubuntu for EKS in the eu-west-2 region. We have provided 20 GB of disk space for each node. With a default installation Ondat will store data locally in the node\u0026rsquo;s file system under the path /var/lib/storageos on each node in hyperconverged mode. In a production infrastructure, we would create multiple Elastic Block Store (EBS) Volumes tweaked for performance or use ephemeral SSD storage and mount our volumes under data device directories with some additions to user data. We would also implement some form of snapshots or backup of these underlying volumes to ensure continuity in a disaster scenario.\n3a - Creating the cluster.yaml file Create the following cluster.yaml file that will be used to create your cluster. Make the following updates:\n The file to use the region and availabilityZones that you need The \u0026lt;key-name\u0026gt; field in the publicKeyName parameter - make sure you update this to match your ssh key name.  # cluster.yaml---apiVersion:eksctl.io/v1alpha5kind:ClusterConfigmetadata:name:ondat-clusterregion:eu-west-2version:\u0026#34;1.22\u0026#34;addons:- name:aws-ebs-csi-driveriam:withOIDC:truemanagedNodeGroups:- name:ondat-ng-2aavailabilityZones:- eu-west-2aminSize:1maxSize:3desiredCapacity:1instanceType:i3en.xlargeamiFamily:Ubuntu2004ssh:allow:truepublicKeyName:\u0026lt;key-name\u0026gt;labels:{ondat:node}volumeSize:20volumeType:gp3volumeEncrypted:truedisableIMDSv1:trueiam:withAddonPolicies:ebs:truepreBootstrapCommands:- mkdir -p /var/lib/storageos- echo \u0026#34;/dev/nvme1n1 /var/lib/storageos ext4 defaults,discard 0 1\u0026#34; \u0026gt;\u0026gt; /etc/fstab- mkfs.ext4 /dev/nvme1n1- mount /var/lib/storageos- name:ondat-ng-2bavailabilityZones:- eu-west-2bminSize:1maxSize:3desiredCapacity:1instanceType:i3en.xlargeamiFamily:Ubuntu2004ssh:allow:truepublicKeyName:\u0026lt;key-name\u0026gt;labels:{ondat:node}volumeSize:20volumeType:gp3volumeEncrypted:truedisableIMDSv1:trueiam:withAddonPolicies:ebs:truepreBootstrapCommands:- mkdir -p /var/lib/storageos- echo \u0026#34;/dev/nvme1n1 /var/lib/storageos ext4 defaults,discard 0 1\u0026#34; \u0026gt;\u0026gt; /etc/fstab- mkfs.ext4 /dev/nvme1n1- mount /var/lib/storageos- name:ondat-ng-2cavailabilityZones:- eu-west-2cminSize:1maxSize:3desiredCapacity:1instanceType:i3en.xlargeamiFamily:Ubuntu2004ssh:allow:truepublicKeyName:\u0026lt;key-name\u0026gt;labels:{ondat:node}volumeSize:20volumeType:gp3volumeEncrypted:truedisableIMDSv1:trueiam:withAddonPolicies:ebs:truepreBootstrapCommands:- mkdir -p /var/lib/storageos- echo \u0026#34;/dev/nvme1n1 /var/lib/storageos ext4 defaults,discard 0 1\u0026#34; \u0026gt;\u0026gt; /etc/fstab- mkfs.ext4 /dev/nvme1n1- mount /var/lib/storageos3b - Creating the cluster Once you have created the yaml file above, run the following eksctl command to create your cluster.\neksctl create cluster --config-file=cluster.yaml ‚ö†Ô∏è With the above configuration, volumes will be deleted when the nodes they are attached to are terminated. Be sure to keep snapshots, for example by using Data Lifecycle Manager.\n4 - Connecting to your cluster First, provision your kubeconfig for kubectl and test that you can connect to Kubernetes. You will need to update the script with the region where your cluster is.\nexport AWS_REGION=\u0026#34;eu-west-2\u0026#34; # Insert your preferred region here aws eks update-kubeconfig --region AWS_REGION --name ondat-cluster kubectl get nodes If you receive the message No resources found or see nodes marked as NotReady, wait for 2-3 minutes in order for your nodes to transition to Ready and check again to ensure they are running before proceeding through the next steps.\n5 - Creating a StorageClass for etcd to use If you used the eksctl cluster configuration defined above, the gp3 storage class is already available so you can skip to the next step. Otherwise you can set up the EBS CSI Driver as follows:\n It is important to note that the Ondat etcd usage of disk depends on the size of the Kubernetes cluster. However, it is recommended that the disks have at least 800 IOPS at any point in time. The best cost-effective storage class that fulfils such requirements is gp3. If gp2 is used, it is paramount to use a volume bigger than 256Gi as it will have enough IOPS even when the burstable credits are exhausted.\n To use a gp3 storage class in Kubernetes it is required to install the Amazon CSI Driver. Follow [this guide] (https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html) to install. Follow the steps below:\n Create IAM permissions Install the CSI driver Using EKS addon Using self-managed add on (AWS clusters, but not in EKS) Install the gp3 StorageClass:  kubectl create -f - \u0026lt;\u0026lt;EOF kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: gp3 allowVolumeExpansion: true provisioner: ebs.csi.aws.com volumeBindingMode: WaitForFirstConsumer parameters: type: gp3 EOF Installation of Ondat Step 1 - Adding a Cluster The Ondat Portal is how you can license and get the commands for installing Ondat:\n Either login or create an account on the Ondat Portal Choose the \u0026lsquo;Install Ondat on your cluster\u0026rsquo; or \u0026lsquo;Add cluster\u0026rsquo; options the UI Add a Name for your cluster and where it is going to be located  Step 2 - Choosing the Installation Method You can use either the kubectl-storageos CLI or Helm 3 CLI to install Ondat onto your cluster. The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below\nStep 3a - Installing via Helm The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.\nThe first two lines of the command adds the Ondat Helm repository and ensures a updated local cache. The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 3b - Installing via kubectl-storageos plugin The Ondat Portal UI will display the following cmd that can be used to install Ondat using the kubectl-storageos plugin. The command created will be unique for you and the screenshot below is just for reference.\nThe command that is provided by the Portal is unique to you and uses the kubectl-storageos plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 4 - Verifying Ondat Installation Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status).\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd kubectl get storageclasses | grep \u0026#34;storageos\u0026#34; Once all the components are up and running the output should look like this:\nStep 5 - Applying a Licence to the Cluster Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see our pricing page.\nTo licence your cluster with the community edition:\n On the Clusters page select \u0026lsquo;View Details\u0026rsquo; Click on \u0026lsquo;Change Licence\u0026rsquo; In the following pop-up select the \u0026lsquo;Community Licence\u0026rsquo; option then click \u0026lsquo;Generate\u0026rsquo;  This process generates a licence and installs it for you. Now you are good to go!\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a Amazon EKS cluster using either the ‚Ä¶","ref":"/docs/install/aws/amazon-web-services-eks/","title":"Amazon Elastic Kubernetes Service (EKS)"},{"body":"Overview This guide will demonstrate how to install Ondat onto a Google Kubernetes Engine (GKE) cluster using either the Ondat kubectl plugin or Helm Chart\n üí° For users who are looking to deploy Ondat onto a Google Anthos cluster, use the Google Anthos Installation guide for more information.\n Prerequisites 1 - Cluster and Node Prerequisites The minimum cluster requirements for a non-production installation of ondat are as follows:\n Linux with a 64-bit architecture. 2 vCPU and 4GB of RAM per node. 3 worker nodes in the cluster and sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster. Make sure your GKE cluster uses ubuntu_containerd as the default node operating system. This node operating system image has the required kernel modules available for Ondat to run successfully.  For a comprehensive list of prerequisites and how to build a production installation of Ondat please refer to Ondat Prerequisites\n2 - Client Tools Prerequisites The following CLI utilities are installed on your local machine and available in your $PATH:\n kubectl  Ondat can be installed either via Helm Chart or using our command-line tool. Depending on which installation method you choose you will require either:\n kubectl-storageos CLI Helm 3 CLI  Installation of Ondat Step 1 - Adding a Cluster The Ondat Portal is how you can license and get the commands for installing Ondat.\n Either login or create an account on the Ondat Portal Choose the \u0026lsquo;Install Ondat on your cluster\u0026rsquo; or \u0026lsquo;Add cluster\u0026rsquo; options in the UI Add a Name for your cluster and where it is going to be located. This will allow you to view the same prerequisites listed above.  Step 2 - Choosing the Installation Method You can use either the kubectl-storageos CLI or Helm 3 CLI to install Ondat onto your cluster. The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below.\nStep 3a - Installing via Helm The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.\nThe first two lines of the command adds the Ondat Helm repository and ensures a updated local cache. The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 3b - Installing via kubectl-storageos plugin The Ondat Portal UI will display the following cmd that can be used to install Ondat using the kubectl-storageos plugin. The command created will be unique for you and the screenshot below is just for reference.\nThe command that is provided by the Portal is unique to you and uses the kubectl-storageos plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 4 - Verifying Ondat Installation Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status)\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd kubectl get storageclasses | grep \u0026#34;storageos\u0026#34; Once all the components are up and running the output should look like this:\nStep 5 - Applying a Licence to the Cluster Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see here.\nTo licence your cluster with the community edition:\n On the Clusters page select \u0026lsquo;View Details\u0026rsquo; Click on \u0026lsquo;Change Licence\u0026rsquo; In the following pop-up select the \u0026lsquo;Community Licence\u0026rsquo; option then click \u0026lsquo;Generate\u0026rsquo;  This process generates a licence and installs it for you. Now you are good to go!\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a Google Kubernetes Engine (GKE) ‚Ä¶","ref":"/docs/install/gcp/google-kubernetes-engine-gke/","title":"Google Kubernetes Engine (GKE)"},{"body":"Overview This guide will demonstrate how to install Ondat onto an Openshift cluster using the Ondat kubectl plugin.\nPrerequisites  ‚ö†Ô∏è Make sure the prerequisites for Ondat are satisfied before proceeding. Including the deployment of an etcd cluster and configuration of CRI-O PID limits.\n  ‚ö†Ô∏è If you have installed OpenShift in AWS ensure that the requisite ports are opened for the worker nodes' security group.\n  ‚ö†Ô∏è Make sure to add an Ondat licence after installing. You can request a licence via the Ondat SaaS Platform.\n  üí° For OpenShift upgrades, refer to the OpenShift platform page.\n Ondat v2 supports OpenShift v4. For more information, see the OpenShift platform page.\ninstallation of Ondat via OperatorHub Step 1: Operatorhub   Select the OperatorHub from the Catalog sub menu and search for StorageOS\n üí° Choose between using the RedHat Marketplace or the Community Operators installation.\n   Select StorageOS and click Install.\n  Select the relevant install options.\n Make sure the Approval Strategy is set to Manual. This option makes sure that the StorageOS Operator doesn\u0026rsquo;t upgrade versions without explicit approval.\n   Start the approval procedure by clicking on the operator name.\n  On Subscription Details, click the approval link.\n  On Review Manual Install panel in the Components tab, click Approve to confirm the installation.\n  The Ondat Operator is installed along the required CRDs.\nStep 2: Authentication   Create a Secret in the openshift-operators project and select the YAML option to create a secret containing the username and an password key. The username and password defined in the secret will be used to authenticate when using the Ondat CLI and GUI. Take note of which project you created the secret in.\nInput the secret as YAML for simplicity.\napiVersion:v1kind:Secretmetadata:name:storageos-apinamespace:openshift-operatorstype:\u0026#34;kubernetes.io/storageos\u0026#34;data:# echo -n \u0026#39;\u0026lt;secret\u0026gt;\u0026#39; | base64username:c3RvcmFnZW9zpassword:c3RvcmFnZW9z  Go to the Operators-\u0026gt;Installed Operators and verify that the StorageOS Operator is installed.\n  Go to the StorageOS Cluster section.\n  Click Create StorageOSCluster.\n üí° An Ondat Cluster is defined using a Custom Resource Definition\n   Create the Custom Resource\nThe StorageOS cluster resource describes the Ondat cluster that will be created. Parameters such as the secretRefName, the secretRefNamespace and the kvBackend.address are mandatory.\n üí° Additional spec parameters are available on the Operator configuration page.\n apiVersion: \u0026#34;storageos.com/v1\u0026#34; kind: StorageOSCluster metadata: name: storageos namespace: openshift-operators spec: # Ondat Pods are in kube-system by default secretRefName: \u0026#34;storageos-api\u0026#34; # Reference the Secret created in the previous step secretRefNamespace: \u0026#34;openshift-operators\u0026#34; # Namespace of the Secret created in the previous step k8sDistro: \u0026#34;openshift\u0026#34; kvBackend: address: \u0026#39;storageos-etcd-client.etcd:2379\u0026#39; # Example address, change for your etcd endpoint # address: \u0026#39;10.42.15.23:2379,10.42.12.22:2379,10.42.13.16:2379\u0026#39; # You can set ETCD server ips resources: requests: memory: \u0026#34;512Mi\u0026#34; cpu: 1 # nodeSelectorTerms: # - matchExpressions: # - key: \u0026#34;node-role.kubernetes.io/worker\u0026#34; # Compute node label will vary according to your installation # operator: In # values: # - \u0026#34;true\u0026#34;   Verify that the StorageOS Cluster resource status is Running.\n It can take up to a minute to report the Ondat Pods ready.\n   Check the StorageOS Pods in the kube-system project\n A Status of 3/3 in the Ready column for the Daemonset Pods indicates that Ondat is bootstrapped successfully.\n   License cluster  ‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.\n To obtain a license, follow the instructions on our licensing operations page.\nFirst Ondat volume If this is your first installation you may wish to follow the Ondat volume guide for an example of how to mount an Ondat volume in a Pod.\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto an Openshift cluster using the Ondat ‚Ä¶","ref":"/docs/install/openshift/openshift-operatorhub/","title":"OpenShift via OperatorHub"},{"body":"Overview If you are running kubernetes in AWS there are a number of options on how you run your kubernetes cluster. Read the following datasheets and blogs for more information about some of the use-cases of running in AWS.\n Whitepaper: Ondat Platform Architecture Overview Datasheet: Ondat and EKS Datasheet: The Kube-Native Data Platform for AWS Blog: An EKS Deep Dive with Ondat Webinar: Reduce your storage costs with ephemeral storage EC2 instances with Ondat Webinar: Storage optimization for containers on AWS  ","excerpt":"Overview If you are running kubernetes in AWS there are a number of options on how you run your ‚Ä¶","ref":"/docs/install/aws/","title":"AWS"},{"body":"Overview This guide will demonstrate how to install Ondat onto a Microsoft AKS cluster using either the Ondat kubectl plugin or Helm Chart\nPrerequisites 1 - Cluster and Node Prerequisites The minimum cluster requirements for a non-production installation of ondat are as follows:\n Linux with a 64-bit architecture 2 vCPU and 8GB of memory 3 worker nodes in the cluster and sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster Make sure your AKS cluster uses Ubuntu as the default node operating system with an optimised kernel. Any Ubuntu-based node operating system with a kernel version greater than 4.15.0-1029-azure is compatible with Ondat  For a comprehensive list of prerequisites and how to build a production installation of Ondat please refer to Ondat Prerequisites\n2 - Client Tools Prerequisites The following CLI utilities are installed on your local machine and available in your $PATH:\n kubectl  Ondat can be installed either via Helm Chart or using our command-line tool. Depending on which installation method you choose you will require either:\n kubectl-storageos CLI Helm 3 CLI  Installation of Ondat Step 1 - Adding a Cluster The Ondat Portal is how you can license and get the commands for installing Ondat\n Either login or create an account on the Ondat Portal Choose the \u0026lsquo;Install Ondat on your cluster\u0026rsquo; or \u0026lsquo;Add cluster\u0026rsquo; options in the UI Add a Name for your cluster and where it is going to be located. This will allow you to view the same prerequisites as are listed above  Step 2 - Choosing the Installation Method You can use either the kubectl-storageos CLI or Helm 3 CLI to install Ondat onto your cluster. The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below\nStep 3a - Installing via Helm The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.\nThe first two lines of the command adds the Ondat Helm repository and ensures a updated local cache. The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 3b - Installing via kubectl-storageos plugin The Ondat Portal UI will display the following cmd that can be used to install Ondat using the kubectl-storageos plugin. The command created will be unique for you and the screenshot below is just for reference.\nThe command that is provided by the Portal is unique to you and uses the kubectl-storageos plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 4 - Verifying Ondat Installation Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status).\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd kubectl get storageclasses | grep \u0026#34;storageos\u0026#34; Once all the components are up and running the output should look like this:\nStep 5 - Applying a Licence to the Cluster Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see here.\nTo licence your cluster with the community edition:\n On the Clusters page select \u0026lsquo;View Details\u0026rsquo; Click on \u0026lsquo;Change Licence\u0026rsquo; In the following pop-up select the \u0026lsquo;Community Licence\u0026rsquo; option then click \u0026lsquo;Generate\u0026rsquo;  This process generates a licence and installs it for you. Now you are good to go!\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a Microsoft AKS cluster using either ‚Ä¶","ref":"/docs/install/azure/microsoft-azure-aks/","title":"Azure Kubernetes Service (AKS)"},{"body":"Overview This guide will demonstrate how to install Ondat onto a DigitalOcean Managed Kubernetes (DOKS) cluster using the Ondat kubectl plugin or Helm Chart\nPrerequisites 1 - Cluster and Node Prerequisites The minimum cluster requirements for a non-production installation of ondat are as follows:\n Linux with a 64-bit architecture. 2 vCPU and 4GB of RAM per node. 3 worker nodes in the cluster and sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster. Make sure your DOKS cluster version is greater than or equal to v1.21.10 or v1.22.7 as they will have the required kernel modules available for Ondat to run successfully. Ensure the following firewall ports are open: Firewalls and VPS providers.  For a comprehensive list of prerequisites and how to build a production installation of Ondat please refer to Ondat Prerequisites\n2 - Client Tools Prerequisites The following CLI utilities are installed on your local machine and available in your $PATH:\n kubectl  Ondat can be installed either via Helm Chart or using our command-line tool. Depending on which installation method you choose you will require either:\n kubectl-storageos CLI Helm 3 CLI  Installation of Ondat Step 1 - Adding a Cluster The Ondat Portal is how you can license and get the commands for installing Ondat\n Either login or create an account on the Ondat Portal Choose the \u0026lsquo;Install Ondat on your cluster\u0026rsquo; or \u0026lsquo;Add cluster\u0026rsquo; options in the UI Add a Name for your cluster and where it is going to be located. This will allow you to view the same prerequisites as are listed above  Step 2 - Choosing the Installation Method You can use either the kubectl-storageos CLI or Helm 3 CLI to install Ondat onto your cluster. The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below\nStep 3a - Installing via Helm The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.\nThe first two lines of the command adds the Ondat Helm repository and ensures a updated local cache. The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 3b - Installing via kubectl-storageos plugin The Ondat Portal UI will display the following cmd that can be used to install Ondat using the kubectl-storageos plugin. The command created will be unique for you and the screenshot below is just for reference.\nThe command that is provided by the Portal is unique to you and uses the kubectl-storageos plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 4 - Verifying Ondat Installation Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status).\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd kubectl get storageclasses | grep \u0026#34;storageos\u0026#34; Once all the components are up and running the output should look like this:\nStep 5 - Applying a Licence to the Cluster Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see here.\nTo licence your cluster with the community edition:\n On the Clusters page select \u0026lsquo;View Details\u0026rsquo; Click on \u0026lsquo;Change Licence\u0026rsquo; In the following pop-up select the \u0026lsquo;Community Licence\u0026rsquo; option then click \u0026lsquo;Generate\u0026rsquo;  This process generates a licence and installs it for you. Now you are good to go!\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a DigitalOcean Managed Kubernetes ‚Ä¶","ref":"/docs/install/digitalocean/digitalocean-kubernetes/","title":"DigitalOcean Kubernetes (DOKS)"},{"body":"Overview This guide will demonstrate how to install Ondat onto a Google Anthos cluster using the Ondat kubectl plugin.\nPrerequisites 1 - Cluster and Node Prerequisites The minimum requirements for the nodes are as follows:\n Linux with a 64-bit architecture. 2 vCPU and 4GB of RAM per node. 3 worker nodes in the cluster and sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster. Make sure your Google Anthos cluster uses ubuntu_containerd as the default node operating system. This node operating system image has the required kernel modules available for Ondat to run successfully. For a comprehensive list of prerequisites please refer to Ondat Prerequisites  2 - Client Tools Prerequisites The following CLI utilities are install on your local machine and available in your $PATH:\n kubectl  Ondat can be installed either via Helm Chart or using our command-line tool. Depending on which installation method you choose you will require either:\n kubectl-storageos CLI Helm 3 CLI  Procedure Step 1 - Choosing where your cluster is located The Ondat Portal is how you can license and get the commands for installing Ondat:\n Either login or create an account on the Ondat Portal https://portal.ondat.io/ Choose the \u0026lsquo;Install Ondat on your cluster\u0026rsquo; or \u0026lsquo;Add cluster\u0026rsquo; options in the UI Add a Name for your cluster and where it is going to be located. This will allow you to view the same prerequisites as are listed above  Step 2 - Choosing the Installation Method You can use either the kubectl-storageos CLI or Helm 3 CLI to install Ondat onto your cluster. The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below.\nStep 3a - Installing via Helm The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.\nThe first two lines of the command adds the Ondat Helm repository and ensures a updated local cache. The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 3b - Installing via kubectl-storageos plugin The Ondat Portal UI will display the following cmd that can be used to install Ondat using the kubectl-storageos plugin. The command created will be unique for you and the screenshot below is just for reference.\nThe command that is provided by the Portal is unique to you and uses the kubectl-storageos plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 4 - Verifying Ondat Installation Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status).\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd kubectl get storageclasses | grep \u0026#34;storageos\u0026#34; Once all the components are up and running the output should look like this:\nStep 5 - Applying a Licence to the Cluster Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see here.\nTo licence your cluster with the community edition:\n On the Clusters page select \u0026lsquo;View Details\u0026rsquo; Click on \u0026lsquo;Change Licence\u0026rsquo; In the following pop-up select the \u0026lsquo;Community Licence\u0026rsquo; option then click \u0026lsquo;Generate\u0026rsquo;  This process generates a licence and installs it for you. Now you are good to go!\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a Google Anthos cluster using the ‚Ä¶","ref":"/docs/install/gcp/anthos/","title":"Google Anthos"},{"body":"Over the past several months, we\u0026rsquo;ve been hard at work on Ondat V2, which contains some significant enhancements over our v1 product. We\u0026rsquo;ve built V2 based on our observations of trends in the industry, as well as our own experience.\nMany of our customers want to run big clusters - in the tens or hundreds of nodes. In these sorts of big environments, the challenges multiply. Not only do we need to scale well, but we also need to be more failure tolerant. Bigger environments typically suffer higher failure rates (more nodes = greater chance of something failing), but are also subject to all sorts of transient conditions such as network partitions.\nThe second trend we\u0026rsquo;ve seen become increasingly common is the desire to run multiple clusters, and consume storage between them in some way - sometimes to implement novel topologies such as a centralised storage cluster with satellites consuming the storage, and sometimes to replicate data between those clusters for HA or DR purposes.\nWe\u0026rsquo;ve built V2 with these architectures and design patterns in mind. Not only does it scale well, but it contains the foundations we need to implement a rich set of multi-cluster functionality.\nüöÄ Upgraded Control Plane At the heart of the V2 release is an upgraded control plane. We\u0026rsquo;ve changed a lot here. Firstly, our usage of etcd is vastly improved. We\u0026rsquo;ve learnt a lot about the subtleties of distributed consensus in the last year, particularly in noisy or unpredictable environments. Not only is Ondat V2 much lighter on your etcd cluster, but it\u0026rsquo;s a lot more tolerant of transient failure conditions that are often found in cloud environments, or clusters under heavy load.\nWe spent some time describing and testing our internal state machine using the TLA+ formal verification language. This allows us to have a much higher degree of confidence that our algorithms will behave correctly, particularly under hard-to-test edge cases and failure conditions.\nAdditionally, we\u0026rsquo;ve changed the way volumes behave with respect to centralised scheduling. Each volume group (consisting of a master and 0 or more replicas) now behaves as a strongly consistent unit allowing it to take action independent of the activities of the rest of the cluster. Other state can be distributed around the cluster using eventually consistent mechanisms. This approach inherently scales better and allows Ondat V2 to effectively manage many more nodes and volumes than before.\nWe\u0026rsquo;ve implemented TLS on all endpoints. Not only does this give you encrypted traffic between nodes in your storage cluster, it also protects all endpoints with strong, public key based authentication. Today\u0026rsquo;s IT environments can\u0026rsquo;t rely on firewalls to keep bad actors out - they must implement security at all layers within the stack - defense in depth. While we recognise that this brings a welcome relief to many security conscious administrators, we also know that managing certificate authorities (CAs) can be an unwelcome source of complexity. For this reason, Ondat V2 implements an internal CA by default, to manage this complexity for you. If you\u0026rsquo;d prefer to integrate your own CA, we support that too - it\u0026rsquo;s up to you.\nFinally - our logging has undergone a complete transformation in this edition. We know that systems engineers and operators don\u0026rsquo;t just value headline features, but that observability and diagnostics are equally important. All logs are now decorated with rich context to help you understand what is happening within your cluster, and we\u0026rsquo;ll output in json by default, for easy ingestion into log aggregators such as Elasticsearch.\nüöÄ Upgraded Data Plane Not to be outdone, our data plane contains some significant improvements.\nFirstly, we\u0026rsquo;ve completely re-written our sync algorithm (see Delta Sync, used when seeding or catching up replicas that have been offline or partitioned. Our new algorithm uses a Hash List to sync only changed sections of a volume (similar in some ways to what rsync does). Ondat maintains these hashes during normal operation, meaning that when resyncing a failed replica, for example after a node reboot, we can very quickly and efficiently catch this replica up, rather than needing to promote and build a new one from scratch. This improves resiliency within your cluster, and prevents using excessive network bandwidth during failover conditions - at a time when it might be needed the most.\nSecondly, a new threading model, with dynamic pool sizing, means that Ondat is faster, a lot faster. In our tests we observed improvements across the board, with improvements in throughput of up to 135% for some scenarios.\n","excerpt":"Over the past several months, we\u0026rsquo;ve been hard at work on Ondat V2, which contains some ‚Ä¶","ref":"/docs/introduction/overview/","title":"Ondat Overview"},{"body":"Overview This guide will demonstrate how to install Ondat onto an Openshift cluster using the Ondat kubectl plugin.\nPrerequisites  ‚ö†Ô∏è Make sure the prerequisites for Ondat are satisfied before proceeding. Including the deployment of an etcd cluster and configuration of CRI-O PID limits.\n  ‚ö†Ô∏è If you have installed OpenShift in AWS ensure that the requisite ports are opened for the worker nodes' security group.\n  ‚ö†Ô∏è Make sure to add an Ondat licence after installing. You can request a licence via the Ondat SaaS Platform.\n  üí° For OpenShift upgrades, refer to the OpenShift platform page.\n Ondat v2 supports OpenShift v4. For more information, see the OpenShift platform page.\ninstallation of Ondat via Red Hat Marketplace Step 1: Red Hat Markerplace  ‚ö†Ô∏è The installation of Ondat using the Red Hat Marketplace requires the Openshift cluster to be registered to the Marketplace Portal, including the roll out of the PullSecret in your cluster. Failure to do so will result in a image pull authentication failure with the Red Hat registry.\n   Select the OperatorHub from the Catalog sub menu and search for StorageOS.\n üí° Choose the RedHat Marketplace option.\n   Select StorageOS and click Purchase. Note that Openshift needs to be registered with the Red Hat Marketplace portal.\n  Select the relevant install option.\n üí° Project Edition is suitable for production workloads, Developer Edition for personal experimentation and evaluation.\n   Specify the product configuration to fit your needs.\n  Navigate to your software within Red Hat Marketplace and install the StorageOS software as specified in the image.\n  Install the Operator. Set the update approval strategy to Automatic to ensure that you always have the latest version of StorageOS installed.\n  The Ondat Operator is installed into your specified cluster.\nStep 2: Authentication   Create a Secret in the openshift-operators project and select the YAML option to create a secret containing the username and an password key. The username and password defined in the secret will be used to authenticate when using the Ondat CLI and GUI. Take note of which project you created the secret in.\nInput the secret as YAML for simplicity.\napiVersion:v1kind:Secretmetadata:name:storageos-apinamespace:openshift-operatorstype:\u0026#34;kubernetes.io/storageos\u0026#34;data:# echo -n \u0026#39;\u0026lt;secret\u0026gt;\u0026#39; | base64username:c3RvcmFnZW9zpassword:c3RvcmFnZW9z  Navigate to StorageOS on your Installed Operators tab.\n üí° Verify that the StorageOS Operator is installed.\n   Open to the StorageOS Cluster tab and click Create StorageOSCluster.\n üí° A StorageOSCluster is defined using a Custom Resource(CR) Definition.\n   Create the CR Definition:\nThe Ondat cluster resource describes the Ondat cluster that will be created. Parameters such as the secretRefName, the secretRefNamespace and the kvBackend.address are mandatory.\n üí° Additional spec parameters are available on the Operator configuration page.\n apiVersion: \u0026#34;storageos.com/v1\u0026#34; kind: StorageOSCluster metadata: name: storageos namespace: openshift-operators spec: # Ondat Pods are in kube-system by default secretRefName: \u0026#34;storageos-api\u0026#34; # Reference the Secret created in the previous step secretRefNamespace: \u0026#34;openshift-operators\u0026#34; # Namespace of the Secret created in the previous step k8sDistro: \u0026#34;openshift\u0026#34; kvBackend: address: \u0026#39;storageos-etcd-client.etcd:2379\u0026#39; # Example address, change for your etcd endpoint # address: \u0026#39;10.42.15.23:2379,10.42.12.22:2379,10.42.13.16:2379\u0026#39; # You can set ETCD server ips resources: requests: memory: \u0026#34;512Mi\u0026#34; cpu: 1 # nodeSelectorTerms: # - matchExpressions: # - key: \u0026#34;node-role.kubernetes.io/worker\u0026#34; # Compute node label will vary according to your installation # operator: In # values: # - \u0026#34;true\u0026#34;   Verify that the StorageOS Cluster status is Running.\n üí° It can take up to a minute to report the Ondat Pods ready.\n   Check the StorageOS Pods in the kube-system project.\n üí° A Status of 3/3 in the Ready column for the Daemonset Pods indicates that Ondat is bootstrapped successfully.\n   License cluster  ‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.\n To obtain a license, follow the instructions on our licensing operations page.\nFirst Ondat volume If this is your first installation you may wish to follow the Ondat volume guide for an example of how to mount an Ondat volume in a Pod.\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto an Openshift cluster using the Ondat ‚Ä¶","ref":"/docs/install/openshift/openshift-marketplace/","title":"OpenShift via Marketplace"},{"body":"Overview This guide will demonstrate how to install Ondat onto a Rancher Kubernetes Engine (RKE) cluster using either the Ondat kubectl plugin or Helm Chart\nPrerequisites 1 - Cluster and Node Prerequisites The minimum requirements for the nodes are as follows:\n Linux with a 64-bit architecture 2 vCPU and 4GB of RAM per node. 3 worker nodes in the cluster and sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster Make sure your RKE cluster uses a Linux distribution that is officially supported by Rancher as your node operating system and has the required LinuxIO related kernel modules are available for Ondat to run successfully. A strong recommendation would be to review SUSE Rancher Support Matrix documentation to ensure that you are using a supported Linux distribution.  For a comprehensive list of prerequisites and how to build a production installation of Ondat please refer to Ondat Prerequisites\n2 - Installing a Local Path Provisioner By default, a newly provisioned RKE cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a Local Path Provisioner and make it the default storageclass to provide local storage for Ondat\u0026rsquo;s embedded etcd cluster operator deployment.\nkubectl apply --filename=\u0026#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.22/deploy/local-path-storage.yaml\u0026#34; kubectl patch storageclass local-path -p \u0026#39;{\u0026#34;metadata\u0026#34;: {\u0026#34;annotations\u0026#34;:{\u0026#34;storageclass.kubernetes.io/is-default-class\u0026#34;:\u0026#34;true\u0026#34;}}}\u0026#39; Verify that the Local Path Provisioner was successfully deployed and ensure that that the deployment is in a RUNNING status, run the following kubectl commands.\nkubectl get pod --namespace=local-path-storage kubectl get storageclass 3 - Client Tools Prerequisites The following CLI utilities are installed on your local machine and available in your $PATH:\n kubectl  Ondat can be installed either via Helm Chart or using our command-line tool. Depending on which installation method you choose you will require either:\n kubectl-storageos CLI Helm 3 CLI  Installation of Ondat Step 1 - Adding a Cluster The Ondat Portal is how you can license and get the commands for installing Ondat\n Either login or create an account on the Ondat Portal Choose the \u0026lsquo;Install Ondat on your cluster\u0026rsquo; or \u0026lsquo;Add cluster\u0026rsquo; options in the UI Add a Name for your cluster and where it is going to be located. This will allow you to view the same prerequisites as are listed above  Step 2 - Choosing the Installation Method You can use either the kubectl-storageos CLI or Helm 3 CLI to install Ondat onto your cluster. The most common way is to use Helm due to its popularity in the Kubernetes community, but both are fully supported and described below.\nStep 3a - Installing via Helm The Ondat Portal UI will display the following cmd that can be used to install Ondat using Helm. The command created will be unique for you and the screenshot below is just for reference.\nThe first two lines of the command adds the Ondat Helm repository and ensures a updated local cache. The remaining command installs Ondat via Helm with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 3b - Installing via kubectl-storageos plugin The Ondat Portal UI will display the following cmd that can be used to install Ondat using the kubectl-storageos plugin. The command created will be unique for you and the screenshot below is just for reference.\nThe command that is provided by the Portal is unique to you and uses the kubectl-storageos plugin command with a set of basic install parameters that are sufficient for a basic trial installation and to connect the Ondat installation with your portal account for licensing. The installation process may take a few minutes. The end of this guide contains information on verifying the installation and licensing.\nStep 4 - Verifying Ondat Installation Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status)\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd kubectl get storageclasses | grep \u0026#34;storageos\u0026#34; Once all the components are up and running the output should look like this:\nStep 5 - Applying a Licence to the Cluster Newly installed Ondat clusters must be licensed within 24 hours. For details of our Community Edition and pricing see here.\nTo licence your cluster with the community edition:\n On the Clusters page select \u0026lsquo;View Details\u0026rsquo; Click on \u0026lsquo;Change Licence\u0026rsquo; In the following pop-up select the \u0026lsquo;Community Licence\u0026rsquo; option then click \u0026lsquo;Generate\u0026rsquo;  This process generates a licence and installs it for you. Now you are good to go!\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a Rancher Kubernetes Engine (RKE) ‚Ä¶","ref":"/docs/install/rancher/rancher/","title":"Rancher Kubernetes Engine (RKE)"},{"body":"Overview This guide will demonstrate how to install Ondat onto a Rancher Kubernetes Engine (RKE) cluster using either the Ondat kubectl plugin or Helm Chart\nPrerequisites 1 - Cluster and Node Prerequisites The minimum cluster requirements for a non-production installation of ondat are as follows:\n Linux with a 64-bit architecture. 2 vCPU and 4GB of RAM per node. 3 worker nodes in the cluster and sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster. Make sure your RKE cluster uses a Linux distribution that is officially supported by Rancher as your node operating system and has the required LinuxIO related kernel modules are available for Ondat to run successfully. A strong recommendation would be to review SUSE Rancher Support Matrix documentation to ensure that you are using a supported Linux distribution.  For a comprehensive list of prerequisites and how to build a production installation of Ondat please refer to Ondat Prerequisites\n2 - Installing a Local Path Provisioner By default, a newly provisioned RKE cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a Local Path Provisioner and make it the default storageclass to provide local storage for Ondat\u0026rsquo;s embedded etcd cluster operator deployment.\nkubectl apply --filename=\u0026#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.22/deploy/local-path-storage.yaml\u0026#34; kubectl patch storageclass local-path -p \u0026#39;{\u0026#34;metadata\u0026#34;: {\u0026#34;annotations\u0026#34;:{\u0026#34;storageclass.kubernetes.io/is-default-class\u0026#34;:\u0026#34;true\u0026#34;}}}\u0026#39; Verify that the Local Path Provisioner was successfully deployed and ensure that that the deployment is in a RUNNING status, run the following kubectl commands.\nkubectl get pod --namespace=local-path-storage kubectl get storageclass 3 - Client Tools Prerequisites The following CLI utilities are installed on your local machine and available in your $PATH:\n kubectl  Ondat can be installed either via Helm Chart or using our command-line tool. Depending on which installation method you choose you will require either:\n kubectl-storageos CLI Helm 3 CLI  Installing Ondat Using Rancher\u0026rsquo;s Apps \u0026amp; Marketplace Step 1 - Setup An etcd Cluster   Ensure that you have an etcd cluster deployed first before installing Ondat through the Helm chart located on Apps \u0026amp; Marketplace. There are two different methods listed below with instructions on how to deploy an etcd cluster;\n Embedded Deployment - deploy an etcd cluster operator into your RKE cluster, recommended for non production environments. External Deployment - deploy an etcd cluster in dedicated virtual machines, recommended for production environments.    Once you have an etcd cluster up and running, ensure that you note down the list of etcd endpoints as comma-separated values that will be used when configuring Ondat in Step 3.\n For example, 203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379    Step 2 - Locate Ondat Operator Helm Chart  In the Rancher UI, under the RKE cluster where Ondat will be deployed - select the Menu button in the top-left corner of the page and then select Apps \u0026amp; Marketplace. Under Apps \u0026amp; Marketplace, a Charts page will be displayed where you can locate the Ondat Operator Helm chart by searching for \u0026ldquo;Ondat\u0026rdquo; in the search filter box. Once you have located the Ondat Operator Helm chart, select the chart. This will direct you to a page showing you more information about the Ondat Operator and how to install it. Select the Install button.  Step 3 - Customising \u0026amp; Installing The Helm Chart   Upon selecting the Install button in the previous step, you will be directed to a page to configure the Application Metadata. Define the namespace and application name where Ondat will be deployed and click Next.\n   Parameter Value Description     Namespace storageos Namespace name for the deployment.   Name ondat-operator Application name for the deployment.      The next page will allow you to configure the Ondat Operator through Helm chart values. Under Edit Options, you are provided with 3 configurable sections called;\n Questions Container Images StorageOS Cluster    Select the StorageOS Cluster section. This will show you a form with configurable parameters that have predefined values for an Ondat deployment. Below are following parameters that will need to be populated before beginning the installation;\n   Parameter Value Description     Password $STORAGEOS_PASSWORD Password of the StorageOS administrator account. Must be at least 8 characters long, for example \u0026gt; storageos   External etcd address(es) $ETCD_ENDPOINTS List of etcd endpoints as comma-separated values. Prefer multiple direct endpoints over a single load-balanced endpoint, for example \u0026gt; 203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379     üí° Advanced Users - For users who are looking to make further customisations to the Helm chart through additional configurable parameters or import your own StorageOSCluster custom resource manifest, review the Ondat Operator README.md document, Operator Configuration and Operator Examples reference pages for more information.\n   Once the parameters have been successfully populated, select Install to deploy Ondat.\n  Step 4 - Verifying Ondat Installation   Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status)\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd # only if the etcd cluster was deployed inside the RKE cluster. kubectl get storageclasses | grep \u0026#34;storageos\u0026#34;   Applying a Licence to the Cluster  ‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.\n To obtain a licence, follow the instructions on our licensing operations page.\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a Rancher Kubernetes Engine (RKE) ‚Ä¶","ref":"/docs/install/rancher/rancher-marketplace/","title":"Rancher Kubernetes Engine (RKE) via Marketplace"},{"body":"StorageOSCluster Resource Configuration The following table lists the configurable spec parameters of the StorageOSCluster custom resource and their default values.\n   Parameter Description Default     csi.deploymentStrategy CSI helper deployment strategy (statefulset or deployment) statefulset   csi.enable Enable CSI setup false   csi.enableControllerPublishCreds Enable CSI controller publish credentials false   csi.enableNodePublishCreds Enable CSI node publish credentials false   csi.enableProvisionCreds Enable CSI provision credentials false   debug Enable debug mode for all the cluster nodes false   disableTelemetry Disable telemetry reports false   images.apiManagerContainer Ondat API Manager container image storageos/api-manager:v1.0.0   images.csiClusterDriverRegistrarContainer CSI Cluster Driver Registrar Container image quay.io/k8scsi/csi-cluster-driver-registrar:v1.0.1   images.csiExternalAttacherContainer CSI External Attacher Container image quay.io/k8scsi/csi-attacher:v1.0.1   images.csiExternalProvisionerContainer CSI External Provisioner Container image storageos/csi-provisioner:v1.0.1   √¨mages.csiLivenessProbeContainer CSI Liveness Probe Container Image quay.io/k8scsi/livenessprobe:v1.0.1   images.csiNodeDriverRegistrarContainer CSI Node Driver Registrar Container image quay.io/k8scsi/csi-node-driver-registrar:v1.0.1   images.hyperkubeContainer Deprecated field - HyperKube Container image Default dependent on Scheduler version   images.initContainer Ondat init container image storageos/init:2.1.0   images.kubeSchedulerContainer Kube scheduler container image Default dependent on Scheduler version   images.nfsContainer Ondat nfs container image storageos/nfs:1.0.0   images.nodeContainer Ondat node container image storageos/node:v2.7.0   k8sDistro The name of the Kubernetes distribution is use, e.g. rancher or eks    kvBackend.address Comma-separated list of addresses of external key-value store. (1.2.3.4:2379,2.3.4.5:2379)    kvBackend.backend (v2 deprecated) Name of the key-value store to use. Set to etcd for external key-value store. embedded   nodeSelectorTerms Set node selector for storageos pod placement    resources Set resource requirements for the containers    secretRefName Reference name of storageos secret within the namespace    service.annotations Annotations of the Service used by the cluster    service.externalPort External port of the Service used by the cluster 5705   service.internalPort Internal port of the Service used by the cluster 5705   service.name Name of the Service used by the cluster storageos   service.type Type of the Service used by the cluster ClusterIP   sharedDir Path to be shared with kubelet container when deployed as a pod /var/lib/kubelet/plugins/kubernetes.io~storageos   storageClassName The name of the default StorageClass created for Ondat volumes storageos   tlsEtcdSecretRefName Secret containing etcd client certificates    tolerations Set pod tolerations for storageos pod placement     ","excerpt":"StorageOSCluster Resource Configuration The following table lists the configurable spec parameters ‚Ä¶","ref":"/docs/reference/operator/configuration/","title":"Configuration"},{"body":"The Dashboard gives you an unified and summarised view of the application you have deployed. If there are any persistent volumes in error this will be indicated on the dashboard as a red side line next to the application name and will also give you the number of affected volumes.\nYour deployed application can be one of the following types:\n  Replica - ensures that one or more pods are running at any given time, according to configuration. Usually, ReplicaSets are managed by Deployments.\n  StatefulSet - represents a stateful application that both manages one or more pods, ensures that they are running at any given time and provides certain guarantees about the order and uniqueness of the pods.\n  Deployment - provides a desired state for one or more sets of pods without guaranteeing order or uniqueness.\nTo view more details about each application, go to the Applications tab.\n  ","excerpt":"The Dashboard gives you an unified and summarised view of the application you have deployed. If ‚Ä¶","ref":"/docs/ondat-portal/dashboard/","title":" Dashboard Page Reference"},{"body":"Overview If you are running kubernetes in GCP there are a number of options on how you run your kubernetes cluster. Please see the following datasheets and blogs for more information about some of the use-cases of running in GCP.\n Whitepaper: Ondat Platform Architecture Overview Datasheet: Ondat for Google Anthos  ","excerpt":"Overview If you are running kubernetes in GCP there are a number of options on how you run your ‚Ä¶","ref":"/docs/install/gcp/","title":"GCP"},{"body":"Overview If you are running Rancher there are a number of options on how you run your kubernetes cluster. Please see the following datasheets and blogs for more information about some of the use-cases of running Ondat in Rancher.\n Whitepaper: Ondat Platform Architecture Overview Blog: Ondat and SUSE Rancher - Run your stateful applications everywhere  ","excerpt":"Overview If you are running Rancher there are a number of options on how you run your kubernetes ‚Ä¶","ref":"/docs/install/rancher/","title":"Rancher"},{"body":"Overview This guide will demonstrate how to install Ondat onto a Rancher Kubernetes Engine 2 (RKE2), also known as RKE Government, cluster using the Ondat kubectl plugin.\nPrerequisites  ‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main Ondat prerequisites page for more information.\n  ‚ö†Ô∏è Make sure the following CLI utilities are installed on your local machine and are available in your $PATH:\n  kubectl kubectl-storageos   ‚ö†Ô∏è Make sure to add an Ondat licence after installing. You can request a licence via the Ondat SaaS Platform.\n  ‚ö†Ô∏è Make sure you have a running RKE2 cluster with a minimum of 5 worker nodes and the sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster.\n  ‚ö†Ô∏è Make sure your RKE2 cluster uses a Linux distribution that is officially supported by RKE2 as your node operating system and the required LinuxIO related kernel modules are available for Ondat to run successfully. A strong recommendation would be to review RKE2 Operating System Requirements documentation to ensure that you are using a supported Linux distribution.\n Procedure Step 1 - Install Local Path Provisioner  By default, a newly provisioned RKE2 cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a Local Path Provisioner to provide local storage for Ondat\u0026rsquo;s embedded etcd cluster operator deployment.  kubectl apply --filename=\u0026#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml\u0026#34; Define and export the ETCD_STORAGECLASS environment variable so that value is local-path, which is the default StorageClass name for the Local Path Provisioner.  export ETCD_STORAGECLASS=\u0026#34;local-path\u0026#34; Verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a RUNNING status, run the following kubectl commands.  kubectl get pod --namespace=local-path-storage kubectl get storageclass  ‚ö†Ô∏è The local-path StorageClass is only recommended for non production clusters as this stores all the data of the etcd peers locally, which makes it susceptible to state being lost on node failures.\n Step 2 - Conducting Preflight Checks  Run the following command to conduct preflight checks against the RKE2 cluster to validate that Ondat prerequisites have been met before attempting an installation.  kubectl storageos preflight Step 3 - Installing Ondat  Define and export the STORAGEOS_USERNAME and STORAGEOS_PASSWORD environment variables that will be used to manage your Ondat instance.  export STORAGEOS_USERNAME=\u0026#34;storageos\u0026#34; export STORAGEOS_PASSWORD=\u0026#34;storageos\u0026#34; Run the following kubectl-storageos plugin command to install Ondat.  kubectl storageos install \\  --include-etcd \\  --etcd-tls-enabled \\  --etcd-storage-class=\u0026#34;$ETCD_STORAGECLASS\u0026#34; \\  --admin-username=\u0026#34;$STORAGEOS_USERNAME\u0026#34; \\  --admin-password=\u0026#34;$STORAGEOS_PASSWORD\u0026#34;  The installation process may take a few minutes.  Step 4 - Verifying Ondat Installation  Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status)  kubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd kubectl get storageclasses | grep \u0026#34;storageos\u0026#34; Step 5 - Applying a Licence to the Cluster  ‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.\n To obtain a licence, follow the instructions on our licensing operations page.\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a Rancher Kubernetes Engine 2 (RKE2), ‚Ä¶","ref":"/docs/install/rancher/rancher-gov/","title":"Rancher Kubernetes Engine 2 (RKE2)"},{"body":"The Applications tab displays all of your applications. For a detailed explanation of the view, refer to the table below:\n   Column Description Possible Values     App Name The name of the app String (can contain special characters)   Kind Indicates the kind of application. Replica StatefulSet Deployment   Pods The number of pods for your application Integer   Pod Status Indicates the number of pods that are ready/syncing or with unknown/failed status Ready Syncing Unknown Failed   PV Amount Indicates the amount of PVs taken up by the app Integer   PVs Size Indicates the size of all Persistent volumes as a percentage of all available storage on all pods Available GB on the pods   PVs Status Indicates the number of PVs that are ready/syncing or with unknown/failed status Ready Syncing Unknown Failed    Detailed View of the Application To view more details of your application, click View Details and you will be given an overview of the status of the app.\n","excerpt":"The Applications tab displays all of your applications. For a detailed explanation of the view, ‚Ä¶","ref":"/docs/ondat-portal/applications/","title":" Applications Page Reference"},{"body":"Before deploying an Ondat cluster, create a Secret to define the Ondat API Username and Password in base64 encoding.\nkubectl create -f - \u0026lt;\u0026lt;END apiVersion: v1 kind: Secret metadata: name: \u0026#34;storageos-api\u0026#34; namespace: \u0026#34;default\u0026#34; labels: app: \u0026#34;storageos\u0026#34; type: \u0026#34;kubernetes.io/storageos\u0026#34; data: username: c3RvcmFnZW9z password: c3RvcmFnZW9z END This example contains a default password, for production installations, use a unique, strong password.\n Make sure that the encoding of the credentials doesn\u0026rsquo;t have special characters such as \u0026lsquo;\\n\u0026rsquo;.\n  You can define a base64 value by echo -n \u0026quot;mystring\u0026quot; | base64.\n Create a cluster-config.yaml according to your needs from the examples below.\nkubectl create -f cluster-config.yaml Note that Ondat will be deployed in spec.namespace (storageos by default), irrespective of what NameSpace the CR is defined in.\n¬†Examples  You can checkout all the parameters configurable in the configuration page.\n All examples must reference the storageos-api Secret.\nspec:secretRefName:\u0026#34;storageos-api\u0026#34;# Reference to the Secret created in the previous stepInstalling with an external etcd spec:kvBackend:address:\u0026#39;10.43.93.95:2379\u0026#39;# IP of the SVC that exposes ETCD# address: \u0026#39;10.42.15.23:2379,10.42.12.22:2379,10.42.13.16:2379\u0026#39; # You can specify individual IPs of the etcd serversIf using Etcd with mTLS, it is required to create the secret with the TLS material on the same namespace as the StorageOSCluster resource. Reference it\u0026rsquo;s name with the following parameter:\nspec:# External mTLS secured etcd cluster specific propertiestlsEtcdSecretRefName:\u0026#34;storageos-etcd-secret\u0026#34;# Secret containing etcd client certificates, within the StorageOSCluster CR namespaceFollow the etcd operations page to setup the secret with the Etcd client certificate, client key and CA.\nInstalling to a subset of nodes In this case we select nodes that are workers. To make sure that Ondat doesn\u0026rsquo;t start in Master nodes.\nYou can see the labels in the nodes by kubectl get node --show-labels.\nspec:nodeSelectorTerms:- matchExpressions:- key:\u0026#34;node-role.kubernetes.io/worker\u0026#34;operator:Invalues:- \u0026#34;true\u0026#34;# OpenShift uses \u0026#34;node-role.kubernetes.io/compute=true\u0026#34;# Rancher uses \u0026#34;node-role.kubernetes.io/worker=true\u0026#34;# Kops uses \u0026#34;node-role.kubernetes.io/node=\u0026#34; Different provisioners and Kubernetes distributions use node labels differently to specify master vs workers. Node Taints are not enough to make sure Ondat doesn\u0026rsquo;t start in a node. The JOIN variable is defined by the operator by selecting all the nodes that match the nodeSelectorTerms.\n Specifying a shared directory for use with kubelet as a container spec:sharedDir:\u0026#39;/var/lib/kubelet/plugins/kubernetes.io~storageos\u0026#39;Defining pod resource requests and reservations spec:resources:requests:memory:\u0026#34;512Mi\u0026#34;# cpu: \u0026#34;1\u0026#34;# limits:# memory: \u0026#34;4Gi\u0026#34;We have the following limits for all of our components:\nname:api-managerresources:limits:cpu:250mmemory:200Mirequests:cpu:10mmemory:100Miname:provisionersecurityContext:privileged:trueresources:limits:cpu:100mmemory:100Mirequests:cpu:5mmemory:30Miname:attacherresources:limits:cpu:50mmemory:100Mirequests:cpu:1mmemory:30Miname:resizerresources:limits:cpu:50mmemory:100Mirequests:cpu:1mmemory:30Miname:storageos-schedulerresources:limits:cpu:100mmemory:200Mirequests:cpu:10mmemory:50MiSpecifying custom Tolerations spec:tolerations:- key:\u0026#34;key1\u0026#34;operator:\u0026#34;Equal\u0026#34;value:\u0026#34;value1\u0026#34;effect:\u0026#34;EffectToTolerate\u0026#34;- key:\u0026#34;key2\u0026#34;operator:\u0026#34;Exists\u0026#34;Custom tolerations specified in the StorageOSCluster definition are added to all Ondat components; the Ondat daemonset, CSI helper and scheduler.\nIn the above example a toleration key1=value1:EffectToTolerate would be tolerated and key2 would be tolerated regardless of the value and effect. For more information about tolerations see the Kubernetes documentation.\n","excerpt":"Before deploying an Ondat cluster, create a Secret to define the Ondat API Username and Password in ‚Ä¶","ref":"/docs/reference/operator/examples/","title":"Operator examples"},{"body":"Overview If you are running Kubernetes in Azure there are a number of options on how you run your kubernetes cluster. See the following datasheets and blogs for more information about some of the use-cases of running in Azure.\n Whitepaper: Ondat Platform Architecture Overview Datasheet: Ondat for AKS Webinar: Deploying stateful applications in an AKS cluster  ","excerpt":"Overview If you are running Kubernetes in Azure there are a number of options on how you run your ‚Ä¶","ref":"/docs/install/azure/","title":"Azure"},{"body":"OS  Linux X86_64 Kernels satisfying our module prerequisites 3.x kernels have a limitation of 256 active volumes per node 4.x kernels have a limitation of 4096 active volumes per node We are distribution agnostic as long as our prerequisites are met  Orchestrators  Kubernetes 1.19 to 1.23 OpenShift 4.0+  ","excerpt":"OS  Linux X86_64 Kernels satisfying our module prerequisites 3.x kernels have a limitation of 256 ‚Ä¶","ref":"/docs/introduction/platforms/","title":"Supported Platforms and Orchestrators"},{"body":"Overview If you are running kubernetes in Digital Ocean there are a number of options on how you run your kubernetes cluster. Please see the following datasheets and blogs for more information about some of the use-cases of running in Digital Ocean.\n Whitepaper: Ondat Platform Architecture Overview  ","excerpt":"Overview If you are running kubernetes in Digital Ocean there are a number of options on how you run ‚Ä¶","ref":"/docs/install/digitalocean/","title":"DigitalOcean"},{"body":"Overview If you are running OpenShift there are a number of options on how you run your kubernetes cluster. Please see the following datasheets and blogs for more information about some of the use-cases of running Ondat in OpenShift.\n Whitepaper: Ondat Platform Architecture Overview Webinar: Run production databases on Red Hat Openshift Webinar: Run production databases on OpenShift with Ondat Blog: Installing on OpenShift  ","excerpt":"Overview If you are running OpenShift there are a number of options on how you run your kubernetes ‚Ä¶","ref":"/docs/install/openshift/","title":"OpenShift"},{"body":"Overview The guides below are recommended for users who are experiened in deploying infrastructure and applications in constrained environments and following Infrastructure as Code (IaC) principles.\n","excerpt":"Overview The guides below are recommended for users who are experiened in deploying infrastructure ‚Ä¶","ref":"/docs/install/advanced/","title":"Advanced"},{"body":"Overview This guide will demonstrate how to install Ondat onto clusters that don\u0026rsquo;t have direct access to the internet - i.e., air-gapped environments. Air-gapped environments require cluster administrators to explicitly ensure that Ondat components are locally available before the installation.\nüí° This guide is recommended for advanced users who have experience and permissions to be able to manage air-gapped deployments in their environment. The full procedure for this deployment method is estimated to take ~60 minutes to complete.\nBelow is a quick summary of the procedure that will be covered in this guide:\n Install the Ondat kubectl plugin. Generate the Ondat deployment manifests for your use case. Push Ondat container images to your private registry. Modify the Ondat deployment manifests. Install Ondat onto your air-gapped cluster.  Prerequisites  Make sure you have met the minimum resource requirements for Ondat so your set up would be successful. Review the main Ondat prerequisites page for more information. Make sure the following CLI utility is installed on your local machine and is available in your $PATH: kubectl Make sure to add an Ondat licence after installing. You can request a licence via the Ondat SaaS Platform. Make sure you have a running Kubernetes cluster with a minimum of 5 worker nodes and the sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster. Make sure your Kubernetes cluster uses a Linux distribution that is officially supported by Ondat as your node operating system. Make sure that the node operating system have the required LinuxIO related kernel modules are available for Ondat to run successfully.  Procedure Step 1 - Install Ondat Kubectl Plugin  Ensure that the Ondat kubectl plugin is installed on your local machine and is available in your $PATH:  kubectl-storageos    Step 2 - Conducting Preflight Checks   Run the following command to conduct preflight checks against the Kubernetes cluster to validate that Ondat prerequisites have been met before attempting an installation.\nkubectl storageos preflight   Step 3 - Generate Ondat Deployment Manifests Option A - Using An Embedded etcd Deployment Install Local Path Provisioner   By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a Local Path Provisioner to provide local storage for Ondat\u0026rsquo;s embedded etcd cluster operator deployment.\n üí° Different Kubernetes distributions may include a CSI driver as part of the deployment. Cluster administrators can leverage the CSI driver provided by their distribution if they don‚Äôt want to use a Local Path Provisioner. If so, ensure that the ETCD_STORAGECLASS environment variable points to the correct value for your Kubernetes distribution‚Äôs default StorageClass name.\n # Download the Local Path Provisioner. wget https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml # Get the list of images and push them to your private registry. grep \u0026#34;image:\u0026#34; local-path-storage.yaml # Modify the manifest and add the private registry URL to pull the images. vi local-path-storage.yaml # Deploy the Local Path Provisioner. kubectl apply --filename=local-path-storage.yaml   Define and export the ETCD_STORAGECLASS environment variable so that value is local-path, which is the default StorageClass name for the Local Path Provisioner.\nexport ETCD_STORAGECLASS=\u0026#34;local-path\u0026#34;   Verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a RUNNING status, run the following kubectl commands.\nkubectl get pod --namespace=local-path-storage kubectl get storageclass    ‚ö†Ô∏è The local-path StorageClass is only recommended for non-production clusters, as this stores all the data of the etcd peers locally, which makes it susceptible to its state being lost on node failures.\n Generate Manifests   Define and export the STORAGEOS_USERNAME and STORAGEOS_PASSWORD environment variables that will be used to manage your Ondat instance. In addition, define and export a KUBERNETES_VERSION environment variable, where the value will be the exact version of your Kubernetes cluster where Ondat is going to be deployed - for example, v1.23.5.\nexport STORAGEOS_USERNAME=\u0026#34;storageos\u0026#34; export STORAGEOS_PASSWORD=\u0026#34;storageos\u0026#34; export KUBERNETES_VERSION=\u0026#34;v1.23.5\u0026#34;   Run the following kubectl-storageos plugin command with the --dry-run flag to generate the Ondat deployment Kubernetes manifests in a directory, called storageos-dry-run.\nkubectl storageos install \\  --dry-run \\  --include-etcd \\  --etcd-tls-enabled \\  --etcd-storage-class=\u0026#34;$ETCD_STORAGECLASS\u0026#34; \\  --k8s-version=\u0026#34;$KUBERNETES_VERSION\u0026#34; \\  --admin-username=\u0026#34;$STORAGEOS_USERNAME\u0026#34; \\  --admin-password=\u0026#34;$STORAGEOS_PASSWORD\u0026#34;   To review the list of manifests generated in the newly created storageos-dry-run directory, run the following commands.\ncd storageos-dry-run/ ls   Option B - Using An External etcd Deployment Setup An etcd Cluster  Ensure that you have an etcd cluster deployed first before installing Ondat. For instructions on how to set up an external etcd cluster, review the etcd documentation page. Once you have an etcd cluster up and running, ensure that you note down the list of etcd endpoints as comma-separated values that will be used when configuring Ondat.  For example, 203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379    Generate Manifests   Define and export the STORAGEOS_USERNAME and STORAGEOS_PASSWORD environment variables that will be used to manage your Ondat instance. In addition, define and export a KUBERNETES_VERSION environment variable, where the value will be the exact version of your Kubernetes cluster where Ondat is going to be deployed - for example, v1.23.5. Lastly, define and export a ETCD_ENDPOINTS environment variable, where the value will be a list of etcd endpoints as comma-separated values.\nexport STORAGEOS_USERNAME=\u0026#34;storageos\u0026#34; export STORAGEOS_PASSWORD=\u0026#34;storageos\u0026#34; export KUBERNETES_VERSION=\u0026#34;v1.23.5\u0026#34; export ETCD_ENDPOINTS=\u0026#34;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379\u0026#34;   Run the following kubectl-storageos plugin command with the --dry-run flag to generate the Ondat deployment Kubernetes manifests in a directory, called storageos-dry-run.\nkubectl storageos install \\  --dry-run \\  --skip-etcd-endpoints-validation \\  --etcd-endpoints=\u0026#34;$ETCD_ENDPOINTS\u0026#34; \\  --k8s-version=\u0026#34;$KUBERNETES_VERSION\u0026#34; \\  --admin-username=\u0026#34;$STORAGEOS_USERNAME\u0026#34; \\  --admin-password=\u0026#34;$STORAGEOS_PASSWORD\u0026#34;   To review the list of manifests generated in the newly created storageos-dry-run directory, run the following commands.\ncd storageos-dry-run/ ls   Step 4 - Push Ondat Images To Private Registry   Get the list of all the container images required for Ondat to be deployed successfully and push them to your private registry which will be accessible through your air-gapped environment.\ngrep --extended-regexp \u0026#34;RELATED|image:\u0026#34; *.yaml   You will also need to pull the kubernetes scheduler image for your release and push that to your private registry.\nexport KUBERNETES_VERSION=\u0026#34;v1.23.5\u0026#34; docker pull k8s.gcr.io/kube-scheduler:${KUBERNETES_VERSION}   Step 5 - Modify Deployment Manifests   etcd-operator - Modify the 2-etcd-operator.yaml manifest and apply the following changes.\n  Locate the storageos-etcd-controller-manager Deployment YAML, navigate to manager container and locate the args section.\n  In this section, add a flag called --etcd-repository= where the value will be your $PRIVATE_REGISTRY_URL/quay.io/coreos/etcd. For example;\n# Before modification.spec:containers:- args:- --enable-leader-election- --proxy-url=storageos-proxy.storageos-etcd.svc# After modification.spec:containers:- args:- --enable-leader-election- --proxy-url=storageos-proxy.storageos-etcd.svc- --etcd-repository=$PRIVATE_REGISTRY_URL/quay.io/coreos/etcd     etcd-cluster - Modify the 3-etcd-cluster.yaml manifest and apply the following changes.\n  Locate the storageos-etcd CustomResource YAML, navigate to the storage section and set the storage size value from 1Gi to 256Gi. For example;\n# Before modification.storage:volumeClaimTemplate:resources:requests:storage:1Gi# After modification.storage:volumeClaimTemplate:resources:requests:storage:256Gi    storageos-operator - Modify the 0-storageos-operator.yaml manifest and apply the following changes.\n  Locate the storageos-operator Deployment YAML, navigate to the manager and kube-rbac-proxy containers. Proceed to change the existing image registry URLs to point to your private registry URLs where the Ondat images reside. For example;\n# Before modification.name:managerimage:storageos/operator:v2.7.0name:kube-rbac-proxyimage:quay.io/brancz/kube-rbac-proxy:v0.10.0# After modification.name:managerimage:$PRIVATE_REGISTRY_URL/operator:v2.7.0name:kube-rbac-proxyimage:$PRIVATE_REGISTRY_URL/brancz/kube-rbac-proxy:v0.10.0  Locate the storageos-related-images ConfigMap YAML, navigate to the environment variables that are prefixed with RELATED_IMAGE_. Proceed to change the existing image registry URLs to point to your private registry URLs where the Ondat images reside. For example;\n# Before modification.kind:ConfigMapdata:RELATED_IMAGE_API_MANAGER:storageos/api-manager:v1.2.9RELATED_IMAGE_CSIV1_EXTERNAL_ATTACHER_V3:quay.io/k8scsi/csi-attacher:v3.1.0RELATED_IMAGE_CSIV1_EXTERNAL_PROVISIONER:storageos/csi-provisioner:v2.1.1-patchedRELATED_IMAGE_CSIV1_EXTERNAL_RESIZER:quay.io/k8scsi/csi-resizer:v1.1.0RELATED_IMAGE_CSIV1_LIVENESS_PROBE:quay.io/k8scsi/livenessprobe:v2.2.0RELATED_IMAGE_CSIV1_NODE_DRIVER_REGISTRAR:quay.io/k8scsi/csi-node-driver-registrar:v2.1.0RELATED_IMAGE_NODE_MANAGER:storageos/node-manager:v0.0.6RELATED_IMAGE_PORTAL_MANAGER:storageos/portal-manager:v1.0.2RELATED_IMAGE_STORAGEOS_INIT:storageos/init:v2.1.2RELATED_IMAGE_STORAGEOS_NODE:storageos/node:v2.7.0RELATED_IMAGE_NODE_GUARD:storageos/node-guard:v0.0.4# After modification.kind:ConfigMapdata:RELATED_IMAGE_API_MANAGER:$PRIVATE_REGISTRY_URL/api-manager:v1.2.9RELATED_IMAGE_CSIV1_EXTERNAL_ATTACHER_V3:$PRIVATE_REGISTRY_URL/k8scsi/csi-attacher:v3.1.0RELATED_IMAGE_CSIV1_EXTERNAL_PROVISIONER:$PRIVATE_REGISTRY_URL/csi-provisioner:v2.1.1-patchedRELATED_IMAGE_CSIV1_EXTERNAL_RESIZER:$PRIVATE_REGISTRY_URL/k8scsi/csi-resizer:v1.1.0RELATED_IMAGE_CSIV1_LIVENESS_PROBE:$PRIVATE_REGISTRY_URL/livenessprobe:v2.2.0RELATED_IMAGE_CSIV1_NODE_DRIVER_REGISTRAR:$PRIVATE_REGISTRY_URL/k8scsi/csi-node-driver-registrar:v2.1.0RELATED_IMAGE_NODE_MANAGER:$PRIVATE_REGISTRY_URL/node-manager:v0.0.6RELATED_IMAGE_PORTAL_MANAGER:$PRIVATE_REGISTRY_URL/portal-manager:v1.0.2RELATED_IMAGE_STORAGEOS_INIT:$PRIVATE_REGISTRY_URL/init:v2.1.2RELATED_IMAGE_STORAGEOS_NODE:$PRIVATE_REGISTRY_URL/node:v2.7.0RELATED_IMAGE_NODE_GUARD:$PRIVATE_REGISTRY_URL/node-guard:v0.0.4    storageos-cluster\n   üí° Optional - For users who are looking to make further customisations to their StorageOSCluster custom resource in the 1-storageos-cluster.yaml manifest, review the Operator Configuration and Operator Examples reference pages for more information.\n Step 6 - Installing Ondat   Run the following kubectl command to install Ondat with the generated manifests in the storageos-dry-run directory.\n# Apply the Operators and CustomResourceDefinitions (CRDs) first. find . -name \u0026#39;*-operator.yaml\u0026#39; | xargs -I{} kubectl apply --filename {} # Apply the Custom Resources next. find . -name \u0026#39;*-cluster.yaml\u0026#39; | xargs -I{} kubectl apply --filename {}   The installation process may take a few minutes.\n  Step 7 - Verifying Ondat Installation   Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status)\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd # only if the etcd cluster was deployed inside the Kubernetes cluster. kubectl get storageclasses | grep \u0026#34;storageos\u0026#34;   Step 8 - Applying a Licence to the Cluster  ‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.\n To obtain a licence, follow the instructions on our licensing operations page.\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto clusters that don\u0026rsquo;t have direct ‚Ä¶","ref":"/docs/install/advanced/airgap/","title":"Air-Gapped Install"},{"body":"Overview This guide will demonstrate how to install Ondat onto a Kubernetes cluster declaratively. Ondat can be installed declaratively onto a Kubernetes cluster through two different methods;\n Using the Ondat kubectl plugin. Using the Ondat Helm chart.  Prerequisites  ‚ö†Ô∏è Make sure you have met the minimum resource requirements for Ondat to successfully run. Review the main Ondat prerequisites page for more information.\n  ‚ö†Ô∏è Make sure the following CLI utility is installed on your local machine and is available in your $PATH:\n  kubectl   ‚ö†Ô∏è Make sure to add an Ondat licence after installing. You can request a licence via the Ondat SaaS Platform.\n  ‚ö†Ô∏è Make sure you have a running Kubernetes cluster with a minimum of 5 worker nodes and the sufficient Role-Based Access Control (RBAC) permissions to deploy and manage applications in the cluster.\n  ‚ö†Ô∏è Make sure your Kubernetes cluster uses a Linux distribution that is officially supported by Ondat as your node operating system and has the required LinuxIO related kernel modules are available for Ondat to run successfully.\n Procedure Option A - Using Ondat Kubectl Plugin Step 1 - Install Ondat Kubectl Plugin  Ensure that the Ondat kubectl plugin is installed on your local machine and is available in your $PATH:  kubectl-storageos    Step 2 - Install Local Path Provisioner   By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a Local Path Provisioner to provide local storage for Ondat\u0026rsquo;s embedded etcd cluster operator deployment.\n üí° Different Kubernetes distributions may include a CSI driver as part of the deployment. Cluster administrators can leverage the CSI driver provided by their distribution if they don\u0026rsquo;t want to use a Local Path Provisioner. If so, ensure that the ETCD_STORAGECLASS environment variable points to the correct value for your Kubernetes distribution\u0026rsquo;s default StorageClass name.\n kubectl apply --filename=\u0026#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml\u0026#34;   Define and export the ETCD_STORAGECLASS environment variable so that value is local-path, which is the default StorageClass name for the Local Path Provisioner.\nexport ETCD_STORAGECLASS=\u0026#34;local-path\u0026#34;   To verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a RUNNING status, run the following kubectl commands.\nkubectl get pod --namespace=local-path-storage kubectl get storageclass    ‚ö†Ô∏è The local-path StorageClass is only recommended for non production clusters, as this stores all the data of the etcd peers locally, which makes it susceptible to state being lost on node failures.\n Step 3 - Conducting Preflight Checks   Run the following command to conduct preflight checks against the Kubernetes cluster to validate that Ondat prerequisites have been met before attempting an installation.\nkubectl storageos preflight   Step 4 - Generate Ondat YAML Kubernetes Manifests   Define and export the STORAGEOS_USERNAME and STORAGEOS_PASSWORD environment variables that will be used to manage your Ondat instance. In addition, define and export a KUBERNETES_VERSION environment variable, where the value will be the exact version of your Kubernetes cluster where Ondat is going to be deployed - for example, v1.23.5.\nexport STORAGEOS_USERNAME=\u0026#34;storageos\u0026#34; export STORAGEOS_PASSWORD=\u0026#34;storageos\u0026#34; export KUBERNETES_VERSION=\u0026#34;v1.23.5\u0026#34;   Run the following kubectl-storageos plugin command with the --dry-run flag to generate the Ondat YAML Kubernetes manifests in a directory, called storageos-dry-run.\nkubectl storageos install \\  --dry-run \\  --include-etcd \\  --etcd-tls-enabled \\  --etcd-storage-class=\u0026#34;$ETCD_STORAGECLASS\u0026#34; \\  --k8s-version=\u0026#34;$KUBERNETES_VERSION\u0026#34; \\  --admin-username=\u0026#34;$STORAGEOS_USERNAME\u0026#34; \\  --admin-password=\u0026#34;$STORAGEOS_PASSWORD\u0026#34;   To review the list of manifests generated in the newly created storageos-dry-run directory run the following commands.\ncd storageos-dry-run/ ls storageos-dry-run/   Step 4 - Installing Ondat   Run the following kubectl command to install Ondat with the generated manifests in the storageos-dry-run directory. The manifests can also be used in your GitOps workflow to deploy Ondat, enabling you to have a fully declarative approach towards managing your infrastructure deployments.\n üí° Advanced Users - For users who are looking to make further customisations to their StorageOSCluster custom resource manifest, review the Operator Configuration and Operator Examples reference pages for more information.\n # Apply the Operators and CustomResourceDefinitions (CRDs) first. find . -name \u0026#39;*-operator.yaml\u0026#39; | xargs -I{} kubectl apply --filename {} # Apply the Custom Resources next. find . -name \u0026#39;*-cluster.yaml\u0026#39; | xargs -I{} kubectl apply --filename {}    The installation process may take a few minutes.  Step 5 - Verifying Ondat Installation   Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status)\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd kubectl get storageclasses | grep \u0026#34;storageos\u0026#34;   Option B - Using Ondat\u0026rsquo;s Helm Chart Step 1 - Install Helm  Ensure that the Helm 3 CLI utility is installed on your local machine and is available in your $PATH:  helm    Step 2 - Setup An etcd Cluster (External etcd)   If you are installing etcd externally, ensure that you have deployed the cluster before installing Ondat through the Helm chart. There are two different methods listed below with instructions on how to deploy an etcd cluster;\n Embedded Deployment - deploy an etcd cluster operator into your Kubernetes cluster, recommended for non production environments. External Deployment - deploy an etcd cluster in dedicated virtual machines, recommended for production environments.    Once you have an etcd cluster up and running, ensure that you note down the list of etcd endpoints as comma-separated values that will be used when configuring Ondat in Step 4.\n For example, 203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379    Step 2 - Setup a StorageClass for etcd (Internal etcd)   If you are installing etcd inside the cluster, ensure that you have at least 3 (recommend 5) nodes ready to ensure high availability. It is recommended that these nodes are placed in different physical or virtual locations (ie. Datacenters or availability zones) for maximum resilience.\n  Before installing Ondat with etcd, create the StorageClass that you want to use for etcd. Note that this cannot be storageos as Ondat depends on etcd to function. The following procedure will install a local path StorageClass that will work in all configurations, ideally there is another more resilient option (eg. Gp3 on AWS) available that can be used instead.\n    By default, a newly provisioned Kubernetes cluster does not have any CSI driver deployed. Run the following commands against the cluster to deploy a Local Path Provisioner to provide local storage for Ondat\u0026rsquo;s embedded etcd cluster operator deployment.\n üí° Different Kubernetes distributions may include a CSI driver as part of the deployment. Cluster administrators can leverage the CSI driver provided by their distribution if they don\u0026rsquo;t want to use a Local Path Provisioner. If so, ensure that the ETCD_STORAGECLASS environment variable points to the correct value for your Kubernetes distribution\u0026rsquo;s default StorageClass name.\n kubectl apply --filename=\u0026#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml\u0026#34;   Define and export the ETCD_STORAGECLASS environment variable so that value is local-path, which is the default StorageClass name for the Local Path Provisioner.\nexport ETCD_STORAGECLASS=\u0026#34;local-path\u0026#34;   To verify that the Local Path Provisioner was successfully deployed and ensure that the deployment is in a RUNNING status, run the following kubectl commands.\nkubectl get pod --namespace=local-path-storage kubectl get storageclass    ‚ö†Ô∏è The local-path StorageClass is only recommended for non production clusters, as this stores all the data of the etcd peers locally, which makes it susceptible to state being lost on node failures.\n Step 3 - Configure Ondat\u0026rsquo;s Helm Chart Repository   Add the Ondat Helm chart repository, update the local Helm repository index using the following helm repo commands.\nhelm repo add ondat https://ondat.github.io/charts helm repo update   Check to confirm that the Ondat Helm chart repository is available using the following helm commands.\nhelm repo list helm search repo \u0026#34;ondat\u0026#34;   Step 4 - Customising \u0026amp; Installing Ondat\u0026rsquo;s Operator Helm Chart  There are two ways to conduct an installation with Helm, declaratively by creating a custom values.yaml (recommended method) or interactively by using the --set flags to overwrite specific values for the deployment.   üí° Advanced Users - For users who are looking to make further customisations to the Helm chart through additional configurable parameters or manually create your own StorageOSCluster custom resource manifest, review the Ondat chart README.md document, Operator Configuration and Operator Examples reference pages for more information.\n Declarative (Recommended)   Make a copy of the values.yaml configuration file, rename it to custom-values.yaml, then ensure that the following configurable parameters have been populated before beginning the installation.\n ondat-operator.cluster.admin.password  # Password to authenticate to the StorageOS API with. This must be at least# 8 characters long.password:# for example -\u0026gt; storageos If an external etcd installation is being used, add ondat-operator.cluster.kvBackend.address  # Key-Value store backend.kvBackend:address:# for example -\u0026gt; 203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379 If an internal etcd installation is being used, set etcd-cluster-operator.cluster.storageclass, set this to the StorageClass installed earlier  # Storageclass for etcd backing storage# NOTE: We CANNOT use storageos here as this is the egg to Ondat\u0026#39;s chickenstorageclass:local-path ‚ö†Ô∏è The local-path StorageClass is only recommended for non production clusters, as this stores all the data of the etcd peers locally, which makes it susceptible to state being lost on node failures.\n   Once the parameters above have been defined, run the following helm install command to install Ondat using the Helm chart. Ensure that you use the --values= flag with your custom-values.yaml file.\nhelm install ondat ondat/ondat \\  --namespace=ondat \\  --create-namespace \\  --values=custom-values.yaml    The installation process may take a few minutes. If you are installing etcd internally, the Ondat pods may initially fail to connect and enter an Error state - they will retry automatically until etcd becomes available.  Interactive   Define and export the STORAGEOS_PASSWORD environment variable that will be used to manage your Ondat instance.\nexport STORAGEOS_PASSWORD=\u0026#34;storageos\u0026#34;   If you are using an internal etcd cluster, define and export a ETCD_STORAGECLASS environment variable, where the value will be the StorageClass to use for etcd volumes.\nexport ETCD_STORAGECLASS=\u0026#34;local-path\u0026#34;   If you are using an external etcd cluster, define and export a ETCD_ENDPOINTS environment variable, where the value will be a list of etcd endpoints as comma-separated values noted down earlier in Step 2.\nexport ETCD_ENDPOINTS=\u0026#34;203.0.113.10:2379,203.0.113.11:2379,203.0.113.12:2379\u0026#34;   Run the following helm install command to install Ondat using the Helm chart.\nInternal Etcd\nhelm install ondat ondat/ondat \\  --namespace=ondat \\  --create-namespace \\  --set ondat-operator.cluster.admin.password=\u0026#34;$STORAGEOS_PASSWORD\u0026#34; \\  --set etcd-cluster-operator.cluster.storageclass=\u0026#34;$ETCD_STORAGECLASS\u0026#34; External etcd\nhelm install ondat ondat/ondat \\  --namespace=ondat \\  --create-namespace \\  --set ondat-operator.cluster.admin.password=\u0026#34;$STORAGEOS_PASSWORD\u0026#34; \\  --set ondat-operator.cluster.kvBackend.address=\u0026#34;$ETCD_ENDPOINTS\u0026#34; \\  --set etcd-cluster-operator.cluster.create=\u0026#34;false\u0026#34;    The installation process may take a few minutes.  Step 5 - Verifying Ondat Installation   Run the following kubectl commands to inspect Ondat\u0026rsquo;s resources (the core components should all be in a RUNNING status)\nkubectl get all --namespace=storageos kubectl get all --namespace=storageos-etcd # only if the etcd cluster was deployed inside the Kubernetes cluster. kubectl get storageclasses | grep \u0026#34;storageos\u0026#34;   Applying a Licence to the Cluster  ‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1 TiB of provisioned storage.\n To obtain a licence, follow the instructions on our licensing operations page.\n","excerpt":"Overview This guide will demonstrate how to install Ondat onto a Kubernetes cluster declaratively. ‚Ä¶","ref":"/docs/install/advanced/declarative-install/","title":"Declarative Install"},{"body":"Overview The Amazon EKS Blueprints for Terraform is a collection of Terraform modules that aim to make it easier and faster for customers to adopt Amazon EKS. It can be used by AWS customers, partners, and internal AWS teams to configure and manage complete EKS clusters that are fully bootstrapped with the operational software that is needed to deploy and operate workloads.\nOndat has published an official add-on to the EKS Blueprints that allows the deployment of Ondat. Access the add-on via the following GitHub repo: terraform-eksblueprints-ondat-addon.\nFor further information, see the following material:\n Ondat is now available via Amazon EKS Blueprints  ","excerpt":"Overview The Amazon EKS Blueprints for Terraform is a collection of Terraform modules that aim to ‚Ä¶","ref":"/docs/install/aws/terraform-aws-eks-blueprints/","title":"Installing Ondat with the EKS Terraform Blueprints"},{"body":"Ondat requires certain standard kernel modules to function. In particular it requires Linux-IO, an open-source implementation of the SCSI target, on all nodes that will execute Ondat (usually the workers). A variety of Linux distributions are made available by AWS/Azure/GCP and other hyperscalers for use within their kubernetes platforms, however note that not all of them ship with Linux-IO.\nSupported Distributions Current (non-EOL) versions of the following distributions are supported by default:\n SUSE Linux Enterprise Server Red Hat Enterprise Linux CentOS Debian Ubuntu  The following distributions include the prerequisite modules but are not yet tested exhaustively by the Ondat team:\n Bottlerocket Google ContainerOS  The following distributions are currently not supported:\n Amazon Linux (lacks target_core_mod and target_core_user)  This has been raised with AWS.\n üí° If you require help with a specific issue with a listed distribution, raise an issue on GitHub or reach out to us on our Community Slack\n Kernel Modules We require the following modules to be loaded:\n target_core_mod tcm_loop configfs target_core_user uio   ‚ö†Ô∏è Other applications utilising TCMU cannot be run concurrently with Ondat. Doing so may result in corruption of data. On startup, Ondat will detect if other applications are using TCMU.\n In most modern distributions, including those listed above, the modules are distributed as part of the Linux kernel package and are included by default. In some older distributions, they were part of a kernel extras package that needed to be installed separately.\nInstalling the required Kernel Modules The script enable-lio.sh from Ondat\u0026rsquo;s init container can be used to ensure that all kernel-level dependencies are installed, any errors will indicate which components are missing.\nFor example, in Ubuntu versions prior to 22.04 several modules were not included in the base kernel configuration. Run the following command to install linux-modules-extra to obtain these additional modules required for Ondat:\nsudo apt-get update sudo apt-get install -y linux-modules-extra-$(uname -r) Automatic Configuration Once required kernel modules are installed on the system, for convenience we provide a container that will ensure the appropriate modules are loaded and ready for use at runtime. You will need to run the init container prior to starting Ondat. Our installation guides for Kubernetes and OpenShift include this step.\nManual Configuration For those wishing to manage their own kernel configuration, rather than using the init container, perform the following steps:\n Ensure kernel modules are all loaded per list above Ensure configfs is loaded and mounted at /sys/kernel/config  ","excerpt":"Ondat requires certain standard kernel modules to function. In particular it requires Linux-IO, an ‚Ä¶","ref":"/docs/prerequisites/systemconfiguration/","title":"System Configuration"},{"body":"We recommend always using \u0026ldquo;tagged\u0026rdquo; versions of Ondat rather than \u0026ldquo;latest\u0026rdquo;, and to perform upgrades only after reading the release notes.\nThe latest tagged release is 2.8.3. For installation instructions see our Install page.\nThe latest CLI release is 2.8.3, available from GitHub.\nUpgrading To upgrade from version 1.x to 2.x, contact Ondat support for assistance.\n2.8.3 - Release 2022-09-14 New Data Plane\n Added support for AWS Bottlerocket Added check for whether the block device directory (usually /var/lib/storageos/volumes) supports creation of devices, and enable it if it is not already  Kubernetes\n The scheduler extender, that attempts to place workloads on the same nodes as volumes, can now be disabled  Fixed Data Plane\n Increased the LIO_DEVICE_TIMEOUT_SECS to 300 seconds (5 minutes) and the LIO_RETRY_LOOP_DURATION_SECS to 240 seconds (4 minutes). This provides additional flexibility for environments experiencing resource contention Added environment variables so time-outs can be adjusted and tuned Fixed spelling mistake in alert log messages Improved the clarity of the log messages which alert users that IO to the backend disk (fdatasync, preadv, pwritev and fallocate) is running unusually slowly Fixed an issue wherein creating a Ondat block device could erroneously fail because we\u0026rsquo;d fail to wait for the underlying kernel device to be available  Kubernetes\n The following fixes apply to k8s clusters running v1.23, v1.24 and v1.25, the bugs did not apply to older cluster versions  api-manager will now have permissions to use podsecuritypolicies api-manager now has the expected resource limits api-manager will no longer run as root api-manager pods will now be spread across nodes    Control Plane\n The control plane will now crash loop less when its pod is restarted  2.8.2 - Release 2022-08-12 Fixed Data Plane\n Fixed a bug that would cause the Data Plane to crash due to a timing issue.  2.8.1 - Release 2022-08-02 New k8s\n Operator:  Install snapshot controller and related CRDs if not present Pod Disruption Budget support for k8s v1.25   Improve logging on kubectl plugin  Data Plane\n Warn that filesystem might go read-only after a failed write or sync SCSI command. The log of interest is: \u0026quot;SCSI command failed - if the block device is mounted the filesystem may go read-only\u0026quot;. Log when the average IO service time from the mount node is greater than 2 seconds. We log the following message on a per volume basis with exponential backoff: \u0026quot;it is taking unsually long to send and receive IO from the presentation node\u0026quot;. Metrics are included in the log message.  Note: this measurement is tracking the time it takes to send the IO over the network to the master and any replicas and for the IO to be committed and the response sent back to the mount node.   Log when the average IO service time from the master node to its replica is greater than 2 seconds. We log the following message, on a per replica basis with exponential backoff: \u0026ldquo;it is taking unsually long to send and receive IO from the master deployment to its replica\u0026rdquo;. Metrics are included in the log message. Note: this measurement is tracking the time it takes to send the IO over the network to the replica and for the IO to be committed and the response sent back to the mount node. Log when it takes more than 1 second to commit a write, read, sync or unmap to disk. Logs of interest are of the format \u0026quot;X operation took longer than Yms to complete completion_time=Zms\u0026quot;.  Control Plane\n Automatically round up storage requests to align with blocksize, instead of rejecting requests  Fixed k8s\n Fixed an issue where Portal Manager would not work if installed in a namespace that was not storageos Fixed an issue where CSI requests would occasionally not be serviced Fixed an issue on GKE where some pods would not be scheduled if there was no resource quota Fixed a bug where the operator would attempt to delete snapshot related CRs when the CRD did not exist Fixed an issue where default containers were not correctly marked  Control Plane\n Reduced the amount of crash loop backoffs when installing via the helm chart Reduced the impact of ListVolumes on etcd (significantly, in the case of clusters with lots of volumes) Fixed an issue where formatting would timeout due to large TRIM writes being sent across the network Fixed an issue where volume deployments would all be scheduled on the same nodes when deploying multiple PVC at the same time  Data Plane\n Fix Convert\u0026lt;\u0026gt; and add support for uint16_t. Fix Volume::GetConsumerCount Improve error message when a write/unmap SCSI command is not committed to the backend disk: \u0026quot;a consumer IO was not committed to rdbplugin because its transaction ID lost. This could mean there are two consumers with the same transaction ID (bad); the CP has forgotten to increment the consumer count in between remounts of the volume (bad) or it could indicate that a retry of this IO operation has overtaken a previous IO attempt (normally indicative of a very slow/flaky network and/or disk).\u0026quot;  2.8.0 - Release 2022-06-29  üí° For Ondat 2.8.0, we recommend having at least a 5 node cluster when running etcd within Kubernetes, as we recommend running etcd with 5 replicas.\n New k8s\n Etcd in Production: We have added support for putting ETCD in your cluster in a production environment Modified CSI provisioner to work with Snapshots Ondat volumes metrics exporter: we have added a Prometheus endpoint to allow users to view metrics for Ondat Volumes  Control Plane\n We have relaxed some Ondat specific security checks for the ReadWriteOnce node volumes that we were doing in the control plane ahead of the new volume mode ReadWriteOncePod which is being introduced in k8s 1.22. This will align the Ondat RWO volumes with the spec and we will in a future release also implement support for RWOP for users that wish to implement these existing controls.  Please note that the relaxation of these security checks could mean that Deployment objects using RWO volumes (if a rolling strategy is used for example) will be able to mount the volume concurrently on the same node, for this reason we suggest users are creating workloads using stateful sets or use RWX volumes for these deployments.    Data Plane\n Snapshot GA: we added the Snapshot feature to allow users to back up their Ondat data outside of their Kubernetes clusters in conjunction with a backup solution  Portal Manager\n Automatic licencing: we added a feature to allow automatic deployment of licence to your cluster when you connect to our Ondat SaaS Platform  Fixed k8s\n Fixed a bug where the StorageOS operator would occasionally restart  2.7.0 - Released 2022-04-11 New k8s \u0026amp; Orchestrator Rolling Upgrade\n Tech Preview: Kubernetes rolling upgrade for AWS EKS, Google Anthos, Google GKE, Microsoft Azure, Openshift and Rancher  ‚ö†Ô∏è This is a tech preview, we only recommend using this feature on your test clusters\n   Operator\n Updated memory limit Introduced topology spread constraint with ScheduledAnyway  API Manager\n Adds a feature so when a PVC is not found scheduling will not be blocked  Control Plane\n Set Only_Numeric_Owners to true on NFSv4 setting on Ganesha  Data Plane\n Removed support for FUSE. Ondat now only supports TCMU. target_core_user must now be used. Read System Configuration for more information Rewrote the RPC interface between the Control Plane and the Data Plane. All of the old ctl tools have been removed Removed the 32-bit mappings and uses the UUIDs passed by the CP directly to address presentations and deployments  ‚ö†Ô∏è If you decide to upgrade to 2.7.0 and want to downgrade, you can only roll back to 2.6.0, not earlier versions. Roll back instruction can be found here\n   Fixed Operator\n Fixed a bug that sometimes caused the operator to enter a deadlock state after Ondat cluster CR object deletion  Control Plane\n Fixed an issue where Ondat was not able to unmount volumes in rare instances, then occasionally causing volumes to become unhealthy Fixed an issue that caused replicas to go into the ‚Äúunknown‚Äù state during failover in somne rare instances Fixed an issue to now display output all dataplane logs even if they don\u0026rsquo;t have the expected syntax Fixed an issue so Ondat would speculatively configure the replica in the dataplane before we advertise ourselves to the master Fix an issue where goroutines attempting to dial remote nodes could be blocked Fix an issue so Ondat volume would remain mounted and online during temporary network issues when pod is on remote, master and replica  Data Plane\n Fix non-null terminated buffer which could lead to garbled logs Fix client-server network to improve robustness  2.6.0 - Released 2022-02-14 New Portal Manager:\n Initial release of the Portal Manager, which supports the connection to Ondat SaaS Platform.  Kubectl Plugin:\n We have added a --dry-run flag into install command, so you can view the installation manifests written locally to ./storageos-dry-run/. We have added capability for conducting an airgapped installation. The new options can also be used outside of an airgapped cluster.  Operator:\n We have defined the resource requests and resource limits for the Ondat components (csi-attacher, csi-provisioner, csi-resizer, api-manager, cluster-operator and ondat-scheduler).  Kubernetes:\n Ondat supports Kubernetes v1.23  Components\n We have added a new component called Node Guard that once enabled allows you to do rolling upgrades to the orchestrator without any downtime. This component is disabled by default and we do not recommend using the feature for production workloads as it is a technical preview feature.  2.5.0 - Released 2021-12-06 Fixed Dataplane:\n Deadlock with unordered UNMAP commands. Spurious log message when detaching a volume - you would often see a spurious warning message ‚Äúmissing fs configuration for presentation_id=2001\u0026quot;. We\u0026rsquo;ve fixed the issue that led to this log message, by ensuring deletion of LUN (Logical Unit Number). Stop potential shutdown hangs - directfs initiator could restart connections after shutdown has been requested. This race condition has been removed. Misleading log message when SetVolumeConsumerCount is called - log message now only sent in correct scenarios. Volume backup tool in disaster recovery scenarios - the volume backup tool is used to extract volume data in disaster recovery scenarios. There was an issue that prevented the tool from running whilst the Dataplane was running. This has been fixed.  New Dataplane:\n Faster replica syncing - new replicas can be provisioned faster and rejoining replicas sync faster. Non-contiguous data regions are collated into the same RPC. Ondat now syncs multiple regions concurrently maximising the network bandwidth. Improved network performance - Up to 2.3 times faster speed and even higher on high-latency networks. Improved error-handling mechanism for synchronise cache commands - we have ensured error messages are propagated when SYNCHRONIZE_CACHE_16 commands fail.  Control Plane:\n Topology-Aware Placement is a feature that enforces placement of data across failure domains to guarantee high availability. Track logs from control plane to data plane with extra details. The command-line tool can now display the availability zone of each of the volume\u0026rsquo;s deployments.  Kubernetes:\n New kubectl plugin to manage Ondat. Upgrades to the operator and improved development speed - StorageOS cluster status now reflects cluster deployment status. Users can now change log-level port to new operator and we have given users increased flexibility for users to configure StorageOS images.  2.4.4 - Released 2021-09-08 Fixed  controlplane: Fix an issue with timeouts when opening gRPC connections to other nodes in the cluster. controlplane: Changes to GUI licensing workflow - See our Licensing page dataplane: Fix an issue where failed IO network connections could be erroneously restarted while we are trying to shutdown. k8s: Leader election requires ability to patch events. k8s: Node label sync could fail to apply updated label.  v2.4.2 - Released 2021-07-15 Fixed   controlplane: Improve error message when unable to set the cluster-wide log level on an individual node.\n  dataplane: Fix rare assert when retrying some writes under certain conditions.\n  dataplane: Log format string safety improvements.\n  dataplane: Backuptool reliability improvements.\n  k8s/cluster-operator: Allow api-manager to patch events for leader election.\n  v2.4.1 - Released 2021-06-30 New  Cluster-wide log level configuration via Custom Resource.  Fixed   controlplane: Improve error message during failed --label argument parsing.\n  controlplane: Double-check the OS performs the NFS mount as directed, and unmount on error.\n  controlplane: Improved FSM and sync CC logging.\n  dataplane: Log message quality, quantity and visibility improvements.\n  dataplane: Volume backup tool error reporting improvements.\n  k8s: Pod scheduler fixes.\n  v2.4.0 - Released 2021-05-27 This release adds production-grade encryption at rest for Ondat volumes, as well as:\n Fencing TRIM Failure modes Kubernetes object sync  Note: v2.4.0 requires Kubernetes 1.17 or newer.\nNew  Volume encryption-at-rest. Fencing support. Block trim support. Kubernetes label sync. Kubernetes node and namespace delete sync. Failure tolerance threshold support.  Fixed   controlplane/api: Compression is not disabled by default when provisioning volumes via the API.\n  controlplane/api: Spec has incorrect response body for partial bundle.\n  controlplane/csi: Error incorrectly returned when concurrent namespace creation requests occur.\n  controlplane/diagnostics: GetDiagnostics RPC response does not indicate if node timed out collecting some data.\n  controlplane/diagnostics: Invalid character \u0026lsquo;\\u0080\u0026rsquo; looking for beginning of value via CLI when a node is down.\n  controlplane/diagnosticutil: Include attachment type in unpacking local volumes.\n  controlplane/diagnotics: Node timing out during local diagnostics is missing logs.\n  controlplane/healthcheck: Combined sources fires callback in initialisation.\n  controlplane/volumerpc: \u0026ldquo;Got unknown replica state 0\u0026rdquo; discards results.\n  dataplane/fix: Check blob writes don\u0026rsquo;t exceed internal limit.\n  dataplane/fix: Checking the return code of InitiatorAddConnection().\n  dataplane/fix: Director signal hander thread is not joined.\n  dataplane/fix: Don\u0026rsquo;t block I/O when many retries are in progress.\n  dataplane/fix: gRPC API robustness improvements.\n  dataplane/fix: Initiator needs to include the node UUID in Endpoint.\n  dataplane/fix: Low-level I/O engines don\u0026rsquo;t propagate IO failures via Wait().\n  dataplane/fix: Log available contextual information where possible.\n  dataplane/fix: Ensure BackingStore is not deleted twice.\n  dataplane/fix: Serialise LIO create/delete operations to avoid kernel bug.\n  dataplane/fix: Dataplane shutdown time can exceed 10 seconds.\n  dataplane/fix: Fix non-threadsafe access on TCMU device object.\n  dataplane/fix: Don\u0026rsquo;t hold lock unecessarily in Rdb::Reap.\n  k8s/api-manager: First ip octet should not be 0, 127, 169 or 224.\n  k8s/api-manager: Keygen should only operate on Ondat PVCs.\n  k8s/cluster-operator: Add perm to allow VolumeAttachment finalizer removal.\n  k8s/cluster-operator: Fix apiManagerContainer tag in v1 deploy CRD.\n  k8s/cluster-operator: Fix docker credentials check.\n  k8s/cluster-operator: Fix ServiceAccountName in the OLM bundle.\n  k8s/cluster-operator: Set webhook service-for label to be unique.\n  Improved   controlplane/api: Make version provided consistent for NFS/Host attach handler.\n  controlplane/attachtracker: Cleanup NFS mounts at shutdown.\n  controlplane/build: Migrate to go modules for dependency management.\n  controlplane/build: Use sentry prod-url if build branch has \u0026ldquo;release\u0026rdquo; prefix.\n  controlplane/cli: Colour for significant feedback.\n  controlplane/cli: Update node must set compute only separately to other labels.\n  controlplane/cli: Warn user that updating labels action can be reverted.\n  controlplane/csi: Bound request handlers with timeout similar to HTTP API.\n  controlplane/csi: Remove error obfuscation and clarify log messages.\n  controlplane/csi: Stop logging not found.\n  controlplane/dataplane: Remove UUID mappings during failed presentation creation rollback.\n  controlplane/dataplaneevents: Decorate logs with extra event details.\n  controlplane/diagnostics: Asymmetrically encrypt bundles.\n  controlplane/diagnostics: Collect FSM state.\n  controlplane/diagnostics: Support single node bundle collection.\n  controlplane/diagnosticutil: Decorate log entries with well-known field corresponding to node id/name.\n  controlplane/diagnosticutil: Parallelise unpacking of disjoint data.\n  controlplane/diagnosticutil: Unpack gathered NFS config data.\n  controlplane/fsm: Perform state match check before version check.\n  controlplane/k8s: Use secret store.\n  controlplane/log: Fix race condition writing logs.\n  controlplane/log: Handle originator timestamps from dataplane logs.\n  controlplane/meta: Error checking code uses Go 1.13 error features.\n  controlplane/rpc: Make CP gRPC calls to the DP configuration endpoints idempotent.\n  controlplane/sentry: Prevent some unnecessary alerts.\n  controlplane/slog: Clean up error logging in RPC provision stack.\n  controlplane/states: Add the \u0026ldquo;from\u0026rdquo; state as a log field for state transition msgs.\n  controlplane/store/etcd: Decorate lock logs with associated ID fields.\n  controlplane/ui: Warn user that updating labels action will be reverted.\n  controlplane/vendor: Bump service repository.\n  controlplane/volume: Encryption support in kubernetes.\n  dataplane/fs: Don\u0026rsquo;t return from PresentationCreate RPC until the device is fully created.\n  dataplane/fs: Each LUN should have it\u0026rsquo;s own HBA.\n  dataplane/fs: Improve device ready check.\n  dataplane/internals: Improve DP stats implementation.\n  dataplane/internals: Major director refactor.\n  dataplane/log: Logs should output originating timestamps.\n  dataplane/log: Move to log3 API exclusively.\n  dataplane/log: Remove log2.\n  dataplane/log: Set log_level and log_filter via the supctl tool.\n  dataplane/rdb: Handle unaligned I/O in RdbPlugin.\n  dataplane/rdb: Implement low-level \u0026ldquo;delete block\u0026rdquo; functionality.\n  dataplane/rdb: rocksdb Get() should use an iterator.\n  dataplane/story: Support for block unmapping.\n  dataplane/story: Add backuptool binary to export volume data.\n  dataplane/story: Volume encryption-at-rest.\n  dataplane/sync: Add retries for failed sync IOs.\n  dataplane/sync: VolumeHash performance improvements.\n  dataplane/sys: Find and check OS pids.max on startup.\n  k8s/api-manager: Don\u0026rsquo;t attempt service creation if the owning PVC doesn\u0026rsquo;t exist.\n  k8s/api-manager: Compare SC and PVC creation time during label sync.\n  k8s/api-manager: Add action to ensure modules tidy \u0026amp; vendored.\n  k8s/api-manager: Add defaults from StorageClass.\n  k8s/api-manager: Add fencing controller.\n  k8s/api-manager: Add flag and support for cert validity.\n  k8s/api-manager: Add flags to disable label sync controllers.\n  k8s/api-manager: Add namespace delete controller.\n  k8s/api-manager: Add node delete controller.\n  k8s/api-manager: Add OpenTelemetry tracing with Jaeger backend.\n  k8s/api-manager: Add PVC label sync controller.\n  k8s/api-manager: Add PVC mutating controller.\n  k8s/api-manager: Add support for failure-mode label.\n  k8s/api-manager: Add support for volume encryption.\n  k8s/api-manager: Allow multiple mutators.\n  k8s/api-manager: Build and tests should use vendored deps.\n  k8s/api-manager: Bump controller-runtime to v0.6.4.\n  k8s/api-manager: Encrypt only provisioned PVCs.\n  k8s/api-manager: Fix tracing example.\n  k8s/api-manager: Introduce StorageClass to PVC annotation mutator.\n  k8s/api-manager: Log API reason.\n  k8s/api-manager: Migrate namespace delete to operator toolkit.\n  k8s/api-manager: Migrate node delete to operator toolkit.\n  k8s/api-manager: Migrate to kubebuilder v3.\n  k8s/api-manager: Node label sync.\n  k8s/api-manager: Node label update must include current reserved labels.\n  k8s/api-manager: Pass context to API consistently.\n  k8s/api-manager: Rename leader election config map.\n  k8s/api-manager: RFC 3339 and flags to configure level \u0026amp; format.\n  k8s/api-manager: Run shared volume controller with manager.\n  k8s/api-manager: Set initial sync delay.\n  k8s/api-manager: Set Pod scheduler.\n  k8s/api-manager: Standardise on ObjectKeys for all API function signatures.\n  k8s/api-manager: Ondat API interface and mocks.\n  k8s/api-manager: Update dependencies and go version 1.16.\n  k8s/api-manager: Update to new external object sync.\n  k8s/api-manager: Use composite client in admission controllers.\n  k8s/api-manager: Use Object interface.\n  k8s/cluster-operator: Changes to the StorageOSCluster CR get applied to Ondat.\n  k8s/cluster-operator: Increase provisioner timeout from 15 to 30s.\n  k8s/cluster-operator: Reduce CSI provisioner worker pool.\n  k8s/cluster-operator: Set priority class for helper pods.\n  k8s/cluster-operator: Add pod anti-affinity to api-manager.\n  k8s/cluster-operator: Add pvc mutator config.\n  k8s/cluster-operator: Add rbac for api-manager fencing.\n  k8s/cluster-operator: Add RBAC for encryption key management.\n  k8s/cluster-operator: Add RBAC needed for csi-resizer v1.0.0.\n  k8s/cluster-operator: Add webhook resource migration.\n  k8s/cluster-operator: Add workflow to push image to RedHat registry.\n  k8s/cluster-operator: Bump csi-provisioner to v2.1.1.\n  k8s/cluster-operator: Call APIManagerWebhookServiceTest test.\n  k8s/cluster-operator: Delete CSI expand secret when cluster is deleted.\n  k8s/cluster-operator: Docker login to avoid toomanyrequests error.\n  k8s/cluster-operator: Move pod scheduler webhook to api-manager.\n  k8s/cluster-operator: RBAC to allow sync functions move to api-manager.\n  k8s/cluster-operator: Remove pool from StorageClass, not used in v2.\n  k8s/cluster-operator: Remove some other v1.14 specific logic.\n  k8s/cluster-operator: Set the default container for kubectl logs.\n  k8s/cluster-operator: Update code owners.\n  k8s/cluster-operator: Update CSI sidecar images.\n  k8s/cluster-operator: Validate minimum Kubernetes version.\n  v2.3.4 - Released 2021-03-24  controlplane/build: Use Sentry prod-url for release branches (CP-4600). controlplane/csi: Improve CSI handler timeout (CP-4585). controlplane/dataplane: UUID mapping cleanup on failed volume creation (CP-4588). controlplane/slog: Improve RPC error logging (CP-4616). dataplane: Allocate fewer aio contexts per volume (DP-305) dataplane: Defer fallocate(2) until first write (DP-312). dataplane: Don\u0026rsquo;t fail replica sync if inter-node connection establishment is slow (DP-319, DP-280). dataplane: Improve logging around gRPC context cancellations (DP-315). dataplane: Improve rollback for failed volume creation (DP-308). dataplane: New support tool to cleanup orphaned volume storage (DP-307). dataplane: supctl can reap named volumes (DP-309). k8s: API token reset failures should trigger re-authentication directly (#38). k8s: Increase lint timeout to reduce CI errors (#305). k8s: Remove PriorityClass from helper pods (#312). k8s: Toleration defaults for helper pods (#311). k8s: Use ubi-minimal base image directly (#307).  v2.3.3 - Released 2021-02-12  Support CSI ListVolumes() API, addressing volume attach problems seen by some customers. Quality-of-life fixes.  New  operator: Use CSI attacher v3 for k8s 1.17+. controlplane/csi: ListVolumes support.  Fixed  api-manager: Reset API after token refresh error. operator: Set scheduler when PVCs use default StorageClass. operator: Update base container image. controlplane/volumerpc: \u0026ldquo;Got unknown replica state 0\u0026rdquo; discards results. controlplane/healthcheck: Combined sources fires callback in initialisation. controlplane/fsm: Perform state match check before version check.  v2.3.2 - Released 2020-11-25 Fixed  controlplane/rejoin: Failure to delete data causes re-advertise loop. controlplane/rejoin: Handle timeout waiting for progress report. dataplane/log: Change buffering of symmetra output to prevent stalls.  v2.3.1 - Released 2020-11-16  Allows access to ReadWriteMany shared volumes when running containers as a non-root user.  Fixed  nfs: root squash to uid=0 is now configured on all shared volumes.  v2.3.0 - Released 2020-10-31 This release adds production-grade shared file support to v2, previously a technology preview in v1.\nBreaking  The v2.3.0 operator is no longer able to run Ondat v1.  New  Adds support for ReadWriteMany shared volumes. See ReadWriteMany. Adds api-manager deployment to support shared volumes. See the api manager GitHub repository for more information. Kubernetes 1.19 support.  Improved  dataplane: Reduce replication thread usage by having the replication processes share the main thread pool. This helps ensure that there isn\u0026rsquo;t a spike in thread usage when a node recovers and begins re-syncing its volumes. This is particularly relevant on CRIO-based orchestrators such as Openshift where the default maximum allowed PID limit (which also governs the thread limit) is low. dataplane: Detect and log the effective maximum PID limit on startup. dataplane: Internal device presentation mappings are now ephemeral and are not persisted across reboots. dataplane: Disabled default verbose logging for fdatasync/flushWAL timers. dataplane: Log both volume inode and UUID in replication error messages for easier correlation. dataplane: On startup, ensure any remnant devices that may have been left after an unclean shutdown have been properly cleared. dataplane: Signal when all startup tasks complete. This ensures no IO can be initiated before this time. ha: Implement a backoff when attempting to repoint an attached volume after the master has failed. ha: Replicas can now rejoin after an asymmetric partition. This can occur when the master has not lost communication to the replica, but the replica can\u0026rsquo;t communicate with the master. Previously the replica would not be able to rejoin until the master determined it had failed. ha: A master that was partitioned can now re-join to the new master as a replica. api: node label changes update target node prior to committing new state. api: Validation errors now include more information on the failure and how to resolve. csi: Volume resize error messages (e.g. capacity exceeded) now passed through in CSI response. csi: Volume attachment is now verified prior to mount for more instructive error message. csi: Returns RESOURCE EXHAUSTED error when attempting to exceed maximum of 250 Ondat volume attachments per node. diagnostics: Multiple improvements to bundle collection and collected data. ui: Allow collection of partial diagnostics bundles. ui: Tolerate clock skew when authenticating via the UI. licensing: Read-through cache added. Licence updates will take up to 60s to propagate to all nodes. cli: Set replicas output formatting. init: Checks the effective maximum PID limit and warns if less than the Ondat recommended PID limit (32,768). CRIO-based distributions such as Openshift have a much lower default value (1024). Consult prerequisites for more information.  Fixed  dataplane: Fixes transport endpoint is not connected on startup after an unclean shutdown. csi: Volume unmount requests now succeed when the mountpoint has already been removed by the orchestrator. csi: Volume detach requests now succeed when the volume has already been deleted. Previously the volume would be stuck in Terminating status.  v2.2.0 - Released 2020-08-18 This release focuses on performance. We analysed existing performance characteristics across a variety of real-world use cases and ended up with improvements across the board. Of particular note:\n Sequential reads have improved by up to 130% Sequential writes have improved by up to 737% Random reads have improved by up to 45% Random writes have improved by up to 135% I/O for large block sizes (128K) has improved by up to 353%  We are extremely proud of our performance and we love to talk about it. Have a look at the Benchmarking section of the self-evaluation guide and consider sharing your results. Our PRE engineers are available to discuss in our slack channel.\nNew   Data engine revamp focused on provable consistency and performance. Key characteristics:\n Metadata is stored in an optimised index, lowering I/O latency and improving performance for all workloads. Large block reads/writes are now be handled in a single operation. Applications like Kafka will go much faster.    On-disk compression is now disabled by default as in most scenarios this offers better performance. To enable on-disk compression for a specific workload, see compression.\n  Improved  dataplane: The number of I/O threads are now determined by the number of processing cores available. This improves scalability and performance on larger servers. ha: Improve partition tolerance behaviour when a volume master that has lost its connection to etcd rejoins. ha: Allow replicas in unhealthy states to be remediated and re-used while maintaining partition tolerance. ha: When a master fails and the new master is not yet available, introduce a back-off to the redirection logic to avoid spamming the logs with connection failure errors. ha: Ignore health advertisements for local node. Local nodes are handled directly. node delete: Only refuse to delete a node if the node health can be authoritatively verified to be in use. api: Increase HTTP server write timeout. cli/ui: Allow partial diagnostic bundle downloads. ui: Namespace dropdown can now be scrolled. ui: Add \u0026ldquo;Job title\u0026rdquo; to UI licence form. logging: Log version at startup at INFO level. logging: Lower verbosity of SCSI warnings that do not apply to Ondat. diagnostics: Include logs that have been rotated. diagnostics: Bundle collection across providers is now done in parallel. build: Update base image to RHEL 8.2. operator: Removed DB migration utility required for v1.3 -\u0026gt; v1.4 upgrades. operator: Automatically refreshes Ondat API token without failing requests when the token expires. operator: Updated CSI attacher and provisioner to latest upstream. operator: Remove cluster.local suffix on Pod scheduler service address. This allows the scheduler to work in clusters with custom DNS configuration. operator: Defaults are now set for most CSI configuration options in the StorageOSCluster custom resource.  Fixed  csi: When unmount request is received for a volume that has already been unmounted, return success. csi: Verify volume is attached on the node before mounting it. xfs: Support older RHEL kernels which have an XFS library that does not allow reflinks/dedupe. dataplane: Reserve 1GiB of capacity on the target disk to allow manual cleanup operations, rather than filling target disk to capacity. operator: In some cases /var/lib/storageos could fail to unmount cleanly after a restart. This resulted in multiple entries in /proc/mounts.  v2.1.0 - Released 2020-06-26 New  csi: Volume expansion now supported in offline mode. To expand a volume, stop any workloads accessing the volume, then edit the PVC to increase the capacity. For more information, see our Volume Resize operations page and the CSI Volume Expansion page. api: Volume configuration including replica count can now be updated while the volume is in use. Other updateable fields include labels and description. failover: Before determining that a node is offline and performing recovery operations, the I/O path is also verified. This provides more robust failure detection and ensures that nodes that are still responding to I/O do not get replaced. This I/O path verification is in addition to the gossip-based failure detection. operator: Default tolerations are now set for the Ondat node container. This helps ensure that the Ondat node container does not get evicted when the node is running low on resources.  Improved  api: Added checks to prevent deletion of a node with active volumes, or if it is the master of at least one volume. This helps prevent orphaned volumes. cli: Add an --offline-delete flag to allow removal of volumes whose master and replica nodes are offline. This allows cleanup of orphaned volumes. ui: Add an offline volume delete option. ui: Volumes can now be detached from the UI. cli: Labels are no longer truncated. api: When a new node is added to the cluster, its capacity is available to use immediately.  Fixed  ui: Favicon was missing. ui: Duplicate volumes could be shown on the node details page. operator: During uninstall a ClusterRoleBinding was not removed.  v2.0.0 - Released 2020-05-05 New  operator: Ondat containers now run in the kube-system namespace by default to allow the system-node-critical priority class to be set. This instructs Kubernetes to start Ondat before application Pods, and to evict Ondat only after application Pods have finished. This setting was previously recommended in documentation; it is now the default. operator: Ondat CSI helper containers now run as privileged. This ensures that the CSI endpoint can be seen on systems with SELinux enabled. ui: replication progress for new or re-joining replicas is now displayed. ui: show warning for unlicensed clusters. cli: new commands:  licence management get policy create namespace create policy describe user describe namespace describe policy delete user delete namespace delete policy   licence: removed the default licence expiry date added for v2.0.0-rc.1.  Improved  dataplane: improved retry behaviour for network I/O. cli: \u0026ldquo;get volumes\u0026rdquo; for all namespaces should be done in parallel. cli: help text document config file ui: link node name and get to node details on the volume details page. ui: node details add available capacity spinner. ui: node list remove capacity values / address port. ui: node list show master/replica counts. ui: node list remove edit action. ui: format entity labels. ui: node details link volumes. ui: align buttons for licences. ui: k8s warning in \u0026ldquo;create volume\u0026rdquo; modal. ui: node list remove \u0026ldquo;API\u0026rdquo; from \u0026ldquo;API Address\u0026rdquo; ui: add some details about the Licence on the licence page. api: include valid for duration in login response. licence: restrict nodes which are unregistered after 24 hours. scheduler: return error for namespace/volume not found dataplane: start gRPC threads separately from rest of the supervisor.  Fixed \u0026laquo;\u0026laquo;\u0026laquo;\u0026lt; HEAD\n  ui: centre licence types.\n  ui: capacity in ui is per namespace.\n  cli: fail gracefully if missing some output details (i.e. no node exists for ID). =======\n  ui: centre licence types.\n  ui: capacity in ui is per namespace.\n  cli: fail gracefully if missing some output details (i.e. no node exists for ID).\n         main\n       v2.0.0-rc.1 - Released 2020-03-31 Initial release of version 2.x. See Ondat v2.0 Release Blog for details.\n","excerpt":"We recommend always using \u0026ldquo;tagged\u0026rdquo; versions of Ondat rather than \u0026ldquo;latest\u0026rdquo;, ‚Ä¶","ref":"/docs/release-notes/","title":"Release Notes"},{"body":"Availability of IPv6 Address Family Certain Ondat components need to be able to listen on a standard dual-stack socket of type AF_INET6. The IPv6 address family must be supported on the server so that this socket can be allocated. Ondat does not require IPv6 to be configured on the server - no addressing or routing needs to be in place, however Ondat does need this functionality to be enabled in the kernel.\n","excerpt":"Availability of IPv6 Address Family Certain Ondat components need to be able to listen on a standard ‚Ä¶","ref":"/docs/prerequisites/ipv6/","title":"Availability of IPv6"},{"body":"","excerpt":"","ref":"/docs/concepts/","title":"Features"},{"body":"Port list Ondat daemons listen on specific ports, which we require to be accessible between all nodes in the cluster:\n   Port Number TCP/UDP Use     5701 TCP gRPC   5703 TCP DirectFS   5704 TCP Dataplane Supervisor   5705 TCP REST API   5710 TCP gRPC API   5711 TCP \u0026amp; UDP Gossip service   25705-25960 TCP RWX Volume Endpoints     üí° Ondat also uses ephemeral ports to dial-out to these ports on other Ondat nodes. For this reason, outgoing traffic should to other nodes be enabled.\n Firewalls and VPS providers Some VPS providers (such as Digital Ocean) ship default firewall rulesets which must be updated to allow Ondat to run. Some example rules are shown below - modify to taste.\nUFW For distributions using UFW, such as RHEL and derivatives:\nufw default allow outgoing ufw allow 5701:5711/tcp ufw allow 5711/udp ufw allow 25705:25960/tcp Firewalld For distributions that enable firewalld to control iptables such as some installations of OpenShift.\nfirewall-cmd --permanent --new-service=storageos firewall-cmd --permanent --service=storageos --add-port=5700-5800/tcp --add-port=25705-25960/tcp firewall-cmd --add-service=storageos --zone=public --permanent firewall-cmd --reload Iptables For those using plain iptables:\n# Inbound traffic iptables -I INPUT -i lo -m comment --comment \u0026#39;Permit loopback traffic\u0026#39; -j ACCEPT iptables -I INPUT -m state --state ESTABLISHED,RELATED -m comment --comment \u0026#39;Permit established traffic\u0026#39; -j ACCEPT iptables -I INPUT -p tcp --dport 5701:5711 -m comment --comment \u0026#39;Ondat\u0026#39; -j ACCEPT iptables -I INPUT -p udp --dport 5711 -m comment --comment \u0026#39;Ondat\u0026#39; -j ACCEPT iptables -I INPUT -p tcp --dport 25705:25960 -m comment --comment \u0026#39;Ondat\u0026#39; -j ACCEPT # Outbound traffic iptables -I OUTPUT -o lo -m comment --comment \u0026#39;Permit loopback traffic\u0026#39; -j ACCEPT iptables -I OUTPUT -d 0.0.0.0/0 -m comment --comment \u0026#39;Permit outbound traffic\u0026#39; -j ACCEPT  ‚ö†Ô∏è Make sure that the iptables rules you have added above come before any default DROP or REJECT rules.\n ","excerpt":"Port list Ondat daemons listen on specific ports, which we require to be accessible between all ‚Ä¶","ref":"/docs/prerequisites/firewalls/","title":"Firewalls"},{"body":"Prerequisites for using Ondat Minimum requirements One machine with the following:\n Minimum two core with 4GB RAM Linux with a 64-bit architecture Kubernetes 1.19 - 1.23 Container Runtime Engine: CRI-O, Containerd or Docker 1.10+ with mount propagation enabled The necessary ports should be open. See the ports and firewall settings Etcd cluster for Ondat A mechanism for device presentation  Recommended  Prepare a cluster with minimum of 5 nodes when running etcd within Kubernetes for replication and high availability; 3 nodes if etcd is outside Kubernetes or a self-eval cluster Install the Ondat CLI If using Helm2, make sure the tiller ServiceAccount has enough privileges to create resources such as Namespaces, ClusterRoles, etc. For instance, following this installation procedure System clocks synchronized using NTP or similar methods. While our distributed consensus algorithm does not require synchronised clocks, it does help to more easily correlate logs across multiple nodes A PID cgroup limit of 32768 Some aspects of product operation require kernel support for IPv6. See the IPv6 prequisites page  ","excerpt":"Prerequisites for using Ondat Minimum requirements One machine with the following:\n Minimum two core ‚Ä¶","ref":"/docs/prerequisites/","title":"Prerequisites"},{"body":"The following guides will help you get Ondat up and running on a variety of different environments. If at any time you need help, please don\u0026rsquo;t hesitate to contacts us on Slack or book in a call where one of our solution architects can talk through your particular scenario.\n","excerpt":"The following guides will help you get Ondat up and running on a variety of different environments. ‚Ä¶","ref":"/docs/install/","title":"Install"},{"body":"Ondat recommends that a PID cgroup limit of 32768 be used for Ondat pods.\n üí° Most environments fulfill this prerequisite by default. Check the Ondat init container logs as shown below to ensure this is the case.\n Ondat pods running in Kubernetes are part of a PID cgroup that may limit the maximum number of PIDs that all containers in the PID cgroup slice can spawn. As the Linux kernel assigns a PID to processes and Light Weight Processes (LWP) a low limit can be easily reached under certain circumstances. The PID limit can be set by the Kubernetes distribution or by the container runtime. Generally the limit is set to the machine wide default limit of 32768 but some environments can set this as low as 1024. A low PID limit may prevent Ondat from spawning the required threads.\nThe Ondat init container runs a script that checks for the PID limit of the PID cGroup slice that the Ondat pod runs in. If the script finds that the limit is less than 32768 it will log a warning. This warning can be viewed using kubectl to check the init container logs.\n$ kubectl -n storageos logs -l app.kubernetes.io/component=control-plane,app=storageos -c init WARNING: Effective max.pids limit (1024) less than RECOMMENDED_MAX_PIDS_LIMIT (32768) Setting a Kubernetes PID limit Kubernetes defaults to an unlimited PodPidsLimit, which results in the usage of the machine wide limit; typically 32768.\nFor information on how to configure the Kubernetes PID limit see the Kubernetes documentation here.\nSetting a CRI-O PID limit Certain orchestrators or setups use CRI-O as the container runtime. Openshift 4.x currently has CRI-O set a PID limit of 1024 by default. To configure the default CRI-O limit in Openshift 4.x see the RedHat documentation here. To configure CRI-O more generally see the CRI-O documentation here.\n","excerpt":"Ondat recommends that a PID cgroup limit of 32768 be used for Ondat pods.\n üí° Most environments ‚Ä¶","ref":"/docs/prerequisites/pidlimits/","title":"PID Limits"},{"body":"","excerpt":"","ref":"/docs/upgrade/","title":"Upgrade"},{"body":"Etcd - In Cluster - Replicas and Availability Zones We recommend running etcd with 5 replicas (etcd peers) and spreading them across availability zones when running etcd inside the cluster, this improves the resiliency of the etcd cluster. This is done by default when installing via the plugin or helm.\nEtcd low latency IO It is recommended to run etcd on low-latency disks and keep other IO-intensive applications separate from the etcd nodes. Etcd is very sensitive to IO latency. Thus, the effect of disk contention can cause etcd downtime.\nBatch jobs such as backups, builds or application bundling can easily cause a high usage of disks making etcd unstable. It is recommended to run such workloads apart from the etcd servers.\nSetup of storage on the hosts We recommend creating a separate filesystem for Ondat to mitigate the risk of filling the root filesystem on nodes. This has to be done for each node in the cluster.\nFollow the managing host storage best practices page for more details.\nResource reservations Ondat resource consumption depends on the workloads and the Ondat features in use.\nThe recommended minimum memory reservation for the Ondat Pods is 512MB for non-production environments. However it is recommended to prepare nodes so Ondat can operate with at least with 1-2GB of memory. Ondat frees memory when possible.\nFor production environments, we recommend 4GB of Memory and 1 CPU as a minimum and to test Ondat using realistic workloads and tune resources accordingly.\nOndat Pods resource allocation will impact directly on the availability of volumes in case of eviction or resource limit triggered restart. It is recommended to not limit Ondat Pods.\nOndat implements a storage engine, therefore limiting CPU consumption might affect the I/O throughput of your volumes.\nSetting a Kubernetes PID limit Ondat recommends that a PID cgroup limit of 32768 be set. Ondat is a multi-threaded application and while most Kubernetes distributions set the PID cgroup limit to 32768, some environments can set a limit as low as 1024. The Ondat init container will print a log message warning if the PID cgroup limit is too low. See our prerequisites for more information.\nMaintain a sufficient number of nodes for replicas to be created To ensure that a new replica can always be created, an additional node should be available. To guarantee high availability, clusters using Volumes with 1 replica must have at least 3 storage nodes. When using Volumes with 2 replicas, at least 4 storage nodes, 3 replicas, 5 nodes, etc.\nMinimum number of storage nodes = 1 (primary) + N (replicas) + 1\nFor more information, see the section on replication.\nOndat API username/password The API grants full access to Ondat functionality, therefore we recommend that the default administrative password of \u0026lsquo;storageos\u0026rsquo; is reset to something unique and strong.\nYou can change the default parameters by encoding the username and password values (in base64) into the storageos-api secret.\nTo generate a unique password, a technique such as the following, which generates a pseudo-random 24 character string, may be used:\n# Generate strong password PASSWORD=$(cat -e /dev/urandom | tr -dc \u0026#39;a-zA-Z0-9-!@#$%^\u0026amp;*()_+~\u0026#39; | fold -w 24 | head -n 1) # Convert password to base64 representation for embedding in a K8S secret BASE64PASSWORD=$(echo -n $PASSWORD | base64) Note that the Kubernetes secret containing a strong password must be created before bootstrapping the cluster. Multiple installation procedures use this Secret to create an Ondat account when the cluster first starts.\nOndat Pod placement Ondat must run on all nodes that will contribute storage capacity to the cluster or that will host Pods which use Ondat volumes. For production environments, it is recommended to avoid placing Ondat Pods on Master nodes.\nOndat is deployed with a DaemonSet controller, and therefore tolerates the standard unschedulable (:NoSchedule) action. If that is the only taint placed on master or cordoned nodes Ondat pods might start on them (see the Kubernetes docs for more details). To avoid scheduling Ondat pods on master nodes, you can add an arbitrary taint to them for which the Ondat DaemonSet won\u0026rsquo;t have a toleration.\nDedicated instance groups Cloud environments give users the ability to quickly scale the number of nodes in a cluster in response to their needs. Because of the ephemeral nature of the cloud, Ondat recommends setting conservative downscaling policies.\nFor production clusters, it recommended to use dedicated instance groups for Stateful applications that allow the user to set different scaling policies and define Ondat pools based on node selectors to collocate volumes.\nLosing a few nodes at the same time could cause the loss of data even when volume replicas are being used.\nPort blocking Ondat exposes ports to operate. It is recommended that the ports are not accessible from outside the scope of your cluster.\n","excerpt":"Etcd - In Cluster - Replicas and Availability Zones We recommend running etcd with 5 replicas (etcd ‚Ä¶","ref":"/docs/best-practices/","title":"Ondat Best Practices"},{"body":"As part of the dataplane operation, Ondat uses Linux AIO (Asynchronous Input Output) contexts to serve I/O requests without blocking. Ondat requires 4 AIO contexts per deployment (i.e. an Ondat volume deployment, whether master or replica).\nMax AIO prerequisite By default there is a maximum number of AIO contexts that can be allocated at once.\nThe current and maximum number of AIO requests is visible in the virtual files /proc/sys/fs/aio-nr and /proc/sys/fs/aio-max-nr.\nThe default context limit has been set at 2^16 or 65536. This figure may vary so do check your /proc/sys/fs/aio-max-nr\nWhen aio-nr reaches aio-max-nr the io_setup syscall will fail with EAGAIN. For more information see the Linux kernel docs here.\nWhy is this relevant? As Ondat requires 4 AIO contexts per deployed volume, there is a limit to the number of volumes that can be deployed per node. Trying to provision additional deployments once the aio-max-nr has been reached will fail as the kernel will be unable to create enough new AIO contexts.\nIncreasing your AIO context cap If your nodes aio-max-nr is set too low you can either provision additional nodes to reduce the number of deployments per node, or increase the aio-max-nr kernel parameter.\nYou can do this by editing your /etc/sysctl.conf file with the following example line:\nfs.aio-max-nr = 1048576 To activate the new settings, run the following command:\nsysctl -p /etc/sysctl.conf ","excerpt":"As part of the dataplane operation, Ondat uses Linux AIO (Asynchronous Input Output) contexts to ‚Ä¶","ref":"/docs/prerequisites/max-aio/","title":"Max AIO"},{"body":"","excerpt":"","ref":"/docs/operations/","title":"Operations"},{"body":"Ondat can be used to provide permanent storage for other applications running in Kubernetes or other Orchestrators that are derived from Kubernetes such as OpenShift or Rancher. This is useful for running stateful applications, such as databases or CI/CD applications, under the control of Kubernetes as Kubernetes can make scheduling decisions without the application data being lost.\nWhat we have outlined in the cookbooks below are some quick deployments of stateful applications into a Kubernetes cluster. These examples are not production ready but have been provided to give you some insight into how to use Ondat with stateful applications.\nStatefulSets The examples we have provided use StatefulSets as a way to deploy applications into Kubernetes. The reason for this is that the StatefulSet controller is designed to manage stateful applications and it \u0026ldquo;provides guarantees about the ordering and uniqueness\u0026rdquo; of sets of pods.\nPractically this means that when a StatefulSet scales, pods are created in order from 0-(N-1), if a StatefulSet scales down then pods are deleted in reverse order from (N-1)-0.\nSecondly, it means that the behaviour of the StatefulSet controller differs from that of Deployment and ReplicaSet controllers. For Deployment and ReplicaSet controllers \u0026ldquo;\u0026hellip; at many points in the lifetime of a replica set there will be 2 copies of a pod\u0026rsquo;s processes running concurrently\u0026rdquo;. Having two different pods mount a volume at the same time can cause corruption of data. Currently Kubernetes accessModes only apply restrictions to nodes mounting volumes rather than pods, so it is important that StatefulSets are used with Ondat volumes so the necessary pod uniqueness guarantees are maintained.\nStatefulSet Manifests The Ondat specific part of the Kubernetes manifests for these examples lies in the VolumeClaimTemplate that\u0026rsquo;s part of the statefulset definition.\nVolumeClaimTemplate\napiVersion:apps/v1kind:StatefulSetmetadata:name:mssqlspec:selector:matchLabels:app:mssqlenv:prodserviceName:mssqlreplicas:1template:metadata:labels:app:mssqlenv:prodspec:serviceAccountName:mssqlcontainers:- name:fooimage:barvolumeMounts:- name:bazmountPath:/var/opt/barenvFrom:- configMapRef:name:mssqlvolumeClaimTemplates:- metadata:name:bazlabels:env:prodspec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:\u0026#34;storageos\u0026#34;# Ondat storageClass resources:requests:storage:5GiIn the StatefulSet definition above the container has a volume mount defined called baz. The definition for this volume is found in the VolumeClaimTemplate where the fast storageClass will be used to dynamically provision storage if the persistent volume does not already exist.\n","excerpt":"Ondat can be used to provide permanent storage for other applications running in Kubernetes or other ‚Ä¶","ref":"/docs/usecases/","title":"Use Cases: Install applications on Kubernetes with Ondat"},{"body":"Ondat requires an etcd cluster in order to function. For more information on why etcd is required, see our etcd concepts page.\nNeither Ondat nor Kubernetes support using Kubernetes' own internal etcd for Ondat.\nFor most use-cases it is recommended to install the Ondat etcd operator that will manage creation and maintenance of Ondat\u0026rsquo;s required etcd cluster. In some circumstances, eg. when cloud storage technologies are not available, it makes sense to install etcd on separate machines outside of your Kubernetes cluster.\nInstalling Etcd Into Your Kubernetes Cluster This is our recommended way to host etcd in both testing and production environments.\nConfiguring Storage for Etcd We highly recommend using cloud provider network attached disks for storing etcd data, such as EBS volumes, Google Persistent Disks, Azure Disks, etc. This allows the etcd operator to recover from node failures.\nFor testing environments or where there are no resilient storage options available, a node-local storage option can be used, such as Local Path Provisioner. This will store etcd data on the node hosting an etcd pod\n ‚ö†Ô∏è The local-path StorageClass is only recommended when other, better storage classes are not available, as this stores all the data of the etcd peers locally, which makes it susceptible to state being lost on node failures. In the case of local-path storage, a minimum of 5 etcd nodes is recommended to increase resilience.\n Installing Etcd An etcd cluster can be created in three different ways:\n Installing the etcd operator via our helm chart Installing Ondat (and the etcd operator) via our Plugin Manually deploying the etcd operator and applying an etcdcluster custom resource  Recommended: Installing the etcd operator via our helm chart For full instructions, visit Ondat Helm Chart repository.\nRecommended: Installing Ondat (and the etcd operator) via our Plugin kubectl storageos install \\ --include-etcd \\ --etcd-storage-class \u0026lt;the storage class you want to use for etcd\u0026gt; \\ --etcd-tls-enabled Configurable: Manually applying an etcdcluster custom resource This installation method allows the most configuration of the etcd cluster, but is error-prone and therefore not recommended in situations in which the Helm chart or plugin can be used, instead.\n Manually applying an etcdcluster custom resource  Recommended: Installing the etcd operator via our helm chart For full instructions, visit here\nRecommended: Installing Ondat (and the etcd operator) via our Plugin kubectl storageos install \\ --include-etcd \\ --etcd-storage-class \u0026lt;the storage class you want to use for etcd\u0026gt; \\ --etcd-tls-enabled Manually applying an etcdcluster custom resource This installation method allows the most configuration of the etcd cluster, but is error-prone and therefore not recommended in situations in which the Helm chart or plugin can be used, instead.\nFind the verison of the etcd operator you want to install from GitHub.\nInstall the etcd operator:\nexport ETCD_OPERATOR_VERSION=\u0026lt;set the version you want to use\u0026gt; kubectl apply -f https://github.com/storageos/etcd-cluster-operator/releases/download/${ETCD_OPERATOR_VERSION}/storageos-etcd-cluster-operator.yaml Then adapt the following sample to your needs and use kubectl to apply it:\nexport ETCD_OPERATOR_VERSION=\u0026lt;set the version you want to use\u0026gt; wget https://github.com/storageos/etcd-cluster-operator/releases/download/${ETCD_OPERATOR_VERSION}/storageos-etcd-cluster.yaml vim storageos-etcd-cluster.yaml kubectl apply -f storageos-etcd-cluster.yaml Installation Verification $ kubectl -n storageos-etcd get pod,svc,pdb NAME READY STATUS RESTARTS AGE pod/storageos-etcd-0-28m5t 1/1 Running 0 18h pod/storageos-etcd-1-2lpn9 1/1 Running 0 18h pod/storageos-etcd-2-dpdz6 1/1 Running 0 18h pod/storageos-etcd-3-7lsmz 1/1 Running 0 18h pod/storageos-etcd-4-q5xjd 1/1 Running 0 18h pod/storageos-etcd-controller-manager-6f5776c64f-dhp7r 1/1 Running 0 18h pod/storageos-etcd-controller-manager-6f5776c64f-vvxrr 1/1 Running 0 18h pod/storageos-etcd-proxy-96bf4bb5f-z5m7f 1/1 Running 0 18h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/storageos-etcd ClusterIP None \u0026lt;none\u0026gt; 2379/TCP,2380/TCP 18h service/storageos-etcd-proxy ClusterIP 10.43.199.194 \u0026lt;none\u0026gt; 80/TCP 18h NAME MIN AVAILABLE MAX UNAVAILABLE ALLOWED DISRUPTIONS AGE poddisruptionbudget.policy/storageos-etcd 3 N/A 2 18h ","excerpt":"Ondat requires an etcd cluster in order to function. For more information on why etcd is required, ‚Ä¶","ref":"/docs/prerequisites/etcd/etcd/","title":"Etcd in Kubernetes"},{"body":"","excerpt":"","ref":"/docs/reference/bundles/","title":"Bundles"},{"body":"This page documents the process for installing etcd outside the Kubernetes cluster.\nIn some circumstances it can make sense to run etcd outside of Kubernetes. One example is when running an on-premises Kubernetes cluster, if you do not have access to reliable cloud disks to provide high availability to etcd data.\nFor production installations running etcd outside the cluster, Ondat strongly recommends running etcd on a minimum of 3 dedicated virtual machines. This topology offers strong guarantees of resilience and uptime.\nOndat doesn\u0026rsquo;t require a high performance etcd cluster as the throughput of metadata to the cluster is low. However, we recommend a careful assessment of IOPS capacity best practices to ensure that etcd operates normally.\nYou can choose between two installation options.\n Manual Installation Ansible Installation  Installation - Manual This section documents the steps required for manual installation of etcd using standard package management commands and systemd manifests.\n ‚ö†Ô∏è Repeat the following steps on all the nodes that will run etcd as a systemd service.\n   Configure Etcd version and ports\nexport ETCD_VERSION=\u0026#34;3.4.9\u0026#34; export CLIENT_PORT=\u0026#34;2379\u0026#34; export PEERS_PORT=\u0026#34;2380\u0026#34;  ‚ö†Ô∏è If targeting Kubernetes Master nodes, you must change CLIENT_PORT, PEERS_PORT\n   Download Etcd from CoreOS official site\ncurl -L https://github.com/coreos/etcd/releases/download/v${ETCD_VERSION}/etcd-v${ETCD_VERSION}-linux-amd64.tar.gz -o /tmp/etcd-${ETCD_VERSION}-linux-amd64.tar.gz mkdir -p /tmp/etcd-v${ETCD_VERSION}-linux-amd64 tar -xzvf /tmp/etcd-${ETCD_VERSION}-linux-amd64.tar.gz -C /tmp/etcd-v${ETCD_VERSION}-linux-amd64 --strip-components=1 rm /tmp/etcd-${ETCD_VERSION}-linux-amd64.tar.gz   Install Etcd binaries\ncd /tmp/etcd-v${ETCD_VERSION}-linux-amd64 mv etcd /usr/local/sbin/etcd3 mv etcdctl /usr/local/sbin/etcdctl chmod 0755 /usr/local/sbin/etcd3 /usr/local/sbin/etcdctl   Set up persistent Etcd data directory\nmkdir /var/lib/storageos-etcd   Create the systemd environment file\nOn all nodes that will run etcd create a systemd environment file /etc/etcd.conf which has the IPs of all the nodes. The NODE_IP will need to change to correspond to the node IP where the environment file resides. NODE1_IP, NODE2_IP and NODE3_IP will remain the same across all three files.\n$ cat \u0026lt;\u0026lt;END \u0026gt; /etc/etcd.conf # NODE_IP is the IP of the node where this file resides. NODE_IP=10.64.10.228 # Node 1 IP NODE1_IP=10.64.10.228 # Node 2 IP NODE2_IP=10.64.14.233 # Node 3 IP NODE3_IP=10.64.12.111 CLIENT_PORT=${CLIENT_PORT} PEERS_PORT=${PEERS_PORT} END # Verify that variables are expanded in the file $ cat /etc/etcd.conf   Create the systemd unit file for etcd3 service\nCreate a systemd unit file /etc/systemd/system/etcd3.service with the following information:\n[Unit] Description=etcd3 Documentation=https://github.com/coreos/etcd Conflicts=etcd2.service [Service] Type=notify Restart=always RestartSec=5s LimitNOFILE=40000 TimeoutStartSec=0 EnvironmentFile=/etc/etcd.conf ExecStart=/usr/local/sbin/etcd3 --name etcd-${NODE_IP} \\  --heartbeat-interval 500 \\  --election-timeout 5000 \\  --max-snapshots 10 \\  --max-wals 10 \\  --data-dir /var/lib/storageos-etcd \\  --quota-backend-bytes 8589934592 \\  --snapshot-count 100000 \\  --auto-compaction-retention 20000 \\  --auto-compaction-mode revision \\  --initial-cluster-state new \\  --initial-cluster-token etcd-token \\  --listen-client-urls http://${NODE_IP}:${CLIENT_PORT},http://127.0.0.1:${CLIENT_PORT} \\  --advertise-client-urls http://${NODE_IP}:${CLIENT_PORT} \\  --listen-peer-urls http://${NODE_IP}:${PEERS_PORT} \\  --initial-advertise-peer-urls http://${NODE_IP}:${PEERS_PORT} \\  --initial-cluster etcd-${NODE1_IP}=http://${NODE1_IP}:${PEERS_PORT},etcd-${NODE2_IP}=http://${NODE2_IP}:${PEERS_PORT},etcd-${NODE3_IP}=http://${NODE3_IP}:${PEERS_PORT} [Install] WantedBy=multi-user.target  üí° $NODE_IP is the IP address of the machine you are installing etcd on.`\n  ‚ö†Ô∏è Note that setting the advertise-client-urls incorrectly will cause any client connection to fail. Ondat will fail to communicate to Etcd.\n  ‚ö†Ô∏è If enabling TLS, it is recomended to generate your own CA certificate and key. You will need to distribute the keys and certificates for the client auth on all etcd nodes. Moreover, the ExecStart value should look as below:\n ExecStart=/usr/local/sbin/etcd3 --name etcd-${NODE_IP} \\  --heartbeat-interval 500 \\  --election-timeout 5000 \\  --max-snapshots 10 \\  --max-wals 10 \\  --data-dir /var/lib/storageos-etcd \\  --quota-backend-bytes 8589934592 \\  --snapshot-count 100000 \\  --auto-compaction-retention 20000 \\  --auto-compaction-mode revision \\  --peer-auto-tls \\  --client-cert-auth --trusted-ca-file=/path/to/client-cert.pem \\  --cert-file=/path/to/ca.pem \\  --key-file=/path/to/client-key.pem \\  --initial-cluster-state new \\  --initial-cluster-token etcd-token \\  --listen-client-urls https://${NODE_IP}:${CLIENT_PORT} \\  --advertise-client-urls https://${NODE_IP}:${CLIENT_PORT} \\  --listen-peer-urls https://${NODE_IP}:${PEERS_PORT} \\  --initial-advertise-peer-urls https://${NODE_IP}:${PEERS_PORT} \\  --initial-cluster etcd-${NODE1_IP}=https://${NODE1_IP}:${PEERS_PORT},etcd-${NODE2_IP}=https://${NODE2_IP}:${PEERS_PORT},etcd-${NODE3_IP}=https://${NODE3_IP}:${PEERS_PORT}   Reload and start the etc3 systemd service\nsystemctl daemon-reload systemctl enable etcd3.service systemctl start etcd3.service   Installation Verification\n üí° The etcdctl binary is installed at /usr/local/bin on the nodes.\n $ ssh $NODE # Any node running the new etcd $ ETCDCTL_API=3 etcdctl --endpoints=http://127.0.0.1:${CLIENT_PORT} member list # $NODE_IP - the IP of the node 66946cff1224bb5, started, etcd-b94bqkb9rf, http://172.28.0.1:2380, http://172.28.0.1:2379 17e7256953f9319b, started, etcd-gjr25s4sdr, http://172.28.0.2:2380, http://172.28.0.2:2379 8b698843a4658823, started, etcd-rqdf9thx5p, http://172.28.0.3:2380, http://172.28.0.3:2379  Read the etcd operations page for our etcd recommendations.\n   Installation - Ansible For a repeatable and automated installation, use of a configuration management tool such as ansible is recommended. Ondat provides an ansible playbook to help you deploy etcd on standalone virtual machines.\n  Clone Ondat deployment repository\ngit clone https://github.com/storageos/deploy.git cd k8s/deploy-storageos/etcd-helpers/etcd-ansible-systemd   Edit the inventory file\n üí° The inventory file targets the nodes that will run etcd. The file hosts is an example of such an inventory file.\n $ cat hosts [nodes] centos-1 ip=\u0026#34;10.64.10.228\u0026#34; fqdn=\u0026#34;ip-10-64-10-228.eu-west-2.compute.internal\u0026#34; centos-2 ip=\u0026#34;10.64.14.233\u0026#34; fqdn=\u0026#34;ip-10-64-14-233.eu-west-2.compute.internal\u0026#34; centos-3 ip=\u0026#34;10.64.12.111\u0026#34; fqdn=\u0026#34;ip-10-64-12-111.eu-west-2.compute.internal\u0026#34; # Edit the inventory file $ vi hosts # Or your own inventory file  ‚ö†Ô∏è The ip or fqdn are used to expose the advertise-client-urls of Etcd. Failing to provide valid ip/fqdn will cause any client connection to fail. Ondat will fail to communicate to Etcd.\n   Edit the etcd configuration\n ‚ö†Ô∏è If targeting Kubernetes Master nodes, you must change etcd_port_client, etcd_port_peers\n $ cat group_vars/all etcd_version: \u0026#34;3.4.9\u0026#34; etcd_port_client: \u0026#34;2379\u0026#34; etcd_port_peers: \u0026#34;2380\u0026#34; etcd_quota_bytes: 8589934592 # 8 GB etcd_auto_compaction_mode: \u0026#34;revision\u0026#34; etcd_auto_compaction_retention: \u0026#34;1000\u0026#34; members: \u0026#34;{{ groups[\u0026#39;nodes\u0026#39;] }}\u0026#34; installation_dir: \u0026#34;/var/lib/storageos-etcd\u0026#34; advertise_format: \u0026#39;fqdn\u0026#39; # fqdn || ip backup_file: \u0026#34;/tmp/backup.db\u0026#34; tls: enabled: false ca_common_name: \u0026#34;eu-west-2.compute.internal\u0026#34; etcd_common_name: \u0026#34;*.eu-west-2.compute.internal\u0026#34; cert_dir: \u0026#34;/etc/etcdtls\u0026#34; ca_cert_file: \u0026#34;etcd-ca.pem\u0026#34; etcd_server_cert_file: \u0026#34;server.pem\u0026#34; etcd_server_key_file: \u0026#34;server-key.pem\u0026#34; etcd_client_cert_file: \u0026#34;etcd-client.crt\u0026#34; etcd_client_key_file: \u0026#34;etcd-client.key\u0026#34; $ vi group_vars/all  üí° Choose between using IP addressing or FQDN in the advertise_format parameter. It allows you to decide how Etcd advertises its address to clients. This is particularly relevant when using TLS.\n  üí° If enabling TLS, it is recomended to generate your own CA certificate and key. You can do it by generating the CA from the machine running Ansible by: ansible-playbook create_ca.yaml.\n   Install\nansible-playbook -i hosts install.yaml   Installation Verification\n üí° The playbook installs the etcdctl binary on the nodes, at /usr/local/bin.\n $ ssh $NODE # Any node running the new etcd $ ETCDCTL_API=3 etcdctl --endpoints=127.0.0.1:2379 member list 66946cff1224bb5, started, etcd-b94bqkb9rf, http://172.28.0.1:2380, http://172.28.0.1:2379 17e7256953f9319b, started, etcd-gjr25s4sdr, http://172.28.0.2:2380, http://172.28.0.2:2379 8b698843a4658823, started, etcd-rqdf9thx5p, http://172.28.0.3:2380, http://172.28.0.3:2379   Bind Etcd IPs to Kubernetes Service Kubernetes external services use a DNS name to reference external endpoints, making them easy to reference from inside the cluster. You can use the example from the helper GitHub repository to deploy the external Service. Using an external service can make monitoring of etcd from Prometheus easier.\nUsing Etcd with Ondat During installation of Ondat the kvBackend.address parameter in the storageoscluster custom resource is used to specify the address of the etcd cluster.\n","excerpt":"This page documents the process for installing etcd outside the Kubernetes cluster.\nIn some ‚Ä¶","ref":"/docs/prerequisites/etcd/etcd-outside-the-cluster/","title":"Etcd outside the cluster"},{"body":"","excerpt":"","ref":"/docs/reference/","title":"Reference"},{"body":"When you need support, raise a ticket via our Help Desk portal.\nIt is important to select the priority of your ticket in accordance with the severity. This helps us to route and prioritise your ticket accordingly.\nResponses to tickets will be cc\u0026rsquo;d via email.\nFor personal support and general enquiries, join our public Slack channel.\nInformation to include in tickets To help us provide effective support, we request that you provide as much information as possible when contacting us. The list below is a suggested starting point. Additionally, include anything specific, such as log entries, that may help us debug your issue.\nPlatform  Cloud provider/Bare metal OS distribution and version Kernel version  Ondat  Version of Ondat storageos get nodes storageos get volumes storageos describe volume VOL_ID # in case of issues with a specific volume  Orchestrator related (Kubernetes, OpenShift, etc)  Version and installation method Managed or self managed? kubectl -n storageos get pod kubectl -n storageos logs -lapp=storageos -c storageos kubectl -n storageos get storageclass Specific for your namespaces: kubectl describe pvc PVC_NAME Specific for your namespaces: kubectl describe pod POD_NAME  Environment Changes  Details of any recent changes to your environment such as planned maintenance, node reboots, network failures, etcd outage, etc.. This can help speed up ticket triage and resolution considerably  Ondat Support Bundle Ondat provides the ability to generate a support bundle that aggregates cluster information. See Support Bundle for a list of what is included.\nOndat engineers might ask for a support bundle to be generated during support cases.\nThe information in the bundle is used only for support purposes, and will be removed once it is no longer needed. If the information is sensitive and can\u0026rsquo;t be given to Ondat, make sure that the support engineers have as much information about your environment as possible.\nRefer to the Support Bundle documentation page for details of how to generate a bundle.\n","excerpt":"When you need support, raise a ticket via our Help Desk portal.\nIt is important to select the ‚Ä¶","ref":"/docs/support/","title":"Support"},{"body":"","excerpt":"","ref":"/docs/knowledgebase/","title":"Knowledge Base"},{"body":"Our self-evaluation guide is a step by step recipe for installing and testing Ondat. This guide is divided into three sections:\n Installation - install Ondat with a single command Feature Testing - short walkthrough of some of our features Benchmarking - a recipe to benchmark Ondat on your infrastructure   üí° For more comprehensive documentation including installation advice for complex setups, operational guides, and use-cases, see our main documentation site.\n Support for Self Evaluations Should you have questions or require support, there are several ways to get in touch with us. The fastest way to get in touch is to join our public Slack channel. You can also get in touch via email to info@storageos.com.\nInstallation In this document we detail a simple installation suitable for evaluation purposes. The etcd we install uses a 3 node cluster with local storage, and as such is not suitable for production workloads. However, for evaluation purposes it should be sufficient. For production deployments, see our main documentation pages.\nA standard Ondat installation uses the Ondat operator, which performs most platform-specific configuration for you. The Ondat operator has been certified by Red Hat and is open source.\nThe basic installation steps are:\n Check prerequisites Prepare Etcd StorageClass Install kubectl-storageos plugin Install Ondat  Prerequisites While we do not require custom kernel modules or additional userspace tooling, Ondat does have a few basic prerequisites that are met by default by most modern distributions:\n At least 1 CPU core, 2GB RAM free. A Kubernetes release within the four most recent versions. TCP ports 5701-5710 and TCP \u0026amp; UDP 5711 open between all nodes in the cluster. A 64bit supported operating system - Ondat can run without additional packages in Debian 9, RancherOS, RHEL7.5,8 and CentOS7,8 and need the package linux-image-extra for Ubuntu. Mainline kernel modules target_core_mod, tcp_loop, target_core_user, configfs, and ui. These are present by default on most modern linux distributions, and can be installed with standard package managers. See our system configuration page for instructions.  Install the storageos kubectl plugin  üí° Run the following command where kubectl is installed and with the context set for your Kubernetes cluster\n curl -sSLo kubectl-storageos.tar.gz \\ https://github.com/storageos/kubectl-storageos/releases/download/v1.3.0/kubectl-storageos_1.3.0_linux_amd64.tar.gz \\ \u0026amp;\u0026amp; tar -xf kubectl-storageos.tar.gz \\ \u0026amp;\u0026amp; chmod +x kubectl-storageos \\ \u0026amp;\u0026amp; sudo mv kubectl-storageos /usr/local/bin/ \\ \u0026amp;\u0026amp; rm kubectl-storageos.tar.gz  üí° You can find binaries for different architectures and systems in kubectl plugin.\n Prepare Etcd StorageClass The following procedure deploys a local-path StorageClass for the Ondat Etcd.\n ‚ö†Ô∏è Note that this Etcd is suitable for evaluation purposes only. Do not use this cluster for production workloads.\n kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml  ‚ö†Ô∏è The local-path StorageClass does not guarantee data safety or availability. Therefore the Ondat cluster cannot operate normally if the Etcd cluster becomes unavailable. For a production Etcd install check the Etcd prerequisites page.\n Install Ondat kubectl storageos install \\  --include-etcd \\  --etcd-namespace storageos \\  --etcd-storage-class local-path \\  --admin-username storageos \\  --admin-password storageos Verify Ondat installation Ondat installs all its components in the storageos namespace.\nkubectl -n storageos get pod -w NAME READY STATUS RESTARTS AGE storageos-api-manager-65f5c9dbdf-59p2j 1/1 Running 0 36s storageos-api-manager-65f5c9dbdf-nhxg2 1/1 Running 0 36s storageos-csi-helper-65dc8ff9d8-ddsh9 3/3 Running 0 36s storageos-node-4njd4 3/3 Running 0 55s storageos-node-5qnl7 3/3 Running 0 56s storageos-node-7xc4s 3/3 Running 0 52s storageos-node-bkzkx 3/3 Running 0 58s storageos-node-gwp52 3/3 Running 0 62s storageos-node-zqkk7 3/3 Running 0 62s storageos-operator-8f7c946f8-npj7l 2/2 Running 0 64s storageos-scheduler-86b979c6df-wndj4 1/1 Running 0 64s  üí° Wait until all the pods are ready. It usually takes ~60 seconds to complete\n Deploy the Ondat CLI as a container kubectl -n storageos create -f-\u0026lt;\u0026lt;END apiVersion: apps/v1 kind: Deployment metadata: name: storageos-cli labels: app: storageos run: cli spec: replicas: 1 selector: matchLabels: app: storageos-cli run: cli template: metadata: labels: app: storageos-cli run: cli spec: containers: - command: - /bin/sh - -c - \u0026quot;while true; do sleep 3600; done\u0026quot; env: - name: STORAGEOS_ENDPOINTS value: http://storageos:5705 - name: STORAGEOS_USERNAME value: storageos - name: STORAGEOS_PASSWORD value: storageos image: storageos/cli:v2.8.2 name: cli END  üí° You can get the ClusterId required on the next step using the CLI pod\n POD=$(kubectl -n storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli) kubectl -n storageos exec $POD -- storageos get licence License cluster  ‚ö†Ô∏è Newly installed Ondat clusters must be licensed within 24 hours. Our Community Edition tier supports up to 1TiB of provisioned storage.\n To obtain a license, follow the instructions on our licensing operations page.\nProvision an Ondat Volume Now that we have a working Ondat cluster, we can provision a volume to test everything is working as expected.\n  Create a PVC\nkubectl create -f - \u0026lt;\u0026lt;END apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc-1 spec: storageClassName: \u0026#34;storageos\u0026#34; accessModes: - ReadWriteOnce resources: requests: storage: 5Gi END   Create 2 replicas by labeling your PVC\nkubectl label pvc pvc-1 storageos.com/replicas=2   Verify that the volume and replicas were created with the CLI\n pvc-1 should be listed in the CLI output\n POD=$(kubectl -n storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli) kubectl -n storageos exec $POD -- storageos get volumes   Create a pod that consumes the PVC\nkubectl create -f - \u0026lt;\u0026lt;END apiVersion: v1 kind: Pod metadata: name: d1 spec: containers: - name: debian image: debian:9-slim command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while true; do sleep 3600; done\u0026#34;] volumeMounts: - mountPath: /mnt name: v1 volumes: - name: v1 persistentVolumeClaim: claimName: pvc-1 END   Check that the pod starts successfully. If the pod starts successfully then the Ondat cluster is working correctly\nkubectl get pod d1 -w The pod mounts an Ondat volume under /mnt so any files written there will persist beyond the lifetime of the pod. This can be demonstrated using the following commands.\n  Execute a shell inside the pod and write some data to a file\nkubectl exec -it d1 -- bash # echo Hello World! \u0026gt; /mnt/hello # cat /mnt/hello  Hello World! should be printed to the console.\n   Delete the pod\nkubectl delete pod d1   Recreate the pod\nkubectl create -f - \u0026lt;\u0026lt;END apiVersion: v1 kind: Pod metadata: name: d1 spec: containers: - name: debian image: debian:9-slim command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while true; do sleep 3600; done\u0026#34;] volumeMounts: - mountPath: /mnt name: v1 volumes: - name: v1 persistentVolumeClaim: claimName: pvc-1 END   Open a shell inside the pod and check the contents of /mnt/hello\nkubectl exec -it d1 -- cat /mnt/hello  Hello World! should be printed to the console.\n   Ondat Features Now that you have a fully functional Ondat cluster we will explain some of our features that may be of use to you as you complete application and synthetic benchmarks.\nOndat features are all enabled/disabled by applying labels to volumes. These labels can be passed to Ondat via persistent volume claims (PVCs) or can be applied to volumes using the Ondat CLI or GUI.\n üí° The following is not an exhaustive feature list but outlines features which are commonly of use during a self-evaluation.\n Volume Replication Ondat enables synchronous replication of volumes using the storageos.com/replicas label.\nThe volume that is active is referred to as the master volume. The master volume and its replicas are always placed on separate nodes. In fact if a replica cannot be placed on a node without a replica of the same volume, the volume will fail to be created. For example, in a three node Ondat cluster a volume with 3 replicas cannot be created as the third replica cannot be placed on a node that doesn\u0026rsquo;t already contain a replica of the same volume.\n üí° See our replication documentation for more information on volume replication.\n   To test volume replication create the following PersistentVolumeClaim\nkubectl create -f - \u0026lt;\u0026lt;END apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc-replicated labels: storageos.com/replicas: \u0026#34;1\u0026#34; spec: storageClassName: \u0026#34;storageos\u0026#34; accessModes: - ReadWriteOnce resources: requests: storage: 5Gi END  üí° Note that volume replication is enabled by setting the storageos.com/replicas label on the volume.\n   Confirm that a replicated volume has been created by using the Ondat CLI or UI\nPOD=$(kubectl -n storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli) kubectl -n storageos exec $POD -- storageos get volumes   Create a pod that uses the PVC\nkubectl create -f - \u0026lt;\u0026lt;END apiVersion: v1 kind: Pod metadata: name: replicated-pod spec: containers: - name: debian image: debian:9-slim command: [\u0026#34;/bin/sleep\u0026#34;] args: [ \u0026#34;3600\u0026#34; ] volumeMounts: - mountPath: /mnt name: v1 volumes: - name: v1 persistentVolumeClaim: claimName: pvc-replicated END   Write data to the volume\nkubectl exec -it replicated-pod -- bash # echo Hello World! \u0026gt; /mnt/hello # cat /mnt/hello  Hello World! should be printed to the console.\n   Find the location of the master volume and shutdown the node\nShutting down a node causes all volumes, with online replicas, on the node to be evicted. For replicated volumes this immediately promotes a replica to become the new master.\nkubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE pvc-replicated Bound pvc-29e2ad6e-8c4e-11e9-8356-027bfbbece86 5Gi RWO storageos 1m POD=$(kubectl -n storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli) kubectl -n storageos exec $POD -- storageos get volumes NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE default pvc-4e796a62-0271-45f9-9908-21d58789a3fe 5.0 GiB kind-worker (online) kind-worker2 1/1 26 seconds ago   Check the location of the master volume and notice that it is on a new node. If the pod that mounted the volume was located on the same node that was shutdown then the pod will need to be recreated.\nPOD=$(kubectl -n storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli) kubectl -n storageos exec $POD -- storageos get volumes NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE default pvc-4e796a62-0271-45f9-9908-21d58789a3fe 5.0 GiB kind-worker2 (online) kind-worker2 1/1 46 seconds ago   Check that the data is still accessible to the pod\nkubectl exec -it replicated-pod -- bash # cat /mnt/hello  Hello World! should be printed to the console.\n   ¬†Benchmarking Benchmarking storage is a complex topic. Considering the many books and papers that have been written about benchmarking, we could write many paragraphs here and only begin to scratch the surface.\nTaking this complexity into account we present recipes for both synthetic benchmarks using FIO, and a sample application benchmark to test PostgreSQL using pgbench. The approaches are complementary - synthetic benchmarks allow us to strictly control the parameters of the IO we put through the system in order to stress various aspects of it. Application benchmarks allow us to get a sense of the performance of the system when running an actual representative workload - which of course is the ultimate arbiter of performance.\nDespite the inherent complexity of benchmarking storage there are a few general considerations to keep in mind.\nConsiderations Local vs. Remote Volumes When a workload is placed on the same node as a volume, there is no network round trip for IO, and performance is consequently improved. When considering the performance of Ondat it is important to evaluate both local and remote volumes; since for certain workloads we want the high performance of a local attachment, but we also desire the flexibility of knowing that our less performance-sensitive workloads can run from any node in the cluster.\nThe Effect of Synchronous Replication Synchronous replication does not impact the read performance of a volume, but it can have a significant impact on the write performance of the volume, since all writes must be propagated to replicas before being acked to the application. The impact varies in proportion to the inter-node latency. For an inter-node latency of 1ms, we have a max ceiling of 1000 write IOPS, and in reality a little less than that to allow for processing time on the nodes. This is less concerning then it may first appear, since many applications will issue multiple writes in parallel (known as increasing the queue depth).\nSynthetic Benchmarks Prerequisites  Kubernetes cluster with a minimum of 3 nodes and a minimum of 30 Gb available capacity Ondat CLI running as a pod in the cluster  Synthetic benchmarks using tools such as FIO are a useful way to begin measuring Ondat performance. While not fully representative of application performance, they allow us to reason about the performance of storage devices without the added complexity of simulating real world workloads, and provide results easily comparable across platforms.\nFIO has a number of parameters that can be adjusted to simulate a variety of workloads and configurations. Parameters that are particularly important are:\n Block Size - the size of the IO units performed. Queue Depth - the amount of concurrent IOs in flight IO Pattern - access can be random across the disk, or sequentially. IO subsystems typically perform better with sequential IO, because of the effect of read ahead caches, and other factors  For this self-evaluation we will run a set of tests based on the excellent DBench, which distills the numerous FIO options into a series of well-crafted scenarios:\n Random Read/Write IOPS and BW - these tests measure the IOPS ceiling (with a 4k block size) and bandwidth ceiling (with a 128K block size) of the volume using a random IO pattern and high queue depth Average Latency - these tests measure the IO latency of the volume under favourable conditions using a random access pattern, low queue depth and low block size Sequential Read/Write - these tests measure the sequential read/write throughput of the volume with a high queue depth and high block size Mixed Random Read/Write IOPS - these tests measure the performance of the volume under a 60/40 read/write workload using a random access pattern and low blocksize  For convenience we present a single script to run the scenarios using local and remote volumes both with and without a replica. Deploy the FIO tests for the four scenarios using the following command:\ncurl -sL https://raw.githubusercontent.com/ondat/use-cases/main/scripts/deploy-synthetic-benchmarks.sh | bash  üí° The script will take approximately 20 minutes to complete, and will print the results to STDOUT.\n The exact results observed will depend on the particular platform and environment, but the following trends should be observable:\n local volumes perform faster than remote volumes read performance is independent of the number of replicas write performance is dependent on the number of replicas  Application Benchmarks While synthetic benchmarks are useful for examining the behaviour of Ondat with very specific workloads, in order to get a realistic picture of Ondat performance actual applications should be tested.\nMany applications come with test suites which provide standard workloads. For best results, test using your application of choice with a representative configuration and real world data.\nAs an example of benchmarking an application the following steps lay out how to benchmark a Postgres database backed by an Ondat volume.\n  Start by cloning the Ondat use cases repository. Note this is the same repository that we cloned earlier so if you already have a copy just cd storageos-usecases/pgbench.\ngit clone https://github.com/storageos/use-cases.git storageos-usecases   Move into the Postgres examples folder\ncd storageos-usecases/pgbench   Decide which node you want the pgbench pod and volume to be located on. The node needs to be labelled app=postgres\nkubectl label node \u0026lt;NODE\u0026gt; app=postgres   Then set the storageos.com/hint.master label in 20-postgres-statefulset.yaml file to match the Ondat nodeID for the node you have chosen before creating all the files. The Ondat nodeID can be obtained using the cli and doing a describe node\nkubectl create -f .   Confirm that Postgres is up and running\nkubectl get pods -w -l app=postgres   Use the Ondat CLI or the GUI to check the master volume location and the mount location. They should match\nPOD=$(kubectl -n storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli) kubectl -n storageos exec $POD -- storageos get volumes   Exec into the pgbench container and run pgbench\nkubectl exec -it pgbench -- bash -c \u0026#39;/opt/cpm/bin/start.sh\u0026#39;   ¬†Conclusion After completing these steps you will have benchmark scores for Ondat.\n üí° Do keep in mind that benchmarks are only part of the story and that there is no replacement for testing actual production or production like workloads.\n Ondat invites you to provide feedback on your self-evaluation to the slack channel or by directly emailing us at info@ondat.io.\n","excerpt":"Our self-evaluation guide is a step by step recipe for installing and testing Ondat. This guide is ‚Ä¶","ref":"/docs/introduction/self-eval/","title":"Self Evaluation Guide"},{"body":"","excerpt":"","ref":"/docs/ondat-portal/","title":"Ondat SaaS Platform"},{"body":"","excerpt":"","ref":"/index.json","title":""},{"body":"Ondat implements a MutatingAdmissionWebhook Admission Controller to ensure that Pods using Ondat Volumes use the storageos-scheduler. An admission controller intercepts requests to the Kubernetes API server prior to persistence of the object, but after the request is authenticated and authorized.\nThe Admission Controller is responsible for mutating the PodSpec at creation time to populate the PodSpec.schedulerName field with the name of the Ondat Scheduler - storageos-scheduler.\nDuring Pod creation, Kubernetes sends a web request to the Ondat WebHook with the Pod specification. The PodSpec is only altered to use the Ondat scheduler if the Pod uses an Ondat volume.\nWeb Server The Web Server hosting the web hook is executed in the Ondat Cluster Operator. Since only HTTPS requests are allowed, the Operator generates a self-signed x509 certificate every time it starts. The Operator will also renew certificates upon expiry (certs are valid for one year).\nThere is no manual intervention required regarding the SSL configuration as the setup is completely transparent between Ondat and Kubernetes.\nSkipping Mutation To avoid scheduler mutation, the storageos.com/scheduler=false annotation can be added to resources that use Ondat volumes.\nWhen using StatefulSets the annotation can be set on the spec.template.metadata.annotations field.\napiVersion:apps/v1kind:StatefulSetspec:...template:metadata:annotations:storageos.com/scheduler:\u0026#34;false\u0026#34;# N.B. the value must be a string and not a booleanWhen using Pods the annotation is set on the metadata.annotations field.\napiVersion:v1kind:Podmetadata:...annotations:storageos.com/scheduler:\u0026#34;false\u0026#34;# N.B. the value must be a string and not a boolean...Explicit SchedulerName  üí° It is not necessary to explicitly set the SchedulerName as the Admission Controller automatically populates the PodSpec field. Set the SchedulerName in your manifests, manually, only if you disable or can\u0026rsquo;t execute the Ondat Admission Controller.\n Kubernetes allows the use of different schedulers by setting the field .spec.schedulerName: storageos-scheduler.\nFor instance a Pod manifest utilising the Ondat scheduler would appear as follows:\napiVersion: v1 kind: Pod metadata: name: d1 spec: schedulerName: storageos-scheduler # --\u0026gt; Ondat Scheduler # No need if using Admission Controller # (enabled by default) containers: - name: debian image: debian:9-slim command: [\u0026#34;/bin/sleep\u0026#34;] args: [ \u0026#34;3600\u0026#34; ] volumeMounts: - mountPath: /mnt name: v1 volumes: - name: v1 persistentVolumeClaim: claimName: persistent-volume # ----\u0026gt; Ondat PVC Compatibility The Admission Controller doesn\u0026rsquo;t need to be enabled at Kubernetes cluster bootstrap time because it is a Dynamic Admission Controller. Hence, any cluster that has the MutatingAdmissionWebhook enabled is supported. Most Kubernetes cluster enable the Webhook admission controller by default.\nThe MutatingAdmissionWebhook is available from Kubernetes v1.13.\nYou can check your Kubernetes cluster compatibility by checking if the following object exists.\nkubectl api-versions | grep admissionregistration.k8s.io ","excerpt":"Ondat implements a MutatingAdmissionWebhook Admission Controller to ensure that Pods using Ondat ‚Ä¶","ref":"/docs/reference/scheduler/admission-controller/","title":"Admission Controller"},{"body":" \t window.onload = function() { const ui = SwaggerUIBundle({ url: \"/yaml/api-swagger-v2.yaml\", dom_id: '#ohpen_swagger_ui', presets: [ SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset ] }) window.ui = ui } \t","excerpt":" \t window.onload = function() { const ui = SwaggerUIBundle({ url: \"/yaml/api-swagger-v2.yaml\", ‚Ä¶","ref":"/docs/reference/api/","title":"API Reference"},{"body":"Cassandra is a popular distributed NoSQL open source database.\nUsing Ondat persistent volumes with Cassandra means that if a Cassandra pod fails, the cluster is only in a degraded state for as long as it takes Kubernetes to restart the pod. When the pod comes back up the pod data is immediately available. Should Kubernetes schedule the Cassandra pod on a new node, Ondat allows for the data to be available to the pod, irrespective of whether or not an Ondat master is located on the same node.\nAs Cassandra has features to allow it to handle replication careful consideration of whether to allow Ondat or Cassandra to handle replication is required.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nDeploying Cassandra on Kubernetes   You can find the latest files in the Ondat use cases repository\ngit clone https://github.com/storageos/use-cases.git storageos-usecases StatefulSet defintion\napiVersion:apps/v1kind:StatefulSetmetadata:name:cassandraspec:selector:matchLabels:app:cassandraserviceName:cassandrareplicas:3...spec:...volumeMounts:- name:cassandra-datamountPath:/var/lib/cassandra...volumeClaimTemplates:- metadata:name:cassandra-dataspec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:\u0026#34;storageos\u0026#34;# Ondat storageClassresources:requests:storage:5GiThis excerpt is from the StatefulSet definition. This file contains the VolumeClaim template that will dynamically provision storage, using the Ondat storage class. Dynamic provisioning occurs as a volumeMount has been declared with the same name as a VolumeClaimTemplate.\n  Move into the Cassandra examples folder and create the objects\ncd storageos-usecases kubectl create -f ./cassandra   Confirm Cassandra is up and running.\n$ kubectl get pods -w -l app=cassandra NAME READY STATUS RESTARTS AGE cassandra-0 1/1 Running 0 8m32s cassandra-1 1/1 Running 0 7m51s cassandra-2 1/1 Running 0 6m36s   Connect to the Cassandra client pod and connect to the Cassandra server through the service\n$ kubectl exec -it cassandra-0 -- cqlsh cassandra-0.cassandra Connected to K8Demo at cassandra-0.cassandra:9042. [cqlsh 5.0.1 | Cassandra 3.11.3 | CQL spec 3.4.4 | Native protocol v4] Use HELP for help. cqlsh\u0026gt; SELECT cluster_name, listen_address FROM system.local; cluster_name | listen_address --------------+---------------- K8Demo | 100.96.7.124 (1 rows)   ","excerpt":"Cassandra is a popular distributed NoSQL open source database.\nUsing Ondat persistent volumes with ‚Ä¶","ref":"/docs/usecases/cassandra/","title":"Cassandra"},{"body":"Ondat clusters represent groups of nodes which run a common distributed control plane.\nTypically, an Ondat cluster maps one-to-one to a Kubernetes (or similar orchestrator) cluster, and we expect our daemonset to run on all worker nodes within the cluster that will consume or present storage.\nClusters use etcd to maintain state and manage distributed consensus between nodes.\n","excerpt":"Ondat clusters represent groups of nodes which run a common distributed control plane.\nTypically, an ‚Ä¶","ref":"/docs/reference/clusters/","title":"Cluster"},{"body":"We are always looking to improve our documentation. If you like to help people and can write, read on for the process for submitting your contributions. If your guide is published, you\u0026rsquo;ll receive $250 per article by PayPal.\nContent guidelines A guide contains step by step instructions for how to accomplish a specific task using Ondat. To be accepted, guides must be:\n Written in English. Relevant, accurate and complete. Technically correct and thoroughly tested.  Guides should avoid:\n Duplicating an existing guide or other sources, such as blogs or forum posts. Including irrelevant material.  Submission and review You should submit your guide as a pull request to the GitHub repository.\nYour submission will be left open for community review for two weeks. After this, your submission will be reviewed internally for about another week.\nIf accepted, your pull request will be approved and you will have 36 hours to send your submission title and PayPal account information. Non-response will be taken as a go-ahead to publish.\nLegal COPYRIGHT OWNERSHIP. The Ondat Guides \u0026amp; Tutorials repository is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.\nCREDIT. Nothing contained in this Agreement shall be deeded to require Ondat to use the Work, or any part thereof, in connection with Ondat Guides \u0026amp; Tutorials or otherwise. Credit for the Work shall read, ‚ÄúContributed by writer‚Äôs name.‚Äù\nPAYMENT. Upon publication of a submission to the Ondat Guides \u0026amp; Tutorials Repository, the writer will be paid the sum of USD $250.00 as an electronic payment.\n","excerpt":"We are always looking to improve our documentation. If you like to help people and can write, read ‚Ä¶","ref":"/docs/reference/contributing/","title":"Contributing to the documentation"},{"body":"When a Kubernetes object is deleted, Ondat controllers automatically sync this deletion to Ondat. For example, when a Kubernets node is deleted, this will automatically be mirrored in Ondat, likewise with Namespaces.\n  Here is an Ondat node, running on Kubernetes node worker1. An Ondat node is any machine that is running the Ondat daemonset pod. The node is visible below in kubectl.\n$ kubectl describe -n storageos pod storageos-daemonset-6q4g8 Name: storageos-daemonset-6q4g8 Namespace: storageos Priority: 2000001000 Priority Class Name: system-node-critical Node: worker1/192.168.152.238 Start Time: Thu, 06 May 2021 15:53:34 +0100 Labels: app=storageos app.kubernetes.io/component=storageos-daemonset app.kubernetes.io/instance=example-ondat app.kubernetes.io/managed-by=storageos-operator app.kubernetes.io/name=storageos app.kubernetes.io/part-of=storageos controller-revision-hash=f5dcf577d kind=daemonset pod-template-generation=1 storageos_cr=example-ondat Annotations: kubectl.kubernetes.io/default-logs-container: storageos Status: Running IP: 192.168.152.238 ... The nodes in your cluster can be seen with storageos get nodes.\n$ storageos get nodes NAME HEALTH AGE LABELS worker1 online 1 day ago beta.kubernetes.io/arch=amd64, beta.kubernetes.io/os=linux, cattle.io/creator=norman, kubernetes.io/arch=amd64, kubernetes.io/hostname=worker1, kubernetes.io/os=linux, node-role.kubernetes.io/worker=true storageos.com/computeonly=true worker2 online 1 day ago beta.kubernetes.io/arch=amd64, beta.kubernetes.io/os=linux, cattle.io/creator=norman, kubernetes.io/arch=amd64, kubernetes.io/hostname=worker2, kubernetes.io/os=linux, node-role.kubernetes.io/worker=true worker3 online 1 day ago beta.kubernetes.io/arch=amd64, beta.kubernetes.io/os=linux, cattle.io/creator=norman, kubernetes.io/arch=amd64, kubernetes.io/hostname=worker3, kubernetes.io/os=linux, node-role.kubernetes.io/worker=true ...   Delete the node.\nkubectl delete node worker1   Verify that the node has been deleted with kubectl get nodes or storageos get nodes. The node has now disappeared from Ondat.\n$ storageos get nodes NAME HEALTH AGE LABELS worker2 online 1 day ago beta.kubernetes.io/arch=amd64, beta.kubernetes.io/os=linux, cattle.io/creator=norman, kubernetes.io/arch=amd64, kubernetes.io/hostname=worker2, kubernetes.io/os=linux, node-role.kubernetes.io/worker=true worker3 online 1 day ago beta.kubernetes.io/arch=amd64, beta.kubernetes.io/os=linux, cattle.io/creator=norman, kubernetes.io/arch=amd64, kubernetes.io/hostname=worker3, kubernetes.io/os=linux, node-role.kubernetes.io/worker=true ...   ","excerpt":"When a Kubernetes object is deleted, Ondat controllers automatically sync this deletion to Ondat. ‚Ä¶","ref":"/docs/operations/delete-stos-objects/","title":"Deleting Ondat Objects"},{"body":"Ondat can generate a cluster diagnostic bundle from the GUI or CLI under user request. The bundle packages the information needed for the engineering team to understand the context of your cluster and begin troubleshooting any issues you may be experiencing.\nGenerate Bundle CLI The CLI can generate the bundle.\nstorageos get diagnostics  üí° The file generated is in the form of diagnostics-${TIME_STAMP}.gz\n GUI Or you can use the StoregeOS GUI.\n Go to section \u0026ldquo;Cluster\u0026rdquo; Press the button \u0026ldquo;DOWNLOAD DIAGNOSTICS\u0026rdquo;.  Data collected in the bundle Most of the data collected in the bundle is regarding the state of the Ondat cluster, however some other information regarding the infrastructure is also gathered. The information is used to have a clear view of the cluster where Ondat is running.\nThe bundle incorporates for each node:\n Ondat Daemonset Pod logs lshw dmesg (kernel logs) Ondat metadata for the ControlPlane and DataPlane  Ondat metadata collected  cluster metadata namespaces metadata nodes metadata volumes metadata capacity stats environment variables health  Privacy Ondat can only obtain the bundle if it is downloaded by the user and given to our engineering team, or uploaded for analysis. The data received by Ondat is private and never leaves nor will leave Ondat Inc.\nThe data contained in the cluster diagnostic bundle has the sole purpose of helping customers troubleshoot their issues.\n","excerpt":"Ondat can generate a cluster diagnostic bundle from the GUI or CLI under user request. The bundle ‚Ä¶","ref":"/docs/reference/bundles/diagnostic-bundle/","title":"Diagnostic bundle"},{"body":"","excerpt":"","ref":"/docs/","title":"Documentation"},{"body":"Elasticsearch is a distributed, RESTful search and analytics engine, most popularly used to aggregate logs, but also to serve as a search backend to a number of different applications.\nUsing Ondat persistent volumes with ElasticSearch (ES) means that if a pod fails, the cluster is only in a degraded state for as long as it takes Kubernetes to restart the pod. When the pod comes back up, the pod data is immediately available. Should Kubernetes schedule the Elasticsearch pod on a new node, Ondat allows for the data to be available to the pod, irrespective of whether or not the original Ondat master volume is located on the same node.\nElasticsearch has features to allow it to handle data replication, and as such careful consideration of whether to allow Ondat or Elasticsearch to handle replication is required.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nDeploying Elasticsearch on Kubernetes Prerequisites Some OS tuning is required, which is done automatically when using our example from the use cases repository.\nElasticsearch requires vm.max_map_count to be increased to a minimum of 262144, which is a system wide setting. One way to achieve this is to run sysctl -w vm.max_map_count=262144 and update /etc/sysctl.conf to ensure it persists over a reboot. See ElasicSearch reference here.\nAdministrators should be aware that this impacts the behaviour of nodes and that there may be collisions with other application settings. Administrators are advised to centrally collate sysctl settings using the tooling of their choice.\nDeployment of the application StatefulSet defintion ---apiVersion:apps/v1kind:StatefulSetmetadata:name:esdata[...]spec:serviceAccountName:elasticsearchcontainers:- name:dataimage:elasticsearch:6.7.0imagePullPolicy:IfNotPresent[...]volumeMounts:- name:datamountPath:/usr/share/elasticsearch/data/data[...]volumeClaimTemplates:- metadata:name:\u0026#34;data\u0026#34;spec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:\u0026#34;storageos\u0026#34;# \u0026lt;--- default Ondat storage class nameresources:requests:storage:10Gi # \u0026lt;--- change this to the appropriate valueThis excerpt is from the StatefulSet definition (/elasticsearch/10-es-data.yaml). The file contains the PersistentVolumeClaim template that will dynamically provision the necessary storage, using the Ondat storage class.\nDynamic provisioning occurs as a volumeMount has been declared with the same name as a VolumeClaimTemplate.\nInstallation Clone the use cases repository You can find the latest files in the Ondat use cases repostiory in /elasticsearch/\ngit clone https://github.com/storageos/use-cases.git storageos-usecases cd storageos-usecases   Create the kubernetes objects\nThis will install an ES cluster with 3 master, 3 data and 3 coordinator nodes. Combined they will require ~ 14 GiB of available memory in your cluster, however, more may be used as the application is being used\nkubectl apply -f ./elasticsearch/ Once completed, an internal service object will have been created making the cluster available as http://elasticsearch:9200/ which is the default Kibana (when installed via Helm) will be using.\n  Confirm Elasticsearch is up and running\nkubectl get pods -l component=elasticsearch NAME READY STATUS RESTARTS AGE elasticsearch-exporter-d86ffd94-zw45l 1/1 Running 0 5m44s es-coordinator-b7b984dd4-7wlz5 1/1 Running 0 5m44s es-coordinator-b7b984dd4-89w26 1/1 Running 0 5m44s es-coordinator-b7b984dd4-b4t6j 1/1 Running 0 5m44s es-master-78dfd5b49f-9gf5c 1/1 Running 0 5m44s es-master-78dfd5b49f-smsbw 1/1 Running 0 5m44s es-master-78dfd5b49f-z4qpj 1/1 Running 0 5m44s esdata-0 1/1 Running 0 5m44s esdata-1 1/1 Running 0 4m34s esdata-2 1/1 Running 0 3m22s   Connect to ElasticSearch\nTo connect to ES directly, you can use the following port-forward command\nkubectl port-forward svc/elasticsearch 9200 and then access it via http://localhost:9200\n  Kibana (optional) One of the most popular uses of ES is to use it for log aggregation and indexing, Kibana helps us visualize the data in these indices and can be easily used when installed via its Helm chart\n  Install the helm chart.\nhelm install stable/kibana   Once installed, use a port-foward to Kibana instead of directly to ES\nkubectl port-forward --namespace default $(kubectl get pods --namespace default -l \u0026#34;app=kibana\u0026#34; -o jsonpath=\u0026#34;{.items[0].metadata.name}\u0026#34;) 5601 and then access it via http://localhost:5601\n  Monitoring (optional) As part of the example deployment, ES metrics are exposed and can be scraped by Prometheus on port 9108 (see 77-es-exporter.yaml). This is enabled by default, and should work with the default Prometheus install via Helm. If you\u0026rsquo;re using the Prometheus service monitors, you can monitor this installation by creating a monitor for the es-exporter service.\n","excerpt":"Elasticsearch is a distributed, RESTful search and analytics engine, most popularly used to ‚Ä¶","ref":"/docs/usecases/elasticsearch/","title":"Elasticsearch"},{"body":"Check the etcd prerequisites page for a step by step installation of etcd.\nBest practices - Etcd Inside the Cluster This page describe best practices when hosting etcd inside Kubernetes using Ondat\u0026rsquo;s etcd operator. Best practices when hosting etcd outside Kubernetes can be found here\nOndat uses etcd as a service, whether it is deployed following the step by step instructions or as a custom installation.\nThe etcd operator will maintain availability and integrity of the etcd cluster, however it is recommended to monitor etcd metrics to ensure the cluster is functioning as expected.\nIt is highly recommended to keep the cluster backed up and ensure high availability of its data.\nNetwork low latency It is important to keep the latency between Ondat nodes and the etcd replicas low. Deploying an etcd cluster in a different data center or region can make Ondat detect etcd nodes as unavailable due to latency. 10ms latency between Ondat and etcd would be the maximum threshold for proper functioning of the system.\nDisk low latency Etcd is very sensitive to disk latency. Because of that, it is recommended to run etcd away from other IO-intensive workloads. Operations such as backups, builds or application bundling cause a heavy usage of disks. If such operations run alongside the etcd nodes, they will cause etcd to become unstable and suffer downtime. It is best to run etcd nodes isolated from other IO workloads.\nIOPS requirements As a general rule, for etcd to operate normally on production clusters, we recommend using the size of machine offered by your cloud provider that guarantees a minimum of 500 IOPS. For example, 750 baseline IOPS are guaranteed on a 250GB AWS gp2 EBS instance at time of writing, and block instances on other cloud providers will also specify baseline IOPS figures.\nCloud providers usually provide \u0026ldquo;bursts\u0026rdquo; of IOPS - temporarily higher rates, limited by credits - with larger volumes providing higher burst capacity. If you are relying on burst capacity for etcd, which requires sustained high performance, careful assessment is necessary to ensure sufficient capacity.\nThe rate of etcd operations is affected by the number of nodes, volumes and replicas in the cluster, therefore the figure of 500 is provided as a guideline only. A development cluster with 5 nodes will not have the same etcd traffic as a production cluster with 100 nodes. Adding monitoring to etcd will help to characterise the traffic, and therefore to assess the individual requirements of a cluster and adjust its resources accordingly.\nMonitoring It is highly recommended to add monitoring to the etcd cluster. When using the Ondat etcd operator etcd serves Prometheus metrics on a separate metrics port http://storageos-etcd.storageos-etcd:2381/metrics.\nYou can use Ondat developed Grafana Dashboards for etcd. When using etcd for production, you can use the etcd-cluster-as-service, while the etcd-cluster-as-pod can be used when using etcd from the operator.\nDefragmentation Etcd uses revisions to store multiple versions of keys. Compaction removes all key revision prior to a certain revision from etcd. Typically the etcd configuration enables the automatic compaction of keys to prevent performance degradation and limit the storage required. Compaction of revisions can create fragmentation that means space on disk is available for use by etcd but is unavailable for use by the file system. In order to reclaim this space, etcd can be defragmented.\nReclaiming space is important because when the etcd database file grows over the \u0026ldquo;DB_BACKEND_BYTES\u0026rdquo; parameter, the cluster triggers an alarm and sets itself read only and only allows reads and deletes. To avoid hitting the db backend bytes limit, compaction and defragmentation are required. How often defragmentation is required depends on the churn of key revisions in etcd.\nBe aware that defragmentation is a blocking operation that is performed per node, hence the etcd node will be locked for the duration of the defragmentation. Defragmentation usually takes a few milliseconds to complete.\nThe etcd operator will automatically defrag the etcd cluster when it reaches 80% used space or every hour. It will never defrag more than one etcd peer at once, so etcd will remain available.\n","excerpt":"Check the etcd prerequisites page for a step by step installation of etcd.\nBest practices - Etcd ‚Ä¶","ref":"/docs/operations/etcd/","title":"Etcd"},{"body":"Ondat requires an etcd cluster in order to function. For more information on why etcd is required, see our etcd concepts page.\nThe etcd used by Kubernetes itself cannot be used for Ondat\u0026rsquo;s configuration as per standards set out by the Kubernetes project.\nFor most use-cases it is recommended to install the Ondat etcd operator, which will manage creation and maintenance of Ondat\u0026rsquo;s etcd cluster. In some circumstances, it makes sense to install etcd on separate machines outside of your Kubernetes cluster.\n","excerpt":"Ondat requires an etcd cluster in order to function. For more information on why etcd is required, ‚Ä¶","ref":"/docs/prerequisites/etcd/","title":"Etcd"},{"body":"This procedure explains how to migrate data from an etcd cluster running outside a Kubernetes cluster towards an installation using the Ondat etcd Operator. As a result the Ondat cluster will use the etcd running as Pods in Kubernetes.\nPrerequisites  Kubectl Helm  It is assumed that both etcd clusters in this procedure are using mTLS.\nProcedure Option A - Manual process   Backup the TLS artifacts from the current etcd cluster (if current etcd uses mTLS) The Secret with the TLS material is usually named storageos-etcd-secret or etcd-client-tls\n$ kubectl get secret \\  -n storageos \\  -o yaml \\  etcd-client-tls \u0026gt; etcd-storageos-tls-secret-backup.yaml   Deploy etcd cluster in Kubernetes\n‚ö†Ô∏è It is required to select a storageClass other than ondat/storageos to run etcd in the cluster. If there is none available in the cluster, you can run the following to deploy a Local Path Provisioner to provide local storage for Ondat\u0026rsquo;s embedded etcd cluster operator deployment. Even though, that CSI provisioner is not intended for production.\n(Optional) Deploy Local path storageClass\nkubectl apply --filename=\u0026#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml\u0026#34; Deploy etcd\n# Add ondat charts repo. $ helm repo add ondat https://ondat.github.io/charts # Install the chart in a namespace. $ helm install storageos-etcd ondat/etcd-cluster-operator \\  --namespace etcd-operator \\  --create-namespace \\  --set ondat.secret=storageos-etcd-secret-incluster \\  --set cluster.storageclass=standard # Choose the one according to your cluster  ‚ö†Ô∏è The Secret name for the etcd client certificates is amended to avoid using the same Secret name as the one used for the old etcd cluster\n  For more details, check the etcd cluster operator chart.\n   Validate etcd\nCheck that etcd pods are starting\n$ kubectl -n storageos-etcd get pod NAME READY STATUS RESTARTS AGE storageos-etcd-0-7b755 1/1 Running 0 1m storageos-etcd-1-q6k5q 1/1 Running 0 1m storageos-etcd-2-s6kck 1/1 Running 0 1m  The pods might take a few minutes to be ready\n   Copy and amend the helper pod definition The following pod will be used as a bridge between the old etcd and the new one. Because of that, it is required to amend the env vars pointing to the URLs of the clusters and mount the TLS secrets to access both of them\nCreate a file helper-etcd-pod.yaml with the following contents.\napiVersion:v1kind:Podmetadata:labels:run:etcdctlname:etcdctl-migrationspec:containers:- image:quay.io/coreos/etcd:v3.5.3name:etcdctlenv:- name:OLD_ETCD_ENDPOINTvalue:https://ip-192-168-17-118.eu-west-1.compute.internal:2379- name:NEW_ETCD_ENDPOINTvalue:https://storageos-etcd.storageos-etcd:2379- name:OLD_ETCD_CERTS_DIRvalue:\u0026#39;/etc/etcd_old/certs\u0026#39;# defined in the volumes from a Secret- name:NEW_ETCD_CERTS_DIRvalue:\u0026#39;/etc/etcd_new/certs\u0026#39;# defined in the volumes from a Secret- name:OLD_ETCD_CMD_OPTSvalue:\u0026#34;--endpoints $(OLD_ETCD_ENDPOINT) --cacert $(OLD_ETCD_CERTS_DIR)/etcd-client-ca.crt --key $(OLD_ETCD_CERTS_DIR)/etcd-client.key --cert $(OLD_ETCD_CERTS_DIR)/etcd-client.crt\u0026#34;- name:NEW_ETCD_CMD_OPTSvalue:\u0026#34;--endpoints $(NEW_ETCD_ENDPOINT) --cacert $(NEW_ETCD_CERTS_DIR)/etcd-client-ca.crt --key $(NEW_ETCD_CERTS_DIR)/etcd-client.key --cert $(NEW_ETCD_CERTS_DIR)/etcd-client.crt\u0026#34;command:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;]args:- \u0026#34; etcdctl make-mirror \\ $(OLD_ETCD_CMD_OPTS) \\ --dest-cacert $(NEW_ETCD_CERTS_DIR)/etcd-client-ca.crt \\ --dest-cert $(NEW_ETCD_CERTS_DIR)/etcd-client.crt \\ --dest-key $(NEW_ETCD_CERTS_DIR)/etcd-client.key \\ $(NEW_ETCD_ENDPOINT) \u0026#34;volumeMounts:- mountPath:/etc/etcd_old/certsname:cert-dir-old- mountPath:/etc/etcd_new/certsname:cert-dir-newvolumes:- name:cert-dir-oldsecret:defaultMode:420secretName:storageos-etcd-secret- name:cert-dir-newsecret:defaultMode:420secretName:storageos-etcd-secret-incluster Amend the env var OLD_ETCD_ENDPOINT with your cluster\u0026rsquo;s URL Amend the spec.volumes.secret.secretName according to the Secrets' names on your cluster.    Run the helper pod\nkubectl -n storageos create -f ./helper-etcd-pod.yaml  The helper pod creates a mirror between both etcd clusters\n   Wait for the mirror\n$ kubectl -n storageos logs etcdctl-migration -f 893  ‚ö†Ô∏è Wait until the command outputs an integer (the number of keys synced). The number must not be 0. If that is the case:\n Exec to the pod: kubectl -n storageos exec -it etcdctl-migration -- bash Check env vars env | grep ETCD Check connectivity etcdctl $OLD_ETCD_CMD_OPTS member list; etcdctl $NEW_ETCD_CMD_OPTS member list     Stop stateful applications Scale down to 0 replicas all applications using Ondat volumes and wait until all pods are stopped\ni.e\nkubectl scale statefulset YOUR_STS --replicas=0   Backup StorageOS CustomResource\nkubectl get storageosclusters.storageos.com \\  -n storageos \\  -oyaml \\  storageoscluster \u0026gt; storageos-cluster.yaml Verify the backup\ncat storageos-cluster.yaml   Stop Ondat\nkubectl -n storageos delete storageosclusters.storageos.com storageoscluster   Stop mirror\nkubectl -n $STOS_NS delete pod etcdctl-migration   Amend the StoragseOS Cluster CustomResource\nEdit the file storageos-cluster.yaml\n Set the new etcd address in kvBackend.address Set the new Secret in tlsEtcdSecretRefName  i.e:\nspec:...kvBackend:address:storageos-etcd.storageos-etcd:2379tlsEtcdSecretRefName:storageos-etcd-secret-inclustertlsEtcdSecretRefNamespace:storageos  Start Ondat\n$ kubectl -n storageos create -f storageos-cluster.yaml storageoscluster.storageos.com/storageoscluster created Wait until pods are running\n$ kubectl -n storageos get pod NAME READY STATUS RESTARTS AGE etcdctl-migration 1/1 Running 0 8m5s storageos-operator-67678c896d-npq5m 2/2 Running 6 (33m ago) 5h44m storageos-scheduler-7fdb74fb8c-t675h 1/1 Running 0 2s storageos-node-8z7mj 3/3 Running 0 2s storageos-node-r8trk 3/3 Running 0 2s storageos-node-c28pk 3/3 Running 0 3s storageos-api-manager-5cccf759d8-c58tx 1/1 Running 0 1s storageos-csi-helper-65db657d7c-hqvdt 3/3 Running 0 2s storageos-api-manager-5cccf759d8-ppxhd 1/1 Running 0 2s   Validate Ondat is connecting to the new etcd Search for ETCD connection established and the new etcd URL in the logs of the daemonset pods.\nThe pattern suggested must be found on any of the daemonset node pods.\n$ kubectl -n storageos logs ds/storageos-node | grep \u0026#34;ETCD connection established\u0026#34; {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;ETCD connection established at: [storageos-etcd.storageos-etcd:2379]\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-06-20T16:16:05.593281009Z\u0026#34;}   Start stateful applications\n  Clean up\n Decommission the old etcd after a period of safety. Delete old TLS secret from the StorageOS namespace when the etcd is decommissioned.    Option B - Automated  Before starting this procedure it is required to stop all usage of Ondat volumes. Therefore any stateful applications need to be scaled to 0.\n  ‚ö†Ô∏è It is required to select a storageClass other than ondat/storageos to run etcd in the cluster. If there is none available in the cluster, you can run the following to deploy a Local Path Provisioner to provide local storage for Ondat\u0026rsquo;s embedded etcd cluster operator deployment. Even though, that CSI provisioner is not intended for production.\n (Optional) Deploy Local path storageClass\nkubectl apply --filename=\u0026#34;https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.21/deploy/local-path-storage.yaml\u0026#34; The following script executes the same steps as the manual procedure.\n  Download script\ncurl -s https://raw.githubusercontent.com/ondat/use-cases/main/scripts/migrate-etcd-external-to-pods.sh -o migrate-etcd-external-to-pods.sh \\  \u0026amp;\u0026amp; chmod +x migrate-etcd-external-to-pods.sh   Run the migration\nETCD_STORAGECLASS=YOUR_STORAGE_CLASS # fill this env var ETCD_ENDPOINT=PROD_ETCD_ENDPOINT # fill this env var ./migrate-etcd-external-to-pods.sh -s $ETCD_STORAGECLASS -e $ETCD_ENDPOINT For example:\n$ ETCD_STORAGECLASS=local-path $ ETCD_ENDPOINT=\u0026#34;ip-192-168-17-118.eu-west-1.compute.internal:2379\u0026#34; $ ./migrate-etcd-external-to-pods.sh \\  -s $ETCD_STORAGECLASS \\  -e $ETCD_ENDPOINT Storing a backup of the storageos-etcd-secret in /tmp/etcd-client-tls.yaml Release \u0026#34;storageos-etcd\u0026#34; does not exist. Installing it now. NAME: storageos-etcd LAST DEPLOYED: Wed Jun 22 16:44:43 2022 NAMESPACE: etcd-operator STATUS: deployed REVISION: 1 TEST SUITE: None Wating for etcd to be ready ........................... Etcd is ready pod/etcdctl-migration created Wating for the mirror ...................... Mirror between etcds is running successfully Backing up the StorageOSCluster configuration Stopping Ondat storageoscluster.storageos.com \u0026#34;storageoscluster\u0026#34; deleted Stopping etcd mirror pod \u0026#34;etcdctl-migration\u0026#34; deleted Starting Ondat storageoscluster.storageos.com/storageoscluster created Wating for Ondat to be ready ........... Ondat is ready Checking that Ondat is pointing to the new etcd cluster in the node container logs: success!   ","excerpt":"This procedure explains how to migrate data from an etcd cluster running outside a Kubernetes ‚Ä¶","ref":"/docs/operations/etcd/cluster-migration-node-to-pod/","title":"Etcd cluster migration"},{"body":"This procedure explains how to add a new etcd member for your Ondat etcd cluster while removing one of the current members. This is useful when the nodes hosting etcd must be recycled.\n ‚ö†Ô∏è It is assumed that the Ondat etcd cluster is installed following the production etcd installation page, where etcd nodes are installed on their own machines.\n  ‚ö†Ô∏è It is also assumed that etcd members are referenced from Kubernetes using a External Service. Example available in the etcd external Service example. This service should be referred to in the spec.kvbackend.address section of your Ondat CustomResource. If that Service is not used, a full restart of the Ondat cluster will be required. The Ondat CustomResource would need to be removed, and amended to reflect the new etcd urls created.\n Preparation Prepare the installation of etcd on a new node, making sure that etcd is not starting on that new node.\nThe steps for preparing an etcd node can be found in the etcd prerequisites page.\n  Back up etcd\nexport ETCDCTL_API=3 # Set all your endpoints export endpoints=\u0026quot;192.168.174.117:2379,192.168.195.168:2379,192.168.174.117:2379\u0026quot; etcdctl --endpoints $endpoints snapshot save /var/tmp/etcd-snapshot.db   Verify etcd health\n$ export ETCDCTL_API=3 $ # Set all your endpoints $ export endpoints=\u0026quot;192.168.174.117:2379,192.168.195.168:2379,192.168.174.117:2379\u0026quot; $ etcdctl member list --endpoints $endpoints -wtable +------------------+---------+-----------------------+------------------------------+-----------------------------+------------+ | ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER | +------------------+---------+-----------------------+------------------------------+-----------------------------+------------+ | 7817aa073b059aab | started | etcd-192.168.195.168 | http://192.168.195.168:2380 | http://192.168.195.168:2379 | false | | e22cdd20a03e5e73 | started | etcd-192.168.202.40 | http://192.168.202.40:2380 | http://192.168.202.40:2379 | false | | e5d0f0e242014d3d | started | etcd-192.168.174.117 | http://192.168.174.117:2380 | http://192.168.174.117:2379 | false | +------------------+---------+-----------------------+------------------------------+-----------------------------+------------+ $ etcdctl endpoint health --endpoints $endpoints -wtable +---------------------+--------+------------+-------+ | ENDPOINT | HEALTH | TOOK | ERROR | +---------------------+--------+------------+-------+ |192.168.174.117:2379 | true | 5.048177ms | | |192.168.195.168:2379 | true | 5.926681ms | | |192.168.202.40:2379 | true | 5.526928ms | | +---------------------+--------+------------+-------+ $ etcdctl endpoint status --endpoints $endpoints -wtable +---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS | +---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ |192.168.174.117:2379 | e5d0f0e242014d3d | 3.4.9 | 311 kB | false | false | 2 | 4281 | 4281 | | |192.168.195.168:2379 | 7817aa073b059aab | 3.4.9 | 315 kB | false | false | 2 | 4281 | 4281 | | |192.168.202.40:2379 | e22cdd20a03e5e73 | 3.4.9 | 352 kB | true | false | 2 | 4281 | 4281 | | +---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+   Migration  üí° In the following procedure NODE4 is a new member to add to the cluster, while NODE1 ought to be removed.\n   Amend etcd configuration to reference the new node (NODE4)\n üí° Make the following change on all running etcd members and NODE4\n $ # NODE4_IP is the NEW_NODE_ADDRESS $ echo \u0026quot;NODE4_IP=192.168.152.142\u0026quot; \u0026gt;\u0026gt; /etc/etcd.conf $ # Check the contents of /etc/etcd.conf $ cat /etc/etcd.conf CLIENT_PORT=2379 PEERS_PORT=2380 # NODE_IP is the IP of the node where this file resides. NODE_IP=192.168.202.40 NODE1_IP=192.168.195.168 NODE2_IP=192.168.202.40 NODE3_IP=192.168.174.117 NODE4_IP=192.168.152.142   Amend SystemD service file on the new etcd node (NODE4)\n üí° The SystemD service file is expected in /etc/systemd/system/etcd3.service\n Change the --initial-cluster-state to existing and add the reference to NODE4 in the --initial-cluster variable.\nvi /etc/systemd/system/etcd3.service The resulting changes would appear as follows:\n... ExecStart=/usr/local/sbin/etcd3 --name etcd-${NODE_IP} \\ ... --initial-cluster-state existing \\ ... --initial-cluster \\ etcd-${NODE1_IP}=http://${NODE1_IP}:${PEERS_PORT},\\ etcd-${NODE2_IP}=http://${NODE2_IP}:${PEERS_PORT},\\ etcd-${NODE3_IP}=http://${NODE3_IP}:${PEERS_PORT},\\ etcd-${NODE4_IP}=http://${NODE4_IP}:${PEERS_PORT} ...  üí° Note the reference to NODE4 at the end of the --initial-cluster variable\n Make sure etcd is not started on the new member NODE4\n  Add etcd member as a learner\n# Set environment variable for the the new etcd member (NODE4) $ NODE4_IP=192.168.152.142 $ ETCD_NEW_MEMBER=\u0026#34;etcd-${NODE4_IP}\u0026#34; $ ETCD_NEW_MEMBER_PEER=\u0026#34;http://$NODE4_IP:2380\u0026#34; # Add the new member to the cluster $ export ETCDCTL_API=3 $ etcdctl member add \\  --learner $ETCD_NEW_MEMBER \\  --peer-urls=\u0026#34;$ETCD_NEW_MEMBER_PEER\u0026#34; Member 52e5c9ac117b3df2 added to cluster b4f4ed717ea44b8d ETCD_NAME=\u0026#34;etcd-192.168.152.142\u0026#34; ETCD_INITIAL_CLUSTER=\u0026#34;etcd-192.168.152.142=http://192.168.152.142:2380,etcd-192.168.195.168=http://192.168.195.168:2380,etcd-192.168.202.40=http://192.168.202.40:2380,etcd-192.168.174.117=http://192.168.174.117:2380\u0026#34; ETCD_INITIAL_ADVERTISE_PEER_URLS=\u0026#34;http://192.168.152.142:2380\u0026#34; ETCD_INITIAL_CLUSTER_STATE=\u0026#34;existing\u0026#34;   Check the etcd members\n$ export endpoints=\u0026quot;192.168.174.117:2379,192.168.195.168:2379,192.168.174.117:2379\u0026quot; $ etcdctl member list --endpoints $endpoints -wtable +------------------+-----------+----------------------+-----------------------------+-----------------------------+------------+ | ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER | +------------------+-----------+----------------------+-----------------------------+-----------------------------+------------+ | 52e5c9ac117b3df2 | unstarted | | http://192.168.152.142:2380 | | true | | 7817aa073b059aab | started | etcd-192.168.195.168 | http://192.168.195.168:2380 | http://192.168.195.168:2379 | false | | e22cdd20a03e5e73 | started | etcd-192.168.202.40 | http://192.168.202.40:2380 | http://192.168.202.40:2379 | false | | e5d0f0e242014d3d | started | etcd-192.168.174.117 | http://192.168.174.117:2380 | http://192.168.174.117:2379 | false | +------------------+-----------+----------------------+-----------------------------+-----------------------------+------------+  üí° Note that the learner is not started yet\n   Start etcd on the new node (NODE4)\n ‚ö†Ô∏è Make sure that /etc/systemd/system/etcd.service only have currently active nodes specified in the --initial-cluster flag.\n # On the new node (NODE4) systemctl daemon-reload systemctl enable etcd3.service systemctl start etcd3.service   Check the etcd members\n$ export endpoints=\u0026quot;192.168.174.117:2379,192.168.195.168:2379,192.168.174.117:2379\u0026quot; $ etcdctl member list --endpoints $endpoints -wtable +------------------+---------+----------------------+-----------------------------+-----------------------------+------------+ | ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER | +------------------+---------+----------------------+-----------------------------+-----------------------------+------------+ | 52e5c9ac117b3df2 | started | etcd-192.168.152.142 | http://192.168.152.142:2380 | http://192.168.152.142:2379 | true | | 7817aa073b059aab | started | etcd-192.168.195.168 | http://192.168.195.168:2380 | http://192.168.195.168:2379 | false | | e22cdd20a03e5e73 | started | etcd-192.168.202.40 | http://192.168.202.40:2380 | http://192.168.202.40:2379 | false | | e5d0f0e242014d3d | started | etcd-192.168.174.117 | http://192.168.174.117:2380 | http://192.168.174.117:2379 | false | +------------------+---------+----------------------+-----------------------------+-----------------------------+------------+  üí° Note that the learner is started\n   Check that the new learner has the same revision applied as the current members\n$ export ETCDCTL_API=3 # Added NODE4 in the endpoints variable $ export endpoints=\u0026quot;192.168.174.117:2379,192.168.195.168:2379,192.168.174.117:2379,192.168.152.142:2379\u0026quot; etcdctl endpoint status --endpoints $endpoints -wtable +---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS | +---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | 192.168.174.117:2379| e5d0f0e242014d3d | 3.4.9 | 352 kB | false | false | 2 | 24570 | 24570 | | | 192.168.195.168:2379| 7817aa073b059aab | 3.4.9 | 352 kB | false | false | 2 | 24570 | 24570 | | | 192.168.202.40:2379 | e22cdd20a03e5e73 | 3.4.9 | 352 kB | true | false | 2 | 24570 | 24570 | | | 192.168.152.142:2379| 52e5c9ac117b3df2 | 3.4.9 | 467 kB | false | true | 2 | 24570 | 24570 | | +---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+  ‚ö†Ô∏è Wait until the cluster has the learner ready, by ensuring that the RAFT TERM and RAFT INDEX of the learner node match the rest of the cluster.\n   Remove the node that needs to be evicted (NODE1)\n üí° Before promoting the learner to a full member, it is best to remove the node from the cluster that initially was selected to be decommissioned to avoid breaking quorum while having 4 nodes being part of the cluster. For more details, check the official etcd documentation regarding this topic.\n $ export ETCDCTL_API=3 $ # Select member of id of the node to remove (NODE1) $ NODE1_MEMBER_ID=e22cdd20a03e5e73 $ etcdctl member remove $NODE1_MEMBER_ID Member e22cdd20a03e5e73 removed from cluster b4f4ed717ea44b8d   Promote the learner to a member\n$ export ETCDCTL_API=3 $ # Select member of id of the node to remove (NODE1) $ NODE4_MEMBER_ID=52e5c9ac117b3df2 $ etcdctl member promote $NODE4_MEMBER_ID Member 52e5c9ac117b3df2 promoted in cluster b4f4ed717ea44b8d  ‚ö†Ô∏è The promotion will fail if the learner is not in sync with the leader member.\n   Check the etcd health\n$ export endpoints=192.168.174.117:2379,192.168.195.168:2379,192.168.152.142:2379 $ etcdctl member list --endpoints $endpoints -wtable +------------------+---------+---------------------+----------------------------+----------------------------+------------+ | ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER | +------------------+---------+---------------------+----------------------------+----------------------------+------------+ | 52e5c9ac117b3df2 | started |etcd-192.168.152.142 |http://192.168.152.142:2380 |http://192.168.152.142:2379 | false | | 7817aa073b059aab | started |etcd-192.168.195.168 |http://192.168.195.168:2380 |http://192.168.195.168:2379 | false | | e5d0f0e242014d3d | started |etcd-192.168.174.117 |http://192.168.174.117:2380 |http://192.168.174.117:2379 | false | +------------------+---------+---------------------+----------------------------+----------------------------+------------+ $ etcdctl endpoint status --endpoints $endpoints -wtable +---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS | +---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ |192.168.174.117:2379 | e5d0f0e242014d3d | 3.4.9 | 352 kB | false | false | 3 | 35939 | 35939 | | |192.168.195.168:2379 | 7817aa073b059aab | 3.4.9 | 352 kB | true | false | 3 | 35939 | 35939 | | |192.168.152.142:2379 | 52e5c9ac117b3df2 | 3.4.9 | 467 kB | false | false | 3 | 35939 | 35939 | | +---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+  üí° Note that NODE4 is now a full quorum member, while NODE1 is no longer part of the cluster\n   Edit Endpoints referencing the Kubernetes Service\n üí° Remove the reference to NODE1 and add the IP for NODE4\n kubectl edit -n storageos-etcd endpoints/storageos-etcd   Make amendments in the SystemD configuration files removing any reference to NODE1\n üí° It is not required to restart the etcd service - this is just to keep the service file up to date.\n   ","excerpt":"This procedure explains how to add a new etcd member for your Ondat etcd cluster while removing one ‚Ä¶","ref":"/docs/operations/etcd/etcd-outside-k8s/migrate-etcd-cluster/","title":"Etcd node migration"},{"body":"Best practices - Etcd Outside the Cluster Ondat uses etcd as a service. It is expected that the user maintains the availability and integrity of the etcd cluster.\nIt is highly recommended to keep the cluster backed up and ensure high availability of its data.\nNetwork low latency It is important to keep the latency between Ondat nodes and the etcd replicas low. Deploying an etcd cluster in a different data center or region can make Ondat detect etcd nodes as unavailable due to latency. 10ms latency between Ondat and etcd would be the maximum threshold for proper functioning of the system.\nDisk low latency Etcd is very sensitive to disk latency. Because of that, it is recommended to run etcd away from other IO-intensive workloads. Operations such as backups, builds or application bundling cause a heavy usage of disks. If such operations run alongside the etcd nodes, they will cause etcd to become unstable and suffer downtime. It is best to run etcd nodes isolated from other IO workloads.\nIOPS requirements As a general rule, for etcd to operate normally on production clusters, we recommend using the size of machine offered by your cloud provider that guarantees a minimum of 500 IOPS. For example, 750 baseline IOPS are guaranteed on a 250GB AWS gp2 EBS instance at time of writing, and block instances on other cloud providers will also specify baseline IOPS figures.\nCloud providers usually provide \u0026ldquo;bursts\u0026rdquo; of IOPS - temporarily higher rates, limited by credits - with larger volumes providing higher burst capacity. If you are relying on burst capacity for etcd, which requires sustained high performance, careful assessment is necessary to ensure sufficient capacity.\nThe rate of etcd operations is affected by the number of nodes, volumes and replicas in the cluster, therefore the figure of 500 is provided as a guideline only. A development cluster with 5 nodes will not have the same etcd traffic as a production cluster with 100 nodes. Adding monitoring to etcd will help to characterise the traffic, and therefore to assess the individual requirements of a cluster and adjust its resources accordingly.\nEtcd advertise URLs The etcd startup parameters advertise-client-urls and initial-advertise-peer-urls specify the addresses etcd clients or other etcd members should use to contact the etcd server. The advertised addresses must be reachable from the remote machines - i.e. where Ondat is running - so it can connect successfully. Do not advertise addresses like localhost or 0.0.0.0 for a production setup since these addresses are unreachable from remote machines.\nMonitoring It is highly recommended to add monitoring to the etcd cluster. Etcd serves Prometheus metrics on the client port http://etcd-url:2379/metrics.\nYou can use Ondat developed Grafana Dashboards for etcd. When using etcd for production, you can use the etcd-cluster-as-service, while the etcd-cluster-as-pod can be used when using etcd from the operator.\nDefragmentation Etcd uses revisions to store multiple versions of keys. Compaction removes all key revision prior to a certain revision from etcd. Typically the etcd configuration enables the automatic compaction of keys to prevent performance degradation and limit the storage required. Compaction of revisions can create fragmentation that means space on disk is available for use by etcd but is unavailable for use by the file system. In order to reclaim this space, etcd can be defragmented.\nReclaiming space is important because when the etcd database file grows over the \u0026ldquo;DB_BACKEND_BYTES\u0026rdquo; parameter, the cluster triggers an alarm and sets itself read only and only allows reads and deletes. To avoid hitting the db backend bytes limit, compaction and defragmentation are required. How often defragmentation is required depends on the churn of key revisions in etcd.\nThe Grafana Dashboards mentioned above indicate when nodes require defragmentation. Be aware that defragmentation is a blocking operation that is performed per node, hence the etcd node will be locked for the duration of the defragmentation. Defragmentation usually takes a few milliseconds to complete.\nYou can also set cronjobs that execute the following defragmentation script. It will run a defrag when the DB is at 80% full. A defragmentation operation has to be executed per etcd node and it is a blocking operation. It is recommended to not execute the defragmentation on all etcd members at the same time. If using a cronjob, set them up for different times.\nhttps://raw.githubusercontent.com/storageos/deploy/master/k8s/deploy-storageos/etcd-helpers/etcd-ansible-systemd/roles/install_etcd/templates/defrag-etcd.sh.j2 chmod +x defrag-etcd.sh ","excerpt":"Best practices - Etcd Outside the Cluster Ondat uses etcd as a service. It is expected that the user ‚Ä¶","ref":"/docs/operations/etcd/etcd-outside-k8s/","title":"Etcd outside the cluster - Best Practices"},{"body":"Follow the recipes on this page to create your first PVC (Persistent Volume Claim) using Ondat. Ondat implements dynamic provisioning, so the creation of a PVC will automatically provision a PV (PersistentVolume) that can be used to persist data written by a Pod.\nCreate the PersistentVolumeClaim   You can find the basic examples in the Ondat use-cases repository, in the 00-basic directory.\ngit clone https://github.com/storageos/use-cases.git storageos-usecases cd storageos-usecases/00-basic PVC definition\napiVersion:v1kind:PersistentVolumeClaimmetadata:name:my-vol-1spec:storageClassName:\u0026#34;storageos\u0026#34;# Ondat StorageClassaccessModes:- ReadWriteOnceresources:requests:storage:5GiThe above PVC will dynamically provision a 5GB volume using the storageos StorageClass. This StorageClass was created during the Ondat install and triggers creation of a PersistentVolume by Ondat.\nFor installations with CSI, you can create multiple StorageClasses in order to specify default labels.\napiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-replicatedprovisioner:csi.storageos.com# Provisioner when using CSIparameters:csi.storage.k8s.io/fstype:ext4storageos.com/replicas:\u0026#34;1\u0026#34;# Enforces 1 replica for the Volumecsi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosThe above StorageClass has the storageos.com/replicas label set. This label tells Ondat to create a volume with a replica. Adding Ondat feature labels to the StorageClass ensures all volumes created with the StorageClass have the same labels. For simplicity\u0026rsquo;s sake this example will use unreplicated volumes.\napiVersion:v1kind:PersistentVolumeClaimmetadata:name:my-vol-1spec:storageClassName:\u0026#34;ondat-replicated\u0026#34;# Reference to the StorageClassaccessModes:- ReadWriteOnceresources:requests:storage:5GiYou can also choose to add the label in the PVC definition rather than the StorageClass. The PVC definition takes precedence over the SC.\napiVersion:v1kind:PersistentVolumeClaimmetadata:name:my-vol-1labels:storageos.com/replicas:\u0026#34;1\u0026#34;spec:storageClassName:\u0026#34;storageos\u0026#34;accessModes:- ReadWriteOnceresources:requests:storage:5GiThe above PVC has the storageos.com/replicas label set. This label tells Ondat to add a replica for the volume that is created. For the sake of keeping this example simple an unreplicated volume will be used.\n  Move into the examples folder and create a PVC using the PVC definition above.\n# from storageos-usecases/00-basic kubectl create -f ./pvc-basic.yaml You can view the PVC that you have created with the command below\n$ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE pvc-1 Bound pvc-f8ffa027-e821-11e8-bc0b-0ac77ccc61fa 5Gi RWO storageos 1m   Create a pod that mounts the PVC created in step 2.\nkubectl create -f ./pod.yaml The command above creates a Pod that uses the PVC that was created in step 1.\napiVersion:v1kind:Podmetadata:name:d1spec:containers:- name:debianimage:debian:9-slimcommand:[\u0026#34;/bin/sleep\u0026#34;]args:[\u0026#34;3600\u0026#34;]volumeMounts:- mountPath:/mntname:v1volumes:- name:v1persistentVolumeClaim:claimName:pvc-1In the Pod definition above volume v1 references the PVC created in step 2, and is mounted in the pod at /mnt. In this example a debian image is used for the container but any container image with a shell would work for this example.\n  Confirm that the pod is up and running\n$ kubectl get pods NAME READY STATUS RESTARTS AGE d1 1/1 Running 0 1m   Execute a shell inside the container and write some contents to a file\n$ kubectl exec -it d1 -- bash root@d1:/# echo \u0026#34;Hello World!\u0026#34; \u0026gt; /mnt/helloworld root@d1:/# cat /mnt/helloworld Hello World! By writing to /mnt inside the container, the Ondat volume created by the PVC is being written to. If you were to kill the pod and start it again on a new node, the helloworld file would still be avaliable.\nIf you wish to see more use cases with actual applications, see our Use Cases documentation.\n  ","excerpt":"Follow the recipes on this page to create your first PVC (Persistent Volume Claim) using Ondat. ‚Ä¶","ref":"/docs/operations/firstpvc/","title":"Ondat Volume Guide"},{"body":"Ondat provides a SaaS Platform to view and manage your clusters.\nThe legacy GUI has been decommissioned. You can view the archived documentation here.\n","excerpt":"Ondat provides a SaaS Platform to view and manage your clusters.\nThe legacy GUI has been ‚Ä¶","ref":"/docs/reference/gui/","title":"GUI"},{"body":"Ondat uses the storage available on the nodes where it is installed to present as available for volumes.\nTo mitigate against problems caused by filling the host root disk, we recommend mounting a separate device into the /var/lib/storageos directory. Ondat is agnostic to the type of filesystem mounted in /var/lib/storageos.\nExtending Available Storage Ondat uses subdirectories of /var/lib/storageos/data to hold user data. By default, the directory /var/lib/storageos/data/dev1 will be created when a node is bootstrapped, and used for pool data. It is possible to shard the data by creating more directories into this structure. Ondat will save data in any directory that conforms to the pattern /var/lib/storageos/data/dev[0-9]+, such as /var/lib/storageos/data/dev2 or /var/lib/storageos/data/dev5. This functionality enables operators to mount different devices into devX directories and Ondat will recognise them as available storage automatically.\nThere are two possible options to expand the available disk space for Ondat to allocate:\n Mount filesystem in /var/lib/storageos/data/devX Use LVM to expand the logical volume available to Ondat  Option 1: Mount Additional Devices This option enables operators to expand the cluster\u0026rsquo;s available space at any time without having to stop applications or forcing operational downtime. The expansion of disk is transparent for applications and Ondat Volumes. Ondat will use the new available space to create new data files.\n  Context\nWe assume that there is a disk available in our Linux system without formatting in addition to the root filesystem. Ondat data dir dev1 (/var/lib/storageos/data/dev1) is using /dev/xvda1. We will use the device /dev/xvdf to expand Ondat available space.\nList available block devices in the host.\nroot@node0:~# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 128G 0 disk `-xvda1 202:1 0 128G 0 part / xvdf 202:80 0 100G 0 disk Check Ondat cluster\u0026rsquo;s available capacity.\n$ storageos get node -ojson | jq -r '.[] | { name: .name, capacity: .capacity.total }' \u0026quot;node0\u0026quot; 137,438,953,472 \u0026quot;node1\u0026quot; 137,438,953,472 \u0026quot;node2\u0026quot; 137,438,953,472   Format device\nroot@node0:/var/lib/storageos/data# mkfs -t ext4 /dev/xvdf mke2fs 1.42.12 (29-Aug-2014) Creating filesystem with 26214400 4k blocks and 6553600 inodes Filesystem UUID: 380712fa-6f82-477a-81a5-d7466d4c6b7f Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424, 20480000, 23887872 Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done   Mount filesystem\nroot@node0:~# mkdir -p /var/lib/storageos/data/dev2 root@node0:~# mount /dev/xvdf /var/lib/storageos/data/dev2   Verify available storage\nIn less than 30 seconds, Ondat will see the new available capacity.\n$ storageos get node -ojson | jq -r '.[] | { name: .name, capacity: .capacity.total }' \u0026quot;node0\u0026quot; 244,491,013,324 \u0026quot;node1\u0026quot; 137,438,953,472 \u0026quot;node2\u0026quot; 137,438,953,472 Note that the node node0 has increased the TOTAL capacity in 100Gi.\n   üí° Persist the mount at boot by adding the mount endpoint to /etc/fstab\n Option 2: Expand Existing Devices Backed by LVM This option enables operators to take advantage of LVM to manage disks.\n  Context\nWe assume that /var/lib/storageos is mounted onto an LVM volume. We are using a volumegroup named storageos and logical volume called data. There is a second physical disk /dev/xvdg unused.\nList available block devices in the host.\nroot@node2:~# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 128G 0 disk `-xvda1 202:1 0 128G 0 part / xvdf 202:80 0 100G 0 disk `-storageos-data 254:0 0 99G 0 lvm /var/lib/storageos xvdg 202:96 0 100G 0 disk Check Ondat cluster\u0026rsquo;s available capacity.\n$ storageos get node -ojson | jq -r '.[] | { name: .name, capacity: .capacity.total }' \u0026quot;node0\u0026quot; 137,438,953,472 \u0026quot;node1\u0026quot; 137,438,953,472 \u0026quot;node2\u0026quot; 107,696,304,947 # --\u0026gt; LVM storageos/data volume   Add physical disk to LVM\nroot@node2:~# vgextend storageos /dev/xvdg Volume group \u0026quot;storageos\u0026quot; successfully extended The volume group storageos must have 2 physical volumes (#PV)\nroot@node2:~# vgs VG #PV #LV #SN Attr VSize VFree storageos 2 1 0 wz--n- 199.99g 104.99g   Extend logical volume data\nroot@node2:~# lvextend -L+100G /dev/storageos/data Size of logical volume storageos/data changed from 95.00 GiB (24320 extents) to 195.00 GiB (49920 extents). Logical volume data successfully resized   Resize the FileSystem\n ‚ö†Ô∏è Your filesystem must support the option to be expanded, and to do so while in use. Otherwise, you need to unmount first.\n root@node2:~# resize2fs /dev/storageos/data resize2fs 1.42.12 (29-Aug-2014) Filesystem at /dev/storageos/data is mounted on /var/lib/storageos; on-line resizing required old_desc_blocks = 6, new_desc_blocks = 13 The filesystem on /dev/storageos/data is now 51118080 (4k) blocks long.   Check new available space\nThe mounted file system to /var/lib/storageos has increased its size.\nroot@node2:~# df -h /dev/mapper/storageos-data Filesystem Size Used Avail Use% Mounted on /dev/mapper/storageos-data 192G 60M 183G 1% /var/lib/storageos Ondat available storage has increased too.\n$ storageos get node -ojson | jq -r '.[] | { name: .name, capacity: .capacity.total }' \u0026quot;node0\u0026quot; 137,438,953,472 \u0026quot;node1\u0026quot; 137,438,953,472 \u0026quot;node2\u0026quot; 206,158,430,208 # --\u0026gt; 100G more available    üí° Persist the mount at boot by adding the mount point to /etc/fstab\n ","excerpt":"Ondat uses the storage available on the nodes where it is installed to present as available for ‚Ä¶","ref":"/docs/operations/managing-host-storage/","title":"Host Storage"},{"body":"Overview This guide will walk you through how to use the Ondat Snapshots feature to backup and restore your Kubernetes applications using CloudCasa. Before starting please consult the Snapshots Concepts page for an overview of the feature.\nWe‚Äôll now run through the steps required to configure and utilise the feature:\n Pre-requisites. Installing Ondat. Setting up a CloudCasa account and deploying the CloudCasa agent. Installing Kubernetes Snapshot Controller. Configuring the Ondat VolumeSnapshotClass. Backup and Recovery functions walkthrough:  Create a dummy application. Setup a backup policy. Define and run a backup. Run a restore operation for the dummy application.    Prerequisites The following pre-requisites must also be met:\n The registered cluster must be Kubernetes version 1.17 or higher to utilize CSI snapshots. The CSI driver must support volume snapshots at the v1beta1 API level. For a list of vendors that support CSI snapshots, review the Kubernetes CSI Drivers documentation. The Ondat driver is supported. kubectl must be installed and configured. You will need cluster administrative access to install CloudCasa\u0026rsquo;s lightweight agent on your cluster. While registering your cluster in the CloudCasa user interface (UI), each cluster will be given a unique YAML file to be applied to your cluster. Network access from your cluster outgoing to the CloudCasa service (agent.cloudcasa.io) on port 443.  Procedure Step 1 - Installing Ondat Ondat Snapshots were introduced in v2.8.0. If you are installing Ondat for the first time then please follow the instructions here. If you are upgrading an existing Ondat deployment then please follow the instructions here.\nStep 2 - Setting up a CloudCasa Account \u0026amp; Deploying the CloudCasa Agent   Navigate to CloudCasa\u0026rsquo;s Get Started page to sign up for a free account by providing the login details. Then sign in to your account after verifying the registered email address, which will take you to the CloudCasa dashboard.\n  After logging in to CloudCasa, navigate to Protection tab \u0026raquo; Clusters Overview and click on the Add Cluster button at the top right.\n  Provide the cluster name and description, then click on the Save button.\n  This will display a kubectl command to run to install the agent.\n  Run the Kubectl command on your cluster and confirm that the registered Kubernetes cluster moves into the Active state in the CloudCasa UI. This should take no more than a couple of minutes. Your CloudCasa agent has now successfully been deployed.\n  Step 3 - Installing the Kubernetes Snapshot Controller By default with CloudCasa we provide the required Kubernetes snapshot CRDs however in order to use the Kubernetes snapshot feature the snapshot-controller must be installed.\n The snapshot controller monitors the Kubernetes API server for VolumeSnapshot and VolumeSnapshotContent CRDs and forwards the necessary requests to the Ondat CSI plugin. One can install the controller with the following commands:  kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-6.0/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-6.0/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml  ‚ö†Ô∏è It is important that v6.0 is used for the CRDs and the snapshot-controller. Other versions may work or may appear to work, but have not been formally tested and ratified by Ondat. v6.0 and v6.1 of the snapshot controller require Kubernetes version 1.20 or above.\n Step 4 - Backup \u0026amp; Recovery Functions walkthrough In the following steps, we‚Äôll create a dummy application and run through the steps required to back up and recover it.\n4.1 - Create a Dummy Application Start by creating an example deployment in a new namespace ondat-and-cloudcasa-test, which utilises a Ondat PVC:\nkubectl create namespace ondat-and-cloudcasa-test Then create a deployment and PVC in the namespace using:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:mypvcnamespace:ondat-and-cloudcasa-testspec:storageClassName:storageosaccessModes:- ReadWriteOnceresources:requests:storage:2Gi---apiVersion:apps/v1kind:Deploymentmetadata:name:myapp-deploymentnamespace:ondat-and-cloudcasa-testspec:replicas:1selector:matchLabels:app:myapptemplate:metadata:labels:app:myappspec:containers:- name:dateimage:debian:9-slimcommand:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;]args:[\u0026#34;while true; do /bin/date | /usr/bin/tee -a /mnt/date ; /bin/sleep 5; done\u0026#34;]volumeMounts:- mountPath:/mntname:data-mount- name:sidecarimage:debian:9-slimcommand:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;]args:[\u0026#34;/bin/sleep 3600\u0026#34;]securityContext:privileged:truevolumeMounts:- mountPath:/mntname:data-mountvolumes:- name:data-mountpersistentVolumeClaim:claimName:mypvcEOFThis deployment creates a pod with 2 containers. The date container will simply append the date to stdout and /mnt/date every 5 seconds:\nThe sidecar container simply mounts in the PVC under /mnt and then lies dormant. This container will be used during the snapshot process to quiesce the filesystem so a consistent snapshot can be taken. It serves no other purpose. Notice how this container must have the privileged flag set to true. This is necessary in order to run the fsfreeze command.\n4.2 - Setup a Backup Policy A backup policy allows you to define when backups that use it will run and for how long they will be retained. You can have multiple schedules with different retention times in one policy. For example, a policy may specify the creation of hourly backups that are retained for 7 days, and daily backups that are retained for 30 days.\nNavigate to the Policies tab via Configuration \u0026raquo; Protection \u0026raquo; Policies.\n Create a Policy by clicking on the Add new policy button. Provide the required information, then click on the Create Policy button.  4.3 - Configure the Ondat VolumeSnapshotClass In order to utilise the Ondat CSI plugin with the Kubernetes snapshot feature you must provide a¬†VolumeSnapshotClass¬†for the Ondat CSI plugin. Once the¬†snapshot-controller¬†has been installed edit your¬†StorageOSCluster via the following command.\nkubectl -n storageos edit storageosclusters.storageos.com storageoscluster Within here add the volumeSnapshotClassName line under snapshots - as per the following:\nsnapshots:volumeSnapshotClassName:cloudcasa-csi-storageos-comThis will prompt the Ondat operator to create a VolumeSnapshotClass named cloudcasa-csi-storageos-com and configure it for use with CloudCasa. You can view the VolumeSnapshotClass by running:\nkubectl get volumesnapshotclasses and:\nkubectl describe volumesnapshotclasses cloudcasa-csi-storageos-com 4.4 - Define \u0026amp; Run a Backup   Navigate to the Dashboard tab. Click on Define Backup. Provide Backup Name, and select the Cluster for which you are defining a backup.\n  Select either Full Cluster, a Specific Namespace, or provide a Label selector (Optional). If backing up a specific namespace, enter the name of the namespace you want to protect.\n  For the backup operation, choose whether to snapshot your PV‚Äôs. Then select one of the two available options:\n  Snapshot only.\n  Snapshot and copy.\n üí° The ‚ÄúSnapshot and copy‚Äù option is only available with a paid subscription.\n  üí° If you want to run pre and post-backup commands to enable application consistent backups, select ‚ÄúEnable app hooks‚Äù and enter the appropriate pre and post backup app hook definitions. You will need to have defined custom hooks under Configuration/App Hooks to quiesce the application and filesystem. This isn‚Äôt necessary for all applications. We plan to add a standardised template for pre and post backup Ondat app hooks using fsfreeze in the near future. If you need assistance with these, get in contact with us via casa@cloudcasa.io\n   On the next page, enable Run now to run the Backup operation immediately and provide Retention days (the retention period is just for this ad-hoc run). Click on the Create button. This will create a Backup definition.\n  Navigate to the Dashboard tab and find the Cluster Backup that you want to run. Click the Run now button on its line. You will see the job running in the dashboard‚Äôs Activity tab. Verify that it completes successfully.\n  4.5 - Run a Restore Operation For the Dummy Application   Let‚Äôs setup a disaster recovery scenario, by deleting our dummy application and the associated namespace\nkubectl delete -n ondat-and-cloudcasa-test deployments.apps myapp-deployment kubectl delete namespaces ondat-and-cloudcasa-test   Now let‚Äôs recover our dummy application. Go back to the Cluster Backups tab on the Dashboard and click the Restore icon next to your backup definition in the list.\n  When the restore page opens, select a specific recovery point by choosing it from the list of available recovery points. Then click Next button.\n  On the next page you can choose whether to restore all namespaces in the backup, or only selected namespaces. If user choose the latter, a list of namespaces will be displayed from which you can select the namespace(s) for which the restore operation will be performed. Remember that only namespaces included in the backup will be shown. For the demo, we will recover the full ondata-and-cloudcasa-test namespace. We also support the recovery of specific resource types, and utilising post-restore scripts for the recovery via enabling app hooks.\n  Note that existing namespaces cannot be over-written, so if you want to restore an existing namespace to a cluster, you need to delete the old one first. You can also rename namespaces when restoring (later).\n  You can add labels to be used to select resources for restore as well. These are key: value pairs, and will not be validated by the UI. We can add them one at a time or add multiple pairs at once, separated by spaces.\n  Finally, we need to choose whether or not to restore PV snapshots. If you toggle off the Exclude persistent volumes option, PVs will be restored using the snapshots or copies associated with the recovery point you‚Äôve selected.\n  Remember that if you have selected specific namespaces or labels for restore, only PVs in the namespaces or with the labels you‚Äôve selected will be restored.\n  On the Next page, you will be presented with few more options.\n  Provide the Restore name for the restore job. Restore jobs have names so that users can easily track the restore job status.\n  The system will also save the job under its name so that you can modify and re-run it later.\n  On the next step, you can choose an alternate cluster to restore to. By default, the restore will go to the original cluster. You can choose to rename restored namespaces by adding a prefix and/or suffix and change the storage classes if desired.\n  Remember that all the restored namespaces will have these prefixes or suffixes added, so if user want to rename only specific namespaces, you should run multiple restores and select those namespaces explicitly.\n  Finally, click the Restore button and CloudCasa will do the rest! You can watch the progress of the restore job in the progress pane. You can also edit and re-run it, if you wish, under the cluster‚Äôs Restore tab.\n  Confirm the application is back up and running:\n  Finally let‚Äôs view the contents of the /mnt/date in the application‚Äôs pod:\n  You can see the 44 min gap here which aligns with the snapshot time of 14:05 and the restore time of 14:51\nRecap Congratulations, You‚Äôre done! That‚Äôs all there is to it! Now you can sit back and relax, knowing that you can now take ad-hoc or scheduled backup and perform restores of your Kubernetes cluster resources, Ondat persistent volumes, and cloud-native applications.\nAny Further Questions? Get in touch with us at https://www.ondat.io/contact or casa@cloudcasa.io\n","excerpt":"Overview This guide will walk you through how to use the Ondat Snapshots feature to backup and ‚Ä¶","ref":"/docs/operations/backups-and-restores-with-ondat-snapshots-and-cloudcasa/","title":"How To Backup \u0026 Restore Using Snapshots with CloudCasa"},{"body":"Overview This guide will walk you through how to use the Ondat Snapshots feature to backup and restore your Kubernetes applications using Kasten K10. Before starting please consult the Snapshots Concepts page for an overview of the feature.\nWe‚Äôll now run through the steps required to configure and utilise the feature:\n Installing Ondat. Installing the Kubernetes snapshot CRDs. Configuring the Ondat VolumeSnapshotClass. Installing and configuring Kasten K10. Backup and restore walkthrough:  Creating an example application. Creating a backup policy. Adding pre/post-snapshot hooks to quiesce the application/filesystem. Manually running a backup job. Restoring an application from a backup.    Prerequisites To utilize the Ondat Snapshot feature the following prerequisites must be met:\n Ondat v2.8.0 or later is installed in the cluster Kasten K10 is installed in the cluster. See the Kasten 10 docs for the full list of prerequisites. Kasten supports Kubernetes versions up to 1.22.  Procedure Step 1 - Installing Ondat Ondat Snapshots were introduced in v2.8.0. If you are installing Ondat for the first time then please follow the instructions here. If you are upgrading an existing Ondat deployment then please follow the instructions here.\nStep 2 - Installing the Kubernetes Snapshot CRDs In order to use the Kubernetes snapshot feature the Kubernetes snapshot CRDs and the snapshot-controller must be installed. Most distributions don‚Äôt install these by default. To install the VolumeSnapshots, VolumeSnapshotContents and VolumeSnapshotClasses CRDs run the following:\nkubectl create -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-6.0/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml kubectl create -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-6.0/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml kubectl create -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-6.0/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml Now you need to install the snapshot-controller. The snapshot controller monitors the Kubernetes API server for VolumeSnapshot and VolumeSnapshotContent CRDs and forwards the necessary requests to the Ondat CSI plugin. One can install the controller with the following command:\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-6.0/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-6.0/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml Note: it‚Äôs important that v6.0 is used for the CRDs and the snapshot-controller. Other versions may work or may appear to work, but have not been formally tested and ratified by Ondat.\nStep 3 - Configuring the Ondat VolumeSnapshotClass In order to utilise the Ondat CSI plugin with the Kubernetes snapshot feature, one must provide a VolumeSnapshotClass for the Ondat CSI plugin. Once the CRDs and the snapshot-controller have been installed edit your StorageOSCluster to add:\nspec:snapshots:volumeSnapshotClassName:$EXAMPLE_NAMEThis will prompt the Ondat operator to create a VolumeSnapshotClass named $EXAMPLE_NAME and configure it for use with Kasten K10. You can edit your StorageOSCluster by using the following command:\nkubectl -n storageos edit storageosclusters.storageos.com cluster You can view the VolumeSnapshotClass by running:\nkubectl get volumesnapshotclasses and:\nkubectl describe volumesnapshotclasses $EXAMPLE_NAME You‚Äôll notice the VolumeSnapshotClass contains the k10.kasten.io/is-snapshot-class: true annotation. This is very important and allows Kasten K10 to utilise the Ondat storage plugin.\nStep 4 - Installing Kasten K10 The next step is to install Kasten K10 on your cluster. Instructions for how to do this can be found here.\nThe remainder of this walk through will assume you have access to the Kasten K10 UI. You can install it following the instructions here. Everything we do in the following steps may be done via kubectl and the command-line, however this is not shown in this guide.\nOnce K10 is installed you can then create a \u0026ldquo;Profile\u0026rdquo; and configure the backup location. Instructions on how to do this can be found here. It‚Äôs also possible to do this via the UI.\nStep 5 - Backup and Restore Example In the following sections, we‚Äôll create a toy application and run through the steps required to back it up and restore from it.\nStep 5.1 - Create an Example Application Start by creating an example deployment in a new namespace ondat-test, which utilises a Ondat PVC:\nkubectl create namespace ondat-test Then apply the following configuration using kubectl create -f:\napiVersion:v1kind:PersistentVolumeClaimmetadata:name:mypvcnamespace:ondat-testspec:storageClassName:storageosaccessModes:- ReadWriteOnceresources:requests:storage:2Gi---apiVersion:apps/v1kind:Deploymentmetadata:name:myapp-deploymentnamespace:ondat-testspec:replicas:1selector:matchLabels:app:myapptemplate:metadata:labels:app:myappspec:containers:- name:dateimage:debian:9-slimcommand:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;]args:[\u0026#34;while true; do /bin/date | /usr/bin/tee -a /mnt/date ; /bin/sleep 5; done\u0026#34;]volumeMounts:- mountPath:/mntname:data-mount- name:sidecarimage:debian:9-slimcommand:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;]args:[\u0026#34;/bin/sleep 3600\u0026#34;]securityContext:privileged:truevolumeMounts:- mountPath:/mntname:data-mountvolumes:- name:data-mountpersistentVolumeClaim:claimName:mypvcThis deployment creates a pod with 2 containers. The date container will simply append the date to stdout and /mnt/date every 5 seconds:\nkubectl -n ondat-test exec myapp-deployment-7749d9984-r57nk -c date -- cat /mnt/date | head Tue Jun 28 08:56:07 UTC 2022 Tue Jun 28 08:59:01 UTC 2022 Tue Jun 28 08:59:06 UTC 2022 ‚Ä¶ The sidecar container simply mounts in the PVC under /mnt and then lies dormant. This container will be used during the snapshot process to quiesce the filesystem so a consistent snapshot can be taken. It serves no other purpose. Notice how this container must have the privileged flag set to true. This is necessary to run the fsfreeze command.\nStep 5.2 - Add Pre/Post-Snapshot Hooks To Quiesce the Application/Filesystem In order to take a snapshot of an application we must first quiesce the application and the underlying filesystem.\nQuiescing the application means putting it into a paused state where all on-going operations have completed and no new operations are started. How to do this depends on what sort of application you are running. For example, a database application may want to ensure that all in progress transactions are committed and flushed and no new transactions are started. An application which is buffering data and writing it to a file may want to ensure that the full write has been completed and the data has been sync‚Äôd.\nQuiescing the filesystem is required in addition to quiescing the application and must always be done when using the Ondat Snapshots feature. This step should be done after quiescing the application and is achieved by doing an fsfreeze --freeze on the mounted filesystem. fsfreeze halts access to the filesystem such that any attempts to issue IO to the filesystem are blocked until the filesystem is unfrozen. It also ensures that any in progress filesystem operations are completed. This leaves the filesystem in a consistent state from which it is safe to take a snapshot.\nAfter we are done taking the snapshot, we can run fsfreeze --unfreeze to unfreeze the filesystem. If required, any steps to quiesce the application can then be performed.\nTo execute these \u0026ldquo;pre-snapshot\u0026rdquo; and \u0026ldquo;post-snapshot\u0026rdquo; operations one can use a Kanister blueprint in conjunction with K10‚Äôs execution hooks feature. Kanister is an open source framework which allows users to automate application specific management tasks via yaml based configuration. Kasten K10 can leverage these blueprints to perform various actions pre and post-snapshot.\nWe‚Äôll use the following blueprint to quiesce the filesystem before taking a snapshot and unquiesce it after taking the snapshot.\n We don‚Äôt perform any application level quiescing here as it‚Äôs not required for our toy application.\n  For statefulsets the blueprint below can be used as a baseline, but change kind to StatefulSet, Deployment.Namespace to StatefulSet.Namespace and Deployment.Pods to StatefulSet.Pods.\n apiVersion:cr.kanister.io/v1alpha1kind:Blueprintmetadata:name:fsfreeze-hooks-deploymentnamespace:kasten-ioactions:backupPrehook:kind:Deployment# or StatefulSetphases:- func:KubeExecname:fsfreezeargs:namespace:\u0026#34;{{ .Deployment.Namespace }}\u0026#34;# or StatefulSet.Namespacepod:\u0026#34;{{ index .Deployment.Pods 0 }}\u0026#34;# or StatefulSet.Podscontainer:sidecarcommand:- bash- -o- errexit- -o- pipefail- -o- xtrace- -c- |fsfreeze --freeze /mntbackupPosthook:kind:Deploymentphases:- func:KubeExecname:fsunfreezeargs:namespace:\u0026#34;{{ .Deployment.Namespace }}\u0026#34;# or StatefulSet.Namespacepod:\u0026#34;{{ index .Deployment.Pods 0 }}\u0026#34;# or StatefulSet.Podscontainer:sidecarcommand:- bash- -o- errexit- -o- pipefail- -o- xtrace- -c- |fsfreeze --unfreeze /mnt If you have installed kasten into a namespace other than kasten-io then you‚Äôll have to modify the namespace field in the above configuration.\n Apply the blueprint with the kubect create -f command. One can observe the blueprint like so:\nkubectl -n kasten-io get blueprints.cr.kanister.io NAME AGE fsfreeze-hooks-deployment 15h k10-deployment-generic-volume-2.0.20 3h2m k10-persistentvolumeclaim-generic-volume-2.0.20 3h19m We must now annotate our deployment so that the aforementioned hooks are used at snapshot time:\nkubectl annotate deployment -n ondat-test myapp-deployment kanister.kasten.io/blueprint=\u0026#39;fsfreeze-hooks-deployment\u0026#39; Step 5.3 - Setting Up a Backup Policy Ensure you have the Kasten K10 dashboard installed (see here). It‚Äôs possible to do the steps in this section via kubectl and the command-line. Please see the Kasten K10 documentation for how to do this.\nGo to the \u0026ldquo;Policies\u0026rdquo; page and click \u0026ldquo;Create New Policy\u0026rdquo;:\nInput a \u0026ldquo;Name\u0026rdquo; for the policy and set the \u0026ldquo;Backup Frequency\u0026rdquo; to \u0026ldquo;On Demand\u0026rdquo;.\nCheck the \u0026ldquo;Enable Backups via Snapshot Exports\u0026rdquo; field. This is very important. The Ondat Snapshots feature only supports restoring from an external snapshot export. Set the \u0026ldquo;Export Location Profile\u0026rdquo; to the profile you previously set up in the \u0026ldquo;Installing Kasten K10\u0026rdquo; section.\nUnder \u0026ldquo;Select Applications\u0026rdquo;, check the \u0026ldquo;By Name\u0026rdquo; checkbox and search for the namespace \u0026ldquo;ondat-test\u0026rdquo;.\nLeave everything else as is then click Create Policy to create the policy.\n ‚ö†Ô∏è Do not try to set the Pre and Post-Snapshot Action Hooks in the Advanced Settings section. This is taken care of by the steps in \u0026ldquo;Adding pre/post-snapshot hooks\u0026rdquo;.\n Step 5.4 - Manually Running a Backup Job We can now manually run a job to backup our application. Browse to the dashboard homepage and select \u0026ldquo;Policies\u0026rdquo;. From there we can find our policy and initiate a backup by clicking \u0026ldquo;run once\u0026rdquo;:\nIf we navigate back to the dashboard we‚Äôll see that our policy is running:\nWe can get further information on what is happening by clicking our policy in the \u0026ldquo;Actions\u0026rdquo; section. When the policy has successfully ran we‚Äôll see a page like this:\nIn order to save space and reduce copy-on-write latency on the parent volume we should now manually delete the VolumeSnapshot object associated with our snapshot. This instructs Ondat that we are done with the snapshot.\nkubectl get volumesnapshots -n ondat-test NAME READYTOUSE SOURCEPVC SOURCESNAPSHOTCONTENT RESTORESIZE SNAPSHOTCLASS SNAPSHOTCONTENT CREATIONTIME AGE k10-csi-snap-wlxhw8vf9dx4qtq2 true mypvc 2Gi csi-storageos-snapclass snapcontent-359f9126-f428-4dbf-82da-932a74d10e83 40m 40m kubectl delete volumesnapshots -n ondat-test k10-csi-snap-wlxhw8vf9dx4qtq2 volumesnapshot.snapshot.storage.k8s.io \u0026#34;k10-csi-snap-wlxhw8vf9dx4qtq2\u0026#34; deleted Step 5.5 - Restoring an Application From a Backup Let‚Äôs emulate a disaster recovery scenario, by deleting our deployment:\nkubectl delete -n ondat-test deployments.apps myapp-deployment Now let‚Äôs restore it. First go to the dashboard and select \u0026ldquo;Applications\u0026rdquo;. From there find \u0026ldquo;ondat-test\u0026rdquo; and select \u0026ldquo;restore\u0026rdquo;:\nSelect the backup you wish to restore from, in this example we‚Äôll select \u0026ldquo;Today, 12:51 pm\u0026rdquo;. When prompted to select an instance make sure you select the \u0026ldquo;EXPORTED\u0026rdquo; instance which has been backed up to S3. The Ondat Snapshots feature does not support restoring from a local backup:\nKasten provides various restore options at this point, but we‚Äôll just leave everything else defaulted. See the Kasten K10 documentation for more information. Click \u0026ldquo;Restore\u0026rdquo; to start the restore process and to restore the application from the backup.\nOne can now browse back to the dashboard and watch the \u0026ldquo;Restore\u0026rdquo; operation progress. Like before, one can click on the drill down into the operation by clicking the relevant restore pane under the \u0026ldquo;Actions\u0026rdquo; sections.\nOnce the restore job has finished you‚Äôll see a screen like this:\nLet‚Äôs check our application is running:\nkubectl get -n ondat-test deployments.apps myapp-deployment NAME READY UP-TO-DATE AVAILABLE AGE myapp-deployment 1/1 1 1 10m And let‚Äôs view the contents of the \u0026ldquo;/mnt/date\u0026rdquo; in the application‚Äôs pod:\nkubectl -n ondat-test exec myapp-deployment-7749d9984-p7jzp -c date -- cat /mnt/date Tue Jun 28 08:56:07 UTC 2022 Tue Jun 28 08:59:01 UTC 2022 ‚Ä¶ Tue Jun 28 11:50:40 UTC 2022 Tue Jun 28 11:50:45 UTC 2022 Tue Jun 28 11:58:33 UTC 2022 Tue Jun 28 11:58:38 UTC 2022 ‚Ä¶ Tue Jun 28 12:10:29 UTC 2022 Tue Jun 28 12:10:34 UTC 2022 Notice how there‚Äôs an 8 minute gap between 11:50:45 and 11:58:33. This coincides with the snapshot being taken at circa 11:51 (UTC) and being restored at 11:58 (UTC).\nKnown Issues \u0026amp; Gotchas Deletion of VolumeSnapshot Ideally the Kubernetes VolumeSnapshot object should be deleted as soon as the application has been backed up externally. There‚Äôs no reason to keep the snapshot as it can‚Äôt be meaningfully used. Furthermore, it takes up space on the local node and can cause a slight performance degradation for IO to the parent volume. At the moment, there is no good way to automate this procedure. Consequently users should: set their snapshot retention policy to 1 hourly snapshot when setting up a backup policy. This does not fix the issue, but ensures that the snapshot is removed within an hour of been taken. It is also possible to remove the snapshot manually by running kubectl delete volumesnapshots -n \u0026lt;app_namespace\u0026gt; \u0026lt;snapshot\u0026gt;.\nPerformance Implications The Ondat snapshots feature utilises copy-on-write semantics under the hood. This means while a VolumeSnapshot object exists any blocks which are written to the parent volume invoke an extra read and write operation as blocks are copied into the snapshot object. The performance decrease incurred by this overhead is dependent on: the size of the volume, the speed of the underlying storage, the amount of data in the page cache and a myriad of other factors. Once the snapshot(s) associated with a volume are deleted, performance will return to baseline.\n","excerpt":"Overview This guide will walk you through how to use the Ondat Snapshots feature to backup and ‚Ä¶","ref":"/docs/operations/backups-and-restores-with-kastenk10/","title":"How To Backup \u0026 Restore Using Snapshots with Kasten K10"},{"body":"Overview This guide demonstrates different methods on how to check and review the health status of your Ondat cluster. Below are two of the common methods on how to assess the health status of a cluster:\n Through the Ondat SaaS Platform. Through the Ondat CLI  Prerequisites  If you are using the Ondat SaaS platform, ensure that your cluster has been successfully registered. If you are using the Ondat CLI, ensure that you have successfully downloaded and configured the utility to communicate with your Ondat cluster.  Procedure Option 1 - Check Cluster Health Status Through The Ondat SaaS Platform   Login to the Ondat SaaS Platform and navigate to the Clusters tab \u0026raquo; Click on View Details on the cluster that you would like to inspect further.\n  In the Cluster Summary tab, information about the Connection Status is provided. To review the health status of the nodes in the cluster, click on the Nodes tab for more information.\n  Option 2 - Check Cluster Health Status Through The Ondat CLI   Deploy and run the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat through kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the pod name of the Ondat CLI utility. kubectl get pods --namespace storageos | grep \u0026#34;storageos-cli\u0026#34; storageos-cli-578c4f4674-7jwrj 1/1 Running 0 70s   With the Ondat CLI now deployed, you can check the cluster health and nodes status:\n# Get the cluster-wide configuration and show the number of healthy nodes. kubectl --namespace=storageos exec storageos-cli-578c4f4674-7jwrj -- storageos get cluster ID: a77e7536-03b9-4d39-98ad-031055c3a2e2 Created at: 2022-09-13T14:25:20Z (4 hours ago) Updated at: 2022-09-13T14:25:20Z (4 hours ago) Nodes: 5 Healthy: 5 Unhealthy: 0 # Get the number of nodes in your cluster and also show their health status. kubectl --namespace=storageos exec storageos-cli-578c4f4674-7jwrj -- storageos get nodes NAME HEALTH AGE aks-default-33007487-vmss000002 online 4 hours ago aks-storage-34962329-vmss000001 online 4 hours ago aks-default-33007487-vmss000001 online 4 hours ago aks-storage-34962329-vmss000000 online 4 hours ago aks-default-33007487-vmss000000 online 4 hours ago   ","excerpt":"Overview This guide demonstrates different methods on how to check and review the health status of ‚Ä¶","ref":"/docs/operations/health/","title":"How To Check The Health Status Of Your Cluster"},{"body":"Overview Storage Classes in Kubernetes are used to link PersistentVolumeClaims (PVCs) with a backend storage provisioner such as Ondat.\n A StorageClass defines parameters to pass to the provisioner, which, in the case of Ondat, can be translated into behaviour applied to the volumes that will be provisioned. End users can create more than one custom Ondat StorageClass with different feature labels. By default, the Ondat Operator creates a storageos StorageClass when Ondat is deployed for the first time. End users can get more information about the StorageClass object created by running the following commands below:  # Get more informaton about the \u0026#34;storageos\u0026#34; StorageClass object. kubectl get storageclasses storageos NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE storageos csi.storageos.com Delete Immediate true 13m # Describe the \u0026#34;storageos\u0026#34; StorageClass object. kubectl describe storageclasses storageos Name: storageos IsDefaultClass: No Annotations: kubectl.kubernetes.io/last-applied-configuration={\u0026#34;allowVolumeExpansion\u0026#34;:true,\u0026#34;apiVersion\u0026#34;:\u0026#34;storage.k8s.io/v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;StorageClass\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;labels\u0026#34;:{\u0026#34;app\u0026#34;:\u0026#34;storageos\u0026#34;,\u0026#34;app.kubernetes.io/component\u0026#34;:\u0026#34;storageclass\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;storageos\u0026#34;},\u0026#34;parameters\u0026#34;:{\u0026#34;csi.storage.k8s.io/fstype\u0026#34;:\u0026#34;ext4\u0026#34;,\u0026#34;csi.storage.k8s.io/secret-name\u0026#34;:\u0026#34;storageos-api\u0026#34;,\u0026#34;csi.storage.k8s.io/secret-namespace\u0026#34;:\u0026#34;storageos\u0026#34;},\u0026#34;provisioner\u0026#34;:\u0026#34;csi.storageos.com\u0026#34;,\u0026#34;reclaimPolicy\u0026#34;:\u0026#34;Delete\u0026#34;,\u0026#34;volumeBindingMode\u0026#34;:\u0026#34;Immediate\u0026#34;} Provisioner: csi.storageos.com Parameters: csi.storage.k8s.io/fstype=ext4,csi.storage.k8s.io/secret-name=storageos-api,csi.storage.k8s.io/secret-namespace=storageos AllowVolumeExpansion: True MountOptions: \u0026lt;none\u0026gt; ReclaimPolicy: Delete VolumeBindingMode: Immediate Events: \u0026lt;none\u0026gt;  Below is the YAML output of the storageos StorageClass object after removing metadata details:  # \u0026#34;storageos\u0026#34; StorageClass.apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:labels:app:storageosapp.kubernetes.io/component:storageclassname:storageosparameters:csi.storage.k8s.io/fstype:ext4csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosprovisioner:csi.storageos.comallowVolumeExpansion:truereclaimPolicy:DeletevolumeBindingMode:Immediate üí° A PersistentVolumeClaim (PVC) definition takes precedence over a StorageClass definition.\n Creating Custom Ondat Storage Classes The following examples will demonstrate how to create custom Ondat storage classes with feature labels to fit end user\u0026rsquo;s use cases.\n End users can also find more custom Ondat storage classes examples in the Ondat Use Cases project repository that is available on GitHub.  # Clone the repository. git clone git@github.com:ondat/use-cases.git # Navigate into the directory cd custom-storage-classes/ # List the StorageClass manifests in the directory. ls -lah Example - Create a StorageClass that Enables Volume Replication Below is an example Ondat StorageClass definition called ondat-replicated that uses the Volume Replication feature label.\n# Create the \u0026#34;ondat-replicated\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-replicatedprovisioner:csi.storageos.comallowVolumeExpansion:trueparameters:storageos.com/replicas:\u0026#34;2\u0026#34;# Create 2 replica volumes.csi.storage.k8s.io/fstype:ext4csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosEOF# Review and confirm that \u0026#34;ondat-replicated\u0026#34; was created. kubectl get sc | grep \u0026#34;ondat-replicated\u0026#34; For a detailed demonstration of how to use the Volume Replication feature with persistent volumes, review the How To Use Volume Replication operations page.\nExample - Create a StorageClass that Enables Volume Replication \u0026amp; Topology-Aware Placement (TAP) Below is an example Ondat StorageClass definition called ondat-tap that uses the Volume Replication and Topology-Aware Placement (TAP) feature labels.\n# Create the \u0026#34;ondat-tap\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-tapprovisioner:csi.storageos.comallowVolumeExpansion:trueparameters:csi.storage.k8s.io/fstype:ext4storageos.com/replicas:\u0026#34;2\u0026#34;# Create 2 replica volumes.storageos.com/topology-aware:\u0026#34;true\u0026#34;# Enable TAP (default looks for \u0026#34;topology.kubernetes.io/zone=\u0026#34; on nodes)csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosEOF# Review and confirm that \u0026#34;ondat-tap\u0026#34; was created. kubectl get sc | grep \u0026#34;ondat-tap\u0026#34; For a detailed demonstration of how to use the Volume Replication \u0026amp; Topology-Aware Placement features with persistent volumes, review the How To Enable Topology-Aware Placement (TAP) operations page.\nExample - Create a StorageClass that Enables Volume Replication, Topology-Aware Placement (TAP) \u0026amp; Volume Encryption Below is an example Ondat StorageClass definition called ondat-replicated-tap-encrypted that uses the Volume Replication, Topology-Aware Placement (TAP) and Volume Encryption feature labels.\n# Create the \u0026#34;ondat-encryption\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-replicated-tap-encryptedprovisioner:csi.storageos.comallowVolumeExpansion:trueparameters:csi.storage.k8s.io/fstype:ext4storageos.com/replicas:\u0026#34;2\u0026#34;# Create 2 replica volumes.storageos.com/encryption:\u0026#34;true\u0026#34;# Enable volume encryption.storageos.com/topology-aware:\u0026#34;true\u0026#34;# Enable TAP (default looks for \u0026#34;topology.kubernetes.io/zone=\u0026#34; on nodes)csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosEOF# Review and confirm that \u0026#34;ondat-replicated-tap-encrypted\u0026#34; was created. kubectl get sc | grep \u0026#34;ondat-replicated-tap-encrypted\u0026#34; For a detailed demonstration of how to use the Volume Encryption feature with persistent volumes, review the How To Enable Data Encryption For Volumes operations page.\nExample - Create a StorageClass that Enables Data Compression Below is an example Ondat StorageClass definition called ondat-compressed that uses the Data Compression feature label.\n# Create the \u0026#34;ondat-compressed\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-compressedprovisioner:csi.storageos.comallowVolumeExpansion:trueparameters:storageos.com/nocompress:\u0026#34;false\u0026#34;# Enable compression of data-at-rest and data-in-transit.csi.storage.k8s.io/fstype:ext4csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosEOF# Review and confirm that \u0026#34;ondat-compressed\u0026#34; was created. kubectl get sc | grep \u0026#34;ondat-compressed\u0026#34; For a detailed demonstration of how to use the compression for persistent volumes, review the How To Enable Data Compression operations page.\n","excerpt":"Overview Storage Classes in Kubernetes are used to link PersistentVolumeClaims (PVCs) with a backend ‚Ä¶","ref":"/docs/operations/storageclasses/","title":"How To Create Custom Storage Classes"},{"body":"Overview Ondat support ReadWriteMany (RWX) persistent volumes. A RWX volume can be used simultaneously by different deployments conducting read and write operations in the same namespace.\n ‚ö†Ô∏è RWX volume provisioning is available in the free Ondat Community Edition. To get the Community Edition licence, register your cluster through the Ondat SaaS platform and generate a licence so that it can be applied to your cluster. For more information on licences, review the Ondat pricing page.\n  üí° For more information on the Ondat Files feature, review the Ondat Files feature page.\n Example - Use the RWX Access Mode Through a PersistentVolumeClaim Definition The following guidance will demonstrate how to use RWX volumes through a PersistentVolumeClaim (PVC) definition.\n The instructions will allow you to use the RWX access mode on a PVC that will be mounted onto a Deployment resource in the ondat-files namespace.    Create a namespace called ondat-files where the encrypted volume and Deployment will reside.\n# Create namespace called \u0026#34;ondat-files\u0026#34;. cat \u0026lt;\u0026lt;EOF | kubectl create --filename - apiVersion: v1 kind: Namespace metadata: name: ondat-files labels: name: ondat-files EOF   Create a custom PersistentVolumeClaim named ondat-files and ensure that you add the following accessMode \u0026raquo; ReadWriteMany to the manifest.\n# Create a \u0026#34;ondat-files\u0026#34; PVC.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:ondat-filesnamespace:ondat-filesspec:storageClassName:storageos # Use the default Ondat StorageClass to provision persistent volumes.accessModes:- ReadWriteMany # Ensure that the access mode is \u0026#34;ReadWriteMany\u0026#34;.resources:requests:storage:5GiEOF  Once the PVC resource has been successfully created, review and confirm that the ReadWriteMany access mode has been applied.\n# Get the label applied to the \u0026#34;ondat-files\u0026#34; PVC. kubectl get pvc ondat-files --output=wide --show-labels --namespace=ondat-files   Create a Deployment workload in the ondat-files namespace that uses the ondat-files PVC that was created in Step 2.\ncat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:apps/v1kind:Deploymentmetadata:labels:app:ondat-filesname:ondat-files-deployment-rwxnamespace:ondat-files # Create the Deployment workload in the \u0026#34;ondat-files\u0026#34; namespace.spec:replicas:3selector:matchLabels:app:ondat-filestemplate:metadata:labels:app:ondat-filesspec:containers:- args:- \u0026#34;3600\u0026#34;command:- /bin/sleepimage:debian:latestname:debianvolumeMounts:- mountPath:/mnt/name:ondat-filesvolumes:- name:ondat-filespersistentVolumeClaim:claimName:ondat-files # Use the \u0026#34;ondat-files\u0026#34; PVC for the StatefulSet workload.EOF  To review and confirm that the ondat-files-deployment-rwx Kubernetes deployment has successfully mounted the RWX volume, run the following commands below to inspect the resources created.\n# Review and confirm that Deployment workload was successfully created. kubectl get pod --namespace=ondat-files kubectl get deployments.apps --namespace=ondat-files   When you review the Kubernetes service in the ondat-files namespace, you will notice that there is an NFS Ganesha service that exposes the PVC as a shared filesystem - in addition, provides the ClusterIP address of the service and the default NFS port of \u0026raquo; 2049/TCP.\n# Check the service created under the \u0026#34;ondat-files\u0026#34; namespace. kubectl get service --namespace ondat-files NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE pvc-41f429ff-3fa9-4361-b7bc-c55f869499ae ClusterIP 10.0.133.137 \u0026lt;none\u0026gt; 2049/TCP 6m46s # Describe the service in the namespace.kubectl describe service --namespace ondat-filesName:pvc-41f429ff-3fa9-4361-b7bc-c55f869499aeNamespace:ondat-filesLabels:storageos.com/volume-id=aad1e4ab-23d2-4a45-9a9b-0305885997ffAnnotations:\u0026lt;none\u0026gt;Selector:\u0026lt;none\u0026gt;Type:ClusterIPIP Family Policy:SingleStackIP Families:IPv4IP:10.0.133.137IPs:10.0.133.137Port:nfs 2049/TCPTargetPort:25918/TCPEndpoints:10.224.0.4:25918Session Affinity:NoneEvents:Type Reason Age From Message---- ------ ---- ---- -------Normal Created 9m35s storageos-api-manager Created service for shared volume ondat-files/pvc-41f429ff-3fa9-4361-b7bc-c55f869499ae  You can also review and confirm that Ondat has successfully provisioned a RWX volume, as defined in the PVC manifest earlier, by running the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat through kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the pod name of the Ondat CLI utility. kubectl get pods --namespace storageos | grep \u0026#34;storageos-cli\u0026#34; storageos-cli-578c4f4674-wr9z2 1/1 Running 0 3m43s # Get the volumes in the \u0026#34;ondat-files\u0026#34; namespace using the Ondat CLI. kubectl --namespace=storageos exec storageos-cli-578c4f4674-wr9z2 -- storageos get volumes --namespace=ondat-files NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE ondat-files pvc-41f429ff-3fa9-4361-b7bc-c55f869499ae 5.0 GiB aks-default-15645363-vmss000000 (online) aks-default-15645363-vmss000000 0/0 2 hours ago # Describe the \u0026#34;pvc-4457be86-54a3-4f2b-8326-5d4c8799d48a\u0026#34; volume. kubectl --namespace=storageos exec storageos-cli-578c4f4674-wr9z2 -- storageos describe volume pvc-41f429ff-3fa9-4361-b7bc-c55f869499ae --namespace=ondat-files ID aad1e4ab-23d2-4a45-9a9b-0305885997ff Name pvc-41f429ff-3fa9-4361-b7bc-c55f869499ae Description AttachedOn aks-default-15645363-vmss000000 (1c9fe8f8-7c33-44b0-802d-875ff4c53fdd) Attachment Type nfs NFS Service Endpoint 10.224.0.4:25918 Exports: - ID 1 Path / Pseudo Path / ACLs - Identity Type hostname Identity Matcher * Squash all Squash UID 0 Squash GUID 0 Namespace ondat-files (97e1ffeb-34e3-4f18-8ef1-5494f34fe9cd) Labels csi.storage.k8s.io/pv/name=pvc-41f429ff-3fa9-4361-b7bc-c55f869499ae, csi.storage.k8s.io/pvc/name=ondat-files, csi.storage.k8s.io/pvc/namespace=ondat-files, storageos.com/nfs/mount-endpoint=10.0.133.137:2049, storageos.com/nocompress=true Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version NQ Created at 2022-09-08T12:54:49Z (2 hours ago) Updated at 2022-09-08T14:29:18Z (28 minutes ago) Master: ID 67cae629-7797-444a-828d-22d5c22d3535 Node aks-default-15645363-vmss000000 (1c9fe8f8-7c33-44b0-802d-875ff4c53fdd) Health online   Notice under Attachment Type nfs, the detailed information about the RWX volume is returned.\n# truncated output..Attachment Type nfsNFSService Endpoint 10.224.0.4:25918Exports:- ID 1Path /Pseudo Path /ACLs- Identity Type hostnameIdentity Matcher *Squash allSquash UID 0Squash GUID 0# truncated ouput...  NFS Squash Mode  üí° This feature is available in release v2.8.0 or greater.\n As part of the v2.8.0 Ondat release, a change was made so that users can configure the squash mode for the NFS service that is used to provision RWX shares.\n Historically, all shares were exported with a Squash = All mode of operation. This was requested by most customers as the idea of identity in a container based deployment is very abstract. There is now a Ondat volume Feature label that can be applied to make this setting configurable. End users can now adjust the squash mode using the following label \u0026raquo; storageos.com/nfs-squash: $APPLY_SQUASH_MODE_VALUE when provisioning RWX volumes. Below are the list of different modes that users can apply (all is the default mode and the label is applied to a PersistentVolumeClaim)     Squash Mode - Options     all (default)   root   rootuid   none    Example - Configure the Squash Mode for a RWX Volume Through a PersistentVolumeClaim Definition The following guidance will demonstrate how to configure the squash mode for a RWX volume through a PersistentVolumeClaim (PVC) definition.\n The instructions will allow you to use the RWX access mode on a PVC which has the squash mode set to rootuid that will be mounted onto a Deployment resource in the ondat-files-squash-mode namespace.    Create a namespace called ondat-files-squash-mode where the encrypted volume and Deployment will reside.\n# Create namespace called \u0026#34;ondat-files-squash-mode\u0026#34;. cat \u0026lt;\u0026lt;EOF | kubectl create --filename - apiVersion: v1 kind: Namespace metadata: name: ondat-files-squash-mode labels: name: ondat-files-squash-mode EOF   Create a custom PersistentVolumeClaim named ondat-files-squash-mode, ensure that the label is set storageos.com/nfs-squash: rootuid and ensure that you add the following accessMode \u0026raquo; ReadWriteMany added to the manifest.\n# Create a \u0026#34;ondat-files-squash-mode\u0026#34; PVC.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:ondat-files-squash-modenamespace:ondat-files-squash-modelabels:storageos.com/nfs-squash:rootuid # set the squash mode to \u0026#34;rootuid\u0026#34;.spec:storageClassName:storageos # Use the default Ondat StorageClass to provision persistent volumes.accessModes:- ReadWriteMany # Ensure that the access mode is \u0026#34;ReadWriteMany\u0026#34;.resources:requests:storage:5GiEOF  Once the PVC resource has been successfully created, review and confirm that the storageos.com/nfs-squash: rootuid label has been applied.\n# Get the label applied to the \u0026#34;ondat-files-squash-mode\u0026#34; PVC. kubectl get pvc ondat-files-squash-mode --output=wide --show-labels --namespace=ondat-files-squash-mode   Create a Deployment workload in the ondat-files-squash-mode namespace that uses the ondat-files-squash-mode PVC that was created in Step 2.\ncat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:apps/v1kind:Deploymentmetadata:labels:app:ondat-files-squash-modename:ondat-files-deployment-rwx-squash-modenamespace:ondat-files-squash-mode # Create the Deployment workload in the \u0026#34;ondat-files-squash-mode\u0026#34; namespace.spec:replicas:3selector:matchLabels:app:ondat-files-squash-modetemplate:metadata:labels:app:ondat-files-squash-modespec:containers:- args:- \u0026#34;3600\u0026#34;command:- /bin/sleepimage:debian:latestname:debianvolumeMounts:- mountPath:/mnt/name:ondat-files-squash-modevolumes:- name:ondat-files-squash-modepersistentVolumeClaim:claimName:ondat-files-squash-mode # Use the \u0026#34;ondat-files-squash-mode\u0026#34; PVC for the StatefulSet workload.EOF  To review and confirm that the oondat-files-deployment-rwx-squash-mode Kubernetes deployment has successfully mounted the RWX volume, run the following commands below to inspect the resources created.\n# Review and confirm that Deployment workload was successfully created. kubectl get pod --namespace=ondat-files-squash-mode kubectl get deployments.apps --namespace=ondat-files-squash-mode   When you review the Kubernetes service in the ondat-files-squash-mode namespace, you will notice that there is an NFS Ganesha service that exposes the PVC as a shared filesystem - in addition, provides the clusterIP address of the service and the default NFS port of \u0026raquo; 2049/TCP.\n# Check the service created under the \u0026#34;ondat-files-squash-mode\u0026#34; namespace. kubectl get service --namespace ondat-files-squash-mode NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE pvc-bd4c93a5-0071-4a56-968c-ae5e12d34342 ClusterIP 10.0.159.162 \u0026lt;none\u0026gt; 2049/TCP 28s # Describe the service in the namespace.kubectl describe service --namespace ondat-files-squash-modeName:pvc-bd4c93a5-0071-4a56-968c-ae5e12d34342Namespace:ondat-files-squash-modeLabels:storageos.com/volume-id=17450a4e-ecf6-4e98-918f-19e748bf9737Annotations:\u0026lt;none\u0026gt;Selector:\u0026lt;none\u0026gt;Type:ClusterIPIP Family Policy:SingleStackIP Families:IPv4IP:10.0.159.162IPs:10.0.159.162Port:nfs 2049/TCPTargetPort:25805/TCPEndpoints:10.224.0.8:25805Session Affinity:NoneEvents:Type Reason Age From Message---- ------ ---- ---- -------Normal Created 4m47s storageos-api-manager Created service for shared volume ondat-files-squash-mode/pvc-bd4c93a5-0071-4a56-968c-ae5e12d34342  You can also review and confirm that Ondat has successfully provisioned a RWX volume, as defined in the PVC manifest earlier, by running the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat through kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the pod name of the Ondat CLI utility. kubectl get pods --namespace storageos | grep \u0026#34;storageos-cli\u0026#34; storageos-cli-578c4f4674-wr9z2 1/1 Running 0 3m43s # Get the volumes in the \u0026#34;ondat-files-squash-mode\u0026#34; namespace using the Ondat CLI. kubectl --namespace=storageos exec storageos-cli-578c4f4674-wr9z2 -- storageos get volumes --namespace=ondat-files-squash-mode NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE ondat-files-squash-mode pvc-bd4c93a5-0071-4a56-968c-ae5e12d34342 5.0 GiB aks-storage-32661963-vmss000001 (online) aks-storage-32661963-vmss000001 0/0 15 minutes ago # Describe the \u0026#34;pvc-bd4c93a5-0071-4a56-968c-ae5e12d34342\u0026#34; volume. kubectl --namespace=storageos exec storageos-cli-578c4f4674-wr9z2 -- storageos describe volume pvc-bd4c93a5-0071-4a56-968c-ae5e12d34342 --namespace=ondat-files-squash-mode ID 17450a4e-ecf6-4e98-918f-19e748bf9737 Name pvc-bd4c93a5-0071-4a56-968c-ae5e12d34342 Description AttachedOn aks-storage-32661963-vmss000001 (acdf3a74-4042-492d-b7b4-8368f5474fb2) Attachment Type nfs NFS Service Endpoint 10.224.0.8:25805 Exports: - ID 1 Path / Pseudo Path / ACLs - Identity Type hostname Identity Matcher * Squash rootuid Squash UID 0 Squash GUID 0 Namespace ondat-files-squash-mode (39d924f6-2d16-48e6-af1a-a69169f4bd6b) Labels csi.storage.k8s.io/pv/name=pvc-bd4c93a5-0071-4a56-968c-ae5e12d34342, csi.storage.k8s.io/pvc/name=ondat-files-squash-mode, csi.storage.k8s.io/pvc/namespace=ondat-files-squash-mode, storageos.com/nfs-squash=rootuid, storageos.com/nfs/mount-endpoint=10.0.159.162:2049, storageos.com/nocompress=true Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version NQ Created at 2022-09-08T17:07:35Z (17 minutes ago) Updated at 2022-09-08T17:15:36Z (8 minutes ago) Master: ID 662ac10a-b695-4c5f-ba4e-2b003b098dfc Node aks-storage-32661963-vmss000001 (acdf3a74-4042-492d-b7b4-8368f5474fb2) Health online   If you notice under Attachment Type nfs, detailed information about the RWX volume is returned.\nAttachment Type nfsNFSService Endpoint 10.224.0.8:25805Exports:- ID 1Path /Pseudo Path /ACLs- Identity Type hostnameIdentity Matcher *Squash rootuidSquash UID 0Squash GUID 0  ","excerpt":"Overview Ondat support ReadWriteMany (RWX) persistent volumes. A RWX volume can be used ‚Ä¶","ref":"/docs/operations/rwx/","title":"How To Create ReadWriteMany (RWX) Volumes"},{"body":"Overview This guide will walk you through how to downgrade from Ondat v2.7.0 to v2.6.0. This procedure can be used if a cluster administrator is required to roll back to the previous version after upgrading to Ondat v2.7.0.\n As part of the v2.7.0 release, the Ondat team implemented a new architectural design for mapping Kubernetes volumes to the underlying data storage containers on disk. This will conduct a one-time step change to upgrade the deployment blob files and their metadata to the new format.  In the past, Ondat supported different container orchestrators, which required Ondat to use an internal UUID reference for these blob files. As Ondat now focuses only Kubernetes distributions (including OpenShift), the Ondat team have removed this abstraction layer and the naming will reflect the Kubernetes objects.   As part of any operational upgrade plans, the Ondat team have provided guidance and steps in this document, should you need to roll back in case you experience any issues. The procedure below has been validated, however it is not a common operation, therefore it is recommended that cluster administrators proactively reach out the Ondat Support Team by creating a support ticket and get assistance from the Customer Success team, as you conduct the downgrade.  Prerequisites  Ensure that all of your stateful workloads using Ondat volumes are scaled down to zero. While the procedure is safe, it is strongly recommended that a backup of important stateful workloads done before performing the downgrade.  Procedure Step 1 - Uninstall Ondat v2.7.0 - As If You Are Conducting An Upgrade  Delete the storageoscluster Custom Resource. Delete the Ondat Operator deployment. Ensure that you do not make any changes to Ondat\u0026rsquo;s etcd cluster.  Step 2 - Download \u0026amp; Update the CLI_TOOL Variable In The Downgrade Script  Download the downgrade script and ensure that the CLI_TOOL variable in the downgrade script is using the correct CLI utility for your distribution.  The default value is kubectl which is used to interact with Kubernetes distributions. If your cluster is and OpenShift distribution, ensure that you use oc as the CLI utility.    # Download the downgrade script. curl -sO https://github.com/ondat/documentation/blob/main/sh/downgrade-db-2-7-to-2-6.sh # edit and apply changes to the CLI_TOOL` according toif necessary. vim downgrade-db-2-7-to-2-6.sh Step 3 - Run The Downgrade Script Against Your Cluster  üí° The downgrade script is idempotent, so in the case of interruption it can be safely run multiple times.\n  Run the downgrade script against your Kubernetes or OpenShift cluster that has Ondat v2.7.0 installed. The script will create a Kubernetes daemonset which will downgrade the internal data store on each node where Ondat is running. Once the downgrade is complete, the daemonset will be deleted.  # run the downgrade script. ./downgrade-db-2-7-to-2-6.sh Step 4 - Install Ondat v2.6.0  Once the downgrade has completed, the next step will be to install Ondat v2.6.0 into your OpenShift or Kubernetes cluster.  For guides on how to install Ondat, review the Install documentation.    ","excerpt":"Overview This guide will walk you through how to downgrade from Ondat v2.7.0 to v2.6.0. This ‚Ä¶","ref":"/docs/operations/downgrade-ondat-2.7-to-2.6/","title":"How To Downgrade Ondat from 'v2.7.0' to 'v2.6.0'"},{"body":"Overview  üí° For more information on Ondat\u0026rsquo;s Compression feature, review the Compression feature page.\n Example - Enable Data Compression Through a PersistentVolumeClaim Definition The following guidance below will demonstrates how to use Ondat‚Äôs Data Compression feature through a PersistentVolumeClaim (PVC) definition.\n  The instructions will enable compression on a PVC with the label ¬ª storageos.com/nocompress=false for the Ondat volume that will be provisioned.\n üí° Labels can be applied to a PVC directly, or indirectly by adding them as parameters on a StorageClass.\n     Create a custom PersistentVolumeClaim named pvc-compressed and ensure that you add the following label ¬ª storageos.com/nocompress=false to the manifest.\n# Create a \u0026#34;pvc-compressed\u0026#34; PVC that enables data compression.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:pvc-compressedlabels:storageos.com/nocompress:\u0026#34;false\u0026#34;# Enable compression of data-at-rest and data-in-transit.spec:storageClassName:storageosaccessModes:- ReadWriteOnceresources:requests:storage:5GiEOF  Once the PVC resource has been successfully created, review and confirm that the storageos.com/nocompress=false, label has been applied.\n# Get the label applied to the \u0026#34;pvc-replicated\u0026#34; PVC. kubectl get pvc pvc-compressed --output=wide --show-labels --namespace=default NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS pvc-compressed Bound pvc-4457be86-54a3-4f2b-8326-5d4c8799d48a 5Gi RWO storageos 15s Filesystem storageos.com/nocompress=false   To review and confirm that Ondat has successfully provisioned a volume that has compression enabled as defined in the PVC manifest earlier - deploy and run the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat through kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the Ondat CLI utility pod name. kubectl --namespace=storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli storageos-cli-79787d586d-qp9dj   With the Ondat CLI now deployed, you can check the volume created for pvc-compressed and confirm if it has compression enabled.\n# Get the volumes in the \u0026#34;default\u0026#34; namespace using the Ondat CLI. kubectl --namespace=storageos exec storageos-cli-79787d586d-qp9dj -- storageos get volumes --namespace=default NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE default pvc-4457be86-54a3-4f2b-8326-5d4c8799d48a 5.0 GiB aks-storage-56882587-vmss000000 (online) 0/0 2 minutes ago # Describe the \u0026#34;pvc-4457be86-54a3-4f2b-8326-5d4c8799d48a\u0026#34; volume. kubectl --namespace=storageos exec storageos-cli-79787d586d-qp9dj -- storageos describe volume pvc-4457be86-54a3-4f2b-8326-5d4c8799d48a --namespace=default ID e1c7e565-4be7-414f-910f-86d97652e8c3 Name pvc-4457be86-54a3-4f2b-8326-5d4c8799d48a Description AttachedOn Attachment Type detached NFS Service Endpoint Exports: Namespace default (371b17d3-6778-4085-b943-6d032e1b5f34) Labels csi.storage.k8s.io/pv/name=pvc-4457be86-54a3-4f2b-8326-5d4c8799d48a, csi.storage.k8s.io/pvc/name=pvc-compressed, csi.storage.k8s.io/pvc/namespace=default, storageos.com/nocompress=false Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version Mg Created at 2022-07-26T15:49:26Z (4 minutes ago) Updated at 2022-07-26T15:49:26Z (4 minutes ago) Master: ID 2f3642b3-a1f0-4dd3-8cc7-7e24bda5a144 Node aks-storage-56882587-vmss000000 (a28e5c43-5847-4968-b777-3bd618d4424e) Health online  üí° Notice in the label metadata section - there is a label \u0026raquo; storageos.com/nocompress=false attached to the volume that was provisioned.\n   Example - Enable Data Compression Through a StorageClass Definition The following guidance below will demonstrates how to use Ondat‚Äôs Data Compression feature through a StorageClass (PVC) definition.\n  The instructions will enable compression through a custom StorageClass and use the following parameter ¬ª storageos.com/nocompress=false - which will be used to create an Ondat volume.\n üí° Labels can be applied to a PVC directly, or indirectly by adding them as parameters on a StorageClass.\n     Create a custom StorageClass, named ondat-compressed and check that it has been successfully created.\n# Create the \u0026#34;ondat-compressed\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-compressedprovisioner:csi.storageos.comallowVolumeExpansion:trueparameters:storageos.com/nocompress:\u0026#34;false\u0026#34;# Enable compression of data-at-rest and data-in-transit.csi.storage.k8s.io/fstype:ext4csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosEOF# Review and confirm that \u0026#34;ondat-compressed\u0026#34; was created. kubectl get sc | grep \u0026#34;ondat-compressed\u0026#34; ondat-compressed csi.storageos.com Delete Immediate true 92s   Create a PersistentVolumeClaim that will use ondat-replicated as its StorageClass and confirm that it was successfully created.\n# Create a \u0026#34;pvc-compressed-2\u0026#34; PVC that uses the \u0026#34;ondat-compressed\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:pvc-compressed-2spec:storageClassName:ondat-compressed # Use the \u0026#34;ondat-compressed\u0026#34; StoragClass created in Step 1accessModes:- ReadWriteOnceresources:requests:storage:5GiEOF# Ensure that the PVC was successfully provisioned with \u0026#34;ondat-compressed\u0026#34;. kubectl get pvc pvc-compressed-2 --output=wide --show-labels --namespace=default NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS pvc-compressed-2 Bound pvc-07e8a7db-fc77-40cf-a4c9-62952da6f820 5Gi RWO ondat-compressed 8s Filesystem \u0026lt;none\u0026gt;  üí° Notice that the output above shows that the PVC does not have any labels applied to it - this is because we are using the ondat-compressed StorageClass parameters defined in Step 1.\n   To review and confirm that Ondat has successfully provisioned a volume that has compression enabled as defined in the PVC manifest earlier - deploy and run the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat through kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the Ondat CLI utility pod name. kubectl --namespace=storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli storageos-cli-79787d586d-qp9dj   With the Ondat CLI now deployed, you can check the volume created for pvc-compressed-2 and confirm if it has compression enabled.\n# Get the volumes in the \u0026#34;default\u0026#34; namespace using the Ondat CLI. kubectl --namespace=storageos exec storageos-cli-79787d586d-qp9dj -- storageos get volumes --namespace=default NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE default pvc-07e8a7db-fc77-40cf-a4c9-62952da6f820 5.0 GiB aks-storage-56882587-vmss000001 (online) 0/0 6 minutes ago default pvc-4457be86-54a3-4f2b-8326-5d4c8799d48a 5.0 GiB aks-storage-56882587-vmss000000 (online) 0/0 23 minutes ago # Describe the \u0026#34;pvc-07e8a7db-fc77-40cf-a4c9-62952da6f820\u0026#34; volume. kubectl --namespace=storageos exec storageos-cli-79787d586d-qp9dj -- storageos describe volume pvc-07e8a7db-fc77-40cf-a4c9-62952da6f820 --namespace=default ID b9ee19fe-f1ab-4099-bae7-34a52323ee55 Name pvc-07e8a7db-fc77-40cf-a4c9-62952da6f820 Description AttachedOn Attachment Type detached NFS Service Endpoint Exports: Namespace default (371b17d3-6778-4085-b943-6d032e1b5f34) Labels csi.storage.k8s.io/pv/name=pvc-07e8a7db-fc77-40cf-a4c9-62952da6f820, csi.storage.k8s.io/pvc/name=pvc-compressed-2, csi.storage.k8s.io/pvc/namespace=default, storageos.com/nocompress=false Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version Mg Created at 2022-07-26T16:06:03Z (8 minutes ago) Updated at 2022-07-26T16:06:04Z (8 minutes ago) Master: ID f2fbfad3-b5d7-4d36-96d4-5c54a4bf8946 Node aks-storage-56882587-vmss000001 (43391062-73d5-4231-ab46-f10ef748bee6) Health online  üí° Notice in the label metadata section - there is a label \u0026raquo; storageos.com/nocompress=false attached to the volume that was provisioned.\n   ","excerpt":"Overview  üí° For more information on Ondat\u0026rsquo;s Compression feature, review the Compression ‚Ä¶","ref":"/docs/operations/compression/","title":"How To Enable Data Compression"},{"body":"Overview Encrypting a volume is done by simply creating a volume with the storageos.com/encryption=true label. This label can be applied against a PersistentVolumeClaim (PVC) resource definition or through a custom Ondat StorageClass resource definition.\n Only the label is required to enable encryption. Once the label is present - during the volume creation, the MutatingAdmissionWebhook that runs as part of the Ondat API Manager, will create the volume encryption key, link it to the PVC and store it in a Kubernetes secret.   ‚ö†Ô∏è Encryption can only be enabled before an Ondat volume is provisioned. Once the encrypted volume has been created, encryption cannot be removed during the volume\u0026rsquo;s lifetime.\n  üí° For more information on the Ondat\u0026rsquo;s Data Encryption feature, review the Data Encryption feature page.\n Example - Enable Volume Data Encryption Through a PersistentVolumeClaim Definition The following guidance will demonstrate how to enable Ondat\u0026rsquo;s Data Encryption through a PersistentVolumeClaim (PVC) definition.\n The instructions will enable data encryption on a PVC that will be used by a StatefulSet resource in the encrypted namespace.    Create a namespace called encrypted where the encrypted volume and StatefulSet will reside.\n# Create namespace called \u0026#34;encrypted\u0026#34;.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:Namespacemetadata:name:encryptedlabels:name:encryptedEOF  Create a custom PersistentVolumeClaim named encrypted and ensure that you add the following label \u0026raquo; storageos.com/encryption=true to the manifest.\n# Create a \u0026#34;encrypted\u0026#34; PVC.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:encryptednamespace:encryptedlabels:storageos.com/encryption:\u0026#34;true\u0026#34;# Enable Data Encryption.spec:storageClassName:storageos # Use the default Ondat StorageClass to provision persistent volumes.accessModes:- ReadWriteOnceresources:requests:storage:5GiEOF  Once the PVC resource has been successfully created, review and confirm that the storageos.com/encryption=true label has been applied.\n# Get the label applied to the \u0026#34;encrypted\u0026#34; PVC. kubectl get pvc encrypted --output=wide --show-labels --namespace=encrypted   Create a StatefulSet workload in the encrypted namespace that uses the encrypted PVC that was created in Step 2.\n# Create a StatefulSet workload that uses the \u0026#34;encrypted\u0026#34; PVC.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:apps/v1kind:StatefulSetmetadata:name:encryptednamespace:encrypted # Create the StatefulSet workload in the \u0026#34;encrypted\u0026#34; namespace.spec:selector:matchLabels:app:encryptedserviceName:encryptedreplicas:1template:metadata:labels:app:encryptedspec:volumes:- name:encryptedpersistentVolumeClaim:claimName:encrypted # Use the \u0026#34;encrypted\u0026#34; PVC for the StatefulSet workload.containers:- name:encryptedimage:spurin/gatsby:latestimagePullPolicy:AlwaysvolumeMounts:- mountPath:\u0026#34;/data\u0026#34;name:encryptedEOF# Review and confirm that StatefulSet workload was successfully created. kubectl get pod --namespace=encrypted kubectl get statefulsets.apps --namespace=encrypted   To review and confirm that volume encryption is enabled and working, run the following commands below to inspect the resources created.\n# Review the secrets created in \u0026#34;encrypted\u0026#34; namespace.  # There will be a \u0026#34;namespace\u0026#34; and \u0026#34;volume\u0026#34; encryption key generated by Ondat. kubectl get secrets --namespace=encrypted NAME TYPE DATA AGE default-token-zm5dk kubernetes.io/service-account-token 3 81s storageos-namespace-key Opaque 1 63s storageos-volume-key-e186b6c8-ba47-4bef-9293-56ad58a2b572 Opaque 4 63s # Describe all of the secrets in the \u0026#34;encrypted\u0026#34; namespace related to Ondat. # Notice that there is a \u0026#34;storageos-namespace-key\u0026#34; - 1 unique key per namespace) # Notice that there is a \u0026#34;storageos-volume-key-$RANDOM\u0026#34; - 1 unique key per volume in the namespace. # Take note of the annotation \u0026#34;storageos.com/pvc=encrypted\u0026#34; under the \u0026#34;storageos-volume-key-$RANDOM\u0026#34; secret kubectl describe secrets \u0026#34;storageos\u0026#34; --namespace=encrypted Name: storageos-namespace-key Namespace: encrypted Labels: app.kubernetes.io/component=storageos-api-manager app.kubernetes.io/managed-by=storageos-operator app.kubernetes.io/name=storageos app.kubernetes.io/part-of=storageos Annotations: \u0026lt;none\u0026gt; Type: Opaque Data ==== key: 32 bytes Name: storageos-volume-key-e186b6c8-ba47-4bef-9293-56ad58a2b572 Namespace: encrypted Labels: app.kubernetes.io/component=storageos-api-manager app.kubernetes.io/managed-by=storageos-operator app.kubernetes.io/name=storageos app.kubernetes.io/part-of=storageos storageos.com/pvc=encrypted Annotations: \u0026lt;none\u0026gt; Type: Opaque Data ==== hmac: 32 bytes iv: 32 bytes key: 64 bytes vuk: 80 bytes # Review \u0026#34;storageos-volume-key-$RANDOM\u0026#34;.# Notice that there are 4 data objects stored in the secret \u0026gt; \u0026#34;hmac\u0026#34;, \u0026#34;iv\u0026#34;, \u0026#34;vuk\u0026#34;, \u0026#34;iv\u0026#34; respectively.kubectl get secrets storageos-volume-key-e186b6c8-ba47-4bef-9293-56ad58a2b572 --namespace=encrypted --output=yamlapiVersion:v1data:hmac:mDIGqgm1mcjdJycz0Mg807+j+B9cCL59tuQwdvW0ow4=iv:gTto6RstRUamHwbn/QDZODTOuE2T2D9WzjX1ck8nZSg=key:FNiJp5hyoKxMTgJismLHuD0fuFgW6ozsg3vKHs2Zpzqj0enLLfT+yIiFtWW88TIi+ZpNP4hwnqpKMvKOKzU3jA==vuk:kWqmRear2ew6lEv48b/d3U6JJh58LCzeuY9r06Xi6dCKTBaHrLQD2A+gtxuZ0HHhoTwO1nEYAIE20QALRAi61GrosRmQzm05Jov0D/aZJ9Q=kind:Secretmetadata:creationTimestamp:\u0026#34;2022-07-25T13:08:12Z\u0026#34;labels:app.kubernetes.io/component:storageos-api-managerapp.kubernetes.io/managed-by:storageos-operatorapp.kubernetes.io/name:storageosapp.kubernetes.io/part-of:storageosstorageos.com/pvc:encryptedname:storageos-volume-key-e186b6c8-ba47-4bef-9293-56ad58a2b572namespace:encryptedresourceVersion:\u0026#34;64424\u0026#34;uid:481ace83-8fb8-4656-8820-a8b8dec88017  The last step will be to try and read the data on the node where the encrypted volume resides.\n# Get the node locations where \u0026#34;encrypted-0\u0026#34; pod is running. kubectl get pods --namespace=encrypted --output=wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES encrypted-0 1/1 Running 0 8m4s 10.244.3.6 aks-storage-26370890-vmss000000 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; # Use \u0026#34;kubectl debug\u0026#34; to temporarily run a privileged container on the node where \u0026#34;encrypted-0\u0026#34; is located. kubectl debug node/aks-storage-26370890-vmss000000 -it --image=ubuntu:latest # Through the privileged container, update the repository index and install \u0026#34;binutils\u0026#34; to access the \u0026#34;strings\u0026#34; utility. apt update \u0026amp;\u0026amp; apt install --yes binutils # Navigate to where data is being stored as blob files on the node and list the files. cd /host/var/lib/storageos/data/dev1/ ls -lah total 340M drwxr-xr-x 2 root root 4.0K Jul 25 13:08 . drwxr-xr-x 4 root root 4.0K Jul 25 13:08 .. -rw------- 1 root root 42M Jul 25 13:09 deployment.094b604f-a30a-4879-8976-0614ae15d5af.0.blob -rw------- 1 root root 42M Jul 25 13:09 deployment.094b604f-a30a-4879-8976-0614ae15d5af.1.blob # Use the \u0026#34;strings\u0026#34; utilty to try and read the content of the blob files in the directory. # Note - the output will return multiple strings of random, unreadable characters as the content is encrypted. strings *.blob | head -10 SbP4E =oZ5 ey{*t|N `0|_ xdR\u0026gt; q6Yul (OF(a kbY#( 5- n 02p8 # exit from the pod and return to your local shell exit   Example - Enable Volume Data Encryption Through a StorageClass Definition The following guidance will demonstrates how to enable Ondat\u0026rsquo;s Data Encryption through a StorageClass definition.\n  The instructions will enable data encryption for PVCs through a custom StorageClass that will be used by a StatefulSet resource in the encrypted namespace.\n# Create the \u0026#34;ondat-encryption\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-encryptionprovisioner:csi.storageos.comallowVolumeExpansion:trueparameters:csi.storage.k8s.io/fstype:ext4storageos.com/encryption:\u0026#34;true\u0026#34;csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosEOF# Review and confirm that \u0026#34;ondat-encryption\u0026#34; was created. kubectl get sc | grep \u0026#34;ondat-encryption\u0026#34;     Create a namespace called encrypted where the encrypted volume and StatefulSet will reside.\n# Create namespace called \u0026#34;encrypted\u0026#34;.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:Namespacemetadata:name:encryptedlabels:name:encryptedEOF  Create a PersistentVolumeClaim that will use ondat-encryption as its StorageClass and confirm that it was successfully created.\n# Create a \u0026#34;encrypted-2\u0026#34; PVC.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:encrypted-2namespace:encryptedspec:storageClassName:ondat-encryption # Use the custom Ondat StorageClass called \u0026#34;ondat-encryption\u0026#34; to provision encrypted persistent volumes.accessModes:- ReadWriteOnceresources:requests:storage:5GiEOF# Ensure that the PVC was successfully provisioned with \u0026#34;ondat-encryption\u0026#34;. kubectl get pvc encrypted-2 --output=wide --show-labels --namespace=encrypted NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS encrypted-2 Bound pvc-fe3958cb-c3d9-43aa-9ae7-530d1362e560 5Gi RWO ondat-encryption 46s Filesystem \u0026lt;none\u0026gt;   Create a StatefulSet workload in the encrypted namespace that uses the encrypted-2 PVC that was created in Step 2.\n# Create a StatefulSet workload that uses the \u0026#34;encrypted\u0026#34; PVC.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:apps/v1kind:StatefulSetmetadata:name:encrypted-2namespace:encrypted # Create the StatefulSet workload in the \u0026#34;encrypted\u0026#34; namespace.spec:selector:matchLabels:app:encryptedserviceName:encryptedreplicas:1template:metadata:labels:app:encryptedspec:volumes:- name:encryptedpersistentVolumeClaim:claimName:encrypted-2 # Use the \u0026#34;encrypted-2\u0026#34; PVC for the StatefulSet workload.containers:- name:encryptedimage:spurin/gatsby:latestimagePullPolicy:AlwaysvolumeMounts:- mountPath:\u0026#34;/data\u0026#34;name:encryptedEOF# Review and confirm that StatefulSet workload was successfully created. kubectl get pod --namespace=encrypted kubectl get statefulsets.apps --namespace=encrypted   To review and confirm that volume encryption is enabled and working, run the following commands below to inspect the resources created.\n# Review the secrets created in \u0026#34;encrypted\u0026#34; namespace.  # There will be a \u0026#34;namespace\u0026#34; and \u0026#34;volume\u0026#34; encryption key generated by Ondat. kubectl get secrets --namespace=encrypted NAME TYPE DATA AGE default-token-wb76h kubernetes.io/service-account-token 3 10m storageos-namespace-key Opaque 1 9m48s storageos-volume-key-bc175830-3ed4-4d0c-90eb-df070b9930eb Opaque 4 9m48s # Describe all of the secrets in the \u0026#34;encrypted\u0026#34; namespace related to Ondat. # Notice that there is a \u0026#34;storageos-namespace-key\u0026#34; - 1 unique key per namespace) # Notice that there is a \u0026#34;storageos-volume-key-$RANDOM\u0026#34; - 1 unique key per volume in the namespace. # Take note of the annotation \u0026#34;storageos.com/pvc=encrypted\u0026#34; under the \u0026#34;storageos-volume-key-$RANDOM\u0026#34; secret kubectl describe secrets \u0026#34;storageos\u0026#34; --namespace=encrypted Name: storageos-namespace-key Namespace: encrypted Labels: app.kubernetes.io/component=storageos-api-manager app.kubernetes.io/managed-by=storageos-operator app.kubernetes.io/name=storageos app.kubernetes.io/part-of=storageos Annotations: \u0026lt;none\u0026gt; Type: Opaque Data ==== key: 32 bytes Name: storageos-volume-key-bc175830-3ed4-4d0c-90eb-df070b9930eb Namespace: encrypted Labels: app.kubernetes.io/component=storageos-api-manager app.kubernetes.io/managed-by=storageos-operator app.kubernetes.io/name=storageos app.kubernetes.io/part-of=storageos storageos.com/pvc=encrypted-2 Annotations: \u0026lt;none\u0026gt; Type: Opaque Data ==== hmac: 32 bytes iv: 32 bytes key: 64 bytes vuk: 80 bytes # Review \u0026#34;storageos-volume-key-$RANDOM\u0026#34;.# Notice that there are 4 data objects stored in the secret \u0026gt; \u0026#34;hmac\u0026#34;, \u0026#34;iv\u0026#34;, \u0026#34;vuk\u0026#34;, \u0026#34;iv\u0026#34; respectively.kubectl get secrets storageos-volume-key-bc175830-3ed4-4d0c-90eb-df070b9930eb --namespace=encrypted --output=yamlapiVersion:v1data:hmac:K26qP2LJF0GnLBLOSPmGlLatPGhLnW4l6LUFapnlKnI=iv:zDrINiKUNS8CAZfOPPzXxDRjdQETR6weTgN8S6irmzQ=key:9rXsIPru1P9X6C+PGBRuGIH5pdRh1Y5LZ4psLjyzy0oyM/yylqUIG9Ez8XBkOW8pCrwY303TC6aBAOdlzEjJtw==vuk:CokhOv1bVPySm/afmpZA9RHSTm2uWd2cPD2WGbw+xB7xAmPx3NqKws2yFcLAf2370K3Sh/iHMeAfNMQoMPWVUZdqIsZcSnUcvtfd1YOHZv8=kind:Secretmetadata:creationTimestamp:\u0026#34;2022-07-25T13:41:05Z\u0026#34;labels:app.kubernetes.io/component:storageos-api-managerapp.kubernetes.io/managed-by:storageos-operatorapp.kubernetes.io/name:storageosapp.kubernetes.io/part-of:storageosstorageos.com/pvc:encrypted-2name:storageos-volume-key-bc175830-3ed4-4d0c-90eb-df070b9930ebnamespace:encryptedresourceVersion:\u0026#34;19756\u0026#34;uid:bb793310-0ad9-46d1-a590-34556dffe3a6type:Opaque  The last step will be to try to read the data on the node where the encrypted volume resides.\n# Get the node locations where \u0026#34;encrypted-2-0\u0026#34; pod is running. kubectl get pods --namespace=encrypted --output=wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES encrypted-2-0 1/1 Running 0 4m46s 10.42.4.7 demo-worker-node-5 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; # Use \u0026#34;kubectl debug\u0026#34; to temporarily run a privileged container on the node where \u0026#34;encrypted-2-0\u0026#34; is located. kubectl debug node/demo-worker-node-5 -it --image=ubuntu:latest # Through the privileged container, update the repository index and install \u0026#34;binutils\u0026#34; to access the \u0026#34;strings\u0026#34; utility. apt update \u0026amp;\u0026amp; apt install --yes binutils # Navigate to where data is being stored as blob files on the node and list the files. cd /host/var/lib/storageos/data/dev1/ ls -lah total 340M drwxr-xr-x 2 root root 4.0K Jul 25 13:41 . drwxr-xr-x 4 root root 4.0K Jul 25 13:41 .. -rw------- 1 root root 42M Jul 25 13:48 deployment.b9ea560c-5fc2-4f6f-9f43-c2d33483ed89.0.blob -rw------- 1 root root 42M Jul 25 13:49 deployment.b9ea560c-5fc2-4f6f-9f43-c2d33483ed89.1.blob # Use the \u0026#34;strings\u0026#34; utilty to try and read the content of the blob files in the directory. # Note - the output will return multiple strings of random, unreadable characters as the content is encrypted. strings *.blob | head -10 n.@LG c%rs/ r`R; |\u0026#39;U% E\u0026#34;k9^ *59G #q={ uOb JC#rtb ]=?b # exit from the pod and return to your local shell exit   ","excerpt":"Overview Encrypting a volume is done by simply creating a volume with the ‚Ä¶","ref":"/docs/operations/encryption/","title":"How To Enable Data Encryption For Volumes"},{"body":"Overview  üí° For more information on the Ondat fencing feature, review the Fencing feature page.\n How To Label a Pod for Fencing? When Ondat detects that a node has gone offline or become partitioned, it marks the node offline and performs volume failover operations.\n The Ondat Fencing Controller watches for node failures and determines if there are any pods targeted for fencing.  In order for a pod to be fenced, the following criteria listed below is required:\n The pod must have the label storageos.com/fenced=true. The pod to be fenced must claim an Ondat volume. The Ondat volume claimed by the pod needs to be online.  If the node becomes offline and these criteria are met, the pod is deleted and rescheduled on another node.\n üí° No changes are made to pods that have Ondat volumes that are unhealthy. This is typically the case when a volume was configured to not have any replicas, and the node with the single copy of the data is offline. In this case it is better to wait for the node to recover.\n Example - Enable Fencing for a StatefulSet Workload Below is an example that shows how a StatefulSet can leverage fencing for its associated pods.\n üí° Note that the storageos.com/fenced: \u0026quot;true\u0026quot; label is applied only in the .spec.template.metadata.label section, as the label must only be present on the pod, but not on the PVC. Otherwise, the Ondat volumes will fail to provision as only special accepted labels can be passed to volumes.\n # Create a \u0026#34;my-statefulset\u0026#34; resource with a fencing enabled. cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:apps/v1kind:StatefulSetmetadata:name:my-statefulsetspec:selector:matchLabels:# Notice that the \u0026#34;matchLabels\u0026#34; does NOT have the fencing label.app:prodserviceName:\u0026#34;default\u0026#34;replicas:1template:metadata:labels:# Notice that the fencing label IS PRESENT here.app:prodstorageos.com/fenced:\u0026#34;true\u0026#34;# Enable Ondat fencing.spec:containers:- name:debianimage:debian:10-slimcommand:[\u0026#34;/bin/sleep\u0026#34;]args:[\u0026#34;3600\u0026#34;]volumeMounts:- name:storageos-volumemountPath:/mntvolumeClaimTemplates:- metadata:name:storageos-volumelabels:env:prodstorageos.com/replicas:\u0026#34;1\u0026#34;spec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:\u0026#34;storageos\u0026#34;resources:requests:storage:10GiEOFOnce the resource has been successfully created and is running, review and confirm that the storageos.com/fenced: \u0026quot;true\u0026quot; label has been applied to the StatefulSet.\n# Get the labels applied to the \u0026#34;my-statefulset-0\u0026#34; pod. kubectl get pod my-statefulset-0 --namespace=default --show-labels --output=wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES LABELS my-statefulset-0 1/1 Running 0 2m34s 10.244.4.6 aks-storage-41375452-vmss000001 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; app=prod,controller-revision-hash=my-statefulset-d7dc867bf,statefulset.kubernetes.io/pod-name=my-statefulset-0,storageos.com/fenced=true Understanding Ondat\u0026rsquo;s Fencing Trigger The Ondat Fencing Controller checks the Ondat node health every 5 seconds. This is how quickly the fencing controller can react to node failures.\n Pods assigned to unhealthy nodes will be evaluated immediately on state change, and then re-evaluated every hour, though this is configurable. This retry allows pods that had unhealthy volumes which have now recovered to eventually failover, or pods that were rescheduled on an unhealthy node to be re-evaluated for fencing.  Fencing Trigger Demonstration The following example below shows how the Ondat API manager fences a pod.\n  Ensure the storageos.com/fenced=true label is present:\n# Get the labels applied to the \u0026#34;mysql\u0026#34; pod. kubectl --namespace=mysql get pod --show-labels --output=wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES LABELS mysql-0 1/1 Running 0 6m33s 10.42.3.7 worker1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; app=mysql,controller-revision-hash=mysql-799fd74b87,env=prod,statefulset.kubernetes.io/pod-name=mysql-0,storageos.com/fenced=true # Get the labels applied to the \u0026#34;mysql\u0026#34; PVC. kubectl --namespace=mysql get pvc --show-labels --output=wide NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS data-mysql-0 Bound pvc-5d7b23a6-e754-4998-98fd-318b3f9382bb 5Gi RWO storageos 19m Filesystem app=mysql,env=prod,storageos.com/replicas=1  üí° Notice that the mysql-0 pod above has the storageos.com/fenced=true label and is on worker1 node.\n   Purposefully stop the node that is hosting the mysql-0 pod:\n# SSH to \u0026#34;worker1\u0026#34; node. ssh worker1 # Shut down \u0026#34;worker1\u0026#34; node. shutdown -h now   Check the logs from the Ondat API Manager:\n# Get the logs from the Ondat API Manager. kubectl --namespace=storageos logs storageos-api-manager-68759bbc78-7l5fw # truncated... {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.413811357Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;nginx-ingress-controller-xbqjf\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;ingress-nginx\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.417605039Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;storageos-api-manager-68759bbc78-7l5fw\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;storageos\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.417748651Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;coredns-7c5566588d-8g5xq\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;storageos\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.417792281Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;metrics-server-6b55c64f86-cnwtk\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;storageos\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.417883383Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;default-http-backend-67cf578fc4-w8sm4\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;ingress-nginx\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.417975663Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;coredns-autoscaler-65bfc8d47d-ph6pn\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;storageos\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.418024204Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;canal-stzdv\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;storageos\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.418065315Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;storageos-etcd-2hkff82fq2\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;storageos-etcd\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.418092165Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;storageos-daemonset-6zrkk\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;storageos\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.418182036Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;skipping pod without storageos.com/fenced=true label set\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;cattle-node-agent-sjspk\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;cattle-system\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.439513312Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;pod has fenced label set and volume(s) still healthy after node failure, proceeding with fencing\u0026#34;,\u0026#34;pod\u0026#34;:\u0026#34;mysql-0\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;mysql\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.495807296Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;pod deleted\u0026#34;,\u0026#34;pod\u0026#34;:\u0026#34;mysql-0\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;mysql\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.505411162Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;volume attachment deleted\u0026#34;,\u0026#34;pod\u0026#34;:\u0026#34;mysql-0\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;mysql\u0026#34;,\u0026#34;pvc\u0026#34;:\u0026#34;data-mysql-0\u0026#34;,\u0026#34;va\u0026#34;:\u0026#34;csi-c2b44cee5a647e20d77e0e217dfaec07afd592eae57bcccc09b3447de653ae8c\u0026#34;,\u0026#34;node\u0026#34;:\u0026#34;worker1\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.505439792Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;fenced pod\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2021-04-28T13:06:49.573478266Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;set scheduler\u0026#34;,\u0026#34;scheduler\u0026#34;:\u0026#34;storageos-scheduler\u0026#34;,\u0026#34;pod\u0026#34;:\u0026#34;mysql/mysql-0\u0026#34;} # truncated...  üí° The Ondat API Manager detects all the pods that are on the failed node, and selects only the ones that meet the fencing criteria as described above. In this case only mysql-0 is selected for fencing.\n   Check the pod\u0026rsquo;s new node location:\n# Get the labels applied to the \u0026#34;mysql\u0026#34; pod. kubectl --namespace=mysql get pod --show-labels --output=wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES LABELS mysql-0 1/1 Running 0 6m33s 10.42.3.7 worker2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; app=mysql,controller-revision-hash=mysql-799fd74b87,env=prod,statefulset.kubernetes.io/pod-name=mysql-0,storageos.com/fenced=true  üí° Notice that the pod mysql-0 started on a different node successfully.\n   ","excerpt":"Overview  üí° For more information on the Ondat fencing feature, review the Fencing feature page.\n How ‚Ä¶","ref":"/docs/operations/fencing/","title":"How To Enable Fencing"},{"body":"Overview Ondat Topology-Aware Placement is a feature that enforces placement of data across failure domains to guarantee high availability.\n TAP uses default labels on nodes to define failure domains. For instance, an Availability Zone. However, the key label used to segment failure domains can be defined by the user per node. In addition, TAP is an opt-in feature per volume.   üí° For more information on the Ondat Topology-Aware Placement feature, review the Ondat Topology-Aware Placement feature page.\n Example - Enable Topology-Aware Placement Through a PersistentVolumeClaim Definition The following guidance will demonstrate how to use Ondat Topology-Aware Placement through a PersistentVolumeClaim (PVC) definition.\n  The instructions will enable Topology-Aware Placement on a PVC, use a custom zone labelling scheme with the label \u0026raquo; storageos.com/topology-key=custom-region and set it to the soft Failure Mode.\n üí° Labels can be applied to a PVC directly, or indirectly by adding them as parameters on a StorageClass.\n     In the code snippet below, we will define a custom node zone label using the following key-value pair layout \u0026raquo; custom-region=\u0026lt;integer\u0026gt; and apply it against the nodes.\n# Label the worker nodes to define custom regions for the TAP feature. kubectl label node demo-worker-node-1 custom-region=1 kubectl label node demo-worker-node-2 custom-region=2 kubectl label node demo-worker-node-3 custom-region=3 kubectl label node demo-worker-node-4 custom-region=1 kubectl label node demo-worker-node-5 custom-region=2 # Check that the worker nodes have been labeled successfully. kubectl describe nodes | grep \u0026#34;custom-region\u0026#34;   Create a custom PersistentVolumeClaim named pvc-tap and ensure that you add the following labels storageos.com/topology-aware=true and storageos.com/topology-key=custom-region to the manifest.\n üí° If PVC label storageos.com/topology-key is not set, the node label topology.kubernetes.io/zone is used by default.\n # Create a \u0026#34;pvc-tap\u0026#34; PVC with TAP, custom topology key label called \u0026#34;custom-region\u0026#34; and \u0026#34;soft\u0026#34; failure mode is enabled.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:pvc-taplabels:storageos.com/topology-aware:\u0026#34;true\u0026#34;# Enable Topology-Aware Placement.storageos.com/topology-key:custom-region # Ensure that the topology failure domain node label is defined.storageos.com/failure-mode:soft # Enable \u0026#34;soft\u0026#34; failure mode.spec:storageClassName:storageosaccessModes:- ReadWriteOnceresources:requests:storage:5GiEOF  Once the PVC resource has been successfully created, review and confirm that the storageos.com/topology-aware: \u0026quot;true\u0026quot;, storageos.com/topology-key: custom-region and storageos.com/failure-mode: soft labels have been applied.\n# Get the labels applied to the \u0026#34;pvc-tap\u0026#34; PVC. kubectl get pvc --output=wide --show-labels --namespace=default NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS pvc-tap Bound pvc-abb18d51-7e1a-4812-8d65-40dbc090362a 5Gi RWO storageos 3m26s Filesystem storageos.com/failure-mode=soft,storageos.com/topology-aware=true,storageos.com/topology-key=custom-region   To quickly demonstrate Ondat TAP, use the storageos.com/replicas feature label to increase the number of volume replicas to 3 to match the number of custom-region zones that were defined in Step 1.\n üí° To place 3 replicas, the cluster needs at least 4 nodes (1 master + 3 replicas).\n # Increase the volume replicas for \u0026#34;pvc-tap\u0026#34; to 3. kubectl label pvc pvc-tap storageos.com/replicas=3   To review and confirm that Ondat TAP has successfully provisioned 3 volumes and evenly distributed in different custom-region zones - deploy and run the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat through kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the Ondat CLI utility pod name. kubectl --namespace=storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli storageos-cli-77885d6d8b-zqmnn   With the Ondat CLI now deployed, you can check the location of the master and replica volumes.\n# Get the volumes in the \u0026#34;default\u0026#34; namespace using the Ondat CLI. kubectl --namespace=storageos exec storageos-cli-77885d6d8b-zqmnn -- storageos get volumes --namespace=default NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE default pvc-abb18d51-7e1a-4812-8d65-40dbc090362a 5.0 GiB demo-worker-node-4 (online) 3/3 41 minutes ago # Describe the \u0026#34;pvc-9af262b3-ab50-4d68-87bc-60eb825f1f99\u0026#34; volume. kubectl --namespace=storageos exec storageos-cli-77885d6d8b-zqmnn -- storageos describe volume pvc-abb18d51-7e1a-4812-8d65-40dbc090362a --namespace=default ID 882ab4dd-1b35-4bb4-a825-68763719b991 Name pvc-abb18d51-7e1a-4812-8d65-40dbc090362a Description AttachedOn Attachment Type detached NFS Service Endpoint Exports: Namespace default (5055ae9d-6278-4374-a6c8-e4779c6cc58f) Labels csi.storage.k8s.io/pv/name=pvc-abb18d51-7e1a-4812-8d65-40dbc090362a, csi.storage.k8s.io/pvc/name=pvc-tap, csi.storage.k8s.io/pvc/namespace=default, storageos.com/failure-mode=soft, storageos.com/nocompress=true, storageos.com/replicas=3, storageos.com/topology-aware=true, storageos.com/topology-key=custom-region Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version OQ Created at 2022-07-22T16:05:04Z (42 minutes ago) Updated at 2022-07-22T16:26:35Z (21 minutes ago) Master: ID 248ea74d-8753-4f64-afbf-73b72ddc211b Node demo-worker-node-4 (1c9284c7-99a4-40c5-9ab9-95df19c1a8ac) Health online Topology Domain 1 Replicas: ID 3172c40c-e745-48a9-91cf-39352389e99e Node demo-worker-node-5 (37fdc95a-e215-44e7-a53d-45c1b7a7bad1) Health ready Promotable true Topology Domain 2 ID 516bb457-4720-4b65-af70-327fb7d74898 Node demo-worker-node-3 (669e2d13-2520-4238-9be6-4f58540f0f64) Health ready Promotable true Topology Domain 3 ID e48d6084-8ce8-4d57-8644-20d61c28005e Node demo-worker-node-1 (114ae6a7-c40d-40c2-87cb-1dc9dcc24348) Health ready Promotable true Topology Domain 1  üí° As demonstrated in the output above, notice how the master volume and each replica volume are deployed on a different nodes (demo-worker-node-4, demo-worker-node-5, demo-worker-node-3 and demo-worker-node-1 respectively) to ensure data protection and high availability in the event of a transient node failure.\n   Example - Enable Topology-Aware Placement Through a StorageClass Definition The following guidance will demonstrate how to use Ondat Topology-Aware Placement through a StorageClass definition.\n  The instructions will enable Topology-Aware Placement through a custom StorageClass, use the node label \u0026raquo; topology.kubernetes.io/zone and set the default volume replica count \u0026raquo; storageos.com/replicas to 2.\n üí° Labels can be applied to a PVC directly, or indirectly by adding them as parameters on a StorageClass.\n     Check and confirm that the worker nodes in your cluster have the topology.kubernetes.io/zone already applied to them first.\n üí° Major Cloud Provider Kubernetes distributions such as GKE, EKS and AKS have topology.kubernetes.io/zone applied to worker nodes that are deployed in different availability zones.\n # Check for the \u0026#34;topology.kubernetes.io/zone\u0026#34; first. kubectl describe nodes | grep \u0026#34;topology.kubernetes.io/zone=\u0026#34; topology.kubernetes.io/zone=northeurope-1 topology.kubernetes.io/zone=northeurope-2 topology.kubernetes.io/zone=northeurope-3 topology.kubernetes.io/zone=northeurope-1 topology.kubernetes.io/zone=northeurope-2   Create a custom StorageClass, named ondat-tap and check that it has been successfully created.\n# Create the \u0026#34;ondat-tap\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-tapprovisioner:csi.storageos.comallowVolumeExpansion:trueparameters:csi.storage.k8s.io/fstype:ext4storageos.com/replicas:\u0026#34;2\u0026#34;storageos.com/topology-aware:\u0026#34;true\u0026#34;csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosEOF# Review and confirm that \u0026#34;ondat-tap\u0026#34; was created. kubectl get sc | grep \u0026#34;ondat-tap\u0026#34;   Create a PersistentVolumeClaim that will use ondat-tap as its StorageClass and confirm that it was successfully created.\n# Create a \u0026#34;pvc-tap-2\u0026#34; PVC that uses the \u0026#34;ondat-tap\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:pvc-tap-2spec:storageClassName:ondat-tapaccessModes:- ReadWriteOnceresources:requests:storage:5GiEOF# Ensure that the PVC was successfully provisioned with \u0026#34;ondat-tap\u0026#34;. kubectl get pvc --output=wide --show-labels --namespace=default NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS pvc-tap-2 Bound pvc-d3662005-0bee-4b62-9a66-59ac65254687 5Gi RWO ondat-tap 4m Filesystem \u0026lt;none\u0026gt;  üí° Notice that the output above shows that the PVC does not have any labels applied to it - this is because we are using the ondat-tap StorageClass parameters defined in Step 2.\n   To review and confirm that Ondat TAP has successfully provisioned 2 volumes and evenly distributed in different zones - deploy and run the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat through kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the Ondat CLI utility pod name. kubectl --namespace=storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli storageos-cli-79787d586d-s2w66   With the Ondat CLI now deployed, you can check the location of the master and replica volumes.\n# Get the volumes in the \u0026#34;default\u0026#34; namespace using the Ondat CLI. kubectl --namespace=storageos exec storageos-cli-79787d586d-s2w66 -- storageos get volumes --namespace=default NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE default pvc-d3662005-0bee-4b62-9a66-59ac65254687 5.0 GiB aks-storage-70602947-vmss000000 (online) 2/2 8 minutes ago # Describe the \u0026#34;pvc-d3662005-0bee-4b62-9a66-59ac65254687\u0026#34; volume. kubectl --namespace=storageos exec storageos-cli-79787d586d-s2w66 -- storageos describe volume pvc-d3662005-0bee-4b62-9a66-59ac65254687 --namespace=default ID 73d3e20a-1d48-472d-b64a-a1dfafceb593 Name pvc-d3662005-0bee-4b62-9a66-59ac65254687 Description AttachedOn Attachment Type detached NFS Service Endpoint Exports: Namespace default (365ca0d2-4f24-4509-a3bd-7e026b8a7b63) Labels csi.storage.k8s.io/pv/name=pvc-d3662005-0bee-4b62-9a66-59ac65254687, csi.storage.k8s.io/pvc/name=pvc-tap-2, csi.storage.k8s.io/pvc/namespace=default, storageos.com/nocompress=true, storageos.com/replicas=2, storageos.com/topology-aware=true Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version Mg Created at 2022-07-22T17:52:54Z (9 minutes ago) Updated at 2022-07-22T17:52:55Z (9 minutes ago) Master: ID 11c2f323-e4a5-4864-861b-ed26501abbad Node aks-storage-70602947-vmss000000 (52619a91-8246-46eb-91dd-d6741739ae0f) Health online Topology Domain northeurope-1 Replicas: ID d681dfc8-7cce-4bac-a4ce-c3784a79e3bd Node aks-storage-70602947-vmss000001 (84305a4d-d007-4552-9733-3ce634161124) Health ready Promotable true Topology Domain northeurope-2 ID d9d3eb81-aec4-4093-bbee-f85e947e2f79 Node aks-default-53125611-vmss000002 (037dd333-9d68-4684-b40a-e0dcc8a53866) Health ready Promotable true Topology Domain northeurope-3  üí° As demonstrated in the output above, notice how the master volume and each replica volume are deployed on a different nodes (aks-storage-70602947-vmss000000, aks-storage-70602947-vmss000001 and aks-default-53125611-vmss000002 respectively) to ensure data protection and high availability in the event of a transient node failure.\n   ","excerpt":"Overview Ondat Topology-Aware Placement is a feature that enforces placement of data across failure ‚Ä¶","ref":"/docs/operations/tap/","title":"How To Enable Topology-Aware Placement (TAP)"},{"body":"Overview Every Ondat cluster has a unique cluster ID that is generated once an Ondat deployment is successfuly completed. In order for end users to be able to generate an Ondat licence and apply it to the cluster, an Ondat cluster ID is required.\nPrerequisites  Ensure that you have successfully installed Ondat into your Kubernetes or Openshift cluster.  Procedure Step 1 - Install The Ondat CLI   Deploy and run the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat alongside kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the Ondat CLI utility pod name. kubectl --namespace=storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli storageos-cli-6958b7c4cd-nc8q5   Step 2 - Locate The Ondat Cluster ID   With the Ondat CLI deployed, you can run one of the following commands below to get the unique ID of the cluster.\n The cluster ID will printed out as a UUID value with either a ID or ClusterID key.  # Get cluster-wide information. kubectl --namespace=storageos exec storageos-cli-6958b7c4cd-nc8q5 -- storageos get cluster ID: ce7c9c90-896e-41d5-b823-27ed9a8d8c8f Created at: 2022-08-23T16:24:33Z (10 minutes ago) Updated at: 2022-08-23T16:24:33Z (10 minutes ago) Nodes: 5 Healthy: 5 Unhealthy: 0 # Get more information about the licence status and unique cluster ID. kubectl --namespace=storageos exec storageos-cli-6958b7c4cd-nc8q5 -- storageos get licence ClusterID: ce7c9c90-896e-41d5-b823-27ed9a8d8c8f Expiration: 2022-08-24T16:24:33Z (23 hours from now) Capacity: 50 GiB (53687091200) Used: 0 B (0) Kind: unregistered Features: [] Customer name:   Step 3 - Generate An Ondat Licence  Note down the unique cluster ID so that it can be used to generate an Ondat licence through the Ondat SaaS Platform and apply it to your cluster so that it is successfully registered.   üí° If you already have an Ondat cluster that is connected to the Ondat SaaS Platform, you can apply the licence automatically to the connected cluster by following the steps below;\n  Login to the Ondat SaaS Platform \u0026raquo; Organisation \u0026raquo; Licences \u0026raquo; Generate A New Licence \u0026raquo; Choose an existing cluster \u0026raquo; Select the cluster that you want to apply a licence to.\n  For information and guidance on how to generate and apply an Ondat licence to a cluster, review the licensing documentation.  ","excerpt":"Overview Every Ondat cluster has a unique cluster ID that is generated once an Ondat deployment is ‚Ä¶","ref":"/docs/operations/cluster-id/","title":"How To Get Your Cluster ID"},{"body":"Overview To completely power down an Ondat cluster, for example, when needing to support a machine hall power event, it is recommended to follow the procedure demonstrated in this operation page.\n The main reason for this is to place the cluster into a pseudo maintenance mode to prevent any automated recovery and failover of volumes. As the graceful and non-graceful shutdown support in Kubernetes progress towards GA we intend to introduce an automated capability in a future release of Ondat to automate this workflow.  Prerequisites  Ensure that you have installed and configured kubectl to communicate with your cluster. Ensure that you have the Ondat CLI utility deployed and configured to communicate with your Ondat cluster.  Procedure - Shut Down The Cluster Step 1 - Inspect The Cluster To Ensure That All Master Volumes Are Online \u0026amp; Replica Volumes Are In-sync Using the Ondat CLI utility, run the command below to query all the master volumes and any replica volumes, and then check that the health status is either \u0026raquo; online for masters volumes and \u0026raquo; ready for replica volumes.\n Ensure that no volume has a health status of \u0026raquo; offline or \u0026raquo; unknown.  # Check and ensure that all volumes are \u0026#34;online\u0026#34; and \u0026#34;ready\u0026#34;. kubectl exec -ti $(kubectl get pods -n storageos -l app=storageos-cli -o=jsonpath=\u0026#39;{.items[0].metadata.name}\u0026#39;) -n storageos -- storageos describe volume -A | grep Health Health online Health ready Health online Health online Health online Health online Health ready Health online Health ready Health online Step 2 - Scale Down Application Workloads To Stop Disk I/O Operations First we want to stop disk I/O workloads gracefully and flush all the data to disk. To achieve this, follow your standard Kubernetes workflow or run book for scaling workloads to zero. Below is it will probably look something similar to:\n# Scale down StatefulSets and Deployments to 0 replicas. kubectl scale statefulset,deployment -n $NAMESPACE --all --replicas=0 At this point, there should be nothing running that is generating I/O operations to any Ondat volumes. This enables end users to move onto the next step of stopping Ondat.\n Ondat needs to be stopped first before powering down your Kubernetes cluster, as Ondat is designed to create new replicas of data for volumes that are no longer available. To avoid Ondat from conducting its normal recovery actions as soon as Kubernetes start shutting down nodes, as this is a planned event. By scaling down the workloads and shutting down Ondat, this will freeze all the data in place and maintain the consistency.   üí° Nothing is being done to the backing data or metadata. All of this will be preserved with this process, but as with every procedure where systems are being powered on and off, it is always recommended that backups are taken as a precaution in case your hardware has an issue powering back on.\n Step 3 - Backup The Ondat Cluster Custom Resource To shut down the Ondat cluster, the first step is to remove the Ondat cluster custom resource. End users, can explore the Ondat cluster definition by examining the Custom Resource Definition \u0026raquo; storageosclusters.storageos.com.\n Before deleting this object, ensure that a copy of the definition YAML manifest is made, as this is going to be used in the restoration stage that will be described later. To back up the YAML manifest, run the following command and ensure that the output backup file \u0026raquo; stos-backup.yaml is stored in a safe place (or even added to a configuration management system):  # Backup the Ondat cluster Custom Resource. kubectl get -n storageos stos storageoscluster \u0026gt; ./stos-backup.yaml  üí° In the code snippet demonstrated above, if you have used a different name for the CRD, ensure that you update the command with the correct name for it to successfully run.\n Step 4 - Backup The etcd Cluster Custom Resource For end users that are also self-hosting etcd in the cluster, a recommendation will be to also back up the etcd definition as well.\n To back up the YAML manifest, run the following command and ensure that the output backup file \u0026raquo; stos-etcd-backup.yaml is stored in a safe place (or even added to a configuration management system):  # Backup the etcd cluster Custom Resource. kubectl get -n storageos-etcd etcdcluster storageos-etcd \u0026gt; ./stos-etcd-backup.yaml Step 5 - Delete The Ondat Cluster Once Custom Resource definitions have been backed up, the next step will be to delete the Ondat cluster object. This will also delete the Ondat daemonset pods from all the nodes and, in effect, will be left with a static system which has all the data intact on the nodes - although the Ondat data plane and control plane are no longer running.\n This means that any node power down actions will not result in any volume recovery or failover actions as desired.  # Delete the Ondat cluster object. kubectl delete -n storageos stos storageoscluster Step 6 - Delete The Ondat etcd Cluster After the Ondat cluster is successfully deleted, the next step will be to need to scale down the Ondat etcd cluster. This will delete the etcd cluster pods, but not the PVCs which contain the member information.\n# Delete the Ondat etcd cluster object. kubectl delete -n storageos-etcd etcdcluster storageos-etcd Step 7 - Shut Down The Kubernetes Nodes The next step will be to follow your Kubernetes distribution guidance on how to power down your cluster. This stage will probably be similar to the following Kubernetes documentation on How to safely drain a node, however, it is recommended to follow the specific instructions provided by your Kubernetes distribution on this topic.\n# Drain a Kubernetes node in your cluster. kubectl drain $NODE # SSH into the worker node and shut it down after the drain workflow is complete. ssh -t user@$NODE \u0026#39;sudo shutdown now\u0026#39; The procedure will probably call for shutting down all the worker nodes first (usually these can be done in parallel), and then the master nodes, which again can usually all be done in parallel.\nProcedure - Start Up The Cluster To power on the cluster after a power down, restart the Kubernetes distribution, which should be as simple as powering on the control plane components and then the worker nodes. After a certain period of time, the Kubernetes nodes should be in a ready state. Once the nodes are in the ready state, the next step will be to restore the Ondat cluster definition and scale up the workloads.\nStep 1 - Restore The Ondat etcd Cluster Custom Resource To restore the Ondat etcd cluster, simply apply the YAML manifest file that was created in the previous procedure:\n# Apply the etcd cluster Custom Resource that was previously backed up. kubectl apply -f ./stos-etcd-backup.yaml Once successfully applied, ensure that all the ectd pods are in a Running state and ready:\n# Check and ensure that the \u0026#34;etcd\u0026#34; pods are \u0026#34;Running\u0026#34; successfully. kubectl get pods -n storageos-etcd Step 2 - Restore The Ondat Cluster Custom Resource After all the etcd pods are in a Running statue and ready, restore the Ondat cluster by applying the other YAML manifest file that was created in the previous procedure:\n# Apply the Ondat cluster Custom Resource that was previously backed up. kubectl apply -f ./stos-backup.yaml Once successfully applied, ensure that all the Ondat pods, including the Ondat daemonset pods, are in a Running state and ready:\n# Check and ensure that the Ondat pods are \u0026#34;Running\u0026#34; successfully. kubectl get pods -n storageos Step 3 - Check That the Ondat Master Volumes \u0026amp; Replicas Are Online \u0026amp; Ready Once you have validated that the Ondat daemonset is up and running, you can query the master volumes and replica volumes to check they are all reporting that they are back online and ready:\nUsing the Ondat CLI utility, run the command below to query all the master volumes and any replica volumes, and then check that the health status is either \u0026raquo; online for masters volumes and \u0026raquo; ready for replica volumes.\n Ensure that no volume has a health status of \u0026raquo; offline or \u0026raquo; unknown.  # Check and ensure that all volumes are \u0026#34;online\u0026#34; and \u0026#34;ready\u0026#34;. kubectl exec -ti $(kubectl get pods -n storageos -l app=storageos-cli -o=jsonpath=\u0026#39;{.items[0].metadata.name}\u0026#39;) -n storageos -- storageos describe volume -A | grep Health Health online Health ready Health online Health online Health online Health online Health ready Health online Health ready Health online Step 4 - Scale Up The Application Workloads To Resume I/O Operations The last step is to scale up the workloads again to resume I/O operations. For example:\n# Scale up the StatefulSets back up to their desired replica count. kubectl scale statefulset -n mynamespace \u0026lt;statefulset-name\u0026gt; --replicas=1 # Scale up the Deployments back up to to their desired replica count. kubectl scale deployment -n mynamespace \u0026lt;deployment-name\u0026gt; --replicas=1 ","excerpt":"Overview To completely power down an Ondat cluster, for example, when needing to support a machine ‚Ä¶","ref":"/docs/operations/how-to-shut-down-start-up-a-cluster-procedure/","title":"How To Safely Shut Down \u0026 Start Up A Cluster"},{"body":"Overview With Ondat, cluster administrators can set the storageos.com/computeonly label against Kubernetes nodes that they want to dedicate to running compute intensive workloads.\n üí° For more information on the Centralised Cluster Topology model, review the Cluster Topologies feature page.\n Example - Configuring A Centralised Cluster Topology The following guidance below will demonstrates how to create a centralised cluster topology model by using Ondat\u0026rsquo;s \u0026raquo; storageos.com/computeonly=true node label.\n üí° In this guideline, we are using an Azure Kubernetes Service (AKS) cluster to demonstrate how to configure a centralised cluster topology model.\n   Get the list of nodes in your Kubernetes cluster.\n# List the nodes available in the cluster. kubectl get nodes --output wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME aks-default-26276352-vmss000000 Ready agent 28m v1.23.5 10.224.0.4 \u0026lt;none\u0026gt; Ubuntu 18.04.6 LTS 5.4.0-1085-azure containerd://1.5.11+azure-2 aks-default-26276352-vmss000001 Ready agent 27m v1.23.5 10.224.0.5 \u0026lt;none\u0026gt; Ubuntu 18.04.6 LTS 5.4.0-1085-azure containerd://1.5.11+azure-2 aks-default-26276352-vmss000002 Ready agent 27m v1.23.5 10.224.0.6 \u0026lt;none\u0026gt; Ubuntu 18.04.6 LTS 5.4.0-1085-azure containerd://1.5.11+azure-2 aks-storage-78891087-vmss000000 Ready agent 24m v1.23.5 10.224.0.7 \u0026lt;none\u0026gt; Ubuntu 18.04.6 LTS 5.4.0-1085-azure containerd://1.5.11+azure-2 aks-storage-78891087-vmss000001 Ready agent 24m v1.23.5 10.224.0.8 \u0026lt;none\u0026gt; Ubuntu 18.04.6 LTS 5.4.0-1085-azure containerd://1.5.11+azure-2   Using the the output, we are going to label the nodes that begin with the prefix \u0026raquo; aks-default- with storageos.com/computeonly=true, whilst we dedicate nodes that begin with the prefix \u0026raquo; aks-storage- as storage nodes.\n# Label the \u0026#34;aks-default-*\u0026#34; nodes with the \u0026#34;storageos.com/computeonly=true\u0026#34; feature label. kubectl label node aks-default-26276352-vmss000000 storageos.com/computeonly=true kubectl label node aks-default-26276352-vmss000001 storageos.com/computeonly=true kubectl label node aks-default-26276352-vmss000002 storageos.com/computeonly=true # Check that the nodes have been labeled successfully. kubectl describe node aks-default-26276352-vmss000000 | grep \u0026#34;computeonly\u0026#34; kubectl describe node aks-default-26276352-vmss000001 | grep \u0026#34;computeonly\u0026#34; kubectl describe node aks-default-26276352-vmss000002 | grep \u0026#34;computeonly\u0026#34;   Now we have labelled nodes with \u0026raquo; storageos.com/computeonly=true - the next step will be to install Ondat onto the cluster.\n Ensure that you have met the prerequisites for the Kubernetes distribution that you will be using for the Ondat deployment.    Once we have successfully deployed Ondat, we are also going to deploy and run the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat alongside kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the Ondat CLI utility pod name. kubectl --namespace=storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli storageos-cli-79787d586d-fkjnk   To test that the storageos.com/computeonly=true is working - create 2 custom PersistentVolumeClaim definitions named - pvc-replicated-centralised-topology and pvc-replicated-centralised-topology-test that use the following specifications below;\n# Create a \u0026#34;pvc-replicated-centralised-topology\u0026#34; PVC that has a replica volume count of 1.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:pvc-replicated-centralised-topologylabels:storageos.com/replicas:\u0026#34;1\u0026#34;# Replica volume count of 1spec:storageClassName:storageosaccessModes:- ReadWriteOnceresources:requests:storage:5GiEOF# Create a \u0026#34;pvc-replicated-centralised-topology-test\u0026#34; PVC that has a replica volume count of 3.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:pvc-replicated-centralised-topology-testlabels:storageos.com/replicas:\u0026#34;3\u0026#34;# Replica volume count of 3spec:storageClassName:storageosaccessModes:- ReadWriteOnceresources:requests:storage:5GiEOF  With the Ondat CLI and kubectl, you can check to see which Ondat volumes have been provisioned and the node location where the volumes reside.\n# List the PVCs that have been created in the previous step. kubectl get pvc --output=wide --namespace=default NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE pvc-replicated-centralised-topology Bound pvc-6ee17ec9-b845-409f-a00b-cb62f64aaca2 5Gi RWO storageos 5m9s Filesystem pvc-replicated-centralised-topology-test Pending storageos 4m32s Filesystem # List the PVs that have been created. kubectl get pv --output=wide NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE VOLUMEMODE pvc-2043e1d5-880f-4ac4-8644-357673709a02 12Gi RWO Delete Bound storageos-etcd/storageos-etcd-2 default 99m Filesystem pvc-404de0a0-12f3-4397-83ae-5160133dd4a6 12Gi RWO Delete Bound storageos-etcd/storageos-etcd-4 default 98m Filesystem pvc-62ea2e89-b980-4b28-a1cf-8ac9df522cef 12Gi RWO Delete Bound storageos-etcd/storageos-etcd-3 default 99m Filesystem pvc-6ee17ec9-b845-409f-a00b-cb62f64aaca2 5Gi RWO Delete Bound default/pvc-replicated-centralised-topology storageos 5m8s Filesystem pvc-741604ef-20c0-4219-bdb4-944d1371f684 12Gi RWO Delete Bound storageos-etcd/storageos-etcd-1 default 99m Filesystem pvc-e8564514-dd7a-4f39-8a60-76cee4cb6452 12Gi RWO Delete Bound storageos-etcd/storageos-etcd-0 default 99m Filesystem # Get the volumes in the \u0026#34;default\u0026#34; namespace using the Ondat CLI. kubectl --namespace=storageos exec storageos-cli-79787d586d-fkjnk -- storageos get volumes --namespace=default NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE default pvc-6ee17ec9-b845-409f-a00b-cb62f64aaca2 5.0 GiB aks-storage-78891087-vmss000001 (online) 1/1 7 minutes ago # Describe the \u0026#34;pvc-6ee17ec9-b845-409f-a00b-cb62f64aaca2\u0026#34; volume. kubectl --namespace=storageos exec storageos-cli-79787d586d-fkjnk -- storageos describe volume pvc-6ee17ec9-b845-409f-a00b-cb62f64aaca2 --namespace=default ID ae1e21c1-d5d2-44ef-9057-29185bb7de13 Name pvc-6ee17ec9-b845-409f-a00b-cb62f64aaca2 Description AttachedOn Attachment Type detached NFS Service Endpoint Exports: Namespace default (ebf3984a-cbe1-47ff-8c47-19d3e94cfeb4) Labels csi.storage.k8s.io/pv/name=pvc-6ee17ec9-b845-409f-a00b-cb62f64aaca2, csi.storage.k8s.io/pvc/name=pvc-replicated-centralised-topology, csi.storage.k8s.io/pvc/namespace=default, storageos.com/nocompress=true, storageos.com/replicas=1 Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version Mg Created at 2022-07-27T13:26:35Z (26 minutes ago) Updated at 2022-07-27T13:26:36Z (26 minutes ago) Master: ID b6311c1f-e7e6-4ca6-af16-8a051bf0ae59 Node aks-storage-78891087-vmss000001 (46a4d6a7-71a8-4403-820b-16a8574bb45f) Health online Replicas: ID 8926e63e-952b-4668-8c1d-2d11e475ce1b Node aks-storage-78891087-vmss000000 (a43882ae-647b-42fb-a460-cbdab2df4386) Health ready Promotable true   As demonstrated above, notice how only pvc-replicated-centralised-topology is in a Bound state and its volume name pvc-6ee17ec9-b845-409f-a00b-cb62f64aaca2 has 1 master volume and 1 replica volume which are located on node aks-storage-78891087-vmss000001 and aks-storage-78891087-vmss000000 respectively.\n The volumes have been successfully been provisioned on nodes which do not have the \u0026raquo; storageos.com/computeonly=true node label.  For pvc-replicated-centralised-topology-test, we can see that it is stuck in a Pending state, as the PVC definition - we used the label \u0026raquo; storageos.com/replicas=3 which requests for 1 master volume and 3 replica volumes respectively.\n This would mean that we require at least 4 nodes to provision the Ondat volume and its replicas - which is not possible as only 2 nodes are available to be used as storage nodes whilst the rest of the nodes are reserved for compute intensive tasks.  ","excerpt":"Overview With Ondat, cluster administrators can set the storageos.com/computeonly label against ‚Ä¶","ref":"/docs/operations/compute-only/","title":"How To Setup A Centralised Cluster Topology"},{"body":"Overview Ondat failure modes offer different guarantees with regards to a volume\u0026rsquo;s mode of operation in the face of replica failure.\n If the failure mode is not specified it defaults to hard. Volume failure modes can be dynamically updated at runtime.   üí° For more information on how the replication and failure mode features work, review the Replication feature page.\n Example - Set Failure Mode to soft for a Volume The failure mode for a specific volume can be set using a label on a PVC or it can be set as a parameter on a custom Ondat StorageClass.\n üí° A PVC definition takes precedence over a StorageClass definition.\n Below is an example of a PVC resource that ensures that 2 replica volumes will be available and sets a soft failure mode.\n# Create a \u0026#34;my-vol-1\u0026#34; PVC with 2 volume replicas and \u0026#34;soft\u0026#34; failure mode enabled.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:my-vol-1labels:storageos.com/replicas:\u0026#34;2\u0026#34;# 2 volumes replicas will be available.storageos.com/failure-mode:\u0026#34;soft\u0026#34;# \u0026#34;soft\u0026#34; failure mode is enabled.spec:storageClassName:\u0026#34;storageos\u0026#34;accessModes:- ReadWriteOnceresources:requests:storage:5GiEOFOnce the PVC resource has been successfully created, review and confirm that the storageos.com/failure-mode: \u0026quot;soft\u0026quot; and storageos.com/replicas: \u0026quot;2\u0026quot; labels have been applied.\n# Get the labels applied to the \u0026#34;my-vol-1\u0026#34; PVC. kubectl get pvc --output=wide --show-labels --namespace=default NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS my-vol-1 Bound pvc-9477f989-8a60-4d10-8407-99bad90b29a3 5Gi RWO storageos 63s Filesystem storageos.com/failure-mode=soft,storageos.com/replicas=2 ","excerpt":"Overview Ondat failure modes offer different guarantees with regards to a volume\u0026rsquo;s mode of ‚Ä¶","ref":"/docs/operations/failure-modes/","title":"How To Use Failure Modes"},{"body":"Overview Ondat volumes support TRIM/UNMAP by default for all uncompressed volumes.\n Compression is disabled by default from release version v2.2.0, therefore Ondat volumes will support TRIM/UNMAP calls - unless compression is explicitly enabled. By trimming an Ondat volume, this will release space that has been taken up by deleted blocks in Ondat volume blob files. TRIM can either be called periodically through fstrim or continuously using the -o discard mount option. The recommended discard method to use is periodic discarding.   üí° For more information on TRIM support with Ondat, review the Volumes feature page.\n Example - Using fstrim To Conduct Periodic Discarding In order to TRIM a volume you can run fstrim against the Ondat volume filesystem. The volume filesystem will be presented at the mount point for the Ondat device.\n Below is an example that shows the effect of fstrim on an Ondat volume mounted on /mnt.  # A Ondat volume with some data written to it. ls -ls --block-size 1 /var/lib/storageos/data/dev1/vol.211585.*.blob | awk \u0026#39;!/^total/ {total = total + $1}END{print total}\u0026#39; 8.85838e+09 # A Ondat volume is mounted on \u0026#34;/mnt\u0026#34;. df -h /mnt Filesystem Size Used Avail Use% Mounted on /var/lib/storageos/volumes/v.bbfae475-3ce3-4238-bf33-cfe88256d813 4.9G 520M 4.1G 12% /mnt # Delete a file from the volume, sync all filesystems to ensure data has been written and then \u0026#34;fstrim\u0026#34; the volume filesystem. rm /mnt/test; sync; fstrim /mnt # Check and confirm that the space in the blob files, (and thus space in the backend filesystem) has been reclaimed. ls -ls --block-size 1 /var/lib/storageos/data/dev1/vol.211585.*.blob | awk \u0026#39;!/^total/ {total = total + $1}END{print total}\u0026#39; 469700608 Example - Automate Periodic Discarding with fstrim Discarding unused blocks can be automated by running fstrim against mounted Ondat volumes.\n When running in Kubernetes, the kubelet component is responsible for mounting volumes into pods so the mount endpoints for pods are accessible under /var/lib/kubelet/pods. Ondat volume mounts appear as mounts from /var/lib/storageos/volumes/v.${DEPLOYMENT_ID} on /var/lib/kubelet/pods/${POD_UID}/volumes/kubernetes.io~csi/${PV_ID}/mount.  mount | awk \u0026#39;/storageos\\/volumes\\/v.*/\u0026#39; /var/lib/storageos/volumes/v.4364e143-865e-45d7-a4a5-e0d964d9e200 on /var/lib/kubelet/pods/29ec4774-71d6-4ba3-b275-f80b47e9f6af/volumes/kubernetes.io~csi/pvc-357a9baa-7b74-49db-8d63-c540b5129ad8/mount type ext4 (rw,relatime,stripe=32) /var/lib/storageos/volumes/v.8dc449a4-1fb5-43d8-86d0-e18916a85c18 on /var/lib/kubelet/pods/6bb92a8f-afb5-48c8-837c-56f45e15e5c4/volumes/kubernetes.io~csi/pvc-2d30a2ba-2663-4036-bb1e-e795f226d6f3/mount type ext4 (rw,relatime,stripe=32) mount | awk \u0026#39;/storageos\\/volumes\\/v.*/ {print $3}\u0026#39; /var/lib/kubelet/pods/29ec4774-71d6-4ba3-b275-f80b47e9f6af/volumes/kubernetes.io~csi/pvc-357a9baa-7b74-49db-8d63-c540b5129ad8/mount /var/lib/kubelet/pods/6bb92a8f-afb5-48c8-837c-56f45e15e5c4/volumes/kubernetes.io~csi/pvc-2d30a2ba-2663-4036-bb1e-e795f226d6f3/mount  With this information in mind, it is therefore possible to use Kubernetes to automate periodic discarding with fstrim. The SYS_ADMIN capability is required to run fstrim and propagation of mounts from the host to the container will allow any new Ondat mounts to be picked up by the UNMAP pod. Below is an example that shows how a Kubenetes pod could be used to run fstrim against Ondat volumes mounted on the same node that the pod is scheduled on.  # Create a pod that conducts periodic discarding of unused blocks with `fstrim`.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:Podmetadata:name:discardspec:containers:- name:fstrimcommand:[\u0026#34;/bin/bash\u0026#34;]image:ubuntu:latestargs:[\u0026#34;-c\u0026#34;,\u0026#34;for mount in $(mount | awk \u0026#39;/storageos\\\\/volumes\\\\/v.*/ {print $3}\u0026#39;); do if [ -d ${mount} ]; then fstrim -v ${mount}; fi; sleep 5; done\u0026#34;]securityContext:capabilities:add:- SYS_ADMINvolumeMounts:- mountPath:/var/lib/kubeletmountPropagation:HostToContainername:kubelet-dirvolumes:- hostPath:path:/var/lib/kubelettype:Directoryname:kubelet-dirEOF Alternatively a Kubernetes CronJob on the node itself could be used to fstrim mounted Ondat volumes using similar logic.   ‚ö†Ô∏è Trimming can be an I/O intensive operation so care should be taken when running fstrim against multiple volumes at once.\n Example - Using the -o discard Mount Option To Conduct Continuous Discarding Ondat volumes can be mounted using the -o discard mount option which will automatically send TRIM commands when blocks are removed.\n ‚ö†Ô∏è Caution should be used enabling this option as testing has shown that volumes with a lot of churn can experience performance degradation. The pathological case being a volume that is continuously filled with small files that are then all deleted, repeatedly.\n The discard option can be enabled as a StorageClass or PersistentVolume. Enabling discard as a StorageClass option will result in all volumes provisioned with that StorageClass being mounted with discard, whereas setting the option through a PersistentVolume will set discarding on a per-volume basis.\n Below is an exmaple that uses a custom Ondat StorageClass to provision StorageClass below would provision xfs volumes with the discard option enabled by default.  # Use the discard mount option for all Ondat volumes created with this StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-discardprovisioner:csi.storageos.comallowVolumeExpansion:trueparameters:csi.storage.k8s.io/fstype:ext4csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosmountOptions:- discard # add the \u0026#34;discard\u0026#34; option hereEOF# Review and confirm that \u0026#34;ondat-discard\u0026#34; was created. kubectl get sc | grep \u0026#34;ondat-discard\u0026#34;  To enable discarding for an existing Ondat PersistentVolume, end users can apply the discard option under the spec.mountOptions section.  # Create a \u0026#34;pvc-discard\u0026#34; PVC that uses the default Ondat StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:pvc-discardspec:storageClassName:storageosaccessModes:- ReadWriteOnceresources:requests:storage:5GiEOF# Get more information on \u0026#34;pvc-discard\u0026#34; and its PV name and resource. kubectl get pvc pvc-discard --output=wide --show-labels --namespace=default NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS pvc-discard Bound pvc-c24d5506-53ae-436a-8e07-5ed6cbefa528 5Gi RWO storageos 3m45s Filesystem \u0026lt;none\u0026gt; kubectl get pv | grep \u0026#34;pvc-discard\u0026#34; pvc-c24d5506-53ae-436a-8e07-5ed6cbefa528 5Gi RWO Delete Bound default/pvc-discard storageos 4m3s  Edit pvc-c24d5506-53ae-436a-8e07-5ed6cbefa528 and add the discard mount option to the resource.  # Edit the \u0026#34;pvc-c24d5506-53ae-436a-8e07-5ed6cbefa528\u0026#34; kubectl edit pv pvc-c24d5506-53ae-436a-8e07-5ed6cbefa528 # apply the discard mount option... mountOptions: - discard # save and exit from the editor.  Check and review that the discard option has been successfully applied to the pvc-c24d5506-53ae-436a-8e07-5ed6cbefa528 persistent volume.  kubectl get pv pvc-c24d5506-53ae-436a-8e07-5ed6cbefa528 --output=yaml apiVersion:v1kind:PersistentVolumemetadata:annotations:pv.kubernetes.io/provisioned-by:csi.storageos.comcreationTimestamp:\u0026#34;2022-08-02T16:29:57Z\u0026#34;finalizers:- kubernetes.io/pv-protectionname:pvc-c24d5506-53ae-436a-8e07-5ed6cbefa528resourceVersion:\u0026#34;121296\u0026#34;uid:e8eef812-6091-43b4-aad3-4faa5bfaed29spec:accessModes:- ReadWriteOncecapacity:storage:5GiclaimRef:apiVersion:v1kind:PersistentVolumeClaimname:pvc-discardnamespace:defaultresourceVersion:\u0026#34;119349\u0026#34;uid:c24d5506-53ae-436a-8e07-5ed6cbefa528csi:controllerExpandSecretRef:name:storageos-apinamespace:storageoscontrollerPublishSecretRef:name:storageos-apinamespace:storageosdriver:csi.storageos.comfsType:ext4nodePublishSecretRef:name:storageos-apinamespace:storageosnodeStageSecretRef:name:storageos-apinamespace:storageosvolumeAttributes:csi.storage.k8s.io/pv/name:pvc-c24d5506-53ae-436a-8e07-5ed6cbefa528csi.storage.k8s.io/pvc/name:pvc-discardcsi.storage.k8s.io/pvc/namespace:defaultstorage.kubernetes.io/csiProvisionerIdentity:1659453485570-8081-csi.storageos.comstorageos.com/nocompress:\u0026#34;true\u0026#34;volumeHandle:88ff9cd9-6f29-4d79-b216-8d8c573bdef5/2f85ce13-7383-4f9d-bb0b-dcbc3e195bf3mountOptions:- discardpersistentVolumeReclaimPolicy:DeletestorageClassName:storageosvolumeMode:Filesystemstatus:phase:Bound","excerpt":"Overview Ondat volumes support TRIM/UNMAP by default for all uncompressed volumes.\n Compression is ‚Ä¶","ref":"/docs/operations/trim/","title":"How To Use TRIM with Volumes"},{"body":"Overview  üí° For more information on Ondat\u0026rsquo;s Replication feature, review the Replication feature page.\n Example - Enable Volume Replication Through a PersistentVolumeClaim Definition The following guidance will demonstrate how to use Ondat\u0026rsquo;s Volume Replication through a PersistentVolumeClaim (PVC) definition.\n  The instructions will enable volume replication on a PVC with the label ¬ª storageos.com/replicas=1 - which will create 1 master volume and 1 replica volume respectively.\n üí° Labels can be applied to a PVC directly, or indirectly by adding them as parameters on a StorageClass.\n     Create a custom PersistentVolumeClaim named pvc-replicated and ensure that you add the following label \u0026raquo; storageos.com/replicas=1 to the manifest.\n# Create a \u0026#34;pvc-replicated\u0026#34; PVC that has a replica volume count of 1.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:pvc-replicatedlabels:storageos.com/replicas:\u0026#34;1\u0026#34;# Replica volume count of 1spec:storageClassName:storageosaccessModes:- ReadWriteOnceresources:requests:storage:5GiEOF  Once the PVC resource has been successfully created, review and confirm that the storageos.com/replicas=1, label has been applied.\n# Get the label applied to the \u0026#34;pvc-replicated\u0026#34; PVC. kubectl get pvc pvc-replicated --output=wide --show-labels --namespace=default NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS pvc-replicated Bound pvc-7fed5a56-42b2-4fe3-bcab-e31c97931b8c 5Gi RWO storageos 26s Filesystem storageos.com/replicas=1```   To review and confirm that Ondat has successfully provisioned 1 master volume and 1 replica volume as defined in the PVC manifest earlier - deploy and run the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat through kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the Ondat CLI utility pod name. kubectl --namespace=storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli storageos-cli-77885d6d8b-mgbr8   With the Ondat CLI now deployed, you can check the count and location of the master and replica volumes created for pvc-replicated.\n# Get the volumes in the \u0026#34;default\u0026#34; namespace using the Ondat CLI. kubectl --namespace=storageos exec storageos-cli-77885d6d8b-mgbr8 -- storageos get volumes --namespace=default NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE default pvc-7fed5a56-42b2-4fe3-bcab-e31c97931b8c 5.0 GiB demo-worker-node-1 (online) 1/1 8 minutes ago # Describe the \u0026#34;pvc-7fed5a56-42b2-4fe3-bcab-e31c97931b8c\u0026#34; volume. kubectl --namespace=storageos exec storageos-cli-77885d6d8b-mgbr8 -- storageos describe volume pvc-7fed5a56-42b2-4fe3-bcab-e31c97931b8c --namespace=default ID 495eb6a5-28de-4593-b6bc-d91094b52326 Name pvc-7fed5a56-42b2-4fe3-bcab-e31c97931b8c Description AttachedOn Attachment Type detached NFS Service Endpoint Exports: Namespace default (b4c020a6-6c54-40cd-a502-9ea4f4b68a9c) Labels csi.storage.k8s.io/pv/name=pvc-7fed5a56-42b2-4fe3-bcab-e31c97931b8c, csi.storage.k8s.io/pvc/name=pvc-replicated, csi.storage.k8s.io/pvc/namespace=default, storageos.com/nocompress=true, storageos.com/replicas=1 Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version Mg Created at 2022-07-25T16:47:51Z (10 minutes ago) Updated at 2022-07-25T16:47:53Z (10 minutes ago) Master: ID 24a56198-1648-46af-ac25-71d02ecba31c Node demo-worker-node-1 (d7a745ff-242a-48f4-a6bf-4f191c14a237) Health online Replicas: ID b7f565c6-860b-4458-aeb2-c2f623da77af Node demo-worker-node-4 (cad83b41-89b7-4520-9b82-632f31d94814) Health ready Promotable true  üí° As demonstrated in the output above, notice the number of master replica volumes created and which node they are located on. If we created a volume without a replica count defined in Step 1 - only the master volume would be provisioned.\n   Example - Enable Volume Replication Through a StorageClass Definition The following guidance will demonstrate how to use Ondat\u0026rsquo;s Volume Replication through a StorageClass (PVC) definition.\n  The instructions will enable volume replication through a custom StorageClass and use the following parameter ¬ª storageos.com/replicas=2 - which will create 1 master volume and 2 replica volumes respectively.\n üí° Labels can be applied to a PVC directly, or indirectly by adding them as parameters on a StorageClass.\n     Create a custom StorageClass, named ondat-replicated and check that it has been successfully created.\n# Create the \u0026#34;ondat-replicated\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:ondat-replicatedprovisioner:csi.storageos.comallowVolumeExpansion:trueparameters:storageos.com/replicas:\u0026#34;2\u0026#34;csi.storage.k8s.io/fstype:ext4csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosEOF# Review and confirm that \u0026#34;ondat-replicated\u0026#34; was created. kubectl get sc | grep \u0026#34;ondat-replicated\u0026#34;   Create a PersistentVolumeClaim that will use ondat-replicated as its StorageClass and confirm that it was successfully created.\n# Create a \u0026#34;pvc-replicated-2\u0026#34; PVC that uses the \u0026#34;ondat-replicated\u0026#34; StorageClass.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:v1kind:PersistentVolumeClaimmetadata:name:pvc-replicated-2spec:storageClassName:ondat-replicated # Use the \u0026#34;ondat-replicated\u0026#34; StoragClass created in Step 1accessModes:- ReadWriteOnceresources:requests:storage:5GiEOF# Ensure that the PVC was successfully provisioned with \u0026#34;ondat-replicated\u0026#34;. kubectl get pvc pvc-replicated-2 --output=wide --show-labels --namespace=default NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS pvc-replicated-2 Bound pvc-c5f4e448-e78e-4ece-ad24-f65c3e04d646 5Gi RWO ondat-replicated 57s Filesystem \u0026lt;none\u0026gt;  üí° Notice that the output above shows that the PVC does not have any labels applied to it - this is because we are using the ondat-replicated StorageClass parameters defined in Step 1.\n   To review and confirm that Ondat has successfully provisioned 1 master volume and 2 replica volume as defined in the StorageClass manifest earlier - deploy and run the Ondat CLI utility as a deployment first, so that you can interact and manage Ondat through kubectl. Once deployed, obtain the Ondat CLI utility pod name for later reference.\n# Get the Ondat CLI utility pod name. kubectl --namespace=storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli storageos-cli-77885d6d8b-mgbr8   With the Ondat CLI now deployed, you can check the count and location of the master and replica volumes created for pvc-replicated-2.\n# Get the volumes in the \u0026#34;default\u0026#34; namespace using the Ondat CLI. kubectl --namespace=storageos exec storageos-cli-77885d6d8b-mgbr8 -- storageos get volumes --namespace=default NAMESPACE NAME SIZE LOCATION ATTACHED ON REPLICAS AGE default pvc-7fed5a56-42b2-4fe3-bcab-e31c97931b8c 5.0 GiB demo-worker-node-1 (online) 1/1 29 minutes ago default pvc-c5f4e448-e78e-4ece-ad24-f65c3e04d646 5.0 GiB demo-worker-node-3 (online) 2/2 4 minutes ago # Describe the \u0026#34;pvc-c5f4e448-e78e-4ece-ad24-f65c3e04d646\u0026#34; volume. kubectl --namespace=storageos exec storageos-cli-77885d6d8b-mgbr8 -- storageos describe volume pvc-c5f4e448-e78e-4ece-ad24-f65c3e04d646 --namespace=default ID 52904e9e-624a-4d56-a7bd-5d353d8701a2 Name pvc-c5f4e448-e78e-4ece-ad24-f65c3e04d646 Description AttachedOn Attachment Type detached NFS Service Endpoint Exports: Namespace default (b4c020a6-6c54-40cd-a502-9ea4f4b68a9c) Labels csi.storage.k8s.io/pv/name=pvc-c5f4e448-e78e-4ece-ad24-f65c3e04d646, csi.storage.k8s.io/pvc/name=pvc-replicated-2, csi.storage.k8s.io/pvc/namespace=default, storageos.com/nocompress=true, storageos.com/replicas=2 Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version Mg Created at 2022-07-25T17:12:32Z (5 minutes ago) Updated at 2022-07-25T17:12:33Z (5 minutes ago) Master: ID e6ba1c26-ba35-4f2f-b3cb-606c259191b5 Node demo-worker-node-3 (1b78adea-6301-4155-95a4-8fab26cc1038) Health online Replicas: ID 6f4a9655-841b-4313-b548-32bdbcd50ea6 Node demo-worker-node-2 (3957692d-dee2-4a4e-9ddc-845b7b0a1fbe) Health ready Promotable true ID b6dd25ab-e338-4555-9c67-aa35dc93ad28 Node demo-worker-node-1 (d7a745ff-242a-48f4-a6bf-4f191c14a237) Health ready Promotable true  üí° As demonstrated in the output above, notice the number of master replica volumes created and which node they are located on. If we created a volume without a replica count defined in Step 1 - only the master volume would be provisioned.\n   ","excerpt":"Overview  üí° For more information on Ondat\u0026rsquo;s Replication feature, review the Replication ‚Ä¶","ref":"/docs/operations/replication/","title":"How To Use Volume Replication"},{"body":"InfluxDB is a popular open source time series database application optimised for managing datasets consisting of many small measurements. Its advantages include the ability to handle very high write and query loads. Its uses include monitoring, analytics and the recording and analysis of data from sensors.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nDeploying InfluxDB on Kubernetes   You can find the latest files in the Ondat use cases repository\ngit clone https://github.com/storageos/use-cases.git storageos-usecases cd storageos-usecases StatefulSet definition:\napiVersion:apps/v1kind:StatefulSetmetadata:name:influxdbspec:replicas:1selector:matchLabels:app:influxdbserviceName:influxdb...spec:serviceAccountName:influxdb...volumeMounts:- mountPath:/var/lib/influxdbname:data...volumeClaimTemplates:- metadata:name:dataspec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:\u0026#34;storageos\u0026#34;# Ondat storageClassresources:requests:storage:20GiThis excerpt is from the StatefulSet definition. This file contains the VolumeClaimTemplate that will dynamically provision storage, using the Ondat storage class. Dynamic provisioning occurs as a volumeMount has been declared with the same name as a VolumeClaim.\n  Create the InfluxDB objects\nkubectl create -f ./influxdb   Confirm InfluxDB is up and running.\n$ kubectl get pods NAME READY STATUS RESTARTS AGE influxdb-client 1/1 Running 0 1m influxdb-0 1/1 Running 0 1m   Connect to the InfluxDB client pod, then to the InfluxDB server through the service (this reflects the common kubernetes pattern of maintaining a client pod to conveniently inspect a resource interactively). The default user (admin) and password (admin) are defined in the StatefulSet.\n$ kubectl exec -it influxdb-client -- bash root@influxdb-client:/# influx -host influxdb-0.influxdb Connected to http://influxdb-0.influxdb:8086 version 1.8.2 InfluxDB shell version: 1.8.2 \u0026gt; auth username: admin password: \u0026gt; show databases name: databases name _internal \u0026gt; CREATE DATABASE weather; \u0026gt; USE weather Using database weather \u0026gt; INSERT temperature,location=London value=26.4 \u0026gt; INSERT temperature,location=London value=24.9 \u0026gt; INSERT temperature,location=London value=22.2 \u0026gt; INSERT temperature,location=London value=14.7 \u0026gt; INSERT temperature,location=London value=19.5 \u0026gt; INSERT temperature,location=Paris value=27.1 \u0026gt; INSERT temperature,location=Paris value=27.5 \u0026gt; INSERT temperature,location=Paris value=21.3 \u0026gt; INSERT temperature,location=Paris value=26.7 \u0026gt; INSERT temperature,location=Paris value=30.0 \u0026gt; SELECT MEAN(*) FROM \u0026#34;temperature\u0026#34; GROUP BY \u0026#34;location\u0026#34; name: temperature tags: location=London time mean_value 0 25.65 name: temperature tags: location=Paris time mean_value 0 26.90   In the above steps we have inserted some time series data on the temperature at two locations, and calculated the mean for both. InfluxDB offers a variety of such aggregations (see the docs here), allowing convenient analysis of time series data.\nConfiguration If you need custom startup options, you can edit or add to the environment variables within the 20-statefulset.yaml file.\nBackups In this example of how to perform backups of an InfluxDB database on a Kubernetes cluster, we write the output backup file to an Amazon Web Services (AWS) S3 bucket. Other approaches, such as backing up to internal servers or other Ondat volumes, are possible. For this example to run successfully, base64-encoded AWS credentials and an S3 bucket name should be inserted into the data field of the backup/50-secret-config.yaml file.\n$ echo -n \u0026#39;\u0026lt;your-aws-access-key-id\u0026gt;\u0026#39; | base64 XXXXXXXXXXXX $ echo -n \u0026#39;\u0026lt;your-aws-secret-access-key\u0026gt;\u0026#39; | base64 XXXXXXXXXXXX $ echo -n \u0026#39;\u0026lt;your-aws-default-region\u0026gt;\u0026#39; | base64 XXXXXXXXXXXX $ echo -n \u0026#39;\u0026lt;your-S3-bucket-name\u0026gt;\u0026#39; | base64 XXXXXXXXXXXX Secret definition:\napiVersion:v1kind:Secretmetadata:name:backup-pod-environmenttype:Opaquedata:AWS_ACCESS_KEY_ID:XXXXXXXXXXXXAWS_SECRET_ACCESS_KEY:XXXXXXXXXXXXAWS_DEFAULT_REGION:XXXXXXXXXXXXBUCKET_NAME:XXXXXXXXXXXXDB_NAME:d2VhdGhlcg==DB_HOST:aW5mbHV4ZGItMC5pbmZsdXhkYjo4MDg4To perform the backup, create the secret and job from the manifest files in the backup directory.\nkubectl create -f ./influxdb/backup/ Confirm that the backup pod has been created, and the backup performed successfully.\nNAME READY STATUS RESTARTS AGE backup-ks976 0/1 Completed 0 1m client 1/1 Running 0 10m influxdb-0 1/1 Running 0 10m mysql-0 1/1 Running 0 10m The files generated by the backup operation should now be available in you S3 bucket. Re-perform the operation at any time by deleting and re-creating the backup job.\n$ kubectl delete -f \u0026#34;influxdb/40-backup-job.yaml\u0026#34; job.batch \u0026#34;backup\u0026#34; deleted $ kubectl create -f \u0026#34;influxdb/40-backup-job.yaml\u0026#34; job.batch/backup created ","excerpt":"InfluxDB is a popular open source time series database application optimised for managing datasets ‚Ä¶","ref":"/docs/usecases/influxdb/","title":"InfluxDB"},{"body":"Ondat has requirements for the configuration of host systems. As such, Ondat starts an init container that sets the system configuration for Ondat. The container also manages configuration changes required when upgrading Ondat versions.\nThe container belongs to the DaemonSet that the Ondat Cluster Operator starts when a StorageOSCluster resource is created. The storageos-init container is executed as an initContainer as part of a Kubernetes Pod. Therefore, only successful execution of the storageos-init container processes will result in the main container starting.\nScript Framework The code responsible for fulfilling the requirements is based on a Script Framework.\nThe script framework executes a set of scripts, performing checks, verifications and other procedures needed for Ondat to be able to start. The scripts stdout and stderr are written to the stdout and stderr of the init app. The container logs contain all the logs of the individual scripts that run. The exit statuses of the scripts are used to determine initialization failure or success. Any non-zero exit status is logged as an event in the Kubernetes Pod events.\nIf any of the scripts fail, the storageos-init container will propagate the failure to Kubernetes, showing the status of the Pod as Init:Err.\nTo view the output of all storageos-init containers the following command can be used:\nkubectl -n storageos logs -l app=storageos,kind=daemonset -c storageos-init For more details, check the Ondat init container project.\nScripts executed The storageos-init container executes the following scripts.\n enable-lio set-limits  ","excerpt":"Ondat has requirements for the configuration of host systems. As such, Ondat starts an init ‚Ä¶","ref":"/docs/reference/init-container/","title":"Init container"},{"body":"This example shows an example of how to deploy Jenkins on Kubernetes with a Ondat persistent volume being mounted on /var/jenkins_home. Deploying Jenkins using Ondat offers multiple benefits. Firstly Jenkins can spin up multiple build pods at once to allow concurrent builds of different projects. Secondly Jenkins configuration is on a PersistentVolume so even if the Jenkins pod is rescheduled the configuration will persist.\nUsing Ondat volume replicas allows for failure of nodes holding the PersistentVolume without interrupting Jenkins. Lastly by enabling Ondat fencing Jenkins time to recover, in case of node failures, is greatly reduced.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information\nDeploying Jenkins on Kubernetes   You can find the latest files in the Ondat example deployment repository.\ngit clone https://github.com/storageos/use-cases.git storageos-usecases cd storageos-usecases kubectl create -f ./jenkins   Confirm that Jenkins is up and running\n$ kubectl get pods -w -l app=jenkins NAME READY STATUS RESTARTS AGE jenkins-0 1/1 Running 0 1m   Connect to the Jenkins UI through the Jenkins service.\nYou can do this by port forwarding the Jenkins Kubernetes service to your localhost and accessing the UI via your browser. Alternatively if you have network access to your Kubernetes nodes then you can create a NodePort service and access Jenkins like that. A NodePort service has been left in 10-service.yaml commented out.\nTo port-foward the Jenkins service use the following command.\nkubectl port-foward svc/jenkins 8080 To login to the Jenkins UI use the credentials specified in 07-config.yaml, unless these have been changed from the defaults the username/password is admin/password.\n  Create a Jenkins job.\nOnce you are logged into the UI you can create a job that will be farmed out to a Kubernetes plugin build agent. Click New Item, enter a name for the project and select Freestyle project. Next add an Execute shell build step. As a proof of concept you can use the bash below to have the pod execute a sleep.\n#!/bin/bash sleep 1000 Save the project and select Schedule a build of your project. You can watch for the appearance of a build pod using kubectl get pods -l jenkins=agent -w. Once the pod is created you should see the Build Executor status in the Jenkins UI display the pod.\nTo see multiple projects being built at once create another project and try scheduling a build of both projects at the same time.\n  ","excerpt":"This example shows an example of how to deploy Jenkins on Kubernetes with a Ondat persistent volume ‚Ä¶","ref":"/docs/usecases/jenkins/","title":"Jenkins"},{"body":"Kafka is a popular stream processing platform combining features from pub/sub and traditional queues.\nUsing Ondat persistent volumes with Apache Kafka means that if a pod fails, the cluster is only in a degraded state for as long as it takes Kubernetes to restart the pod. When the pod comes back up, the pod data is immediately available. Should Kubernetes schedule the kafka pod on a new node, Ondat allows for the data to be available to the pod, irrespective of whether or not the original Ondat master volume is located on the same node.\nKafka has features to allow it to handle replication, and as such careful consideration of whether to allow Ondat or Kafka to handle replication is required.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nPrerequisites  Apache Zookeeper is required by Kafka to function; we assume it to already exist and be accessible within the Kubernetes cluster as zookeeper, see how to run Zookeeper with Ondat here Ondat is assumed to have been installed; check for the latest available version here Kafka pods require 1536 MB of memory for successful scheduling  Helm To simplify the deployment of kafka, we\u0026rsquo;ve used this Kafka helm chart (incubator) (version 0.13.8, app version 5.0.1) and rendered it into the example deployment files you can find in our GitHub repository.\nClone the use cases repository You can find the latest files in the Ondat use cases repository in /kafka/\ngit clone https://github.com/storageos/use-cases.git storageos-usecases cd storageos-usecases StatefulSet definition\n---apiVersion:apps/v1beta1kind:StatefulSetmetadata:name:kafkalabels:app:kafka...spec:serviceName:kafka-headlesspodManagementPolicy:OrderedReadyupdateStrategy:type:OnDeletereplicas:3# \u0026lt;--- number of kafa pods to runtemplate:...spec:serviceAccountName:kafkacontainers:...- name:kafka-brokerimage:\u0026#34;confluentinc/cp-kafka:5.0.1\u0026#34;imagePullPolicy:\u0026#34;IfNotPresent\u0026#34;...volumeMounts:- name:datadirmountPath:\u0026#34;/var/data\u0026#34;volumes:- name:jmx-configconfigMap:name:kafka-metricsterminationGracePeriodSeconds:60volumeClaimTemplates:- metadata:name:datadirspec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]resources:requests:storage:10Gi # \u0026lt;--- storage requested for each podstorageClassName:\u0026#34;storageos\u0026#34;# \u0026lt;--- the StorageClass to useThis excerpt is from the StatefulSet definition (10-statefulset.yaml). The file contains the PersistentVolumeClaim template that will dynamically provision the necessary storage, using the Ondat storage class.\nDynamic provisioning occurs as a volumeMount has been declared with the same name as a VolumeClaimTemplate.\n  Create the kubernetes objects\nkubectl apply -f ./kafka/   Confirm kafka is up and running\n$ kubectl get pods -l app=kafka NAME READY STATUS RESTARTS AGE kafka-0 2/2 Running 0 10m kafka-1 2/2 Running 0 9m26s kafka-2 2/2 Running 0 7m59s   Connect to kafka\nConnect to the kafka test client pod and send some test data to kafka through its service endpoint\n  Connect to the pod\nkubectl exec -it kafka-test-client /bin/bash   Create a topic\n/usr/bin/kafka-topics --zookeeper zookeeper:2181 --create --topic test-rep-one --partitions 6 --replication-factor 1   Send some test data\n/usr/bin/kafka-run-class org.apache.kafka.tools.ProducerPerformance --topic test-rep-one --num-records 5000 --record-size 100 --throughput -1 --print-metrics --producer-props acks=1 bootstrap.servers=kafka:9092 buffer.memory=67108864 batch.size=8196   ","excerpt":"Kafka is a popular stream processing platform combining features from pub/sub and traditional ‚Ä¶","ref":"/docs/usecases/kafka/","title":"Kafka"},{"body":"The below controllers are part of the Ondat API manager, and handle a variety of cases where information about Kubernetes objects from your cluster needs to be synced to your Ondat cluster.\nThe CSI Driver annotation mentioned below is added to your PVC or Node automatically by Ondat and is not removed. It is set by default in the case of a PVC StorageClass or PVC\u0026rsquo;s StorageClassName parameter, or in the case of a node, by the node driver registrar.\nPVC Label Sync The PVC Label Sync Controller applies labels that have been added to your PVCs to your Ondat Volume objects. The PVC must have the Ondat CSI Driver annotation. If there is a label with the same key on the PVC and on the StorageClass the PVC label will take precedence.\nOndat dynamically provisions Ondat Volumes when you create a PVC object. Labels are initially applied to your Ondat Volume object when it is created. These come from the labels specified in the PVC manifest as well as any default labels specified in the StorageClass.\nThis controller is triggered on any subsequent PVC label update event, so long as the CSI Driver annotation is present.\nIf a label sync fails the change will be requeued and retried. A periodic resync runs every hour (this is configurable via -pvc-label-resync-interval flag for the API Manager).\nNode Label Sync The Node Label Sync controller ensures that labels applied to your Kubernetes nodes are synced through to Ondat. It is necessary for your Node to have the Ondat CSI Driver annotation.\nWhen labels are applied to your Kubernetes nodes, they do not automatically sync to Ondat, hence this controller is required to automatically apply the expected behaviour to your Ondat cluster.\nIt is triggered on any Kubernetes label update event, so long as the CSI Drive annotation is present.\nIf a label sync fails the change will be requeued and retried. A periodic resync runs every hour (this is configurable via -node-label-resync-interval flag for the API Manager).\nNode Delete The Node Delete Controller syncs deletions from your Kubernetes cluster to Ondat.\nThis controller dynamically removes nodes from your Ondat cluster, being triggered when the Kubernetes node is removed.\nWhenever a node delete event occurs the Node Delete Controller will trigger if the node has the Ondat CSI driver annotation.\nIf the node holds an Ondat Volume without a replica then it cannot be deleted by this controller. The Volume must be deleted first and then the node. This is to prevent data loss by accidental deletion of a master volume.\nA periodic garbage collection runs every hour (this is configurable via -node-delete-gc-interval flag for the API Manager.\nNamespace Delete The Namespace Delete Controller is responsible for removing Ondat namespaces from the Ondat cluster when the corresponding Kubernetes namespace has been removed from Kubernetes.\nThe Ondat controlplane automatically creates a new Ondat namespace when a PVC is created in a Kubernetes namespace. Ondat does not automatically remove namespaces when there are no volumes in them. Instead this controller triggers on any Kubernetes namespace deletion event, syncing Kubernetes namespace deletion to Ondat namespace deletion.\nA periodic garbage collection runs every hour (this is configurable via -namespace-delete-gc-interval flag for the API Manager.\n","excerpt":"The below controllers are part of the Ondat API manager, and handle a variety of cases where ‚Ä¶","ref":"/docs/reference/kubernetes-object-sync/","title":"Kubernetes Object Sync"},{"body":"Kubevirt is a CNCF sandbox project that allows the running of virtual machines (VMs) in Kubernetes pods.\nDeploying Kubevirt using Ondat offers multiple benefits. Kubevirt can spin up VMs as Kubernetes pods, using images on Ondat persistent volumes. Doing this allows the VM data to persist through restarts and rescheduling. Using Ondat volume replicas also allows for failure of nodes holding the PersistentVolume without interrupting the VM running off the PersistentVolume. Containerized Data Importer (CDI) can also be used to prepare Ondat volumes with disk images in an automated fashion. Simply by declaring that a VirtualMachine will use a DataVolume and providing the disk image URL, an Ondat volume can be dynamically provisioned and automatically prepared with the disk image.\nThis usecase will guide you through installing KubeVirt and CDI on your Kubernetes cluster, and create a VM. By the end of the guide you\u0026rsquo;ll be able to launch a shell inside the KubeVirt VM that\u0026rsquo;s running as a Kubernetes pod.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nPrerequisites Ensure you have met the Kubevirt prerequisites, see the Kubevirt installation instructions  for more information.\nAs part of this installation it is assumed that you are running a Kubernetes cluster on VMs. As such nested virtualization or hardware emulation need to be enabled.\nDeploying KubeVirt on Kubernetes  üí° For ease of installation we have enabled hardware emulation. If your VMs support nested virtualization then edit the Kubevirt ConfigMap ./kubevirt-install/10-cm.yaml, removing the line debug.useEmulation: \u0026quot;true\u0026quot;.\n   In order to deploy Kubevirt you just need to clone this repository and use kubectl to create the Kubernetes objects.\ngit clone https://github.com/storageos/use-cases.git storageos-usecases cd storageos-usecases/kubevirt kubectl create -f ./kubevirt-install   Check that the Kubevirt pods are running.\n$ kubectl get pods -w -n kubevirt NAME READY STATUS RESTARTS AGE virt-api-57546d479b-p26d4 1/1 Running 0 1m virt-api-57546d479b-zs5dw 1/1 Running 0 1m virt-controller-56b5498854-7xsfz 1/1 Running 1 1m virt-controller-56b5498854-bz559 1/1 Running 1 1m virt-handler-6z4kq 1/1 Running 0 1m virt-handler-7szhl 1/1 Running 0 1m virt-handler-jmm6w 1/1 Running 0 1m virt-operator-79c9bdd859-8xq98 1/1 Running 0 1m virt-operator-79c9bdd859-kfjz6 1/1 Running 0 1m   Once Kubevirt is running install CDI.\nkubectl create -f ./cdi   Check that the CDI pods are running correctly.\n$ kubectl get pods -n cdi NAME READY STATUS RESTARTS AGE cdi-apiserver-8668f888df-s6pp4 1/1 Running 0 1m cdi-deployment-5cf794896b-whh4j 1/1 Running 0 1m cdi-operator-5887f96c-dz2hg 1/1 Running 0 1m cdi-uploadproxy-97fbbfcbf-6f9xs 1/1 Running 0 1m   Now that CDI and Kubevirt are running, VMs can be created. In this example VMs running Cirros, a small and lightweight OS, will be created. The vm-cirros.yaml manifest creates a VirtualMachine that uses a DataVolume. This means that CDI will create a Ondat backed PVC and download the image that the VirtualMachineInstance (VMI) will boot from onto the PVC.\nkubectl create -f ./vm-cirros.yaml   Check that the VMI is running. Note that the VMI will only be created after CDI has downloaded the Cirros disk image onto an Ondat persistent volume so depending on your connection speed this may take some time.\n$ kubectl get vmi NAME AGE PHASE IP NODENAME cirros 1m Running 10.244.2.12 ip-10-1-10-154.storageos.net $ kubectl get pods NAME READY STATUS RESTARTS AGE virt-launcher-cirros-drqhr 1/1 Running 0 1m   Connect to the VM console.\nThis example uses the virtctl kubectl plugin in order to connect to the VMs console. The escape sequence ^] is ctrl + ]\n$ kubectl virt console cirros Successfully connected to cirros console. The escape sequence is ^] login as \u0026#39;cirros\u0026#39; user. default password: \u0026#39;gocubsgo\u0026#39;. use \u0026#39;sudo\u0026#39; for root. cirros login: cirros Password: $   Cloning Volumes CDI allows for images to be cloned using a DataVolume manifest. Verify that the cirros pvc, created as part of the vm-cirros.yaml file, exists before attempting to clone the volume.\n ‚ö†Ô∏è Ensure that the VMI is stopped before continuing!\n   Verify that the VMI is stopped before continuing, and that the cirros pvc, created as part of the vm-cirros.yaml file, exists before attempting to clone the volume.\n$ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE cirros Bound pvc-f4833060-5a77-420c-927e-6bc518d9df3c 12Gi RWO storageos 1m   Once the PVC\u0026rsquo;s existence is confirmed then create a new DataVolume that uses the cirros PVC as its source.\nkubectl create -f ./cloned.yaml   Watch as the CDI pods are created.\nkubectl get pods -w You\u0026rsquo;ll see that a cdi-upload-cloned-datavolume pod is created and then a cdi-clone-source pod is created. The cdi-source pod mounts the original cirros volume and sends the contents of the volume to the cdi-upload pod. The cdi-upload pod creates and mounts a new PVC and writes the contents of the original volume to it.\n  ","excerpt":"Kubevirt is a CNCF sandbox project that allows the running of virtual machines (VMs) in Kubernetes ‚Ä¶","ref":"/docs/usecases/kubevirt/","title":"Kubevirt"},{"body":"For more information regarding the Ondat Label Sync feature, see our Kubernetes Object Sync reference page.\nLabel Syncing The Ondat API Manager handles cases where information from objects in your Kubernetes Cluster needs to be synced to your Ondat cluster.\nLabel Syncing on PVCs The below guide shows how to apply a label to your PVCs, and how these labels sync through to your Ondat Volumes. This operation is used often - for example it is used here to add replicas to an Ondat Volume.\n  Create a PVC, following the instructions here. When you create a PVC, Ondat automatically provisions an Ondat volume for it. An example PVC and Ondat volume can be seen below. Note the labels app=mysql and env=prod under Labelsin the PVC description and the VolumeAttributesof the Ondat Volume.\n$ kubectl describe pvc/data-mysql-0 Name: data-mysql-0 Namespace: default StorageClass: storageos Status: Bound Volume: pvc-2e6339f0-96f9-4098-a388-149fd0daa14f Labels: app=mysql env=prod Annotations: pv.kubernetes.io/bind-completed: yes pv.kubernetes.io/bound-by-controller: yes storageos.com/storageclass: 572794ab-2d02-4fec-9aaf-43cd725f498e volume.beta.kubernetes.io/storage-provisioner: csi.storageos.com ... $ storageos describe volume pvc-2e6339f0-96f9-4098-a388-149fd0daa14f -oyaml id: 286fd3a6-c8f8-480a-b5e1-d16896db0c72 name: pvc-2e6339f0-96f9-4098-a388-149fd0daa14f ... labels: app: mysql csi.storage.k8s.io/pv/name: pvc-2e6339f0-96f9-4098-a388-149fd0daa14f csi.storage.k8s.io/pvc/name: data-mysql-0 csi.storage.k8s.io/pvc/namespace: default env: prod storageos.com/nocompress: \u0026quot;true\u0026quot; storageos.com/replicas: \u0026quot;0\u0026quot; ...   Now, apply a label to the PVC.\nkubectl label pvc data-mysql-0 storageos.com/replicas=3   By using the Ondat CLI, you can verify that the label applied has been synced through to our Ondat volume and the replicas are all present.\n$ storageos describe volume pvc-2e6339f0-96f9-4098-a388-149fd0daa14f -oyaml id: 286fd3a6-c8f8-480a-b5e1-d16896db0c72 name: pvc-2e6339f0-96f9-4098-a388-149fd0daa14f description: \u0026quot;\u0026quot; attachedOn: 72b50fa0-d870-4d57-95fc-980cc41ab951 attachedOnName: worker5 attachmentType: host nfs: exports: [] serviceendpoint: \u0026quot;\u0026quot; namespaceID: d4eb1a29-39e1-477f-b57c-1c264b797575 namespaceName: default labels: app: mysql csi.storage.k8s.io/pv/name: pvc-2e6339f0-96f9-4098-a388-149fd0daa14f csi.storage.k8s.io/pvc/name: data-mysql-0 csi.storage.k8s.io/pvc/namespace: default env: prod storageos.com/nocompress: \u0026quot;true\u0026quot; storageos.com/replicas: \u0026quot;3\u0026quot; filesystem: ext4 sizeBytes: 5368709120 master: id: 836d8bbc-d356-4ad1-89d2-b1da7f6a4e47 nodeID: 72b50fa0-d870-4d57-95fc-980cc41ab951 nodeName: worker5 health: online promotable: true replicas: - id: 46d9ef46-7572-4b23-80c9-097b77c4f7a0 nodeID: b812eb26-f59e-4867-824f-152acfa70968 nodeName: worker4 health: ready promotable: true - id: 7876164b-b2f0-4148-9688-6b154dfa073a nodeID: 52a98f1a-4d33-41e6-891a-6931052c4ba3 nodeName: worker1 health: ready promotable: true - id: 3987e698-68c9-4e8b-adee-16d0f424a106 nodeID: d2b8ca25-4ffb-43ae-90cc-e1bc68be12ee nodeName: worker6 health: ready promotable: true createdAt: 2021-05-06T14:57:58Z updatedAt: 2021-05-06T16:47:26Z version: Mzg   Label Syncing on Nodes Some Ondat functionality is set by labeling nodes - for example setting a node to \u0026ldquo;compute-only\u0026rdquo; mode, as demonstrated here.\n  Note labels on the node that will be labeled and on the Ondat node corresponding to that Kubernetes node.\n$ kubectl describe node worker1 Name: worker1 Roles: worker Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux cattle.io/creator=norman kubernetes.io/arch=amd64 kubernetes.io/hostname=worker1 kubernetes.io/os=linux node-role.kubernetes.io/worker=true Annotations: csi.volume.kubernetes.io/nodeid: {\u0026quot;csi.storageos.com\u0026quot;:\u0026quot;52a98f1a-4d33-41e6-891a-6931052c4ba3\u0026quot;} flannel.alpha.coreos.com/backend-data: {\u0026quot;VtepMAC\u0026quot;:\u0026quot;06:7b:af:b9:a5:2b\u0026quot;} flannel.alpha.coreos.com/backend-type: vxlan flannel.alpha.coreos.com/kube-subnet-manager: true flannel.alpha.coreos.com/public-ip: 212.71.244.105 node.alpha.kubernetes.io/ttl: 0 projectcalico.org/IPv4IPIPTunnelAddr: 10.42.2.1 rke.cattle.io/external-ip: 212.71.244.105 rke.cattle.io/internal-ip: 192.168.152.238 volumes.kubernetes.io/controller-managed-attach-detach: true CreationTimestamp: Thu, 06 May 2021 13:28:30 +0100 ... $ kubectl describe -n storageos pod storageos-daemonset-6q4g8 Name: storageos-daemonset-6q4g8 Namespace: storageos Priority: 2000001000 Priority Class Name: system-node-critical Node: worker1/192.168.152.238 Start Time: Thu, 06 May 2021 15:53:34 +0100 Labels: app=storageos app.kubernetes.io/component=storageos-daemonset app.kubernetes.io/instance=example-ondat app.kubernetes.io/managed-by=storageos-operator app.kubernetes.io/name=storageos app.kubernetes.io/part-of=storageos controller-revision-hash=f5dcf577d kind=daemonset pod-template-generation=1 storageos_cr=example-ondat Annotations: kubectl.kubernetes.io/default-logs-container: storageos Status: Running IP: 192.168.152.238 IPs: IP: 192.168.152.238   Now, apply the label to the node.\nkubectl label node worker1 storageos.com/computeonly=true   The label has synced to the node and it has been set to compute-only mode.\n$ storageos describe node worker1 ID 52a98f1a-4d33-41e6-891a-6931052c4ba3 Name worker1 Health online Addresses: Data Transfer address 192.168.152.238:5703 Gossip address 192.168.152.238:5711 Supervisor address 192.168.152.238:5704 Clustering address 192.168.152.238:5710 Labels beta.kubernetes.io/arch=amd64, beta.kubernetes.io/os=linux, cattle.io/creator=norman, kubernetes.io/arch=amd64, kubernetes.io/hostname=worker1, kubernetes.io/os=linux, node-role.kubernetes.io/worker=true, storageos.com/computeonly=true   ","excerpt":"For more information regarding the Ondat Label Sync feature, see our Kubernetes Object Sync ‚Ä¶","ref":"/docs/operations/label-stos-objects/","title":"Labeling Ondat Objects"},{"body":"Overview This document will walk you through how to request an Ondat license for your cluster, and what types of licenses can be requested.\nYou will need a license for Ondat if you want to make use of the full functionalities of our product. The cluster will run unlicensed for 24 hours, but after this time period, any new operations will be blocked. You can unlock the normal functioning of the cluster by applying a valid license to the cluster.\nTypes of Licenses Community Edition You can use Ondat with many features, including RWX volume support, for free without any time limit with a 1 TB usable capacity and up to 3 nodes.\nEnterprise Premium You can obtain a tailor-made licence suitable for your needs with commercial support and a higher storage limit. For more information, contact hello@ondat.io or message us via Intercom.\nYou can also book a demo with our customer success team here.\nObtaining a License Procedure Step 1 - Register on the Ondat SaaS Platform You need to register yourself on the Ondat SaaS Platform in order to retrieve your license.\nStep 2 - Generate a License  Note: For airgapped use case: If you don\u0026rsquo;t have a cluster connected to the portal you can generate a licence just by using the clusterId. To obtain your clusterId, follow the steps here\n  Go to the ‚ÄúOrganization‚Äù tab on the menu bar Click on ‚ÄúGenerate a New License‚Äù Choose the cluster you want to add a license to. You can add your airgapped clusterId on this step. Choose the type of license you want the cluster to use Click generate  For Ondat 2.8.0 or above: Your cluster would be licensed automatically with your chosen licence type. No further action needed.\nStep 3 - For Ondat 2.7.0 or below: Add license to the cluster  Copy the command displayed on your screen and run the CLI command on your machine Congratulations, you have successfully applied the license to your cluster!  Further Reading: Manage Your License in CLI Running the Ondat CLI Step 1 - Launch target Kubernetes Cluster  In order to get the CLI running, you must launch it on the target Kubernetes cluster.   ‚ö†Ô∏è Be sure to edit the environment variables appropriately for your target cluster, eg. the username/password for the administrative user.\n kubectl -n storageos create -f-\u0026lt;\u0026lt;END apiVersion: apps/v1 kind: Deployment metadata: name: storageos-cli namespace: storageos labels: app: storageos run: cli spec: replicas: 1 selector: matchLabels: app: storageos-cli run: cli template: metadata: labels: app: storageos-cli run: cli spec: containers: - command: - /bin/sh - -c - \u0026#34;while true; do sleep 3600; done\u0026#34; env: - name: STORAGEOS_ENDPOINTS value: http://storageos:5705 - name: STORAGEOS_USERNAME value: storageos - name: STORAGEOS_PASSWORD value: storageos image: storageos/cli:v2.5.0 name: cli END Step 2 - Retrieve Unique Identifier Once the pod is launched, run the following script:\nPOD=$(kubectl -n storageos get pod -ocustom-columns=_:.metadata.name --no-headers -lapp=storageos-cli) Now that the POD variable is set, the pod is accessible via that variable for the rest of the lifetime of that terminal.\n Note: If you open a new terminal, you\u0026rsquo;ll need to run this command again to rediscover the ID of the pod.\n Retrieving a cluster ID via the Ondat CLI Prerequisites  ‚ö†Ô∏è You need to have Ondat CLI running - see instructions\n  üí° For more information refer to the licence CLI command reference documentation.\n Procedure   Run the following command\nkubectl -n storageos exec $POD -- storageos get cluster   You will see the following message:\nID: 704dd165-9580-4da4-a554-0acb96d328cb Created at: 2022-01-10T13:58:00Z (2 weeks ago) Updated at: 2022-01-10T14:05:27Z (2 weeks ago) Nodes: 3 Healthy: 3 Unhealthy: 0   The UUID in the ID field is unique to your cluster and is the only information you need in order to obtain your first license.\nView your license details on the CLI A license contains a list of capabilities and capacities, the cluster ID, an expiry time, any extra features and a license type alongside a digital signature.\nPrerequisites  ‚ö†Ô∏è You need to have Ondat CLI running - see instructions üí° For more information refer to the licence CLI command reference documentation.\n Procedure   Run the following command to view the license details\ncat license.dat   The following message will appear\nclusterCapacityGiB: 5120 clusterID: 164237eb-f88a-4bb8-a7cf-a23d468e07c0 customerName: storageos expiresAt: \u0026quot;2021-11-15T14:00:00Z\u0026quot; features: - nfs kind: project ------------- LICENCE SIGNATURE ------------- KyjNleTcdmieZVLmZ/rg0SzdAM7I/CH0j22FIFJJSJaeB71OvQrTMtHGyL5TSFNMrEGbyh1HQlDgZb5A V1HyjBlS3LjoB/MoagulTxIlZh/R8eRXCOQ46qNZ8Yb7+dHLdCVXBnRqZT11hLqZsMqIeO1y9f5dw65H kvl6vWW7YIS9r655S25jMMU7brrGDQVdjvU7tSA74BrnzDFHu7/poopIuFqcxZc/NLrKp/akkvyZI5Ex 1wH7D4onjVG2pgi30Kia+mjbI1B9pxQyRppQQ4hNXy4qBUUNMFh0menh0wHdQoM1VLU4Il22PrkeICV0 NaalLsK/96bJov6tpbg96g==   Ondat CLI - Applying a licence via the CLI This information is only applicable if you have received a license file from our Customer Success team. Otherwise, you should receive and install your license via the Ondat SaaS Platform.\nPrerequisites  ‚ö†Ô∏è You need to have Ondat CLI running - see instructions\n  ‚ö†Ô∏è Make sure POD variable is set as per the CLI instructions\n  ‚ö†Ô∏è You need to have received a license from our Customer Success team. Contct hello@ondat.io for more details.\n  üí° For more information refer to the licence CLI command reference documentation.\n Procedure Step 1 - Apply license key Run the following command to apply the licence key stored in /path/to/storageos-licence.dat\ncat /path/to/storageos-license.dat | kubectl -n storageos exec -it $POD -- storageos apply license --from-stdin Step 2 - Check for extra features Run the following command to check for extra featurs provided by your latest license:\nkubectl -n storageos exec $POD -- storageos get license You will see the message below:\nClusterID: 033a4774-c18f-4d05-ba86-90b818957f34 Expiration: 2024-01-01T23:59:59Z (2 years from now) Capacity: 15 TiB (16520591704064) Used: 0 B (0) Kind: standard Features: [nfs] Customer name: Sally Forth  üí° Don\u0026rsquo;t worry if you don\u0026rsquo;t see all of these fields - some of them are only visible when they are relevant to your individual license.\n ","excerpt":"Overview This document will walk you through how to request an Ondat license for your cluster, and ‚Ä¶","ref":"/docs/operations/licensing/","title":"Licensing"},{"body":"Enable the metrics To enable the Ondat Volume metrics, add the following field to your StorageOSCluster resource.\nspec:metrics:enabled:true ‚ö†Ô∏è On OCP you may need to follow their instructions for enabling monitoring of user-defined projects, here\n Example setup Here‚Äôs an example ServiceMonitor resource that scrapes our metrics endpoints:\napiVersion:monitoring.coreos.com/v1kind:ServiceMonitormetadata:labels:app:storageosrelease:prometheusname:storageos-metrics-service-monitornamespace:storageosspec:endpoints:- interval:15spath:/metricsport:metricsnamespaceSelector:matchNames:- storageosselector:matchLabels:app:storageosapp.kubernetes.io/component:metrics-exporter‚ö†Ô∏è The label selector fields must match those of our service.\nAfter the manifest is applied, Ondat metrics will be scraped by your Prometheus server.\n","excerpt":"Enable the metrics To enable the Ondat Volume metrics, add the following field to your ‚Ä¶","ref":"/docs/operations/metric-exporter/","title":"Metric Exporter"},{"body":"Beginning with Microsoft SQL Server 2017, Microsoft has supported MSSQL on linux.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nDeploying MS SQL on Kubernetes   You can find the latest files in the Ondat use cases repository\ngit clone https://github.com/storageos/use-cases.git storageos-usecases StatefulSet defintion\nkind:StatefulSetmetadata:name:mssqlspec:selector:matchLabels:app:mssqlenv:prodserviceName:mssqlreplicas:1...spec:serviceAccountName:mssql...volumeMounts:- name:datamountPath:/var/opt/mssql...volumeClaimTemplates:- metadata:name:datalabels:env:prodspec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:\u0026#34;storageos\u0026#34;# Ondat storageClass resources:requests:storage:5GiThis excerpt is from the StatefulSet definition. This file contains the VolumeClaim template that will dynamically provision storage, using the Ondat storage class. Dynamic provisioning occurs as a volumeMount has been declared with the same name as a VolumeClaim.\n  Move into the MS SQL examples folder and create the objects\ncd storageos-usecases kubectl create -f ./mssql   Confirm MS SQL is up and running.\n$ kubectl get pods -w -l app=mssql NAME READY STATUS RESTARTS AGE mssql-0 1/1 Running 0 1m   Connect to the MS SQL client pod and connect to the MS SQL server through the service\n$ kubectl exec -it mssql-0 -- /opt/mssql-tools/bin/sqlcmd -S mssql-0.mssql -U SA -P \u0026#39;Password15\u0026#39; 1\u0026gt; USE master; 2\u0026gt; GO Changed database context to \u0026#39;master\u0026#39;. 1\u0026gt; SELECT name, database_id, create_date FROM sys.databases ; 2\u0026gt; GO name database_id create_date --------------------------- ----------- ----------------------- master 1 2003-04-08 09:13:36.390 tempdb 2 2018-11-02 16:30:37.907 model 3 2003-04-08 09:13:36.390 msdb 4 2018-10-19 01:18:57.300 (4 rows affected)   Configuration If you need custom startup options, you can edit the ConfigMap file 15-mssql-configmap.yaml with your desired MS SQL configuration settings.\n","excerpt":"Beginning with Microsoft SQL Server 2017, Microsoft has supported MSSQL on linux.\nBefore you start, ‚Ä¶","ref":"/docs/usecases/mssql/","title":"MS SQL"},{"body":"Ondat supports secure communication with an external etcd cluster using mutual TLS (mTLS). With mTLS both Ondat and etcd authenticate each other ensuring that communication only happens between mutually authenticated end points, and that all communication is encrypted.\nOndat uses the certificates and keys from a Secret to cypher and authenticate Etcd traffic.\nHow to create the certificates Secret The client auth certificates need the following filenames, in the Secret.\n etcd-client-ca.crt - containing the etcd Certificate Authority certificate etcd-client.crt - containing the etcd Client certificate etcd-client.key - containing the etcd Client key  kubectl create secret -n storageos generic \\  storageos-etcd-secret \\  --from-file=\u0026#34;etcd-client-ca.crt\u0026#34; \\  --from-file=\u0026#34;etcd-client.crt\u0026#34; \\  --from-file=\u0026#34;etcd-client.key\u0026#34; How to use the mTLS certificates Secret with Ondat Below is an example StorageOSCluster resource that can be used to setup Ondat with etcd using mTLS.\napiVersion:storageos.com/v1kind:StorageOSClustermetadata:name:storageos-clusterspec:# Ondat Pods are in storageos NS by defaultsecretRefName:\u0026#34;storageos-api\u0026#34;storageClassName:\u0026#34;ondat\u0026#34;# The storage class created by the Ondat operator is configurableimages:nodeContainer:\u0026#34;storageos/node:v2.8.2\u0026#34;\u0026#34; namespace: \u0026#34;storageos\u0026#34;# External mTLS secured etcd cluster specific propertiestlsEtcdSecretRefName:\u0026#34;storageos-etcd-secret\u0026#34;# Secret containing etcd client certificates in the samekvBackend:address:\u0026#34;https://storageos-etcd-cluster-client.storagos-etcd.svc:2379\u0026#34;# Etcd client service address.backend:\u0026#34;etcd\u0026#34;# Backend typetlsEtcdSecretRefName is used to pass a reference to the Secret.\nThe Ondat operator uses the etcd secret that contains the client certificates, to build a secret in the Ondat installation namespace. This secret contains the certificate filenames and certificate file contents. The Ondat daemonset that is created by the operator mounts the secret as a volume so that the certificate files are available inside the pod. Environment variables containing the file paths are passed to the Ondat process in order to use the files from the mounted path.\nA worked example of setting up Ondat with external etcd using mTLS is available here. For ease of use the example uses the CoreOS etcd operator and the CoreOS guide The example uses the CoreOS etcd operator and follows the CoreOS guide for Cluster TLS.\n","excerpt":"Ondat supports secure communication with an external etcd cluster using mutual TLS (mTLS). With mTLS ‚Ä¶","ref":"/docs/operations/etcd/etcd-outside-k8s/storageos-secret-info/","title":"Encryption communication with Etcd"},{"body":"Ondat supports secure communication with an external etcd cluster using mutual TLS (mTLS). With mTLS both Ondat and etcd authenticate each other ensuring that communication only happens between mutually authenticated end points, and that all communication is encrypted.\nOndat uses the certificates and keys from a Secret to cypher and authenticate Etcd traffic.\nHow mTLS Works with the Etcd Operator When mTLS is enabled, the etcd operator will handle the creation of mTLS certificates, as well as the Kubernetes secrets Ondat requires.\nHow to enable mTLS Enabling mTLS must be done at etcd cluster creation time. It is not possible to retroactively enable mTLS.\nThe method to enable mTLS depends on how you are installing the etcd operator, guides are available here.\nIn short:\n Helm chart: mTLS is enabled by default Plugin: mTLS is enabled when using the --etcd-tls-enabled flag Applying CR directly: Set the following in the CR  spec: tls: enabled: true storageOSClusterNamespace: \u0026quot;storageos\u0026quot; storageOSEtcdSecretName: \u0026quot;storageos-etcd-secret\u0026quot; ","excerpt":"Ondat supports secure communication with an external etcd cluster using mutual TLS (mTLS). With mTLS ‚Ä¶","ref":"/docs/operations/etcd/mtls/","title":"Encryption communication with Etcd"},{"body":"MySQL is a popular SQL open source database for a wide range of popular web-based applications including WordPress.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nDeploying MySQL on Kubernetes   You can find the latest files in the Ondat use cases repository\ngit clone https://github.com/storageos/use-cases.git storageos-usecases StatefulSet defintion\napiversion:apps/v1kind:statefulsetmetadata:name:mysqlspec:selector:matchlabels:app:mysqlenv:prodservicename:mysqlreplicas:1...spec:serviceaccountname:mysql...volumemounts:- name:datamountpath:/var/lib/mysqlsubpath:mysql- name:confmountpath:/etc/mysql/mysql.conf.d...volumeclaimtemplates:- metadata:name:datalabels:env:prodspec:accessmodes:[\u0026#34;readwriteonce\u0026#34;]storageclassname:\u0026#34;storageos\u0026#34;resources:requests:storage:5giThis excerpt is from the StatefulSet definition. This file contains the VolumeClaim template that will dynamically provision storage, using the Ondat storage class. Dynamic provisioning occurs as a volumeMount has been declared with the same name as a VolumeClaim.\n  Move into the MySQL examples folder and create the objects\ncd storageos-usecases kubectl create -f ./mysql   Confirm MySQL is up and running.\n$ kubectl get pods -w -l app=mysql NAME READY STATUS RESTARTS AGE mysql-0 1/1 Running 0 1m   Connect to the MySQL client pod and connect to the MySQL server through the service\n$ kubectl exec client -- mysql -h mysql-0.mysql -e \u0026#34;show databases;\u0026#34; Database information_schema mysql performance_schema   Configuration If you need custom startup options, you can edit the ConfigMap file 15-mysqld-configmap.yaml with your desired MySQL configuration settings.\n","excerpt":"MySQL is a popular SQL open source database for a wide range of popular web-based applications ‚Ä¶","ref":"/docs/usecases/mysql/","title":"MySQL"},{"body":"Namespaces help different projects or teams share an Ondat cluster. Only the default namespace is created by default.\nNamespaces apply to volumes.\nManaging Namespaces In order to create a new namespace navigate to \u0026ldquo;Namespaces\u0026rdquo; in the GUI, and select \u0026ldquo;Create Namespace\u0026rdquo;.\nWhen a Kubernetes PVC is created in a namespace, Ondat automatically maps the Volume in the same namespace. Namespaces are created by Ondat to fulfil the RBAC rules enforced by Kubernetes roles.\nIn order to delete a namespace, all volumes must be deleted from the namespace before the namespace can be deleted.\n","excerpt":"Namespaces help different projects or teams share an Ondat cluster. Only the default namespace is ‚Ä¶","ref":"/docs/operations/namespaces/","title":"Namespaces"},{"body":"Nginx is a popular web server that can be used as a reverse proxy, load balancer or even as a Kubernetes ingress controller.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nDeploying Nginx on Kubernetes   You can find the latest files in the Ondat use cases repostiory\ngit clone https://github.com/storageos/use-cases.git storageos-usecases StatefulSet definition\napiVersion:apps/v1kind:StatefulSetmetadata:name:nginxspec:serviceName:nginxspec:serviceAccountName:nginxcontainers:- name:nginximage:nginxports:- containerPort:80volumeMounts:- name:nginx-datamountPath:/usr/share/nginx/htmlsubPath:html- name:nginx-configmountPath:/etc/nginx/conf.dvolumes:- name:nginx-configconfigMap:name:nginxvolumeClaimTemplates:- metadata:name:nginx-dataspec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:\u0026#34;storageos\u0026#34;# Ondat storageClass resources:requests:storage:5GiThis excerpt is from the StatefulSet definition. This file contains the VolumeClaim template that will dynamically provision storage, using the Ondat storage class. Dynamic provisioning occurs as a volumeMount has been declared with the same name as a VolumeClaim.\n  Move into the Nginx examples folder and create the objects\ncd storageos-usecases kubectl create -f ./nginx   Confirm Nginx is up and running.\n$ kubectl get pods -w -l app=nginx NAME READY STATUS RESTARTS AGE nginx-0 1/1 Running 0 1m   Connect to the nginx pod and write a file to /usr/share/nginx/html that Nginx will serve.\n$ kubectl exec nginx-0 -it -- bash root@nginx-0:/# echo Hello world! \u0026gt; /usr/share/nginx/html/greetings.txt   Connect to the Busybox pod and connect to the Nginx server through the service and retrieve the directory index from Nginx.\n$ kubectl exec -it busybox -- /bin/sh / # wget -q -O- nginx \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;Index of /\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Index of /\u0026lt;/h1\u0026gt;\u0026lt;hr\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;a href=\u0026#34;/docs/\u0026#34;\u0026gt;/docs/\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;greetings.txt\u0026#34;\u0026gt;greetings.txt\u0026lt;/a\u0026gt; 27-Feb-2019 12:04 13 \u0026lt;/pre\u0026gt;\u0026lt;hr\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   Retrieve and display the contents of the greetings.txt file\n/ # wget -q -O- nginx/greetings.txt Hello world!   Configuration If you need custom startup options, you can edit the ConfigMap file 15-nginx-configmap.yaml with your desired Nginx configuration settings.\n","excerpt":"Nginx is a popular web server that can be used as a reverse proxy, load balancer or even as a ‚Ä¶","ref":"/docs/usecases/nginx/","title":"NGINX"},{"body":"","excerpt":"","ref":"/","title":"Ondat"},{"body":"The following document lists the open source software attributions in the Ondat Control Plane, Data Plane and CLI.\nCNats The MIT License (MIT) Copyright (c) 2015 Apcera Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. CppUTest  Copyright (c) 2007, Michael Feathers, James Grenning and Bas Vodde All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of the \u0026lt;organization\u0026gt; nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE EARLIER MENTIONED AUTHORS ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL \u0026lt;copyright holder\u0026gt; BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Hayai Copyright (c) 2011 - Nick Bruun. This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software. Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions: The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. If you meet (any of) the author(s), you're encouraged to buy them a beer, a drink or whatever is suited to the situation, given that you like the software. This notice may not be removed or altered from any source distribution. LZ4 LZ4 Library Copyright (c) 2011-2016, Yann Collet All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. LibreSSL  LICENSE ISSUES ============== The OpenSSL toolkit stays under a dual license, i.e. both the conditions of the OpenSSL License and the original SSLeay license apply to the toolkit. See below for the actual license texts. Actually both licenses are BSD-style Open Source licenses. In case of any license issues related to OpenSSL please contact openssl-core@openssl.org. OpenSSL License --------------- ==================================================================== Copyright (c) 1998-2011 The OpenSSL Project. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. All advertising materials mentioning features or use of this software must display the following acknowledgment: \u0026quot;This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit. (http://www.openssl.org/)\u0026quot; 4. The names \u0026quot;OpenSSL Toolkit\u0026quot; and \u0026quot;OpenSSL Project\u0026quot; must not be used to endorse or promote products derived from this software without prior written permission. For written permission, please contact openssl-core@openssl.org. 5. Products derived from this software may not be called \u0026quot;OpenSSL\u0026quot; nor may \u0026quot;OpenSSL\u0026quot; appear in their names without prior written permission of the OpenSSL Project. 6. Redistributions of any form whatsoever must retain the following acknowledgment: \u0026quot;This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit (http://www.openssl.org/)\u0026quot; THIS SOFTWARE IS PROVIDED BY THE OpenSSL PROJECT ``AS IS'' AND ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE OpenSSL PROJECT OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. ==================================================================== This product includes cryptographic software written by Eric Young (eay@cryptsoft.com). This product includes software written by Tim Hudson (tjh@cryptsoft.com). Original SSLeay License ----------------------- Copyright (C) 1995-1998 Eric Young (eay@cryptsoft.com) All rights reserved. This package is an SSL implementation written by Eric Young (eay@cryptsoft.com). The implementation was written so as to conform with Netscapes SSL. This library is free for commercial and non-commercial use as long as the following conditions are aheared to. The following conditions apply to all code found in this distribution, be it the RC4, RSA, lhash, DES, etc., code; not just the SSL code. The SSL documentation included with this distribution is covered by the same copyright terms except that the holder is Tim Hudson (tjh@cryptsoft.com). Copyright remains Eric Young's, and as such any Copyright notices in the code are not to be removed. If this package is used in a product, Eric Young should be given attribution as the author of the parts of the library used. This can be in the form of a textual message at program startup or in documentation (online or textual) provided with the package. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. All advertising materials mentioning features or use of this software must display the following acknowledgement: \u0026quot;This product includes cryptographic software written by Eric Young (eay@cryptsoft.com)\u0026quot; The word 'cryptographic' can be left out if the rouines from the library being used are not cryptographic related :-). 4. If you include any Windows specific code (or a derivative thereof) from the apps directory (application code) you must include an acknowledgement: \u0026quot;This product includes software written by Tim Hudson (tjh@cryptsoft.com)\u0026quot; THIS SOFTWARE IS PROVIDED BY ERIC YOUNG ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. The licence and distribution terms for any publically available version or derivative of this code cannot be changed. i.e. this code cannot simply be copied and put under another distribution licence [including the GNU Public Licence.] protobuf This license applies to all parts of Protocol Buffers except the following: - Atomicops support for generic gcc, located in src/google/protobuf/stubs/atomicops_internals_generic_gcc.h. This file is copyrighted by Red Hat Inc. - Atomicops support for AIX/POWER, located in src/google/protobuf/stubs/atomicops_internals_power.h. This file is copyrighted by Bloomberg Finance LP. Copyright 2014, Google Inc. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Code generated by the Protocol Buffer compiler is owned by the owner of the input file used when generating it. This code is not standalone and requires a support library to be linked with it. This support library is itself covered by the above license. rocksdb BSD License For rocksdb software Copyright (c) 2011-present, Facebook, Inc. All rights reserved. --------------------------------------------------------------------- Copyright (c) 2011 The LevelDB Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/armon/go-metrics The MIT License (MIT) Copyright (c) 2013 Armon Dadgar Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/armon/go-radix The MIT License (MIT) Copyright (c) 2014 Armon Dadgar Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/bgentry/speakeasy  Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \u0026quot;License\u0026quot; shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \u0026quot;Licensor\u0026quot; shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \u0026quot;Legal Entity\u0026quot; shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \u0026quot;control\u0026quot; means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \u0026quot;You\u0026quot; (or \u0026quot;Your\u0026quot;) shall mean an individual or Legal Entity exercising permissions granted by this License. \u0026quot;Source\u0026quot; form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \u0026quot;Object\u0026quot; form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \u0026quot;Work\u0026quot; shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \u0026quot;Derivative Works\u0026quot; shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \u0026quot;Contribution\u0026quot; shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \u0026quot;submitted\u0026quot; means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \u0026quot;Not a Contribution.\u0026quot; \u0026quot;Contributor\u0026quot; shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \u0026quot;NOTICE\u0026quot; text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \u0026quot;[]\u0026quot; replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \u0026quot;printed page\u0026quot; as the copyright notice for easier identification within third-party archives. Copyright [2013] [the CloudFoundry Authors] Licensed under the Apache License, Version 2.0 (the \u0026quot;License\u0026quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. github.com/dgrijalva/jwt-go Copyright (c) 2012 Dave Grijalva Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/dgrijalva/jwt-go/request Copyright (c) 2012 Dave Grijalva Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/dgryski/go-metro MetroHash This package is a mechanical translation of the reference C++ code for MetroHash, available at https://github.com/jandrewrogers/MetroHash I claim no additional copyright over the original implementation. The MIT License (MIT) Copyright (c) 2015 J. Andrew Rogers Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/docker/docker/pkg/mount  Apache License Version 2.0, January 2004 https://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \u0026quot;License\u0026quot; shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \u0026quot;Licensor\u0026quot; shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \u0026quot;Legal Entity\u0026quot; shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \u0026quot;control\u0026quot; means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \u0026quot;You\u0026quot; (or \u0026quot;Your\u0026quot;) shall mean an individual or Legal Entity exercising permissions granted by this License. \u0026quot;Source\u0026quot; form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \u0026quot;Object\u0026quot; form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \u0026quot;Work\u0026quot; shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \u0026quot;Derivative Works\u0026quot; shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \u0026quot;Contribution\u0026quot; shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \u0026quot;submitted\u0026quot; means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \u0026quot;Not a Contribution.\u0026quot; \u0026quot;Contributor\u0026quot; shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \u0026quot;NOTICE\u0026quot; text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS Copyright 2013-2016 Docker, Inc. Licensed under the Apache License, Version 2.0 (the \u0026quot;License\u0026quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. github.com/docker/libkv  Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \u0026quot;License\u0026quot; shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \u0026quot;Licensor\u0026quot; shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \u0026quot;Legal Entity\u0026quot; shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \u0026quot;control\u0026quot; means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \u0026quot;You\u0026quot; (or \u0026quot;Your\u0026quot;) shall mean an individual or Legal Entity exercising permissions granted by this License. \u0026quot;Source\u0026quot; form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \u0026quot;Object\u0026quot; form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \u0026quot;Work\u0026quot; shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \u0026quot;Derivative Works\u0026quot; shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \u0026quot;Contribution\u0026quot; shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \u0026quot;submitted\u0026quot; means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \u0026quot;Not a Contribution.\u0026quot; \u0026quot;Contributor\u0026quot; shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \u0026quot;NOTICE\u0026quot; text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS Copyright 2014-2016 Docker, Inc. Licensed under the Apache License, Version 2.0 (the \u0026quot;License\u0026quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. github.com/docker/libkv/store  Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \u0026quot;License\u0026quot; shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \u0026quot;Licensor\u0026quot; shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \u0026quot;Legal Entity\u0026quot; shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \u0026quot;control\u0026quot; means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \u0026quot;You\u0026quot; (or \u0026quot;Your\u0026quot;) shall mean an individual or Legal Entity exercising permissions granted by this License. \u0026quot;Source\u0026quot; form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \u0026quot;Object\u0026quot; form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \u0026quot;Work\u0026quot; shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \u0026quot;Derivative Works\u0026quot; shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \u0026quot;Contribution\u0026quot; shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \u0026quot;submitted\u0026quot; means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \u0026quot;Not a Contribution.\u0026quot; \u0026quot;Contributor\u0026quot; shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \u0026quot;NOTICE\u0026quot; text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS Copyright 2014-2016 Docker, Inc. Licensed under the Apache License, Version 2.0 (the \u0026quot;License\u0026quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. github.com/fsnotify/fsnotify Copyright (c) 2012 The Go Authors. All rights reserved. Copyright (c) 2012 fsnotify Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/golang/protobuf/proto Go support for Protocol Buffers - Google's data interchange format Copyright 2010 The Go Authors. All rights reserved. https://github.com/golang/protobuf Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/gorilla/context Copyright (c) 2012 Rodrigo Moraes. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/gorilla/handlers Copyright (c) 2013 The Gorilla Handlers Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/gorilla/mux Copyright (c) 2012 Rodrigo Moraes. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/gorilla/websocket Copyright (c) 2013 The Gorilla WebSocket Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/hashicorp/consul/API Mozilla Public License, version 2.0 1. Definitions 1.1. ‚ÄúContributor‚Äù means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software. 1.2. ‚ÄúContributor Version‚Äù means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor‚Äôs Contribution. 1.3. ‚ÄúContribution‚Äù means Covered Software of a particular Contributor. 1.4. ‚ÄúCovered Software‚Äù means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof. 1.5. ‚ÄúIncompatible With Secondary Licenses‚Äù means a. that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or b. that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License. 1.6. ‚ÄúExecutable Form‚Äù means any form of the work other than Source Code Form. 1.7. ‚ÄúLarger Work‚Äù means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software. 1.8. ‚ÄúLicense‚Äù means this document. 1.9. ‚ÄúLicensable‚Äù means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License. 1.10. ‚ÄúModifications‚Äù means any of the following: a. any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or b. any new file in Source Code Form that contains any Covered Software. 1.11. ‚ÄúPatent Claims‚Äù of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version. 1.12. ‚ÄúSecondary License‚Äù means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses. 1.13. ‚ÄúSource Code Form‚Äù means the form of the work preferred for making modifications. 1.14. ‚ÄúYou‚Äù (or ‚ÄúYour‚Äù) means an individual or a legal entity exercising rights under this License. For legal entities, ‚ÄúYou‚Äù includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, ‚Äúcontrol‚Äù means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity. 2. License Grants and Conditions 2.1. Grants Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license: a. under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and b. under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version. 2.2. Effective Date The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution. 2.3. Limitations on Grant Scope The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor: a. for any code that a Contributor has removed from Covered Software; or b. for infringements caused by: (i) Your and any other third party‚Äôs modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or c. under Patent Claims infringed by Covered Software in the absence of its Contributions. This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4). 2.4. Subsequent Licenses No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3). 2.5. Representation Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License. 2.6. Fair Use This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents. 2.7. Conditions Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1. 3. Responsibilities 3.1. Distribution of Source Form All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients‚Äô rights in the Source Code Form. 3.2. Distribution of Executable Form If You distribute Covered Software in Executable Form then: a. such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and b. You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients‚Äô rights in the Source Code Form under this License. 3.3. Distribution of a Larger Work You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s). 3.4. Notices You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies. 3.5. Application of Additional Terms You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction. 4. Inability to Comply Due to Statute or Regulation If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it. 5. Termination 5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice. 5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate. 5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination. 6. Disclaimer of Warranty Covered Software is provided under this License on an ‚Äúas is‚Äù basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer. 7. Limitation of Liability Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party‚Äôs negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You. 8. Litigation Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party‚Äôs ability to bring cross-claims or counter-claims. 9. Miscellaneous This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor. 10. Versions of the License 10.1. New Versions Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number. 10.2. Effect of New Versions You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward. 10.3. Modified Versions If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License). 10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/. If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership. Exhibit B - ‚ÄúIncompatible With Secondary Licenses‚Äù Notice This Source Code Form is ‚ÄúIncompatible With Secondary Licenses‚Äù, as defined by the Mozilla Public License, v. 2.0. github.com/hashicorp/errwrap Mozilla Public License, version 2.0 1. Definitions 1.1. ‚ÄúContributor‚Äù means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software. 1.2. ‚ÄúContributor Version‚Äù means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor‚Äôs Contribution. 1.3. ‚ÄúContribution‚Äù means Covered Software of a particular Contributor. 1.4. ‚ÄúCovered Software‚Äù means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof. 1.5. ‚ÄúIncompatible With Secondary Licenses‚Äù means a. that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or b. that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License. 1.6. ‚ÄúExecutable Form‚Äù means any form of the work other than Source Code Form. 1.7. ‚ÄúLarger Work‚Äù means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software. 1.8. ‚ÄúLicense‚Äù means this document. 1.9. ‚ÄúLicensable‚Äù means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License. 1.10. ‚ÄúModifications‚Äù means any of the following: a. any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or b. any new file in Source Code Form that contains any Covered Software. 1.11. ‚ÄúPatent Claims‚Äù of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version. 1.12. ‚ÄúSecondary License‚Äù means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses. 1.13. ‚ÄúSource Code Form‚Äù means the form of the work preferred for making modifications. 1.14. ‚ÄúYou‚Äù (or ‚ÄúYour‚Äù) means an individual or a legal entity exercising rights under this License. For legal entities, ‚ÄúYou‚Äù includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, ‚Äúcontrol‚Äù means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity. 2. License Grants and Conditions 2.1. Grants Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license: a. under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and b. under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version. 2.2. Effective Date The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution. 2.3. Limitations on Grant Scope The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor: a. for any code that a Contributor has removed from Covered Software; or b. for infringements caused by: (i) Your and any other third party‚Äôs modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or c. under Patent Claims infringed by Covered Software in the absence of its Contributions. This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4). 2.4. Subsequent Licenses No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3). 2.5. Representation Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License. 2.6. Fair Use This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents. 2.7. Conditions Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1. 3. Responsibilities 3.1. Distribution of Source Form All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients‚Äô rights in the Source Code Form. 3.2. Distribution of Executable Form If You distribute Covered Software in Executable Form then: a. such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and b. You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients‚Äô rights in the Source Code Form under this License. 3.3. Distribution of a Larger Work You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s). 3.4. Notices You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies. 3.5. Application of Additional Terms You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction. 4. Inability to Comply Due to Statute or Regulation If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it. 5. Termination 5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice. 5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate. 5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination. 6. Disclaimer of Warranty Covered Software is provided under this License on an ‚Äúas is‚Äù basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer. 7. Limitation of Liability Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party‚Äôs negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You. 8. Litigation Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party‚Äôs ability to bring cross-claims or counter-claims. 9. Miscellaneous This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor. 10. Versions of the License 10.1. New Versions Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number. 10.2. Effect of New Versions You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward. 10.3. Modified Versions If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License). 10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/. If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership. Exhibit B - ‚ÄúIncompatible With Secondary Licenses‚Äù Notice This Source Code Form is ‚ÄúIncompatible With Secondary Licenses‚Äù, as defined by the Mozilla Public License, v. 2.0. github.com/hashicorp/go-cleanhttp Mozilla Public License, version 2.0 1. Definitions 1.1. \u0026quot;Contributor\u0026quot; means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software. 1.2. \u0026quot;Contributor Version\u0026quot; means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor's Contribution. 1.3. \u0026quot;Contribution\u0026quot; means Covered Software of a particular Contributor. 1.4. \u0026quot;Covered Software\u0026quot; means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof. 1.5. \u0026quot;Incompatible With Secondary Licenses\u0026quot; means a. that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or b. that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License. 1.6. \u0026quot;Executable Form\u0026quot; means any form of the work other than Source Code Form. 1.7. \u0026quot;Larger Work\u0026quot; means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software. 1.8. \u0026quot;License\u0026quot; means this document. 1.9. \u0026quot;Licensable\u0026quot; means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License. 1.10. \u0026quot;Modifications\u0026quot; means any of the following: a. any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or b. any new file in Source Code Form that contains any Covered Software. 1.11. \u0026quot;Patent Claims\u0026quot; of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version. 1.12. \u0026quot;Secondary License\u0026quot; means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses. 1.13. \u0026quot;Source Code Form\u0026quot; means the form of the work preferred for making modifications. 1.14. \u0026quot;You\u0026quot; (or \u0026quot;Your\u0026quot;) means an individual or a legal entity exercising rights under this License. For legal entities, \u0026quot;You\u0026quot; includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, \u0026quot;control\u0026quot; means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity. 2. License Grants and Conditions 2.1. Grants Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license: a. under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and b. under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version. 2.2. Effective Date The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution. 2.3. Limitations on Grant Scope The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor: a. for any code that a Contributor has removed from Covered Software; or b. for infringements caused by: (i) Your and any other third party's modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or c. under Patent Claims infringed by Covered Software in the absence of its Contributions. This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4). 2.4. Subsequent Licenses No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3). 2.5. Representation Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License. 2.6. Fair Use This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents. 2.7. Conditions Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1. 3. Responsibilities 3.1. Distribution of Source Form All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients' rights in the Source Code Form. 3.2. Distribution of Executable Form If You distribute Covered Software in Executable Form then: a. such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and b. You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients' rights in the Source Code Form under this License. 3.3. Distribution of a Larger Work You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s). 3.4. Notices You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies. 3.5. Application of Additional Terms You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction. 4. Inability to Comply Due to Statute or Regulation If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it. 5. Termination 5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice. 5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate. 5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination. 6. Disclaimer of Warranty Covered Software is provided under this License on an \u0026quot;as is\u0026quot; basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer. 7. Limitation of Liability Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party's negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You. 8. Litigation Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party's ability to bring cross-claims or counter-claims. 9. Miscellaneous This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor. 10. Versions of the License 10.1. New Versions Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number. 10.2. Effect of New Versions You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward. 10.3. Modified Versions If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License). 10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/. If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership. Exhibit B - \u0026quot;Incompatible With Secondary Licenses\u0026quot; Notice This Source Code Form is \u0026quot;Incompatible With Secondary Licenses\u0026quot;, as defined by the Mozilla Public License, v. 2.0. github.com/hashicorp/go-msgpack/codec Copyright (c) 2012, 2013 Ugorji Nwoke. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of the author nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/hashicorp/go-multierror Mozilla Public License, version 2.0 1. Definitions 1.1. ‚ÄúContributor‚Äù means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software. 1.2. ‚ÄúContributor Version‚Äù means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor‚Äôs Contribution. 1.3. ‚ÄúContribution‚Äù means Covered Software of a particular Contributor. 1.4. ‚ÄúCovered Software‚Äù means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof. 1.5. ‚ÄúIncompatible With Secondary Licenses‚Äù means a. that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or b. that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License. 1.6. ‚ÄúExecutable Form‚Äù means any form of the work other than Source Code Form. 1.7. ‚ÄúLarger Work‚Äù means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software. 1.8. ‚ÄúLicense‚Äù means this document. 1.9. ‚ÄúLicensable‚Äù means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License. 1.10. ‚ÄúModifications‚Äù means any of the following: a. any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or b. any new file in Source Code Form that contains any Covered Software. 1.11. ‚ÄúPatent Claims‚Äù of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version. 1.12. ‚ÄúSecondary License‚Äù means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses. 1.13. ‚ÄúSource Code Form‚Äù means the form of the work preferred for making modifications. 1.14. ‚ÄúYou‚Äù (or ‚ÄúYour‚Äù) means an individual or a legal entity exercising rights under this License. For legal entities, ‚ÄúYou‚Äù includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, ‚Äúcontrol‚Äù means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity. 2. License Grants and Conditions 2.1. Grants Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license: a. under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and b. under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version. 2.2. Effective Date The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution. 2.3. Limitations on Grant Scope The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor: a. for any code that a Contributor has removed from Covered Software; or b. for infringements caused by: (i) Your and any other third party‚Äôs modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or c. under Patent Claims infringed by Covered Software in the absence of its Contributions. This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4). 2.4. Subsequent Licenses No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3). 2.5. Representation Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License. 2.6. Fair Use This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents. 2.7. Conditions Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1. 3. Responsibilities 3.1. Distribution of Source Form All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients‚Äô rights in the Source Code Form. 3.2. Distribution of Executable Form If You distribute Covered Software in Executable Form then: a. such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and b. You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients‚Äô rights in the Source Code Form under this License. 3.3. Distribution of a Larger Work You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s). 3.4. Notices You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies. 3.5. Application of Additional Terms You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction. 4. Inability to Comply Due to Statute or Regulation If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it. 5. Termination 5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice. 5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate. 5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination. 6. Disclaimer of Warranty Covered Software is provided under this License on an ‚Äúas is‚Äù basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer. 7. Limitation of Liability Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party‚Äôs negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You. 8. Litigation Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party‚Äôs ability to bring cross-claims or counter-claims. 9. Miscellaneous This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor. 10. Versions of the License 10.1. New Versions Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number. 10.2. Effect of New Versions You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward. 10.3. Modified Versions If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License). 10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/. If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership. Exhibit B - ‚ÄúIncompatible With Secondary Licenses‚Äù Notice This Source Code Form is ‚ÄúIncompatible With Secondary Licenses‚Äù, as defined by the Mozilla Public License, v. 2.0. github.com/hashicorp/memberlist Mozilla Public License, version 2.0 1. Definitions 1.1. ‚ÄúContributor‚Äù means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software. 1.2. ‚ÄúContributor Version‚Äù means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor‚Äôs Contribution. 1.3. ‚ÄúContribution‚Äù means Covered Software of a particular Contributor. 1.4. ‚ÄúCovered Software‚Äù means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof. 1.5. ‚ÄúIncompatible With Secondary Licenses‚Äù means a. that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or b. that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License. 1.6. ‚ÄúExecutable Form‚Äù means any form of the work other than Source Code Form. 1.7. ‚ÄúLarger Work‚Äù means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software. 1.8. ‚ÄúLicense‚Äù means this document. 1.9. ‚ÄúLicensable‚Äù means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License. 1.10. ‚ÄúModifications‚Äù means any of the following: a. any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or b. any new file in Source Code Form that contains any Covered Software. 1.11. ‚ÄúPatent Claims‚Äù of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version. 1.12. ‚ÄúSecondary License‚Äù means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses. 1.13. ‚ÄúSource Code Form‚Äù means the form of the work preferred for making modifications. 1.14. ‚ÄúYou‚Äù (or ‚ÄúYour‚Äù) means an individual or a legal entity exercising rights under this License. For legal entities, ‚ÄúYou‚Äù includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, ‚Äúcontrol‚Äù means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity. 2. License Grants and Conditions 2.1. Grants Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license: a. under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and b. under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version. 2.2. Effective Date The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution. 2.3. Limitations on Grant Scope The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor: a. for any code that a Contributor has removed from Covered Software; or b. for infringements caused by: (i) Your and any other third party‚Äôs modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or c. under Patent Claims infringed by Covered Software in the absence of its Contributions. This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4). 2.4. Subsequent Licenses No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3). 2.5. Representation Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License. 2.6. Fair Use This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents. 2.7. Conditions Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1. 3. Responsibilities 3.1. Distribution of Source Form All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients‚Äô rights in the Source Code Form. 3.2. Distribution of Executable Form If You distribute Covered Software in Executable Form then: a. such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and b. You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients‚Äô rights in the Source Code Form under this License. 3.3. Distribution of a Larger Work You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s). 3.4. Notices You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies. 3.5. Application of Additional Terms You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction. 4. Inability to Comply Due to Statute or Regulation If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it. 5. Termination 5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice. 5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate. 5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination. 6. Disclaimer of Warranty Covered Software is provided under this License on an ‚Äúas is‚Äù basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer. 7. Limitation of Liability Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party‚Äôs negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You. 8. Litigation Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party‚Äôs ability to bring cross-claims or counter-claims. 9. Miscellaneous This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor. 10. Versions of the License 10.1. New Versions Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number. 10.2. Effect of New Versions You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward. 10.3. Modified Versions If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License). 10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/. If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership. Exhibit B - ‚ÄúIncompatible With Secondary Licenses‚Äù Notice This Source Code Form is ‚ÄúIncompatible With Secondary Licenses‚Äù, as defined by the Mozilla Public License, v. 2.0. github.com/hashicorp/serf/coordinate Mozilla Public License, version 2.0 1. Definitions 1.1. ‚ÄúContributor‚Äù means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software. 1.2. ‚ÄúContributor Version‚Äù means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor‚Äôs Contribution. 1.3. ‚ÄúContribution‚Äù means Covered Software of a particular Contributor. 1.4. ‚ÄúCovered Software‚Äù means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof. 1.5. ‚ÄúIncompatible With Secondary Licenses‚Äù means a. that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or b. that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License. 1.6. ‚ÄúExecutable Form‚Äù means any form of the work other than Source Code Form. 1.7. ‚ÄúLarger Work‚Äù means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software. 1.8. ‚ÄúLicense‚Äù means this document. 1.9. ‚ÄúLicensable‚Äù means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License. 1.10. ‚ÄúModifications‚Äù means any of the following: a. any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or b. any new file in Source Code Form that contains any Covered Software. 1.11. ‚ÄúPatent Claims‚Äù of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version. 1.12. ‚ÄúSecondary License‚Äù means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses. 1.13. ‚ÄúSource Code Form‚Äù means the form of the work preferred for making modifications. 1.14. ‚ÄúYou‚Äù (or ‚ÄúYour‚Äù) means an individual or a legal entity exercising rights under this License. For legal entities, ‚ÄúYou‚Äù includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, ‚Äúcontrol‚Äù means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity. 2. License Grants and Conditions 2.1. Grants Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license: a. under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and b. under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version. 2.2. Effective Date The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution. 2.3. Limitations on Grant Scope The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor: a. for any code that a Contributor has removed from Covered Software; or b. for infringements caused by: (i) Your and any other third party‚Äôs modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or c. under Patent Claims infringed by Covered Software in the absence of its Contributions. This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4). 2.4. Subsequent Licenses No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3). 2.5. Representation Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License. 2.6. Fair Use This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents. 2.7. Conditions Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1. 3. Responsibilities 3.1. Distribution of Source Form All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients‚Äô rights in the Source Code Form. 3.2. Distribution of Executable Form If You distribute Covered Software in Executable Form then: a. such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and b. You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients‚Äô rights in the Source Code Form under this License. 3.3. Distribution of a Larger Work You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s). 3.4. Notices You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies. 3.5. Application of Additional Terms You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction. 4. Inability to Comply Due to Statute or Regulation If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it. 5. Termination 5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice. 5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate. 5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination. 6. Disclaimer of Warranty Covered Software is provided under this License on an ‚Äúas is‚Äù basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer. 7. Limitation of Liability Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party‚Äôs negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You. 8. Litigation Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party‚Äôs ability to bring cross-claims or counter-claims. 9. Miscellaneous This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor. 10. Versions of the License 10.1. New Versions Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number. 10.2. Effect of New Versions You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward. 10.3. Modified Versions If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License). 10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/. If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership. Exhibit B - ‚ÄúIncompatible With Secondary Licenses‚Äù Notice This Source Code Form is ‚ÄúIncompatible With Secondary Licenses‚Äù, as defined by the Mozilla Public License, v. 2.0. github.com/hashicorp/serf/serf Mozilla Public License, version 2.0 1. Definitions 1.1. ‚ÄúContributor‚Äù means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software. 1.2. ‚ÄúContributor Version‚Äù means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor‚Äôs Contribution. 1.3. ‚ÄúContribution‚Äù means Covered Software of a particular Contributor. 1.4. ‚ÄúCovered Software‚Äù means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof. 1.5. ‚ÄúIncompatible With Secondary Licenses‚Äù means a. that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or b. that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License. 1.6. ‚ÄúExecutable Form‚Äù means any form of the work other than Source Code Form. 1.7. ‚ÄúLarger Work‚Äù means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software. 1.8. ‚ÄúLicense‚Äù means this document. 1.9. ‚ÄúLicensable‚Äù means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License. 1.10. ‚ÄúModifications‚Äù means any of the following: a. any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or b. any new file in Source Code Form that contains any Covered Software. 1.11. ‚ÄúPatent Claims‚Äù of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version. 1.12. ‚ÄúSecondary License‚Äù means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses. 1.13. ‚ÄúSource Code Form‚Äù means the form of the work preferred for making modifications. 1.14. ‚ÄúYou‚Äù (or ‚ÄúYour‚Äù) means an individual or a legal entity exercising rights under this License. For legal entities, ‚ÄúYou‚Äù includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, ‚Äúcontrol‚Äù means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity. 2. License Grants and Conditions 2.1. Grants Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license: a. under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and b. under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version. 2.2. Effective Date The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution. 2.3. Limitations on Grant Scope The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor: a. for any code that a Contributor has removed from Covered Software; or b. for infringements caused by: (i) Your and any other third party‚Äôs modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or c. under Patent Claims infringed by Covered Software in the absence of its Contributions. This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4). 2.4. Subsequent Licenses No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3). 2.5. Representation Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License. 2.6. Fair Use This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents. 2.7. Conditions Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1. 3. Responsibilities 3.1. Distribution of Source Form All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients‚Äô rights in the Source Code Form. 3.2. Distribution of Executable Form If You distribute Covered Software in Executable Form then: a. such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and b. You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients‚Äô rights in the Source Code Form under this License. 3.3. Distribution of a Larger Work You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s). 3.4. Notices You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies. 3.5. Application of Additional Terms You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction. 4. Inability to Comply Due to Statute or Regulation If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it. 5. Termination 5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice. 5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate. 5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination. 6. Disclaimer of Warranty Covered Software is provided under this License on an ‚Äúas is‚Äù basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer. 7. Limitation of Liability Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party‚Äôs negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You. 8. Litigation Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party‚Äôs ability to bring cross-claims or counter-claims. 9. Miscellaneous This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor. 10. Versions of the License 10.1. New Versions Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number. 10.2. Effect of New Versions You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward. 10.3. Modified Versions If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License). 10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/. If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership. Exhibit B - ‚ÄúIncompatible With Secondary Licenses‚Äù Notice This Source Code Form is ‚ÄúIncompatible With Secondary Licenses‚Äù, as defined by the Mozilla Public License, v. 2.0. github.com/kelseyhightower/envconfig Copyright (c) 2013 Kelsey Hightower Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/mattn/go-isatty Copyright (c) Yasuhiro MATSUMOTO \u0026lt;mattn.jp@gmail.com\u0026gt; MIT License (Expat) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/miekg/dns Extensions of the original work are copyright (c) 2011 Miek Gieben As this is fork of the official Go code the same license applies: Copyright (c) 2009 The Go Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/mitchellh/cli Mozilla Public License, version 2.0 1. Definitions 1.1. ‚ÄúContributor‚Äù means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software. 1.2. ‚ÄúContributor Version‚Äù means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor‚Äôs Contribution. 1.3. ‚ÄúContribution‚Äù means Covered Software of a particular Contributor. 1.4. ‚ÄúCovered Software‚Äù means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof. 1.5. ‚ÄúIncompatible With Secondary Licenses‚Äù means a. that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or b. that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License. 1.6. ‚ÄúExecutable Form‚Äù means any form of the work other than Source Code Form. 1.7. ‚ÄúLarger Work‚Äù means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software. 1.8. ‚ÄúLicense‚Äù means this document. 1.9. ‚ÄúLicensable‚Äù means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License. 1.10. ‚ÄúModifications‚Äù means any of the following: a. any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or b. any new file in Source Code Form that contains any Covered Software. 1.11. ‚ÄúPatent Claims‚Äù of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version. 1.12. ‚ÄúSecondary License‚Äù means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses. 1.13. ‚ÄúSource Code Form‚Äù means the form of the work preferred for making modifications. 1.14. ‚ÄúYou‚Äù (or ‚ÄúYour‚Äù) means an individual or a legal entity exercising rights under this License. For legal entities, ‚ÄúYou‚Äù includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, ‚Äúcontrol‚Äù means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity. 2. License Grants and Conditions 2.1. Grants Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license: a. under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and b. under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version. 2.2. Effective Date The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution. 2.3. Limitations on Grant Scope The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor: a. for any code that a Contributor has removed from Covered Software; or b. for infringements caused by: (i) Your and any other third party‚Äôs modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or c. under Patent Claims infringed by Covered Software in the absence of its Contributions. This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4). 2.4. Subsequent Licenses No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3). 2.5. Representation Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License. 2.6. Fair Use This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents. 2.7. Conditions Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1. 3. Responsibilities 3.1. Distribution of Source Form All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients‚Äô rights in the Source Code Form. 3.2. Distribution of Executable Form If You distribute Covered Software in Executable Form then: a. such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and b. You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients‚Äô rights in the Source Code Form under this License. 3.3. Distribution of a Larger Work You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s). 3.4. Notices You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies. 3.5. Application of Additional Terms You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction. 4. Inability to Comply Due to Statute or Regulation If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it. 5. Termination 5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice. 5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate. 5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination. 6. Disclaimer of Warranty Covered Software is provided under this License on an ‚Äúas is‚Äù basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer. 7. Limitation of Liability Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party‚Äôs negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You. 8. Litigation Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party‚Äôs ability to bring cross-claims or counter-claims. 9. Miscellaneous This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor. 10. Versions of the License 10.1. New Versions Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number. 10.2. Effect of New Versions You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward. 10.3. Modified Versions If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License). 10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/. If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership. Exhibit B - ‚ÄúIncompatible With Secondary Licenses‚Äù Notice This Source Code Form is ‚ÄúIncompatible With Secondary Licenses‚Äù, as defined by the Mozilla Public License, v. 2.0. github.com/mitchellh/mapstructure The MIT License (MIT) Copyright (c) 2013 Mitchell Hashimoto Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/nats-io/gnatsd/conf The MIT License (MIT) Copyright (c) 2012-2016 Apcera Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/nats-io/gnatsd/logger The MIT License (MIT) Copyright (c) 2012-2016 Apcera Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/nats-io/gnatsd/server The MIT License (MIT) Copyright (c) 2012-2016 Apcera Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/nats-io/gnatsd/server/pse The MIT License (MIT) Copyright (c) 2012-2016 Apcera Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/nats-io/gnatsd/util The MIT License (MIT) Copyright (c) 2012-2016 Apcera Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/nats-io/nats The MIT License (MIT) Copyright (c) 2012-2016 Apcera Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/nats-io/nats/encoders/builtin The MIT License (MIT) Copyright (c) 2012-2016 Apcera Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/nats-io/nuid The MIT License (MIT) Copyright (c) 2012-2016 Apcera Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/pborman/uuid Copyright (c) 2009,2014 Google Inc. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. github.com/Sirupsen/logrus The MIT License (MIT) Copyright (c) 2014 Simon Eskildsen Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/thejerf/suture Copyright (c) 2014-2015 Barracuda Networks, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. github.com/urfave/negroni The MIT License (MIT) Copyright (c) 2014 Jeremy Saenz Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. golang.org/x/crypto/bcrypt Copyright (c) 2009 The Go Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. golang.org/x/crypto/blowfish Copyright (c) 2009 The Go Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. golang.org/x/net/context Copyright (c) 2009 The Go Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. golang.org/x/sys/unix Copyright (c) 2009 The Go Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. golang.org/x/sys/windows Copyright (c) 2009 The Go Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. golang.org/x/sys/windows/registry Copyright (c) 2009 The Go Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. golang.org/x/sys/windows/svc/eventlog Copyright (c) 2009 The Go Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. golang.org/x/time/rate Copyright (c) 2009 The Go Authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. gopkg.in/yaml.v2 Copyright 2011-2016 Canonical Ltd. Licensed under the Apache License, Version 2.0 (the \u0026quot;License\u0026quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. ","excerpt":"The following document lists the open source software attributions in the Ondat Control Plane, Data ‚Ä¶","ref":"/docs/reference/open_source_attribution/","title":"Ondat Open Source Software Attribution Notice"},{"body":"Our operator is a Kubernetes native application developed to deploy and configure Ondat clusters, and assist with maintenance operations. We recommend its use for standard installations.\nThe operator acts as a Kubernetes controller that watches the StorageOSCluster CR (Custom Resource). Once the controller is ready, an Ondat cluster definition can be created. The operator will deploy an Ondat cluster based on the configuration specified in the cluster definition.\nYou can find the source code in the operator repository.\n","excerpt":"Our operator is a Kubernetes native application developed to deploy and configure Ondat clusters, ‚Ä¶","ref":"/docs/reference/operator/","title":"Ondat Operator"},{"body":"Ondat has the capacity to influence Kubernetes Pod placement decisions to ensure that Pods are scheduled on the same nodes as their data. This functionality is known as Pod Locality.\nOndat grants access to data by presenting, on local or remote nodes, the devices used in a Pod\u0026rsquo;s VolumeMounts. However, it is often the case that it is required or preferred to place the Pod on the node where the Ondat Primary Volume is located, because IO operations are fastest as a result of minimized network traffic and associated latency. Read operations are served locally and writes require fewer round trips to the replicas of the volume.\nOndat automatically enables the use of a custom scheduler for any Pod using Ondat Volumes. Checkout the Admission Controller reference for more information.\nStorageos Kubernetes Scheduler Ondat achieves Pod locality by implementing a Kubernetes scheduler extender. The Kubernetes standard scheduler interacts with the Ondat scheduler when placement decisions need to be made.\nThe Kubernetes standard scheduler selects a set of nodes for a placement decision based on nodeSelectors, affinity rules, etc. This list of nodes is sent to the Ondat scheduler which sends back the target node where the Pod shall be placed.\nThe Ondat scheduler logic is provided by a Pod in the Namespace where Ondat Pods are running.\nScheduling process When a Pod needs to be scheduled, the scheduler collects information about all available nodes and the requirements of the Pod. The collected data is then passed through the Filter phase, during which the scheduler predicates are applied to the node data to decide if the given nodes are compatible with the Pod requirements. The result of the filter consists of a list of nodes that are compatible for the given Pod and a list of nodes that aren\u0026rsquo;t compatible.\nThe list of compatible nodes is then passed to the Prioritize phase, in which the nodes are scored based on attributes such as the state. The result of the Prioritize phase is a list of nodes with their respective scores. The more favorable nodes get higher scores than less favorable nodes. The list is then used by the scheduler to decide the final node to schedule the Pod on.\nOnce a node has been selected, the third phase, Bind, handles the binding of the Pod to the Kubernetes apiserver. Once bound, the kubelet on the node provisions the Pod.\nThe Ondat scheduler implement Filter and Prioritization phases and leaves binding to the default Kubernetes scheduler.\nAvailable +------------------+ +------------------+ NodeList \u0026amp; Pod | | Filtered NodeList | | Scored Information | | \u0026amp; Pod Information | | NodeList +--------------------\u0026gt;+ Filter +--------------------\u0026gt;+ Prioritize |---------------\u0026gt; | (Predicates) | | (Priorities) | | | | | +------------------+ +------------------+ Scheduling Rules The Ondat scheduler filters nodes ensuring that the remaining subset fulfill the following prerequisites:\n The node is running Ondat The node is healthy  ","excerpt":"Ondat has the capacity to influence Kubernetes Pod placement decisions to ensure that Pods are ‚Ä¶","ref":"/docs/reference/scheduler/","title":"Ondat Scheduler"},{"body":"Ondat collects telemetry and error reports from Ondat clusters via two different methods for two different purposes.\nTelemetry  Telemetry is made up a DNS version check query and a once per day report. Error reporting is the sentry.io crash dump reporting.  sentry.io Ondat sends crash reports to sentry.io. This information helps our developers monitor and fix crashes. Information is sent to sentry.io when a process inside the Ondat container crashes.\n The crash report contains the signal that triggered the shutdown (e.g. SIGSEGV), the exit code and whether or not the crash generated a core dump.  All Ondat clusters with a routable connection to the internet will send crash reports to sentry.io over tcp/443. Ondat respects environment variables that ProxyFromEnvironment uses.\nAn exhaustive list of information included in the crash report is below:\n Ondat version Crash description string Anonymized Cluster ID Anonymized Node ID  DNS Query Ondat will perform a \u0026ldquo;latest version check\u0026rdquo; using a DNS query in order to inform administrators that a new version is available. Ondat will also send anonymized node IDs, cluster ID and Ondat version information to Ondat using a DNS query. The information that we send in the query is encoded as well as being anonymized. This query allows us to inform Cluster admins when Ondat upgrades are available in the Ondat GUI and in the logs.\nThe DNS query includes:\n Anonymized Ondat Cluster ID Anonymized Ondat node ID Ondat version number  Once Per Day Report The once per day report contains information about the Ondat cluster and Kubernetes versions to help Ondat focus our development efforts on the most popular platforms. The once per day data is encrypted and sent to an Ondat telemetry server so it is never processed outside of Ondat assets.\nAn exhaustive list of information included in the once per day report is below:\n api_call_metrics cluster_disable_crash_reporting cluster_disable_version_check cluster_log_format cluster_log_level cluster_tls_provided k8s_distribution k8s_in_k8s k8s_scheduler_extender_enabled k8s_version node_available_bytes node_capacity node_crash_files_on_disk node_created_at_time node_etcd_config node_etcd_namespacing_enabled node_etcd_tls_enabled node_free_bytes node_health node_http_tls_enabled node_id node_labels node_status node_storageos_version node_system_clock_time node_total_bytes node_version volume_fs_type volume_id volume_labels volume_master_attach volume_master_delete_deployment volume_master_detach volume_master_failover_deployment volume_master_promote volume_master_provision volume_master_recover_replica volume_master_trigger_rejoin volume_metrics volume_placement_strategy volume_provision_source_user_agent volume_replica_delete_deployment volume_replica_failover_deployment volume_replica_promote volume_replica_provision volume_replicas volume_replica_trigger_rejoin volume_size_bytes  Disable Telemetry It is possible to disable telemetry using the GUI, CLI, API, environment variables or the Ondat Cluster Spec.\nOndat Cluster Spec Disable telemetry explicitly through the configurable spec parameters of the StorageOSCluster custom resource.\nEnvironment Variables You can use the following environmental variables to disable or enable telemetry.\nDISABLE_VERSION_CHECK # Disable the DNS version check DISABLE_TELEMETRY # Disable the once per day reporting DISABLE_ERROR_REPORTING # Disable sentry.io crash reports ","excerpt":"Ondat collects telemetry and error reports from Ondat clusters via two different methods for two ‚Ä¶","ref":"/docs/reference/telemetry/","title":"Ondat Telemetry"},{"body":"Policies control access to Ondat namespaces. Policies can be configured at the group or user level so access can be controlled granularly.\nUsers can belong to one or more groups to control their namespace permissions. Additionally user specific policies can be created to grant a user access to a namespace. Users can belong to any number of groups and have any number of user level policies configured.\n ‚ö†Ô∏è Users are created with access to the default namespace. Policies cannot be applied to the default namespace.\n Managing Policies To start creating policies, at least one custom namespace and user are required. For more information on how to create namespaces, see our Namespace guide, and for users see our Users CLI reference.\nIn order to create a policy navigate to \u0026ldquo;Policies\u0026rdquo; in the GUI and select \u0026ldquo;Create Policy\u0026rdquo;. A policy controls access to a variety of Ondat resources and is applied to a user, by placing the user in the policies group.\nIn order to delete a policy, all users must be removed from the policy group before deletion of the policy can be completed.\n","excerpt":"Policies control access to Ondat namespaces. Policies can be configured at the group or user level ‚Ä¶","ref":"/docs/operations/policies/","title":"Policies"},{"body":"PostgreSQL or \u0026ldquo;Postgres\u0026rdquo; is an open source object-relational database management system (ORDBMS).\nPostgres is deployed across a wide variety of platforms with a mix of workloads ranging from small, single-node use cases to large internet-facing clusters with many concurrent users.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. If you need to setup Ondat on Kubernetes then see our guide to installing Ondat on Kubernetes.\nDeploying PostgreSQL on Kubernetes   You can find the latest files in the Ondat use cases repository\ngit clone https://github.com/storageos/use-cases.git storageos-usecases PersistentVolumeClaim and Pod definition excerpts\nkind:PersistentVolumeClaimmetadata:name:pg-datastorageClassName:\u0026#34;storageos\u0026#34;...kind:Podmetadata:name:postgressspec:securityContext:fsGroup:26containers:- name:pgimage:crunchydata/crunchy-postgres:centos7-10.4-1.8.3volumeMounts:- mountPath:/pgdataname:data...volumes:- name:datapersistentVolumeClaim:claimName:pg-dataThis excerpt is from the PersistentVolumeClaim and Pod definition. The pod definition references the pg-data VolumeClaim so storage is dynamically provision storage, using the Ondat storage class. Dynamic provisioning occurs as a volumeMount has been declared with the same name as a Volume Claim.\n  Move into the PostgreSQL examples folder and create the objects\ncd storageos-usecases kubectl create -f ./postgres   Confirm PostgreSQL is up and running.\n$ kubectl get pod postgres-0 -w NAME READY STATUS RESTARTS AGE postgres-0 1/1 Running 0 1m   Connect to the PostgreSQL client pod and connect to the PostgreSQL server through the service.\n$ kubectl exec -it postgres-0 -- psql -h postgres-0.postgres -U primaryuser postgres -c \u0026#34;\\l\u0026#34; Password for user primaryuser: password List of Databases Name | Owner | Encoding | Collate | Ctype | Access privileges +=========================================================================+ postgres | postgres | SQL_ASCII | C | C | template0 | postgres | SQL_ASCII | C | C | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | SQL_ASCII | C | C | =c/postgres + | | | | | postgres=CTc/postgres userdb | postgres | SQL_ASCII | C | C | =Tc/postgres + | | | | | postgres=CTc/postgres+ | | | | | testuser=CTc/postgres (4 rows) The password for the primary user is password. You can see this is set in the ConfigMap file.\n  Configuration If you need custom startup options, you can edit the ConfigMap file 15-postgresd-configmap.yaml with your desired PostgreSQL configuration settings.\n","excerpt":"PostgreSQL or \u0026ldquo;Postgres\u0026rdquo; is an open source object-relational database management system ‚Ä¶","ref":"/docs/usecases/postgres/","title":"PostgreSQL"},{"body":"Prometheus is a popular application used for event monitoring and alerting in Kubernetes.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nDeploying Prometheus on Kubernetes This is the Prometheus use case for Ondat. Following are the steps for creating a Prometheus StatefulSet and using Ondat to provide persistent storage.\n  You can find the latest files in the Ondat use cases repository\ngit clone https://github.com/storageos/use-cases.git storageos-usecases Prometheus Custom Resource definition\napiVersion:monitoring.coreos.com/v1kind:Prometheusmetadata:name:prometheus-storageoslabels:app:prometheus-operatorspec:...storage:volumeClaimTemplate:metadata:name:datalabels:env:prodspec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:ondat-replicatedresources:requests:storage:1GiThis excerpt is from the Prometheus Custom Resource definition. This file contains the VolumeClaimTemplate that will dynamically provision storage, using the Ondat storage class. Dynamic provisioning occurs due to the VolumeClaimTemplate in the Prometheus StatefulSet. The Prometheus StatefulSet is created by the Prometheus Operator, triggered by the creation of the Prometheus resource.\n  Move into the Prometheus examples folder and install the Prometheus Operator and create a Prometheus resource.\ncd storageos-usecases/prometheus ./install-prometheus.sh   Confirm Prometheus is up and running.\n$ kubectl get pods -w -l app=prometheus NAME READY STATUS RESTARTS AGE prometheus-prometheus-storageos-0 3/3 READY 0 1m   You can see the created PVC using.\n$ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE data-prometheus-prometheus-storageos-0 Bound pvc-b6c17c0a-e76b-4a0b-8fc6-46c0e1629210 1Gi RWO ondat-replicated 65m   In the Prometheus deployment script, a service monitor is created. A Service Monitor is a special object that the Prometheus operator uses to create configuration for Endpoints for Prometheus to scrape. Although the name implies that a Service Monitor defines Kubernetes services that will be scraped, Prometheus actually targets the Endpoints that the services point to. The new Prometheus instance will use the storageos-etcd service monitor to start scraping metrics from the storageos-etcd pods. Assuming the storageos cluster was setup using ETCD as pods. For more information about service monitors, have a look at the upstream documentation.\n$ kubectl get servicemonitor NAME AGE storageos-etcd 5d1h   The Prometheus web ui can be accessed by port-forwarding the Prometheus pods port to localhost.\nkubectl port-forward prometheus-prometheus-storageos-0 9090 Then launch a web browser and go to localhost:9090 to access the Prometheus web ui. You can confirm that the storageos-etcd target is configured there.\n  Configuration In the storageos-usecases/prometheus/manifests/prometheus directory there are other example Service Monitors. For more information about Prometheus, check out the prometheus documentation.\n","excerpt":"Prometheus is a popular application used for event monitoring and alerting in Kubernetes.\nBefore you ‚Ä¶","ref":"/docs/usecases/prometheus/","title":"Prometheus"},{"body":"Redis is a popular networked, in-memory, key-value data store with optional durability to disk.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nDeploying Redis on Kubernetes   You can find the latest files in the Ondat use cases repository\ngit clone https://github.com/storageos/use-cases.git storageos-usecases StatefulSet defintion\nkind:StatefulSetmetadata:name:redisspec:selector:matchLabels:app:redisenv:prodserviceName:redisreplicas:1...spec:serviceAccountName:redis...volumeMounts:- name:datamountPath:/bitnami/redis/data...volumeClaimTemplates:- metadata:name:datalabels:env:prodspec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:\u0026#34;storageos\u0026#34;# Ondat storageClass resources:requests:storage:5GiThis excerpt is from the StatefulSet definition. This file contains the VolumeClaim template that will dynamically provision storage, using the Ondat storage class. Dynamic provisioning occurs as a volumeMount has been declared with the same name as a Volume Claim.\n  Move into the Redis examples folder and create the objects\ncd storageos-usecases kubectl create -f ./redis   Confirm Redis is up and running.\n$ kubectl get pods -w -l app=redis NAME READY STATUS RESTARTS AGE redis-0 1/1 Running 0 1m   Connect to the Redis client pod and connect to the Redis server through the service\n$ kubectl exec -it redis-0 -- redis-cli -a password Warning: Using a password with \u0026#39;-a\u0026#39; option on the command line interface may not be safe. 127.0.0.1:6379\u0026gt; CONFIG GET maxmemory 1) \u0026#34;maxmemory\u0026#34; 2) \u0026#34;0\u0026#34;   Configuration If you need custom startup options, you can edit the ConfigMap file 15-redis-configmap.yaml with your desired Redis configuration settings.\n","excerpt":"Redis is a popular networked, in-memory, key-value data store with optional durability to disk. ‚Ä¶","ref":"/docs/usecases/redis/","title":"Redis"},{"body":"Managing Resources for Ondat containers Kubernetes resource requests and limits are two optional Pod properties that allow you to specify how much of a resource a container in a Pod needs or can use. They are two main resources that you can specify requests and limits for, CPU and Memory.\nAs Ondat is an infrastructure component, the health of other applications depends on being able to write to the Ondat volumes. As such it is of paramount importance to avoid restarts of the Ondat DaemonSet Pods. Restarting an Ondat Pod results in the volumes of the node the Ondat Pod is running on being marked as Read Only, and causes the failover of primary volumes on that node to their replicas. After an Ondat Pod restart, once the Ondat DaemonSet Pod is \u0026ldquo;READY\u0026rdquo;, the application Pods running on the node need to be restarted in order to trigger a mount of the filesystem hosted on the Ondat volume and resume normal operations. To avoid restarts of the Ondat main container by Kubernetes due to resource limits being reached, it is recommended to not set resource limits on the Ondat DaemonSet. In addition to avoiding resource limits, Ondat uses a high priority class when the DaemonSet is installed in the \u0026lsquo;storageos\u0026rsquo; namespace. That avoids the DaemonSet Pods of being evicted.\nFor more information about managing resources for containers see the Kubernetes documentation\nDefining Pod resource requests and reservations To add resource requests and reservations to the Ondat DaemonSet configure them in the StorageOSCluster resource.\n","excerpt":"Managing Resources for Ondat containers Kubernetes resource requests and limits are two optional Pod ‚Ä¶","ref":"/docs/reference/resource_requests_and_limits/","title":"Resource Requests and Limits"},{"body":"","excerpt":"","ref":"/search/","title":"Search Results"},{"body":"In this example use case we provide three different strategies for accessing files that have been written to an Ondat persistent volume.\nIn the following examples the \u0026ldquo;application\u0026rdquo; container is the container main, which has a rsync, Nginx or sftp sidecar container. The Ondat volume that the application is writing to will be mounted into the sidecar container so files written by the application are available for export. Files can be exported using Nginx as a web file server, transferred using rsync or accessed via SFTP.\nThe files create a stateful set that can be used AFTER an Ondat cluster has been created. See our guide on how to install Ondat on Kubernetes for more information.\nClone Repository In order to deploy the examples, clone this repository and use kubectl to create the Kubernetes objects.\ngit clone https://github.com/storageos/use-cases.git storageos-usecases cd storageos-usecases/backup  üí° Before deploying the backup-example stateful set we recommend looking through the examples to understand how the different containers are configured\n Exfiltrating files through HTTP   Deploy the Nginx example\n$ kubectl create -f nginx/ service/backup-example created configmap/nginx-config created statefulset.apps/backup-example created pod/busybox created   Check that a backup-example pod is running\n$ kubectl get pods -w -l app=backup-example-nginx NAME READY STATUS RESTARTS AGE backup-example-0 1/1 Running 0 1m   Exec into the main container and write some data to a file\n$ kubectl exec -it backup-example-nginx-0 -c main bash root@backup-example-0:/# echo $(date) \u0026gt; /data/date.txt   Check that the service exists\n$ kubectl get svc backup-example-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE backup-example-nginx ClusterIP 100.65.18.199 \u0026lt;none\u0026gt; 80/TCP 46s   Use wget to access the files served by Nginx. Nginx is sharing files from the same volume that the main application container is writing to. The connection to the Nginx container is made via the backup-example service.\n$ kubectl exec -it busybox -- /bin/wget -q -O- http://backup-example-nginx \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;Index of /\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Index of /\u0026lt;/h1\u0026gt;\u0026lt;hr\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;a href=\u0026#34;/docs/\u0026#34;\u0026gt;/docs/\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;lost%2Bfound/\u0026#34;\u0026gt;lost+found/\u0026lt;/a\u0026gt; 12-Feb-2019 12:32 - \u0026lt;a href=\u0026#34;date.txt\u0026#34;\u0026gt;date.txt\u0026lt;/a\u0026gt; 12-Feb-2019 12:49 29 \u0026lt;/pre\u0026gt;\u0026lt;hr\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ kubectl exec -it busybox -- /bin/wget -q -O- http://backup-example-nginx/date.txt Tue Feb 12 12:49:15 UTC 2019   Depending on what files have been written to the Ondat volume the output of the index file will be different. In the example the date.txt file we created in Step 2 is present on the volume.\nExfiltrating files through Rsync   Deploy the rsync example\n$ kubectl create -f rsync/ service/backup-example created configmap/rsync-config created secret/rsync-credentials created statefulset.apps/backup-example created pod/rsync created   Check that a backup-example pod is running\n$ kubectl get pods -w -l app=backup-example-rsync NAME READY STATUS RESTARTS AGE backup-example-0 1/1 Running 0 1m   Exec into the main container and write some data to a file\n$ kubectl exec -it backup-example-rsync-0 -c main bash root@backup-example-0:/# echo $(date) \u0026gt; /data/date.txt   Check that the service exists\n$ kubectl get svc backup-example-rsync NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE backup-example-rsync ClusterIP 100.65.18.199 \u0026lt;none\u0026gt; 873/TCP 46s   Use rsync to access the files shared by the rsync daemon. rsync is sharing files from the same volume that the main container is writing to. A username and password that are set in the rsync-credentials secret. The secret supplied in the example has the username and password set to username and password.\n$ kubectl exec -it rsync sh / # rsync --list-only rsync://username@backup-example-rsync/share Password: drwxr-xr-x 4,096 2019/02/12 12:49:15 . -rw-r--r-- 29 2019/02/12 12:49:15 date.txt drwx------ 16,384 2019/02/12 12:32:40 lost+found / # rsync -chavzP rsync://username@backup-example-rsync/share/date.txt . Password: receiving incremental file list date.txt 29 100% 28.32kB/s 0:00:00 (xfr#1, to-chk=0/1) sent 43 bytes received 135 bytes 50.86 bytes/sec total size is 29 speedup is 0.16 / # cat date.txt Tue Feb 12 12:49:15 UTC 2019   In the example above the list of available files was shown and a file called date.txt was synchronized to the rsync container.\nExfiltrating files through SFTP   Deploy the sftp example\nkubectl create -f sftp/   Exec into the main container and write some data to a file\n$ kubectl exec -it backup-example-sftp-0 -c main bash root@backup-example-0:/# echo $(date) \u0026gt; /data/date.txt   Check that the service exists\n$ kubectl get svc backup-example-sftp NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE backup-example-sftp ClusterIP 100.70.50.56 \u0026lt;none\u0026gt; 22/TCP 2h   Use SFTP to access the files shared by the SFTP container. If you have made no changes to the sftp-config secret the password is password.\n$ kubectl exec -it sftp -- bash root@sftp:/# sftp alex@backup-example-sftp alex@backup-example-sftp\u0026#39;s password: Connected to backup-example-sftp. sftp\u0026gt; ls date.txt lost+found sftp\u0026gt; get date.txt Fetching /date.txt to date.txt /date.txt 100% 29 15.9KB/s 00:00 sftp\u0026gt; bye root@sftp:/# cat date.txt Tue Feb 12 17:51:32 UTC 2019   In order to do this a SFTP user needs to be configured. The details for the user are stored in the sftp-config secret (see sftp/17-secret.yaml). The secret consists of base64 encoded username:password:uid:guid and the user is chroot\u0026rsquo;ed inside their home directory so the mount point for the Ondat volume in the SFTP container in sftp/20-backup-pod.yaml needs to be configured.\nUsing custom SSH Keys The ConfigMap ssh-key-pub (see sftp/15-configmap.yaml) needs to be populated with a public key. The corresponding private key needs to be base64 encoded and put into the ssh-key-private secret (see sftp/17-secret.yaml). The user to connect as is determined by the user that is configured in the sftp-config configMap. To restrict logins to the SSH key edit the sftp-config secret so it contains no password (user::uid:guid).\n  Connect to the sftp pod and connect through the service to the SFTP container running inside the backup-example pod.\n$ kubectl exec -it sftp -- bash root@sftp:/# sftp -i /home/alex/.ssh/id_rsa alex@backup-example-sftp Connected to backup-example-sftp. sftp\u0026gt; ls date.txt lost+found   ","excerpt":"In this example use case we provide three different strategies for accessing files that have been ‚Ä¶","ref":"/docs/usecases/sidecar-backups/","title":"Sidecar Backups"},{"body":"Issue You are experiencing issues with performing operations to volumes and nodes in an Ondat cluster. Below are some of the operations that you are unable to execute;\n A specific PersistentVolumeClaim (PVC) can‚Äôt be created or deleted successfully.  # Describe the PVC named \u0026#34;my-pvc\u0026#34;. kubectl describe pvc my-pvc # truncated output... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning ProvisioningFailed 27s (x9 over 10m) csi.storageos.com_storageos-csi-helper-f7569f986-6prpq_debad2f4-27a8-4033-81af-7fb2e338afd4 failed to provision volume with StorageClass \u0026#34;storageos\u0026#34;: rpc error: code = DeadlineExceeded desc = context deadline exceeded  Volumes cannot be used (ie, failing to attach and mount) and are reporting a FailedScheduling event.  # Describe the pod \u0026#34;d2\u0026#34;. kubectl describe pod d2 # truncated output... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 4s storageos-scheduler Post \u0026#34;http://storageos:5705/v2/k8s/scheduler/filter\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers)  Volumes are not successfully failing over. Nodes cannot be added or deleted.  In addition, when reviewing the logs for the Ondat daemonset, you may see the following error and warning messages;\n# Get the logs for the Ondat daemonset/ kubectl logs daemonsets.apps/storageos-node --namespace=storageos # truncated output... {\u0026#34;auth_req_username\u0026#34;:\u0026#34;storageos\u0026#34;,\u0026#34;error\u0026#34;:\u0026#34;context deadline exceeded\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;error while performing login\u0026#34;,\u0026#34;req_id\u0026#34;:\u0026#34;4ba51f16-0f69-4b4f-bb83-0d7f9b58ff0c\u0026#34;,\u0026#34;req_ip\u0026#34;:\u0026#34;10.73.0.217:49118\u0026#34;,\u0026#34;req_xff\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-13T18:48:54.796090712Z\u0026#34;} {\u0026#34;error\u0026#34;:\u0026#34;context deadline exceeded\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;storing remote capacity failed\u0026#34;,\u0026#34;node_id\u0026#34;:\u0026#34;d8d3d8dc-c3cd-4f97-86fb-4706d01dff33\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-13T18:49:03.674273759Z\u0026#34;} {\u0026#34;error\u0026#34;:\u0026#34;context deadline exceeded\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;warning\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;failed to update node size value in remote store\u0026#34;,\u0026#34;node_id\u0026#34;:\u0026#34;d8d3d8dc-c3cd-4f97-86fb-4706d01dff33\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-13T18:49:03.674370036Z\u0026#34;} {\u0026#34;error\u0026#34;:\u0026#34;context deadline exceeded\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;failed to fetch latest available licence information\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-13T18:49:03.675980929Z\u0026#34;} {\u0026#34;error\u0026#34;:\u0026#34;context deadline exceeded\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;warning\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;lock operation failure - is etcd healthy?\u0026#34;,\u0026#34;node_id\u0026#34;:\u0026#34;d8d3d8dc-c3cd-4f97-86fb-4706d01dff33\u0026#34;,\u0026#34;store_lock_key\u0026#34;:\u0026#34;storageos/default/v1/locks/node/d8d3d8dc-c3cd-4f97-86fb-4706d01dff33\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-13T18:49:11.026773582Z\u0026#34;} {\u0026#34;error\u0026#34;:\u0026#34;context deadline exceeded\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;abandoning expired lock\u0026#34;,\u0026#34;node_id\u0026#34;:\u0026#34;d8d3d8dc-c3cd-4f97-86fb-4706d01dff33\u0026#34;,\u0026#34;store_lock_key\u0026#34;:\u0026#34;storageos/default/v1/locks/node/d8d3d8dc-c3cd-4f97-86fb-4706d01dff33\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-13T18:49:11.026865788Z\u0026#34;} # Use jq for clearer formatting and only show the error messages in the daemonset pods. kubectl logs daemonsets.apps/storageos-node --namespace=storageos | jq \u0026#39;{msg: .msg, error: .error}\u0026#39; { \u0026#34;msg\u0026#34;: \u0026#34;storing remote capacity failed\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;context deadline exceeded\u0026#34; } { \u0026#34;msg\u0026#34;: \u0026#34;failed to update node size value in remote store\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;context deadline exceeded\u0026#34; } { \u0026#34;msg\u0026#34;: \u0026#34;failed to fetch latest available licence information\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;context deadline exceeded\u0026#34; } { \u0026#34;msg\u0026#34;: \u0026#34;lock operation failure - is etcd healthy?\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;context deadline exceeded\u0026#34; } { \u0026#34;msg\u0026#34;: \u0026#34;abandoning expired lock\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;context deadline exceeded\u0026#34; } { \u0026#34;msg\u0026#34;: \u0026#34;error during authentication\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;context deadline exceeded\u0026#34; } Root Cause  The error messages that are returned from the Ondat daemonset daemonsets.apps/storageos-node indicates that the daemonset pods cannot successfully communicate with the etcd cluster.  Resolution To resolve the operations issues, this will require assessing and repairing the etcd cluster and ensuring that the cluster is healthy again - whether the issue is etcd, your network configuration, or because the nodes where Ondat is deployed are overutilised to the point where they cannot fulfil requests to and from etcd successfully.\n Ensure that your etcd cluster is running and is healthy.  etcdctl member list -wtable etcdctl endpoint status -wtable etcdctl endpoint health -wtable   Check to see if your etcd cluster has lost quorum by reviewing the etcd logs. Check to see if your etcd cluster is routable. Check to see if your etcd cluster is in a Read Only (RO) state that has been caused by an etcd alarm.  etcdctl alarm list   Check to see if your etcd cluster is struggling to write to disk fast enough (etcd is sensitive to latency on disk).  Review the logs and prometheus monitoring metrics for disk_wal_fsync and db_fsync and check to see if there is any performance degradation. (ie, orders of seconds rather than milliseconds or nanoseconds).   If your etcd cluster is healthy and routable, check to see if the nodes running the Ondat daemonset pods daemonsets.apps/storageos-node are healthy.  Are the pods under unusual load? Are there any errors being reported in one daemonset pod or more?    ","excerpt":"Issue You are experiencing issues with performing operations to volumes and nodes in an Ondat ‚Ä¶","ref":"/docs/knowledgebase/solution-cannot-perform-ondat-operations-to-volumes-or-nodes/","title":"Solution - Cannot Perform Operations To Volumes Or Nodes"},{"body":"Issue  You are experiencing an issue where your Kubernetes resource that is using an Ondat RWX volume is stuck in ContainerCreating state. Below is example outputs of a deployment experiencing this error message;  # Get the status of the pods in the \u0026#34;ondat-files\u0026#34; namespace. kubectl get pod --namespace=ondat-files NAME READY STATUS RESTARTS AGE ondat-files-deployment-rwx-d68b4866d-khl2d 0/1 ContainerCreating 0 13m ondat-files-deployment-rwx-d68b4866d-twzrt 0/1 ContainerCreating 0 13m ondat-files-deployment-rwx-d68b4866d-z5xhm 0/1 ContainerCreating 0 13m # Get the status of the deployment, notice that the 0 out 3 pods are READY. kubectl get deployments.apps --namespace ondat-files NAME READY UP-TO-DATE AVAILABLE AGE ondat-files-deployment-rwx 0/3 3 0 18m  Upon describing one of the replica pods of the deployment to further investigate, you may notice the following error message in the Events: section \u0026raquo; rpc error: code = Internal desc = internal error: the \u0026quot;nfs\u0026quot; licence feature is required to perform the requested operation.  # Describe one of the affected replica pods of the deployment kubectl describe pod ondat-files-deployment-rwx-d68b4866d-twzrt --namespace ondat-files # truncated output... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 18m storageos-scheduler Successfully assigned ondat-files/ondat-files-deployment-rwx-d68b4866d-twzrt to aks-default-15645363-vmss000000 Warning FailedMount 14m kubelet Unable to attach or mount volumes: unmounted volumes=[ondat-files], unattached volumes=[kube-api-access-ng2c5 ondat-files]: timed out waiting for the condition Warning FailedMount 67s (x7 over 16m) kubelet Unable to attach or mount volumes: unmounted volumes=[ondat-files], unattached volumes=[ondat-files kube-api-access-ng2c5]: timed out waiting for the condition Warning FailedAttachVolume 22s (x17 over 18m) attachdetach-controller AttachVolume.Attach failed for volume \u0026#34;pvc-41f429ff-3fa9-4361-b7bc-c55f869499ae\u0026#34; : rpc error: code = Internal desc = internal error: the \u0026#34;nfs\u0026#34; licence feature is required to perform the requested operation Root Cause  In order for end user to be able to successfully provision RWX volumes, an Ondat cluster must be licensed with either a Community, Standard or Enterprise Edition. RWX volume provisioning is available in the free Ondat Community Edition.  For more information on licences, review the Ondat pricing page.    Resolution  To get the Community Edition licence, register your cluster through the Ondat SaaS platform and generate a licence so that it can be applied to your cluster.   üí° If you already have an Ondat cluster that is connected to the Ondat SaaS Platform, you can apply the licence automatically to the connected cluster following the steps below;\n  Login to the Ondat SaaS Platform ¬ª Organisation ¬ª Licences ¬ª Generate A New Licence ¬ª Choose an existing cluster ¬ª Select the cluster that you want to apply a licence to. Once the cluster has been successfully licensed, end users will be able to create resources that use Ondat RWX volumes.  ","excerpt":"Issue  You are experiencing an issue where your Kubernetes resource that is using an Ondat RWX ‚Ä¶","ref":"/docs/knowledgebase/solution-deployment-using-rwx-volume-is-stuck-in-a-container-creating-state/","title":"Solution - Deployment Using A RWX Volume Is Stuck In A 'ContainerCreating' State"},{"body":"Issue  You are experiencing a ProvisioningFailed event error message when you try to create a PersistentVolumeClaim (PVC) and it remains in a Pending state, thus preventing the pods that needs to mount that PVC from successfully starting up. Below is an example of the error message that shows up in the Events: log of the PVC.  # Get the status of the PVC. kubectl get pvc vol-1 --namespace example-namespace NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE vol-1 Pending storageos 7s # Describe the PVC that is stuck in a Pending state. kubectl describe pvc vol-1 --namespace example-namespace # truncated output. Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning ProvisioningFailed 7s (x2 over 18s) persistentvolume-controller Failed to provision volume with StorageClass \u0026#34;storageos\u0026#34;: Get http://storageos-cluster/version: failed to dial all known cluster members, (10.233.59.206:5705) Root Cause For non Container Storage Interface (CSI) installations of Ondat, Kubernetes uses the Ondat API endpoint to communicate. If that communication fails, relevant actions such as create or mount volume can‚Äôt be transmitted to Ondat, hence the PVC will remain in Pending state. Ondat never received the action to perform, so it never sent back an acknowledgement.\n In this case, the Events: message indicates that Ondat API is not responding, implying that Ondat is not running. For Kubernetes to confirm that Ondat pods are READY, health checks must be passed first.  Resolution  Check and ensure that Ondat pods deployed in the cluster are READY, ie 1/1 instead of 0/1:  # check the status of Ondat pods. kubectl --namespace storageos get pods --selector app=storageos NAME READY STATUS RESTARTS AGE storageos-node-qrqkj 0/1 Running 0 1m storageos-node-s4bfv 0/1 Running 0 1m storageos-node-vcpfx 0/1 Running 0 1m storageos-node-w98f5 0/1 Running 0 1m  If the Ondat pods are not READY, the service will not forward traffic to the API they serve thus, the PVC will remain in Pending state until Ondat pods are available.   üí° Kubernetes will keep trying to ensure that startup containers successfully. If a PVC is created before Ondat finish starting, the PVC will be created eventually once the Ondat pods are running.\n  Ondat\u0026rsquo;s health check gives 60 seconds of grace period before reporting as READY. If Ondat successfully startups after that period, the volume will be created when Ondat finishes its bootstrap. If Ondat pods are still not in a READY state after waiting for some time, a recommendation would be to investigate further into the Ondat deployment and ensure that there is no mis-configuration issue.  ","excerpt":"Issue  You are experiencing a ProvisioningFailed event error message when you try to create a ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-failed-to-dial-all-known-cluster-members-provisioning-volumes/","title":"Solution - Troubleshooting 'failed to dial all known cluster members' Error When Provisioning Volumes"},{"body":"Issue  You are experiencing an issue where a PersistentVolumeClaim (PVC) that has been created, continues to remain in a Pending state - thus preventing pods from successfully starting up as they require the said PVC to mount first. Below is an example output of the error message from the Events: section of an affected PVC;  # Describe the PVC that is stuck in a Pending state. kubectl describe pvc vol-1 --namespace example-namespace # Truncated output. Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning ProvisioningFailed 13s (x2 over 28s) persistentvolume-controller Failed to provision volume with StorageClass \u0026#34;storageos\u0026#34;: failed to get secret from [\u0026#34;storageos\u0026#34;/\u0026#34;storageos-api\u0026#34;] Root Cause For non Container Storage Interface (CSI) installations of Ondat, Kubernetes uses the Ondat API endpoint to communicate. If that communication fails, relevant actions such as create or mount volume can‚Äôt be transmitted to Ondat, hence the PVC will remain in Pending state. Ondat never received the action to perform, so it never sent back an acknowledgement.\n The StorageClass provisioned for Ondat references a Kubernetes Secret from where it retrieves the API endpoint and the authentication parameters. If that secret is incorrect or missing, the connections won‚Äôt be established. It is common to see the secret has been deployed in a different namespace from where the StorageClass expects it, or that is has been deployed with a different name.  Resolution   Ensure that you have successfully deployed Ondat onto your Kubernetes or OpenShift cluster. If you are using the generated deployment manifests provided for declarative installations to deploy Ondat, make sure that the StorageClass parameters and the Secret reference match.\n  Check and ensure that the StorageClass parameters defined point to the correct location.\n  # Describe the Ondat StorageClass.kubectl get storageclass storageos --output yamlapiVersion:storage.k8s.io/v1kind:StorageClassmetadata:labels:app:storageosapp.kubernetes.io/component:storageclassname:storageosallowVolumeExpansion:trueprovisioner:csi.storageos.comparameters:csi.storage.k8s.io/fstype:ext4csi.storage.k8s.io/secret-name:storageos-api # Secret name.csi.storage.k8s.io/secret-namespace:storageos # Secret namespace. üí° Note that the parameters specify secret-namespace and secret-name.\n  Check and ensure that the secret exists in the namespace.  # Check the secrets that are available in the \u0026#34;storageos\u0026#34; namespace. kubectl get secrets --namespace storageos NAME TYPE DATA AGE sh.helm.release.v1.ondat.v1 helm.sh/release.v1 1 5h10m storageos-etcd-0 Opaque 3 5h9m storageos-etcd-1 Opaque 3 5h9m storageos-etcd-2 Opaque 3 5h9m storageos-etcd-ca Opaque 2 5h10m storageos-etcd-client Opaque 3 5h10m storageos-etcd-secret Opaque 3 5h9m storageos-iot-keys Opaque 2 5h8m storageos-operator-webhook Opaque 4 5h10m storageos-portal-client Opaque 4 5h10m storageos-webhook Opaque 4 5h8m # Check to see if \u0026#34;storageos-api\u0026#34; secret exists. kubectl get secrets storageos-api --namespace storageos # Missing secret. No resources found. Error from server (NotFound): secrets \u0026#34;storageos-api\u0026#34; not found # The expected output returned to look like the example provided below: NAME TYPE DATA AGE storageos-api kubernetes.io/storageos 2 5h11m ","excerpt":"Issue  You are experiencing an issue where a PersistentVolumeClaim (PVC) that has been created, ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-failed-to-get-secret-from-error-when-provisioning-volumes/","title":"Solution - Troubleshooting 'failed to get secret from' Error When Provisioning Volumes"},{"body":"Issue When attempting to deploy Ondat into an OpenShift or Kubernetes cluster, you notice that the Ondat daemonset set pods are stuck in a Init:Err state. Below is an example of the error message being reported under the STATUS column.\n# Get the status of the pods in the \u0026#34;storageos\u0026#34; namespace. kubectl get pods --namespace storageos NAME READY STATUS RESTARTS AGE # Truncated output... storageos-node-8fhf6 0/3 Init:Err 0 6s storageos-node-8z77g 0/3 Init:Err 0 6s storageos-node-pzvp7 0/3 Init:Err 0 6s storageos-node-qbjbr 0/3 Init:Err 0 6s storageos-node-vkj92 0/3 Init:Err 0 6s # Truncated output... Root Cause The root cause of this issue is due to missing Linux-IO (LIO) related kernel modules on worker nodes that are required for Ondat to successfully start up and run.\n The Ondat daemonset will attempt to load the required kernel modules onto the worker nodes. If Ondat is unsuccessful in loading the kernel modules, an Init:Err error will be returned and stop Ondat from starting up without the required kernel modules.  Resolution   Check and ensure that the logs of the init container report any kernel modules that Ondat tried to load:\n# Chec the logs of the \u0026#34;init\u0026#34; container to list the missing kernel modules required for Ondat to run. kubectl --namespace storageos logs storageos-node-8z77g --container init # Truncated output... Checking configfs configfs mounted on sys/kernel/config Module target_core_mod is not running executing modprobe -b target_core_mod Module tcm_loop is not running executing modprobe -b tcm_loop modprobe: FATAL: Module tcm_loop not found. # \u0026#34;tcm_loop\u0026#34; kernel module is missing.   End users can install the linux-image-extra-$(uname -r) package for your distribution which contains extra kernel modules that may have been left out of the base kernel package. End user can also use modprobe to load the required kernel modules:\n# Ensure that \u0026#34;kmod\u0026#34; is installed. sudo apt install kmod # Debian based distributions. sudo dnf install kmod # Red Hat based distributions. # Use \u0026#34;modprobe\u0026#34; to load the kernel modules below on the worker nodes were Ondat will run. modprobe --all target_core_mod tcm_loop configfs target_core_user uio  üí° For more information on the required kernel modules for Ondat, review the Ondat Prerequisites page.\n   Once the kernel modules have been successfully installed on the nodes, restart the Ondat daemonset pods by deleting the pods and let Kubernetes recreate the pods, which will detect the new system changes on the nodes.\n  ","excerpt":"Issue When attempting to deploy Ondat into an OpenShift or Kubernetes cluster, you notice that the ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-init-error-status-error-message-after-deploying-ondat/","title":"Solution - Troubleshooting 'Init:Error' Status Error Message After Deploying Ondat"},{"body":"Issue When attempting to deploy Ondat into an OpenShift or Kubernetes cluster, you notice that the Ondat daemonset set pods are unable to start. Upon reviewing the logs of one of the Ondat daemonset pods, there is WARN and FATAL log entry that was reported:\n# Truncated output. category=lio level=WARN msg=\u0026#34;Runtime error checking stage \u0026#39;Start TCMU and create device\u0026#39;: /sys/module/target_core_user is missing, is kernel configfs present and target_core_user loaded?\u0026#34; category=lio level=FATAL msg=\u0026#34;liocheck: FAIL (platform not supported, see previous error messages)\u0026#34; Root Cause The root cause of this issue is due to one or more of the required Linux-IO (LIO) related kernel modules have not been successfully loaded onto the worker nodes where the Ondat daemonset will run.\nResolution  Ensure that the following kernel modules are loaded onto the worker nodes where an Ondat daemonset pod will run.  # Check to see if you can successfully find and list the kernel modules that are required for Ondat to run. lsmod | egrep \u0026#34;^tcm_loop|^target_core_mod|^target_core_user|^configfs|^uio\u0026#34;  End users can install the linux-image-extra-$(uname -r) package for your distribution which contains extra kernel modules that may have been left out of the base kernel package. End user can also use modprobe to load the required kernel modules:  # Ensure that \u0026#34;kmod\u0026#34; is installed. sudo apt install kmod # Debian based distributions. sudo dnf install kmod # Red Hat based distributions. # Use \u0026#34;modprobe\u0026#34; to load the kernel modules below on the worker nodes were Ondat will run. modprobe --all target_core_mod tcm_loop configfs target_core_user uio  üí° For more information on the required kernel modules for Ondat, review the Ondat Prerequisites page.\n  Once the kernel modules have been successfully installed on the nodes, restart the Ondat daemonset pods by deleting the pods and let Kubernetes recreate the pods, which will detect the new system changes on the nodes.  ","excerpt":"Issue When attempting to deploy Ondat into an OpenShift or Kubernetes cluster, you notice that the ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-liocheck-fail-platform-not-supported-see-previous-error-messages-after-deploying-ondat/","title":"Solution - Troubleshooting 'liocheck: FAIL (platform not supported, see previous error messages)' Error Message After Deploying Ondat"},{"body":"Issue You are experiencing an issue where you get the following error message \u0026raquo; no such file or directory being displayed in the Events: section of a pod - causing it to be stuck in a Pending state. Below is an example output of the error message upon describing the affected pod.\n# Describe the affected pod to get more information from the \u0026#34;Events:\u0026#34; section. kubectl describe pod affected-pod-name # Truncated output. Events: (...) Normal Scheduled 11s default-scheduler Successfully assigned default/d1 to node3 Warning FailedMount 4s (x4 over 9s) kubelet, node3 MountVolume.SetUp failed for volume \u0026#34;pvc-f2a49198-c00c-11e8-ba01-0800278dc04d\u0026#34; : stat /var/lib/storageos/volumes/d9df3549-26c0-4cfc-62b4-724b443069a1: no such file or directory Root Cause There are two root causes on why this issue may arise:\n The Ondat DEVICE_DIR location is wrongly configured when using kubelet as a container. Mount Propagation is not enabled.  Resolution  Option 1 - Correctly Configure The DeviceDir/SharedDir Path  Some Kubernetes distributions such as Rancher or different deployments of OpenShift may deploy the kubelet as a container. Because of this, the device files that Ondat creates to mount into the containers need to be visible to the kubelet. Ondat can be configured to share the device directory. Modern Kubernetes and OpenShift deployments use the Container Storage Interface (CSI) to handle the complexity internally. To resolve this issue, check and confirm that the SharedDir key-value pair in the Ondat Custom Resource is not blank. If it is blank, edit the Ondat Custom Resource to point the SharedDir key to \u0026raquo; /var/lib/kubelet/plugins/kubernetes.io~storageos as demonstrated below.    # Get more information about the Ondat Custom Resource. kubectl --namespace storageos describe storageosclusters.storageos.com | grep \u0026#34;Shared Dir\u0026#34; Shared Dir: # This key-value pair should have a defined path. # Edit the Custom Resource and ensure that the SharedDir key points to \u0026#34;/var/lib/kubelet/plugins/kubernetes.io~storageos\u0026#34; kubectl --namespace storageos edit storageosclusters.storageos.com # Truncated output. spec: sharedDir: \u0026#39;/var/lib/kubelet/plugins/kubernetes.io~storageos\u0026#39; # This is required if the \u0026#34;kubelet\u0026#34; is running as a container in your cluster. # Truncated output. üí° For more information on how to configure the Ondat Custom Resource, review the Ondat Operator Examples page.\n Option 2 - Enable Mouth Propagation   üí° The guidance below only applies if Option 1 has been configured correctly.\n  For older versions of Kubernetes \u0026amp; OpenShift, users need to enable mount propagation, as it is not enabled by default. Most Kubernetes distributions allow MountPropagation to be enabled using Feature Gates. Rancher, specifically, needs to enable it in the ‚ÄúView in API‚Äù section of your cluster. You need to edit the section rancherKubernetesEngineConfig to enable the kubelet feature gate. If your cluster is NOT using the kubelet as a container - ssh into one of the nodes and check if \u0026raquo; /var/lib/storageos/volumes is empty. If the directory is empty, exec into any of the Ondat daemonset pods and check the same directory to further verify if the directory inside the container and the device files are visible. If they are visible in the container, check ensure that mount propagation is enabled.  # ssh into one of the nodes to check if the directory and device files exist (the directory should not be empty). ls /var/lib/storageos/volumes/ # exec into one any of the Ondat daemonset pods to check if the directory and directory and device files exist. kubectl --namespace storageos exec storageos-node-mvbtw --container storageos -- ls -l /var/lib/storageos/volumes # Output. bst-196004 d529b340-0189-15c7-f8f3-33bfc4cf03fa ff537c5b-e295-e518-a340-0b6308b69f74  If your cluster is using the kubelet as a container - ssh into one of the nodes and check if \u0026raquo; /var/lib/kubelet/plugins/kubernetes.io~storageos/devices is empty. If the directory is empty, exec into any of the Ondat daemonset pods and check the same directory to further verify if the directory inside the container and the device files are visible. If they are visible in the container, check and ensure that mount propagation is enabled.  # ssh into one of the nodes to check if the directory and device files exist (the directory should not be empty). ls /var/lib/kubelet/plugins/kubernetes.io~storageos/devices # exec into one any of the Ondat daemonset pods to check if the directory and directory and device files exist. kubectl --namespace storageos exec storageos-node-mvbtw --container storageos -- ls -l /var/lib/kubelet/plugins/kubernetes.io~storageos/devices # Output. bst-196004 d529b340-0189-15c7-f8f3-33bfc4cf03fa ff537c5b-e295-e518-a340-0b6308b69f74 References  Kubelet - Kubernetes Reference Documentation. Volumes - Mount Propagation - Kubernetes Documentation. Feature Gates - Kubernetes Documentation.  ","excerpt":"Issue You are experiencing an issue where you get the following error message \u0026raquo; no such file ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-no-such-file-or-directory-error-message-when-mounting-a-volume-to-a-pod/","title":"Solution - Troubleshooting 'no such file or directory' Error Message When Mounting A Volume To A Pod"},{"body":"Issue After deploying a stateful application into an Ondat cluster, you experience an issue where provisioning Ondat volume for the stateful application is stuck in a Pending state.\n Upon further investigation into the persistent volume claims, the Events: section reports an failed to provision volume with StorageClass \u0026quot;storageos\u0026quot;: rpc error: code = OutOfRange desc = unsupported capacity size: 1000000000 error message.  # Describe the persistent volume claims in a \u0026#34;Pending\u0026#34; state to get more information about the issue.$ kubectl describe pvc --namespace pgoName:cluster1Namespace:pgoStorageClass:storageosStatus:PendingVolume:Labels:pg-cluster=cluster1vendor=crunchydataAnnotations: storageos.com/storageclass:81e66e90-9140-47ac-8648-c17bbdb7ab8avolume.beta.kubernetes.io/storage-provisioner:csi.storageos.comvolume.kubernetes.io/storage-provisioner:csi.storageos.comFinalizers:[kubernetes.io/pvc-protection]Capacity:Access Modes:VolumeMode:FilesystemUsed By:\u0026lt;none\u0026gt;Events:Type Reason Age From Message---- ------ ---- ---- -------Normal Provisioning 4m10s (x10 over 10m) csi.storageos.com_storageos-csi-helper-6bf49c4bd5-fb4wn_ac8d4cb4-3ac4-4766-9cef-2037af393fef External provisioner is provisioning volume for claim \u0026#34;pgo/cluster1\u0026#34;Warning ProvisioningFailed 4m8s (x10 over 10m) csi.storageos.com_storageos-csi-helper-6bf49c4bd5-fb4wn_ac8d4cb4-3ac4-4766-9cef-2037af393fef failed to provision volume with StorageClass \u0026#34;storageos\u0026#34;: rpc error: code = OutOfRange desc = unsupported capacity size: 1000000000Normal ExternalProvisioning 44s (x42 over 10m) persistentvolume-controller waiting for a volume to be created, either by external provisioner \u0026#34;csi.storageos.com\u0026#34; or manually created by system administratorName:cluster1-pgbr-repoNamespace:pgoStorageClass:storageosStatus:PendingVolume:Labels:pg-cluster=cluster1vendor=crunchydataAnnotations: storageos.com/storageclass:81e66e90-9140-47ac-8648-c17bbdb7ab8avolume.beta.kubernetes.io/storage-provisioner:csi.storageos.comvolume.kubernetes.io/storage-provisioner:csi.storageos.comFinalizers:[kubernetes.io/pvc-protection]Capacity:Access Modes:VolumeMode:FilesystemUsed By:cluster1-backrest-shared-repo-77b9566957-f8jfvEvents:Type Reason Age From Message---- ------ ---- ---- -------Normal Provisioning 4m10s (x10 over 10m) csi.storageos.com_storageos-csi-helper-6bf49c4bd5-fb4wn_ac8d4cb4-3ac4-4766-9cef-2037af393fef External provisioner is provisioning volume for claim \u0026#34;pgo/cluster1-pgbr-repo\u0026#34;Warning ProvisioningFailed 4m9s (x10 over 10m) csi.storageos.com_storageos-csi-helper-6bf49c4bd5-fb4wn_ac8d4cb4-3ac4-4766-9cef-2037af393fef failed to provision volume with StorageClass \u0026#34;storageos\u0026#34;: rpc error: code = OutOfRange desc = unsupported capacity size: 1000000000Normal ExternalProvisioning 29s (x42 over 10m) persistentvolume-controller waiting for a volume to be created, either by external provisioner \u0026#34;csi.storageos.com\u0026#34; or manually created by system administratorRoot Cause The cause of this error message is due to the usage of powers of 10 storage size units \u0026raquo; (ie, E, P, T, G, M, k ) defined in your stateful application manifests instead of using powers of 2 storage size units \u0026raquo; (ie, Ei, Pi, Ti, Gi, Mi, Ki).\n 1 kilobyte (symbol kB) == 1,000 bytes, whereas 1 kibibyte (symbol KiB) == 1,024 bytes.  From the vmstat man page;\n All linux blocks are currently 1024 bytes. Old kernels may report blocks as 512 bytes, 2048 bytes, or 4096 bytes. Since procps 3.1.9, vmstat lets you choose units (k, K, m, M). Default is K (1024 bytes) in the default mode.\n Ondat conforms to using the default kernel block size \u0026ndash; 1024 bytes as compared to 1000 bytes.\nResolution To resolve this issue, end users can either;\n Option 1 - Upgrade Ondat to release v2.8.0 or greater.  If users would like to continue to use powers of 10 storage sizing units, ensure that you Ondat cluster is on version v2.8.0 or greater.   Option 2 - Change you manifests to use powers of 2 storage sizing units.  Users can modify their manifests to use Ei, Pi, Ti, Gi, Mi, Ki storage sizing units to allow for volumes to be successfully provisioned.    References  Byte, Multiple-byte Units - Wikipedia Resource Units In Kubernetes - Kubernetes Documentation Kubernetes API, Common Definitions, Quantity - Kubernetes Documentation  ","excerpt":"Issue After deploying a stateful application into an Ondat cluster, you experience an issue where ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-outofrange-desc-unsupported-capacity-size-provisioning-ondat-volumes/","title":"Solution - Troubleshooting 'OutOfRange desc = unsupported capacity size' Error When Provisioning Volumes"},{"body":"Issue  When reviewing the status of the Ondat daemonset pods named storageos-node-xxxx, the pods are fail to startup and are stuck in a CrashLoopBackOff state loop.  # Get the pods in the \u0026#34;storageos\u0026#34; namespace kubectl get pods --namespace storageos storageos storageos-node-6v9x2 3/3 Running 2 (16s ago) 55s storageos storageos-node-g7vhn 2/3 CrashLoopBackOff 1 (14s ago) 55s storageos storageos-node-ph567 3/3 Running 2 (17s ago) 55s storageos storageos-node-tw8fk 2/3 CrashLoopBackOff 1 (12s ago) 55s storageos storageos-node-xtvgd 3/3 Running 2 (12s ago) 55s  Upon reviewing the logs for one of the failing daemonset pods, there is an \u0026quot;unable to connect to etcd\u0026quot; error message and \u0026quot;failed to initialise store client\u0026quot; error message that shows up before the pod shutsdown and restarts.  # Check the logs of a Ondat daemonset that is in a \u0026#34;CrashLoopBackOff\u0026#34; loop. kubectl logs storageos-node-tw8fk --namespace storageos {\u0026#34;endpoints\u0026#34;:[\u0026#34;http://10.73.16.8:2379\u0026#34;],\u0026#34;error\u0026#34;:\u0026#34;context deadline exceeded\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;unable to connect to etcd\u0026#34;,\u0026#34;store\u0026#34;:\u0026#34;etcd\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-13T19:17:35.556128015Z\u0026#34;} {\u0026#34;error\u0026#34;:\u0026#34;failed to instantiate ETCD: context deadline exceeded\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;failed to initialise store client\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-13T19:17:35.55625352Z\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;shutting down\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-13T19:17:35.556274893Z\u0026#34;} Root Cause  This issue is cause by the Ondat daemonset pods not being able to connect to the etcd cluster. This is generally caused by etcd being unreachable due to network partitioning or misconfiguration.  Resolution  Ensure that your etcd cluster is healthy. Ensure that etcd is running. Ensure that the etcd URL that is set in the StorageOSCluster custom resource is correct and it includes the port number. Ensure that the etcd peers are routable from the etcd advertise addresses of each peer, and not only from a load balancer. Ensure that etcd is routable from the network where the worker nodes reside.  ","excerpt":"Issue  When reviewing the status of the Ondat daemonset pods named storageos-node-xxxx, the pods are ‚Ä¶","ref":"/docs/knowledgebase/solution-unable-to-connect-to-etcd/","title":"Solution - Troubleshooting 'unable to connect to etcd' Error Message"},{"body":"Issue When attempting to deploy Ondat into an OpenShift cluster, you notice that Ondat daemonset pods are missing in the project where Ondat is supposed to reside in. Below is the example of the Events: error message that shows up when you investigate further into why the daemonset is not running:\n# Get the status of the pods in the \u0026#34;storageos\u0026#34; project. oc get pods No resources found. # Describe the Ondat daemonset in the \u0026#34;storageos\u0026#34; project. oc describe daemonset storageos # Truncated output. Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedCreate 0s (x12 over 10s) daemonset-controller Error creating: pods \u0026#34;storageos-\u0026#34; is forbidden: unable to validate against any security context constraint: [provider restricted: .spec.securityContext.hostNetwork: Invalid value: true: Host network is not allowed to be used provider restricted: .spec.securityContext.hostPID: Invalid value: true: Host PID is not allowed to be used spec.volumes[0]: Invalid value: \u0026#34;hostPath\u0026#34;: hostPath volumes are not allowed to be used spec.volumes[1]: Invalid value: \u0026#34;hostPath\u0026#34;: hostPath volumes are not allowed to be used spec.volumes[2]: Invalid value: \u0026#34;hostPath\u0026#34;: hostPath volumes are not allowed to be used spec.volumes[3]: Invalid value: \u0026#34;hostPath\u0026#34;: hostPath volumes are not allowed to be used spec.initContainers[0].securityContext.privileged: Invalid value: true: Privileged containers are not allowed capabilities.add: Invalid value: \u0026#34;SYS_ADMIN\u0026#34;: capability may not be added spec.initContainers[0].securityContext.hostNetwork: Invalid value: true: Host network is not allowed to be used spec.initContainers[0].securityContext.containers[0].hostPort: Invalid value: 5705: Host ports are not allowed to be used spec.initContainers[0].securityContext.hostPID: Invalid value: true: Host PID is not allowed to be used spec.containers[0].securityContext.privileged: Invalid value: true: Privileged containers are not allowed capabilities.add: Invalid value: \u0026#34;SYS_ADMIN\u0026#34;: capability may not be added spec.containers[0].securityContext.hostNetwork: Invalid value: true: Host network is not allowed to be used spec.containers[0].securityContext.containers[0].hostPort: Invalid value: 5705: Host ports are not allowed to be used spec.containers[0].securityContext.hostPID: Invalid value: true: Host PID is not allowed to be used] Root Cause The root cause of this issue is due to the default Security Context Constraints (SCCs) polices in your OpenShift cluster. By default, the polices forbid any pod without an explicitly, defined policy for the ServiceAccount used by Ondat.\nResolution  Check and ensure that the Ondat ServiceAccount has the correct permissions to be able to successfully create objects.  # Get more information about the ServiceAccounts that are under the \u0026#34;privileged\u0026#34; SCC. oc get scc privileged --output yaml # Truncated output. users: - system:admin - system:serviceaccount:openshift-infra:build-controller - system:serviceaccount:management-infra:management-admin - system:serviceaccount:management-infra:inspector-admin - system:serviceaccount:tiller:tiller If Ondat\u0026rsquo;s ServiceAccount \u0026raquo; system:serviceaccount:storageos:storageos does not show up as demonstrated in in the command above, the next step will be to add the ServiceAccount to the privileged SCC as demonstrated below:  # Add Ondat ServiceAccount to the \u0026#34;privileged\u0026#34; SCC. oc adm policy add-scc-to-user privileged system:serviceaccount:storageos:storageos References  Managing security context constraints - OpenShift Documentation Understanding and creating service accounts - OpenShift Documentation  ","excerpt":"Issue When attempting to deploy Ondat into an OpenShift cluster, you notice that Ondat daemonset ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-unable-to-validate-against-any-security-context-constraint-error-ondat-openshift/","title":"Solution - Troubleshooting 'unable to validate against any security context constraint' Error When Deploying Into A OpenShift Cluster"},{"body":"Issue You are experiencing an issue where a new PersistentVolumeClaim (PVC) can‚Äôt be provisioned and stays in a Pending state.\n# Get the status of PVCs. kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE my-pvc Pending storageos 2m56s Upon describing the PVC that is in a Pending state, under the Events section, you see a number of Warning events that report a unregistered licence period has expired error message;\n# Describe the PVC named \u0026#34;my-pvc\u0026#34;. kubectl describe pvc my-pvc Name: my-pvc Namespace: default StorageClass: storageos Status: Pending Volume: Labels: \u0026lt;none\u0026gt; Annotations: storageos.com/encryption-secret-name: storageos-volume-key-7749ab0b-5859-4841-b22a-e06d797dfebb storageos.com/encryption-secret-namespace: default storageos.com/storageclass: e6bd6278-bc09-43e5-8f5d-c5a59863ab47 volume.beta.kubernetes.io/storage-provisioner: csi.storageos.com Finalizers: [kubernetes.io/pvc-protection] Capacity: Access Modes: VolumeMode: Filesystem Used By: \u0026lt;none\u0026gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning ProvisioningFailed 52s csi.storageos.com_storageos-csi-helper-65db657d7c-495t9_e8de55aa-5024-4366-a4ce-29ffdf8bd2d6 failed to provision volume with StorageClass \u0026#34;storageos-rep-enc-tap\u0026#34;: rpc error: code = Internal desc = internal error: unregistered licence period has expired (expired at 2022-03-09 12:17:35.171452772 +0000 UTC, now 2022-03-15 11:18:29.841123428 +0000 UTC) - see https://docs.storageos.com/v2/help/unlicensed-expired for more information Warning ProvisioningFailed 49s csi.storageos.com_storageos-csi-helper-65db657d7c-495t9_e8de55aa-5024-4366-a4ce-29ffdf8bd2d6 failed to provision volume with StorageClass \u0026#34;storageos-rep-enc-tap\u0026#34;: rpc error: code = Internal desc = internal error: unregistered licence period has expired (expired at 2022-03-09 12:17:35.171452772 +0000 UTC, now 2022-03-15 11:18:32.000038608 +0000 UTC) - see https://docs.storageos.com/v2/help/unlicensed-expired for more information Warning ProvisioningFailed 47s csi.storageos.com_storageos-csi-helper-65db657d7c-495t9_e8de55aa-5024-4366-a4ce-29ffdf8bd2d6 failed to provision volume with StorageClass \u0026#34;storageos-rep-enc-tap\u0026#34;: rpc error: code = Internal desc = internal error: unregistered licence period has expired (expired at 2022-03-09 12:17:35.171452772 +0000 UTC, now 2022-03-15 11:18:34.713556096 +0000 UTC) - see https://docs.storageos.com/v2/help/unlicensed-expired for more information Warning ProvisioningFailed 41s csi.storageos.com_storageos-csi-helper-65db657d7c-495t9_e8de55aa-5024-4366-a4ce-29ffdf8bd2d6 failed to provision volume with StorageClass \u0026#34;storageos-rep-enc-tap\u0026#34;: rpc error: code = Internal desc = internal error: unregistered licence period has expired (expired at 2022-03-09 12:17:35.171452772 +0000 UTC, now 2022-03-15 11:18:40.23564811 +0000 UTC) - see https://docs.storageos.com/v2/help/unlicensed-expired for more information Warning ProvisioningFailed 32s csi.storageos.com_storageos-csi-helper-65db657d7c-495t9_e8de55aa-5024-4366-a4ce-29ffdf8bd2d6 failed to provision volume with StorageClass \u0026#34;storageos-rep-enc-tap\u0026#34;: rpc error: code = Internal desc = internal error: unregistered licence period has expired (expired at 2022-03-09 12:17:35.171452772 +0000 UTC, now 2022-03-15 11:18:49.096283513 +0000 UTC) - see https://docs.storageos.com/v2/help/unlicensed-expired for more information Normal Provisioning 16s (x6 over 54s) csi.storageos.com_storageos-csi-helper-65db657d7c-495t9_e8de55aa-5024-4366-a4ce-29ffdf8bd2d6 External provisioner is provisioning volume for claim \u0026#34;default/pvc-xa\u0026#34; Warning ProvisioningFailed 15s csi.storageos.com_storageos-csi-helper-65db657d7c-495t9_e8de55aa-5024-4366-a4ce-29ffdf8bd2d6 failed to provision volume with StorageClass \u0026#34;storageos-rep-enc-tap\u0026#34;: rpc error: code = Internal desc = internal error: unregistered licence period has expired (expired at 2022-03-09 12:17:35.171452772 +0000 UTC, now 2022-03-15 11:19:06.286764945 +0000 UTC) - see https://docs.storageos.com/v2/help/unlicensed-expired for more information Normal ExternalProvisioning 1s (x5 over 54s) persistentvolume-controller waiting for a volume to be created, either by external provisioner \u0026#34;csi.storageos.com\u0026#34; or manually created by system administrator Root Cause  The error message that is returned is due to an Ondat licence expiring or an Ondat cluster that has not been registered yet.  For more information on the types of licences available, review the Ondat features and pricing page.    Resolution  Ensure that you apply a valid Ondat licence to your cluster to be able to continue provisioning volumes with Ondat. You can find more information on how to get an Ondat licence on the Licensing operations page.  ","excerpt":"Issue You are experiencing an issue where a new PersistentVolumeClaim (PVC) can‚Äôt be provisioned and ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-unregistered-licence-period-has-expired/","title":"Solution - Troubleshooting 'unregistered licence period has expired' Error Message"},{"body":"Issue Ondat nodes cannot successfully join the cluster due to the following error message \u0026raquo; error verifying UUID: UUID aed3275f-846b-1f75-43a1-adbfec8bf974 has already been registered and has hostname 'debian-4', not 'node4' as demonstrated in the log entry below:\n# Truncated output. time=\u0026#34;2018-09-24T13:47:02Z\u0026#34; level=error msg=\u0026#34;failed to start api\u0026#34; error=\u0026#34;error verifying UUID: UUID aed3275f-846b-1f75-43a1-adbfec8bf974 has already been registered and has hostname \u0026#39;debian-4\u0026#39;, not \u0026#39;node4\u0026#39;\u0026#34; module=command Root Cause The Ondat registration process to start the cluster uses the hostname of the node where the Ondat container is running, provided by the kubelet.\n However, Ondat verifies the network hostname of the OS as a preflight check to make sure it can communicate with other nodes. If those names don‚Äôt match, Ondat is unable to start.  Resolution Ensure that the hostnames match with the names advertised by your Kubernetes cluster.\n If you have changed the hostname of your nodes, ensure that you restart the nodes for changes to be applied successfully.  ","excerpt":"Issue Ondat nodes cannot successfully join the cluster due to the following error message \u0026raquo; ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-uuid-has-already-been-registered-and-has-hostname-error/","title":"Solution - Troubleshooting 'UUID has already been registered and has hostname' Error"},{"body":"Issue You have noticed that nodes cannot successfully join the cluster. Upon investigation, you also notice the following error messages in after 1 minute of uptime:\n# Truncated output... time=\u0026#34;2018-09-24T13:40:20Z\u0026#34; level=info msg=\u0026#34;not first cluster node, joining first node\u0026#34; action=create address=172.28.128.5 category=etcd host=node3 module=cp target=172.28.128.6 time=\u0026#34;2018-09-24T13:40:20Z\u0026#34; level=error msg=\u0026#34;could not retrieve cluster config from api\u0026#34; status_code=503 time=\u0026#34;2018-09-24T13:40:20Z\u0026#34; level=error msg=\u0026#34;failed to join existing cluster\u0026#34; action=create category=etcd endpoint=\u0026#34;172.28.128.3,172.28.128.4,172.28.128.5,172.28.128.6\u0026#34; error=\u0026#34;503 Service Unavailable\u0026#34; module=cp time=\u0026#34;2018-09-24T13:40:20Z\u0026#34; level=info msg=\u0026#34;retrying cluster join in 5 seconds...\u0026#34; action=create category=etcd module=cp # Truncated output... Root Cause Ondat uses a gossip protocol to discover nodes in the cluster. When Ondat starts, one or more nodes can be referenced so new nodes can query existing nodes for the list of members.\n The error demonstrated in the code snippet above indicates that the node can‚Äôt connect to any of the nodes in the known list. The known list is defined in the JOIN variable.  Resolution   Check and ensure that the required ports for Ondat to run, are not being blocked by a firewall.\n# Connect to, for example \u0026#34;node04\u0026#34; on port 5705 from \u0026#34;node06\u0026#34; using \u0026#34;nc\u0026#34;. nc -zv node04 5705 Ncat: Version 7.50 ( https://nmap.org/ncat ) Ncat: Connected to 10.0.1.166:5705. Ncat: 0 bytes sent, 0 bytes received in 0.01 seconds.   Ondat exposes network diagnostics through its API - which is viewable from the Ondat CLI. The diagnostic results show information from all known cluster members - If all the ports are blocked during the first bootstrap of the cluster, the diagnostics results won‚Äôt show any data as nodes could not register:\n üí° The command below is only available in Ondat v1 deployments. For Ondat v2 deployments, end users can generate diagnostic and support bundles to get more information about the connectivity in the cluster.\n # Check the network diagnostic results from the Ondat CLI (Ondat v1 deployments only). storageos cluster connectivity SOURCE NAME ADDRESS LATENCY STATUS MESSAGE node4 node2.nats 172.28.128.4:5708 1.949275ms OK node4 node3.api 172.28.128.5:5705 3.070574ms OK node4 node3.nats 172.28.128.5:5708 2.989238ms OK node4 node2.directfs 172.28.128.4:5703 2.925707ms OK node4 node3.etcd 172.28.128.5:5707 2.854726ms OK node4 node3.directfs 172.28.128.5:5703 2.833371ms OK node4 node1.api 172.28.128.3:5705 2.714467ms OK node4 node1.nats 172.28.128.3:5708 2.613752ms OK node4 node1.etcd 172.28.128.3:5707 2.594159ms OK node4 node1.directfs 172.28.128.3:5703 2.601834ms OK node4 node2.api 172.28.128.4:5705 2.598236ms OK node4 node2.etcd 172.28.128.4:5707 16.650625ms OK node3 node4.nats 172.28.128.6:5708 1.304126ms OK node3 node4.api 172.28.128.6:5705 1.515218ms OK node3 node2.directfs 172.28.128.4:5703 1.359827ms OK node3 node1.api 172.28.128.3:5705 1.185535ms OK node3 node4.directfs 172.28.128.6:5703 1.379765ms OK node3 node1.etcd 172.28.128.3:5707 1.221176ms OK node3 node1.nats 172.28.128.3:5708 1.330122ms OK node3 node2.api 172.28.128.4:5705 1.238541ms OK node3 node1.directfs 172.28.128.3:5703 1.413574ms OK node3 node2.etcd 172.28.128.4:5707 1.214273ms OK node3 node2.nats 172.28.128.4:5708 1.321145ms OK node1 node4.directfs 172.28.128.6:5703 1.140797ms OK node1 node3.api 172.28.128.5:5705 1.089252ms OK node1 node4.api 172.28.128.6:5705 1.178439ms OK node1 node4.nats 172.28.128.6:5708 1.176648ms OK node1 node2.directfs 172.28.128.4:5703 1.529612ms OK node1 node2.etcd 172.28.128.4:5707 1.165681ms OK node1 node2.api 172.28.128.4:5705 1.29602ms OK node1 node2.nats 172.28.128.4:5708 1.267454ms OK node1 node3.nats 172.28.128.5:5708 1.485657ms OK node1 node3.etcd 172.28.128.5:5707 1.469429ms OK node1 node3.directfs 172.28.128.5:5703 1.503015ms OK node2 node4.directfs 172.28.128.6:5703 1.484ms OK node2 node1.directfs 172.28.128.3:5703 1.275304ms OK node2 node4.nats 172.28.128.6:5708 1.261422ms OK node2 node4.api 172.28.128.6:5705 1.465532ms OK node2 node3.api 172.28.128.5:5705 1.252768ms OK node2 node3.nats 172.28.128.5:5708 1.212332ms OK node2 node3.directfs 172.28.128.5:5703 1.192792ms OK node2 node3.etcd 172.28.128.5:5707 1.270076ms OK node2 node1.etcd 172.28.128.3:5707 1.218522ms OK node2 node1.api 172.28.128.3:5705 1.363071ms OK node2 node1.nats 172.28.128.3:5708 1.349383ms OK   References  Gossip Protocol - Wikipedia  ","excerpt":"Issue You have noticed that nodes cannot successfully join the cluster. Upon investigation, you also ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-etcd-503-service-unavailable-error-peer-discovery/","title":"Solution - Troubleshooting etcd '503 Service Unavailable' Error Message During Peer Discovery"},{"body":"Issue You are experiencing an issue where nodes cannot successfully join the cluster. Upon investigation, you also notice the following error messages in the logs:\n# Truncated output... time=\u0026#34;2018-09-24T13:40:20Z\u0026#34; level=info msg=\u0026#34;not first cluster node, joining first node\u0026#34; action=create address=172.28.128.5 category=etcd host=node3 module=cp target=172.28.128.6 time=\u0026#34;2018-09-24T13:40:20Z\u0026#34; level=error msg=\u0026#34;could not retrieve cluster config from api\u0026#34; status_code=503 time=\u0026#34;2018-09-24T13:40:20Z\u0026#34; level=error msg=\u0026#34;failed to join existing cluster\u0026#34; action=create category=etcd endpoint=\u0026#34;172.28.128.3,172.28.128.4,172.28.128.5,172.28.128.6\u0026#34; error=\u0026#34;503 Service Unavailable\u0026#34; module=cp time=\u0026#34;2018-09-24T13:40:20Z\u0026#34; level=info msg=\u0026#34;retrying cluster join in 5 seconds...\u0026#34; action=create category=etcd module=cp # Truncated output... Root Cause Ondat uses a gossip protocol to discover nodes in the cluster. When Ondat starts, one or more nodes can be referenced so new nodes can query existing nodes for the list of members.\n The error demonstrated in the code snippet above indicates that the node can‚Äôt connect to any of the nodes in the known list. The known list is defined in the JOIN variable. If there are no active nodes, the bootstrap process will elect the first node in the JOIN variable as master, and the rest will try to discover from it. In case of that node not starting, the whole cluster will remain unable to bootstrap. Deployments of Ondat use a Kubernetes DaemonSet, and by default do not schedule Ondat pods to master nodes, due to the presence of the \u0026raquo; node-role.kubernetes.io/master:NoSchedule taint that is typically present. In such cases the JOIN variable must not contain master nodes or the Ondat cluster will not start.  Resolution  Check and ensure that the first node of the JOIN variable started properly.  # Describe the daemonset and grep for \u0026#34;JOIN\u0026#34;. kubectl --namespace storageos describe daemonset.apps/storageos-node | grep \u0026#34;JOIN\u0026#34; JOIN: 172.28.128.3,172.28.128.4,172.28.128.5 # Check for the pod with the \u0026#34;172.28.128.3\u0026#34; IP address. kubectl --namespace storageos get pods --output wide | grep 172.28.128.3 storageos-node-8zqxl 1/1 Running 0 2m 172.28.128.3 node1  Make sure that the JOIN variable doesn‚Äôt specify the master nodes. In case you are using the discovery service, it is necessary to ensure that the Ondat daemonset won‚Äôt allocate pods on the master nodes. This can be achieved with taints, node selectors or labels. For deployments with the Ondat operator you can specify which nodes to deploy Ondat on using nodeSelectors.  For more information on how to configure the Ondat Custom Resource, review the Ondat Operator Examples page.   For more advanced deployments that are using compute-only and storage nodes, check the \u0026raquo; storageos.com/computeonly=true label that can be added to the nodes through Kubernetes node labels has been configured correctly.  For more information on how to use the storageos.com/computeonly=true review the How To Setup A Centralised Cluster Topology operations page.    References  Gossip Protocol - Wikipedia. Taints and Tolerations - Kubernetes Documentation. Assign Pods to Nodes - Kubernetes Documentation. Kubernetes DaemonSet.  ","excerpt":"Issue You are experiencing an issue where nodes cannot successfully join the cluster. Upon ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-etcd-failed-to-join-existing-cluster-error-message-during-peer-discovery/","title":"Solution - Troubleshooting etcd 'failed to join existing cluster' Error Message During Peer Discovery"},{"body":"Issue  You are noticing the following error messages (demonstrated in the snippet below) in the logs of a Ondat daemonset pod named storageos-node-xxxx that is running on a node that is running out of space.  # Check the logs of a Ondat daemonset pod.kubectl logs storageos-node-xxxx --namespace storageos# Truncated output.\u0026#34;msg\u0026#34;: \u0026#34;StartAsyncFallocate: insufficient free space on file system free_space=1048305664 required_free_space=1073741824\u0026#34;,\u0026#34;msg\u0026#34;: \u0026#34;Write: write failed volid=155051 error=BlobStorage::PrepWrite encountered a previous IO error preventing future IO for safety\u0026#34;,\u0026#34;msg\u0026#34;: \u0026#34;Write: write failed volid=155051 error=all blob files are full - can not complete write\u0026#34;,\u0026#34;msg\u0026#34;: \u0026#34;Write: write failed volid=155051 error=BlobStorage::PrepWrite encountered a previous IO error preventing future IO for safety\u0026#34;,\u0026#34;msg\u0026#34;: \u0026#34;SCSI command failed type=write error=FATAL retries=0 time_to_deadline_secs=89\u0026#34;, When you try to attach a volume to a node with a full disk, you see the following event error message after describing the pod using the volume:  # Describe the pod trying to use the affected volume. kubectl describe pod $POD_NAME_USING_VOLUME --namespace $POD_NAMESPACE # Truncated output. AttachVolume.Attach failed for volume \u0026#34;pvc-xxx\u0026#34; : rpc error: code = Internal desc = internal error: rpc error: code = Internal desc = rpc error: code = Internal desc = fs: STATUS_FORBIDDEN: create failed in Notify handler error=Failed to create LUN for FsConfigVolume{volume_id= Root Cause The root cause of the issue due to the physical storage disks connected to your worker nodes in your Ondat cluster becoming full, or they are using disk space too quickly. To reduce the chances of downtime in the cluster, Kubernetes will automatically apply the node.kubernetes.io/disk-pressure taint on affected nodes.\n The Ondat daemonset pods, which have the control and data plane components, has a toleration applied for this taint, to allow the daemonset to continue to run.  What Are The Consequences Of A Full Storage Disk?  Unable To Conduct Replica Failovers.  If there is a replica on a node where the storage disk has run out of space, the replica will be unable to failover successfully.   Unable To Provision Volumes.  When provisioning a new volume, the data plane component will check that there is at least 1GB of storage space left on the nodes' underlying filesystem for the blob files located under \u0026raquo; /var/lib/storageos/data/dev[0-9]+/vol.xxxxxx.0.blob and \u0026raquo; /var/lib/storageos/data/dev[0-9]+/vol.xxxxxx.1.blob. If there is insufficient storage space for both of the blob files that Ondat uses to store data, then the data plane component will fail to complete the volume create request.   Runtime Access Issues.  At runtime, if an attempted write to a blob file returns an ENOSPC exception, the data plane component marks the file as full. Once both Ondat blob files in a volume are marked as full, the data plane component marks the deployment with an error flag, and all subsequent read/write operations will return an I/O error.     üí° This flag is only stored in memory, therefore, to clear this flag, the Ondat daemonset pod on the affected node must be restarted after remediating the disk space issue.\n Resolution To recover from a reported full disk error message, end users are recommended to either:\nOption 1 - Expand Storage Capacity By Adding More Disks.\n If you choose to address this issue by expanding your capacity, users have two main options:  Add new storage devices under /var/lib/storageos/data/dev[0-9]+ as demonstrated in the How To Extend Storage Capacity On Nodes operations page. Expand the underlying filesystem that Ondat is using as demonstrated in the How To Extend Storage Capacity On Nodes operations page.    Option 2 - Delete Existing PersistentVolumeClaims (PVCs).\n If you choose to address by deleting existing PersistentVolumeClaims, users can use kubectl to achieve this and ensure that you restart/bounce the Ondat daemonset pod on the affected node.  kubectl delete pvc $NAME_OF_PVC --namespace $PVC_NAMESPACE  ‚ö†Ô∏è Regardless of the solution used to address this issue - it is important that the Ondat Daemonset Pod restarted for changes to be applied and take effect. The reason for this is because blob files disallow operations at runtime through the previously discussed ENOSPC error flag stored in memory. This flag does not survive boot cycles, so after the the daemonset pod restarts, volumes can begin to successfully operate again.\n ","excerpt":"Issue  You are noticing the following error messages (demonstrated in the snippet below) in the logs ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-insufficient-free-space-on-disks-attached-to-nodes/","title":"Solution - Troubleshooting Insufficient Free Space On Storage Disks Attached To Nodes"},{"body":"Issue You are experiencing CrashLoopBackOff states for Ondat daemonset pods \u0026raquo; storageos-node-* after conducting an Ondat re-installation on a cluster that was previously running Ondat.\n# Get the status of Ondat daemonset pods. kubectl get pods --namespace storageos NAME READY STATUS RESTARTS AGE storageos-node-6kjvg 2/3 CrashLoopBackOff 7 (2m5s ago) 13m storageos-node-7mxth 2/3 CrashLoopBackOff 7 (106s ago) 13m storageos-node-8vrl8 2/3 CrashLoopBackOff 7 (117s ago) 13m storageos-node-8zssp 2/3 CrashLoopBackOff 7 (2m1s ago) 13m storageos-node-qvf58 2/3 CrashLoopBackOff 7 (2m13s ago) 13m storageos-operator-6fdccfd899-g5hff 2/2 Running 0 14m storageos-scheduler-7f7ddd896b-4ngb9 1/1 Running 0 13m Upon further investigation into the logs of one of the Ondat daemonset pods that are in a CrashLoopBackOff state, there is an error message related to the /var/lib/storageos/config.json configuration file.\n# Get the logs for one of the Ondat daemonset pods. kubectl logs storageos-node-8zssp --namespace storageos {\u0026#34;bin_build_date\u0026#34;:\u0026#34;2022-08-08T15:55:20.630504657+00:00\u0026#34;,\u0026#34;bin_build_ref\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;bin_git_branch\u0026#34;:\u0026#34;release/v2.8.2\u0026#34;,\u0026#34;bin_git_commit_hash\u0026#34;:\u0026#34;396dcc6ea2c4a267a33f1204d2836e1aee6f24de\u0026#34;,\u0026#34;bin_version\u0026#34;:\u0026#34;2.8.2\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;starting StorageOS\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-08-28T15:18:57.006231412Z\u0026#34;} {\u0026#34;env_advertise_address\u0026#34;:\u0026#34;10.106.0.3\u0026#34;,\u0026#34;env_api_bind_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_api_tls_ca\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_bind_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_bootstrap_namespace\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_bootstrap_username\u0026#34;:\u0026#34;storageos\u0026#34;,\u0026#34;env_csi_endpoint\u0026#34;:\u0026#34;unix:///var/lib/kubelet/plugins_registry/storageos/csi.sock\u0026#34;,\u0026#34;env_csi_version\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;env_dataplane_daemon_dir\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_dataplane_dir\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_device_dir\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_dial_timeout\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_disable_crash_reporting\u0026#34;:\u0026#34;false\u0026#34;,\u0026#34;env_disable_telemetry\u0026#34;:\u0026#34;false\u0026#34;,\u0026#34;env_disable_version_check\u0026#34;:\u0026#34;false\u0026#34;,\u0026#34;env_encryption_enabled\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_etcd_endpoints\u0026#34;:\u0026#34;storageos-etcd.storageos-etcd:2379\u0026#34;,\u0026#34;env_etcd_namespace\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_etcd_tls_client_ca\u0026#34;:\u0026#34;/run/storageos/pki/etcd-client-ca.crt\u0026#34;,\u0026#34;env_etcd_tls_client_cert\u0026#34;:\u0026#34;/run/storageos/pki/etcd-client.crt\u0026#34;,\u0026#34;env_etcd_tls_client_key\u0026#34;:\u0026#34;/run/storageos/pki/etcd-client.key\u0026#34;,\u0026#34;env_etcd_username\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_gossip_advertise_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_gossip_bind_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_health_grace_period\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_health_probe_interval\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_health_probe_timeout\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_health_tcp_timeout\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_hostname\u0026#34;:\u0026#34;default-7f882\u0026#34;,\u0026#34;env_internal_api_advertise_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_internal_api_bind_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_internal_tls_ca_cert\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_internal_tls_node_cert\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_internal_tls_node_key\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_io_advertise_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_io_bind_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_jaeger_endpoint\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_jaeger_service_name\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_k8s_config_path\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_k8s_distribution\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_k8s_enable_scheduler_extender\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;env_k8s_namespace\u0026#34;:\u0026#34;default\u0026#34;,\u0026#34;env_log_file\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_log_format\u0026#34;:\u0026#34;json\u0026#34;,\u0026#34;env_log_level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;env_log_size_limit\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_nfs_advertise_ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_nfs_binary_path\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_nfs_bind_ip\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_nfs_bind_port_base\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_nfs_log_size_limit\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_node_capacity_interval\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_node_lock_ttl\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_placement_api_bind_address\u0026#34;:\u0026#34;127.0.0.1:5712\u0026#34;,\u0026#34;env_placement_log_level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;env_placement_service_address\u0026#34;:\u0026#34;127.0.0.1:5712\u0026#34;,\u0026#34;env_placement_service_binary_dir\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_placement_service_binary_name\u0026#34;:\u0026#34;placement\u0026#34;,\u0026#34;env_prometheus_exporter_bind_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_prometheus_exporter_username\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_prometheus_tls_ca\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_root_dir\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_socket_dir\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_supervisor_advertise_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_supervisor_bind_address\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;env_volume_lock_ttl\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;environment variables at startup\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-08-28T15:18:57.006601003Z\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;ETCD connection established at: [storageos-etcd.storageos-etcd:2379]\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-08-28T15:18:57.056503227Z\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;local node StorageOS ID: 33c6c45a-5109-4092-bd5e-0e76ade7fd6e\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-08-28T15:18:57.062314134Z\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;local node Hostname is: default-7f882\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-08-28T15:18:57.062367342Z\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;joining cluster: eb5546d9-7332-4b73-935a-5d2373b93bf2\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-08-28T15:18:57.690018218Z\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;node lock refresh interval: 30s\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-08-28T15:18:57.690187309Z\u0026#34;} {\u0026#34;error\u0026#34;:\u0026#34;node \\\u0026#34;33c6c45a-5109-4092-bd5e-0e76ade7fd6e\\\u0026#34; was previously a member of cluster id \\\u0026#34;26cb5845-93c9-489d-bb80-e4a31791989f\\\u0026#34;, tried to join another cluster (\\\u0026#34;eb5546d9-7332-4b73-935a-5d2373b93bf2\\\u0026#34;) - aborting startup. To delete all data on the node and join the new cluster, remove the \\\u0026#34;/var/lib/storageos/config.json\\\u0026#34; directory. To recover this node data, please contact support.\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;failed to initialise local node\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-08-28T15:18:57.704875437Z\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;shutting down\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-08-28T15:18:57.704982197Z\u0026#34;} # Get the logs for one of the Ondat daemonset pods and use jq to clean up the formatting of the logs. kubectl logs storageos-node-8zssp --namespace storageos | jq # truncated log output... { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;ETCD connection established at: [storageos-etcd.storageos-etcd:2379]\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-08-28T15:18:57.056503227Z\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;local node StorageOS ID: 33c6c45a-5109-4092-bd5e-0e76ade7fd6e\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-08-28T15:18:57.062314134Z\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;local node Hostname is: default-7f882\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-08-28T15:18:57.062367342Z\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;joining cluster: eb5546d9-7332-4b73-935a-5d2373b93bf2\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-08-28T15:18:57.690018218Z\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;node lock refresh interval: 30s\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-08-28T15:18:57.690187309Z\u0026#34; } { \u0026#34;error\u0026#34;: \u0026#34;node \\\u0026#34;33c6c45a-5109-4092-bd5e-0e76ade7fd6e\\\u0026#34; was previously a member of cluster id \\\u0026#34;26cb5845-93c9-489d-bb80-e4a31791989f\\\u0026#34;, tried to join another cluster (\\\u0026#34;eb5546d9-7332-4b73-935a-5d2373b93bf2\\\u0026#34;) - aborting startup. To delete all data on the node and join the new cluster, remove the \\\u0026#34;/var/lib/storageos/config.json\\\u0026#34; directory. To recover this node data, please contact support.\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;failed to initialise local node\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-08-28T15:18:57.704875437Z\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;shutting down\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-08-28T15:18:57.704982197Z\u0026#34; } # Drill down into the Ondat daemonset logs further and search for the \u0026#34;error\u0026#34; message that is reported. kubectl logs storageos-node-8zssp --namespace storageos | jq | grep \u0026#34;error\u0026#34; \u0026#34;error\u0026#34;: \u0026#34;node \\\u0026#34;33c6c45a-5109-4092-bd5e-0e76ade7fd6e\\\u0026#34; was previously a member of cluster id \\\u0026#34;26cb5845-93c9-489d-bb80-e4a31791989f\\\u0026#34;, tried to join another cluster (\\\u0026#34;eb5546d9-7332-4b73-935a-5d2373b93bf2\\\u0026#34;) - aborting startup. To delete all data on the node and join the new cluster, remove the \\\u0026#34;/var/lib/storageos/config.json\\\u0026#34; directory. To recover this node data, please contact support.\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;error\u0026#34;, Root Cause The root cause of this is due to the existing Ondat configuration file that is stored at the following location \u0026raquo; var/lib/storageos/config.json on each node where Ondat daemonset pods runs. The configuration file is not removed to allow cluster administrators and end users to be able to successfully recover incase the uninstall was unintentional.\n For more information on uninstalling Ondat, review the How To Uninstall Ondat operations page.  Resolution  If you have already re-installed Ondat, follow the How To Uninstall Ondat operations page again to remove Ondat. Once Ondat has been removed, run the following command below against the cluster - the command will execute a bash script that deploys a daemonset which will remove the Ondat data directory \u0026raquo; /var/lib/storageos/ - permanently deleting data and metadata related to Ondat on the nodes.   ‚ö†Ô∏è WARNING - This step is irreversible and will permanently remove any existing data in \u0026raquo; /var/lib/storageos/. Ensure that you have backed up your data before executing this step. Users can also review the contents of the bash script which is available in the Ondat Use Case repository publicly available on GitHub to verify before executing.\n # Permanetly delete the contents located in \u0026#34;/var/lib/storageos/\u0026#34;. curl --silent https://raw.githubusercontent.com/ondat/use-cases/main/scripts/permanently-delete-storageos-data.sh | bash Once the script has finished executing, you can re-install Ondat again into your cluster without experiencing CrashLoopBackOff states for Ondat daemonset pods - caused by an old var/lib/storageos/config.json configuration file.  ","excerpt":"Issue You are experiencing CrashLoopBackOff states for Ondat daemonset pods \u0026raquo; storageos-node-* ‚Ä¶","ref":"/docs/knowledgebase/solution-troubleshooting-daemonset-crashloopbackoff-pod-after-reinstalling-ondat/","title":"Solution - Troubleshooting Ondat Daemonset 'CrashLoopBackOff'  Pod States after Re-installing Ondat"},{"body":"Issue When attempting to deploy Ondat onto a new GKE cluster with the Ondat kubectl plugin, you experience a permission error message that causes the installation to fail.\n# installing Ondat using the Ondat kubectl plugin kubectl storageos install \\  --include-etcd \\  --admin-username \u0026#34;storageos\u0026#34; \\  --admin-password \u0026#34;storageos\u0026#34; # log output namespace/storageos-etcd created Warning: resource namespaces/storageos is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by apply. apply should only be used on resources created declaratively by either create --save-config or apply. The missing annotation will be patched automatically. namespace/storageos configured customresourcedefinition.apiextensions.k8s.io/etcdbackups.etcd.improbable.io created customresourcedefinition.apiextensions.k8s.io/etcdbackupschedules.etcd.improbable.io created customresourcedefinition.apiextensions.k8s.io/storageosclusters.storageos.com created customresourcedefinition.apiextensions.k8s.io/etcdclusters.etcd.improbable.io created customresourcedefinition.apiextensions.k8s.io/etcdpeers.etcd.improbable.io created serviceaccount/storageos-operator created customresourcedefinition.apiextensions.k8s.io/etcdrestores.etcd.improbable.io created service/storageos-etcd-proxy created deployment.apps/storageos-etcd-controller-manager created configmap/storageos-operator created configmap/storageos-related-images created deployment.apps/storageos-etcd-proxy created service/storageos-operator created service/storageos-operator-webhook created deployment.apps/storageos-operator created validatingwebhookconfiguration.admissionregistration.k8s.io/storageos-operator-validating-webhook created Error: Multiple errors: [error when creating \u0026#34;manifestString\u0026#34;: roles.rbac.authorization.k8s.io is forbidden: User \u0026#34;jane@example.com\u0026#34; cannot create resource \u0026#34;roles\u0026#34; in API group \u0026#34;rbac.authorization.k8s.io\u0026#34; in the namespace \u0026#34;storageos-etcd\u0026#34;: requires one of [\u0026#34;container.roles.create\u0026#34;] permission(s)., error when creating \u0026#34;manifestString\u0026#34;: clusterroles.rbac.authorization.k8s.io is forbidden: User \u0026#34;jane@example.com\u0026#34; cannot create resource \u0026#34;clusterroles\u0026#34; in API group \u0026#34;rbac.authorization.k8s.io\u0026#34; at the cluster scope: requires one of [\u0026#34;container.clusterRoles.create\u0026#34;] permission(s)., error when creating \u0026#34;manifestString\u0026#34;: rolebindings.rbac.authorization.k8s.io is forbidden: User \u0026#34;jane@example.com\u0026#34; cannot create resource \u0026#34;rolebindings\u0026#34; in API group \u0026#34;rbac.authorization.k8s.io\u0026#34; in the namespace \u0026#34;storageos-etcd\u0026#34;: requires one of [\u0026#34;container.roleBindings.create\u0026#34;] permission(s)., error when creating \u0026#34;manifestString\u0026#34;: clusterrolebindings.rbac.authorization.k8s.io is forbidden: User \u0026#34;jane@example.com\u0026#34; cannot create resource \u0026#34;clusterrolebindings\u0026#34; in API group \u0026#34;rbac.authorization.k8s.io\u0026#34; at the cluster scope: requires one of [\u0026#34;container.clusterRoleBindings.create\u0026#34;] permission(s).] [error when creating \u0026#34;manifestString\u0026#34;: clusterroles.rbac.authorization.k8s.io is forbidden: User \u0026#34;jane@example.com\u0026#34; cannot create resource \u0026#34;clusterroles\u0026#34; in API group \u0026#34;rbac.authorization.k8s.io\u0026#34; at the cluster scope: requires one of [\u0026#34;container.clusterRoles.create\u0026#34;] permission(s)., error when creating \u0026#34;manifestString\u0026#34;: clusterrolebindings.rbac.authorization.k8s.io is forbidden: User \u0026#34;jane@example.com\u0026#34; cannot create resource \u0026#34;clusterrolebindings\u0026#34; in API group \u0026#34;rbac.authorization.k8s.io\u0026#34; at the cluster scope: requires one of [\u0026#34;container.clusterRoleBindings.create\u0026#34;] permission(s).] Root Cause  The permission error messages that are returned is due to not having the correct privileges to be able to install Ondat in a GKE cluster.  For more information how to manage permissions in GKE clusters, review the GKE documentation on how to authorize actions in clusters using role-based access control.    Resolution  To resolve this issue, ensure that your user account has cluster administrator privileges first so that you can install Ondat successfully.  kubectl create clusterrolebinding cluster-admin-binding \\  --clusterrole=cluster-admin \\  --user=$(gcloud config get-value account) References  Authorize actions in clusters using role-based access control - Google Kubernetes Engine Documentation  ","excerpt":"Issue When attempting to deploy Ondat onto a new GKE cluster with the Ondat kubectl plugin, you ‚Ä¶","ref":"/docs/knowledgebase/solution-permission-errors-when-deploying-ondat-to-a-gke-cluster/","title":"Solution - Troubleshooting Permission Errors When Deploying Into A GKE Cluster"},{"body":"Issue You have created a custom StorageClass object in your Ondat cluster but you are experiencing an issue where you cannot interactively edit or patch the said StorageClass object to apply a custom StorageClass parameter to enable specific Ondat features.\n# Get the list of StorageClasses available. kubectl get sc NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE storageos csi.storageos.com Delete Immediate true 3h3m storageos-rep csi.storageos.com Delete Immediate true 23s Using the example below, try to edit storageos-rep and change the replica count to 2:\n# Please edit the object below. Lines beginning with a \u0026#39;#\u0026#39; will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#allowVolumeExpansion:trueapiVersion:storage.k8s.io/v1kind:StorageClassmetadata:annotations:kubectl.kubernetes.io/last-applied-configuration:|{\u0026#34;allowVolumeExpansion\u0026#34;:true,\u0026#34;apiVersion\u0026#34;:\u0026#34;storage.k8s.io/v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;StorageClass\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;name\u0026#34;:\u0026#34;storageos-rep\u0026#34;},\u0026#34;parameters\u0026#34;:{\u0026#34;csi.storage.k8s.io/fstype\u0026#34;:\u0026#34;ext4\u0026#34;,\u0026#34;csi.storage.k8s.io/secret-name\u0026#34;:\u0026#34;storageos-api\u0026#34;,\u0026#34;csi.storage.k8s.io/secret-namespace\u0026#34;:\u0026#34;storageos\u0026#34;,\u0026#34;storageos.com/replicas\u0026#34;:\u0026#34;1\u0026#34;},\u0026#34;provisioner\u0026#34;:\u0026#34;csi.storageos.com\u0026#34;}creationTimestamp:\u0026#34;2022-09-01T18:08:46Z\u0026#34;name:storageos-represourceVersion:\u0026#34;68902\u0026#34;uid:74ad669c-885c-466a-b9b8-a8100c10d35eparameters:csi.storage.k8s.io/fstype:ext4csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosstorageos.com/replicas:\u0026#34;2\u0026#34;provisioner:csi.storageos.comreclaimPolicy:DeletevolumeBindingMode:ImmediateAfter attempting to save the changes you made and exiting from the editor, an error message \u0026raquo; error: storageclasses.storage.k8s.io \u0026quot;storageos-rep\u0026quot; is invalid is returned as demonstrated below:\nerror: storageclasses.storage.k8s.io \u0026#34;storageos-rep\u0026#34; is invalid A copy of your changes has been stored to \u0026#34;/var/folders/h5/8782r8c93190wt_mmly0ph5r0000gn/T/kubectl-edit-2033723251.yaml\u0026#34; error: Edit cancelled, no valid changes were saved. Root Cause In Kubernetes, a StorageClass is an immutable object once it has been created - therefore it is not possible to patch or add custom parameters to an existing StorageClass object.\nResolution To resolve this issue, an end user can either;\n Option 1 - Use volume labels to enable Ondat features.  Users can use the existing StorageClass object and dynamically create PersistentVolumeClaim definitions that enable Ondat features through volume labels:    apiVersion:v1kind:PersistentVolumeClaimmetadata:name:test-pvclabels:storageos.com/replicas:\u0026#34;2\u0026#34;spec:storageClassName:\u0026#34;storageos-rep\u0026#34;accessModes:- ReadWriteOnceresources:requests:storage:1Gi# Create the PVC and get the details of the label applied to the PVC. kubectl apply -f test-pvc.yaml kubectl get pvc test-pvc --output wide --show-labels NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE LABELS test-pvc Bound pvc-3afbc6ff-09f2-4360-84dc-440193a9fbd9 1Gi RWO storageos-rep 2m59s Filesystem storageos.com/replicas=2  Option 2 - Create a new StorageClass object with the desired parameters.  # Create a \u0026#34;storageos-rep-2\u0026#34; StorageClass object.cat \u0026lt;\u0026lt;EOF | kubectl create --filename -apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:storageos-rep-2provisioner:csi.storageos.comallowVolumeExpansion:trueparameters:csi.storage.k8s.io/fstype:ext4csi.storage.k8s.io/secret-name:storageos-apicsi.storage.k8s.io/secret-namespace:storageosstorageos.com/replicas:\u0026#34;2\u0026#34;EOF# Describe the \u0026#34;storageos-rep-2\u0026#34; StorageClass object to verify the label\u0026#39;s existance.kubectl describe sc storageos-rep-2Name:storageos-rep-2IsDefaultClass:NoAnnotations:\u0026lt;none\u0026gt;Provisioner:csi.storageos.comParameters:csi.storage.k8s.io/fstype=ext4,csi.storage.k8s.io/secret-name=storageos-api,csi.storage.k8s.io/secret-namespace=storageos,storageos.com/replicas=2AllowVolumeExpansion:TrueMountOptions:\u0026lt;none\u0026gt;ReclaimPolicy:DeleteVolumeBindingMode:ImmediateEvents:\u0026lt;none\u0026gt;References  Storage Classes - Kubernetes Documentation  ","excerpt":"Issue You have created a custom StorageClass object in your Ondat cluster but you are experiencing ‚Ä¶","ref":"/docs/knowledgebase/solution-unable-to-apply-paramters-to-an-existing-storageclass-object/","title":"Solution - Unable To Apply Parameters To An Existing StorageClass Object"},{"body":"Issue A PersistentVolumeClaim (PVC) is bound and the Ondat volume appears to be in a healthy state, but the volume was never mounted to the assigned pod.\n Below is the error message that is returned in the Events section when you describe the pod.  # describe the \u0026#34;my-pod-mounting-rwx-volume\u0026#34; pod. kubectl describe pod my-pod-mounting-rwx-volume # truncated output. Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 7m39s storageos-scheduler Successfully assigned default/test4-849f875f74-dmjtr to ip-10-73-16-8.eu-west-2.compute.internal Warning FailedMount 94s kubelet MountVolume.SetUp failed for volume \u0026#34;pvc-c30e3215-bbd6-4dd5-a6e2-84de1fb06097\u0026#34; : rpc error: code = DeadlineExceeded desc = context deadline exceeded Warning FailedMount 63s (x3 over 5m36s) kubelet Unable to attach or mount volumes: unmounted volumes=[v1], unattached volumes=[v1 kube-api-access-h9njv]: timed out waiting for the condition Root Cause  The error message is related to the fact that there is no Service Endpoint: for the RWX NFS server.  The Ondat Control Plane in the storageos-node-xxxx daemonset pod spawns a Ganesha NFS server that is bound to the host network on a port in the range 25705-25960. If the Pod cannot bound to the port for the Ganesha the Service Endpoint: value will show as empty.    Resolution  Check and ensure that there is a service for the RWX volume in the same namespace where the pod is located. If the service does not exist, a recommendation would be to follow the instructions below.  # Define environment variables. PVC_NAME=\u0026#34;my-volume-name\u0026#34; PV_NAME=$(kubectl get pvc $PVC_NAME -ojsonpath=\u0026#39;{.spec.volumeName}\u0026#39;)) # Get the PersistentVolume (PV) name associated to your PersistentVolumeClaim (PVC). kubectl get service | grep $PV_NAME  You can also use the Ondat CLI to also check the health status of the volume. Notice that there is no assigned port under the Service Endpoint: key-value pair as demonstrated below;  # Use the Ondat CLI to describe the RWX volume which does not have a service. storageos describe volume $PV_NAME ID a3802f33-93f5-4b1e-9253-5430c7abc71e Name pvc-5a7abc65-a0b7-4397-b782-1597c9e1ab8d Description AttachedOn Attachment Type nfs NFS Service Endpoint: Exports: - ID 1 Path / Pseudo Path / ACLs - Identity Type hostname Identity Matcher * Squash all Squash UID 0 Squash GUID 0 Namespace default (e4344675-311b-453c-8a59-71ef5b2e98cf) Labels csi.storage.k8s.io/pv/name=pvc-5a7abc65-a0b7-4397-b782-1597c9e1ab8d, csi.storage.k8s.io/pvc/name=pvc-rwx2, csi.storage.k8s.io/pvc/namespace=default, storageos.com/nocompress=true Filesystem ext4 Size 5.0 GiB (5368709120 bytes) Version NQ Created at 2022-02-10T16:55:12Z (7 minutes ago) Updated at 2022-02-10T16:55:34Z (6 minutes ago) Master: ID 4c5a91a5-f7cd-4d2c-a63e-fc23049b4321 Node ip-10-73-17-108.eu-west-2.compute.internal (26d7a07c-1d68-49e9-a541-d0eb93ab77b9) Health online  Check and ensure that the ports in the range of 25705-25960 is accessible between the worker nodes in your Kubernetes cluster. You can find more information on the ports required for RWX Volume Endpoints in the Firewall prerequisites page.  ","excerpt":"Issue A PersistentVolumeClaim (PVC) is bound and the Ondat volume appears to be in a healthy state, ‚Ä¶","ref":"/docs/knowledgebase/solution-unable-to-mount-rwx-volumes-to-a-pod/","title":"Solution - Unable To Mount RWX Volumes To A Pod"},{"body":"The support bundle is a tool that gathers information both about Ondat and the environment in which it is operating. It provides information about the state and configuration of the cluster, nodes and other Kubernetes objects, as well as system performance metrics.\nThe support bundle is an addition rather than a replacement to the diagnostic bundle.\nInstall Kubectl Ondat plugin The support bundle is generated with the Ondat kubectl plugin, which can be installed as follows:\ncurl -sL https://raw.githubusercontent.com/ondat/use-cases/main/scripts/storageos-support-bundle-install.sh | bash If you prefer to run the installation commands individually, we provide them here:\n# Create a temporary directory in which to store the plugin binaries TMP_DIR=$(mktemp -d /tmp/storageos-kubectl-plugin-XXXXX) # Download the plugin binaries and extract to the temporary directory TARGET=\u0026#34;kubectl-storageos_linux_amd64.tar.gz\u0026#34; curl -sSL -o kubectl-storageos.tar.gz https://github.com/storageos/storageos.github.io/raw/master/sh/$TARGET tar -xf kubectl-storageos.tar.gz -C $TMP_DIR/ # Clean up the tar file rm -f kubectl-storageos.tar.gz # Add executable permissions for the plugin binaries and move into system path # For details of the bundle-generation tool\u0026#39;s functionality, visit: #https://docs.storageos.com/docs/bundles/support-bundle/ chmod +x $TMP_DIR/bin/kubectl-storageos-bundle sudo mv $TMP_DIR/bin/kubectl-storageos-bundle /usr/local/bin/  For MacOS build, use TARGET=kubectl-storageos_darwin_amd64.tar.gz\n Generate Bundle To generate a bundle, use the following command, the specification of which can be viewed and edited by obtaining the bundle-configuration.yaml file, which is publicly available.\nOndat is usually installed in the kube-system namespace. If you have installed Ondat in a different namespace make sure to replace the namespace in the storage bundle config as below.\nSTORAGEOS_NS=my-namespace curl -s https://raw.githubusercontent.com/ondat/use-cases/main/scripts/bundle-configuration.yaml | sed \u0026#34;s/namespace: storageos/namespace: $STORAGEOS_NS/g\u0026#34; \u0026gt; /tmp/storageos-kubectl-config.yaml kubectl storageos bundle /tmp/storageos-kubectl-config.yaml Please note that if you have a custom selector for your worker nodes you should update the bundle-configuration.yaml under spec.collectors.run.nodeselector to reflect this.\nNote also that the bundle tool expects there to be an Ondat CLI running in the namespace storageos as a Pod with the name name=storageos-cli. The tool will exec into this pod to get information from the Ondat API. If the Ondat CLI Pod does not match this criteria, you can either pull the YAML file and change the selector in the file, or add the label to the Pod. You can run the cli container following these instructions.\nData collected in the bundle The data collected covers both the state of the Ondat cluster, and in particular information regarding the infrastructure on which Ondat is operating. It includes:\n Ondat CLI information Ondat Operator logs Ondat logs Cluster metadata Cluster resources (DaemonSets, Events, Services, Pods, etc.) Backend disk configuration and performance statistics Load average Network checks across Ondat nodes and ports Running processes  Privacy Ondat can only obtain the bundle if it is downloaded by the user and given to our engineering team, or uploaded for analysis. The data received by Ondat is private and never leaves nor will leave Ondat Inc.\nThe data contained in the support bundle has the sole purpose of helping customers troubleshoot their issues.\n","excerpt":"The support bundle is a tool that gathers information both about Ondat and the environment in which ‚Ä¶","ref":"/docs/reference/bundles/support_bundle/","title":"Support bundle"},{"body":"Host Filesystems Ondat will automatically use /var/lib/storageos on each host as a base directory for storing configuration and blob files. Supported host filesystem types are ext4 and xfs. If you require a specific filesystem, contact Ondat.\nPersistent Volume Filesystems Ondat provides a block device on which a file system can be created. The creation of the filesystem is either handled by Ondat or by Kubernetes which affects what filesystems can be created.\nCSI Driver When using Ondat with the CSI driver, Ondat is responsible for running mkfs against the block device that pods mount. Ondat is able to create ext2, ext3, ext4 and xfs file systems.\n","excerpt":"Host Filesystems Ondat will automatically use /var/lib/storageos on each host as a base directory ‚Ä¶","ref":"/docs/reference/filesystems/","title":"Supported File System"},{"body":"Kubernetes Tolerations Tolerations are a Kubernetes pod property that allow pods to tolerate certain node taints. Taints can be thought of as the opposite of Node affinity in that taints repel pods. Node taints are automatically applied by Kubernetes in response to node resources coming under contention. As Ondat provides storage to pods it should not be evicted during periods of resource contention, as any pods using Ondat volumes on the same node would need to be restarted.\nAs Ondat runs as a daemonset some Kubernetes tolerations are added by Kubernetes while others are automatically added by the Ondat operator.\nFor more information about tolerations, see the Kubernetes documentation.\ntolerations:# The unreachable and not-ready tolerations are added by Kubernetes to daemonsets automatically- key:\u0026#34;node.kubernetes.io/unreachable\u0026#34;operator:\u0026#34;Exists\u0026#34;effect:\u0026#34;NoExecute\u0026#34;- key:\u0026#34;node.kubernetes.io/not-ready\u0026#34;operator:\u0026#34;Exists\u0026#34;effect:\u0026#34;NoExecute\u0026#34;# The following tolerations are added to the Ondat daemonset by the Ondat operator- key:node.kubernetes.io/disk-pressureoperator:Exists- key:node.kubernetes.io/memory-pressureoperator:Exists- key:node.kubernetes.io/network-unavailableoperator:Exists- key:node.kubernetes.io/out-of-diskoperator:Exists- key:node.kubernetes.io/pid-pressureoperator:Exists- key:node.kubernetes.io/unschedulableoperator:ExistsAdding Custom Tolerations To add custom tolerations to the Ondat daemonset configure them in the StorageOSCluster resource.\n","excerpt":"Kubernetes Tolerations Tolerations are a Kubernetes pod property that allow pods to tolerate certain ‚Ä¶","ref":"/docs/reference/tolerations/","title":"Tolerations"},{"body":"This document details a step-by-step procedure on how to remove Ondat from a Kubernetes cluster.\nRemember that Ondat enables the stateful applications within your cluster. It\u0026rsquo;s very important to remove any applications that rely on Ondat before you remove Ondat itself, or those applications will suffer unrecoverable errors.\nRemoving Stateful Workloads and Data   Delete any resources using Ondat volumes\nDelete any statefulsets, deployments or pods that are using Ondat Volumes.\n  Delete PVCs using Ondat\nDelete any Persistent Volume Claims that are using Ondat.\nkubectl -n $NS delete pvc $PVC  ‚ö†Ô∏è This will delete data held by Ondat and won\u0026rsquo;t be recoverable.\n   Removing Ondat Cluster   Delete Ondat Cluster\nkubectl get storageoscluster --all-namespaces # Find the namespace where the Custom Resource runs kubectl -n $NS delete storageoscluster --all # $NS is the namespace found via the above command   Wait until the Ondat resources are gone\nkubectl -n storageos get pod   Uninstalling the Ondat Operator Delete the Operator once the Ondat Pods are terminated.\nThe procedure is finished. Ondat is now uninstalled.\nRemoving Ondat contents and metadata (unrecoverable) The steps up until now have been recoverable - as long as the etcd backing Ondat and the contents of /var/lib/storageos on your nodes are safe then Ondat can be reinstalled. For complete removal and recovery of disk space, proceed as follows:\n ‚ö†Ô∏è Warning: The following steps will delete all data held by Ondat and won\u0026rsquo;t be recoverable.\n   Remove the Ondat data directory\nYou can choose between the following options for removing the Ondat data directory:\n  (Option 1) Login in to the hosts and execute the following commands\nsudo rm -rf /var/lib/storageos sudo umount /var/lib/kubelet/plugins_registry/storageos   (Option 2) Execute the following command to deploy a DaemonSet that removes the Ondat data directory.\n ‚ö†Ô∏è This step is irreversible and once the data is removed it cannot be recovered.\n  Run the following command where kubectl is installed and with the context set for your Kubernetes cluster.\n curl -s https://raw.githubusercontent.com/ondat/use-cases/main/scripts/permanently-delete-storageos-data.sh | bash     Flush Etcd Data\n ‚ö†Ô∏è This will remove any keys written by Ondat.\n export ETCDCTL_API=3 etcdctl --endpoints=http://$ETCD_IP:2379 del --prefix \u0026#34;storageos\u0026#34; If running Etcd with mTLS, you can set the certificates location with the following command.\n$ export ETCDCTL_API=3 $ etcdctl --endpoints=https://$ETCD_IP:2379 \\  --cacert=/path/to/ca.pem \\  --cert=/path/to/client-cert.pem \\  --key=/path/to/client-key.pem \\  del --prefix \u0026#34;storageos\u0026#34;   ","excerpt":"This document details a step-by-step procedure on how to remove Ondat from a Kubernetes cluster. ‚Ä¶","ref":"/docs/operations/uninstall/","title":"Uninstall Ondat"},{"body":"An Ondat cluster admin can create users and restrict their access rights to Ondat namespaces using policies.\n üí° Users are created with access to the default namespace. This access is only revoked when a policy is created for the user or their group.\n Managing users Users can be created and deleted by navigating to the \u0026ldquo;Users\u0026rdquo; section of the GUI.\nAlternatively users can also be managed using the CLI.\nTo create a user with the CLI, run:\nstorageos user create jim The above command will create a user named jim. The command will also prompt you to enter a password for the newly created user.\n","excerpt":"An Ondat cluster admin can create users and restrict their access rights to Ondat namespaces using ‚Ä¶","ref":"/docs/operations/users/","title":"User Management"},{"body":"Using Velero to backup your Ondat volumes Velero is an open source tool to safely backup and restore, perform disaster recovery, and migrate Kubernetes cluster resources and persistent volumes.\nVelero consists of the following components:\n A Velero Server in the cluster A CLI client A restic daemonset in the cluster  Here\u0026rsquo;s a diagram on how Velero backups work:\nAnd here\u0026rsquo;s how Velero restores work:\nIn our case, we will use MinIO in the Kubernetes cluster as the \u0026ldquo;cloud provider\u0026rdquo; pictured in the backup diagram. MinIO is an object store that uses an S3 compatible API and as such can be used to store our backed up resources.\nWe will set up MinIO through a StatefulSet with a 50GiB Ondat volume and a ClusterIP service. The UI can be accessed through the browser by port-forwarding the MinIO service.\nVelero uses Restic to backup Kubernetes volumes. Restic is a fast and secure backup program for filesystems whose documentation can be found here. The way it works is that it scans the volume directory for its files and then splits those files into blobs which are then sent to MinIO. Here\u0026rsquo;s how it integrates with Velero.\nPrerequisites Here are the prerequisites for running Velero in your Kubernetes cluster:\n Kubernetes cluster version 1.19 to 1.23 with DNS Kubectl installed Velero cli installed https://Velero.io/docs/main/basic-install/   üí° Velero can also be installed from a helm chart\n Install MinIO with an Ondat volume   First, make sure to clone the Ondat use cases repository and navigate to the Velero directory:\ngit clone https://github.com/storageos/use-cases.git cd use-cases/Velero   Installing MinIO is really simple, just deploy it using the minio-deploy.yaml manifest file:\nkubectl apply -f ./minio   Confirm that MinIO was deployed successfully:\n$ kubectl get pods -n velero NAME READY STATUS RESTARTS AGE minio-0 1/1 Running 0 3m48s minio-setup-zvcdg 0/1 Completed 1 3m47s You can access the web UI of MinIO by port-forwarding the MinIO service with this command:\nkubectl port-forward service/minio -n velero 9000   Install Velero Use the following command to install Velero via the Velero CLI or alternatively use the helm chart. To install it using the Velero cli, just run this command:\n üí° The AWS plugin is being used because MinIO implements the S3 API. This is required even if you\u0026rsquo;re not using AWS.\n velero install \\ --provider aws \\ --plugins velero/velero-plugin-for-aws:v1.0.0 \\ --bucket velero \\ --secret-file ./credentials-Velero \\ --use-volume-snapshots=false \\ --backup-location-config region=minio,s3ForcePathStyle=\u0026#34;true\u0026#34;,s3Url=http://minio.velero.svc:9000 \\ --use-restic Make sure that Velero is installed correctly:\n$ kubectl logs deployment/velero -n velero ... time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Server started successfully\u0026#34; logSource=\u0026#34;pkg/cmd/server/server.go:881\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Starting controller\u0026#34; controller=restic-repository logSource=\u0026#34;pkg/controller/generic_controller.go:76\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Starting controller\u0026#34; controller=restore logSource=\u0026#34;pkg/controller/generic_controller.go:76\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Starting controller\u0026#34; controller=backup-sync logSource=\u0026#34;pkg/controller/generic_controller.go:76\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Starting controller\u0026#34; controller=backup logSource=\u0026#34;pkg/controller/generic_controller.go:76\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Starting controller\u0026#34; controller=backup-deletion logSource=\u0026#34;pkg/controller/generic_controller.go:76\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Checking for expired DeleteBackupRequests\u0026#34; controller=backup-deletion logSource=\u0026#34;pkg/controller/backup_deletion_controller.go:551\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Done checking for expired DeleteBackupRequests\u0026#34; controller=backup-deletion logSource=\u0026#34;pkg/controller/backup_deletion_controller.go:579\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Starting controller\u0026#34; controller=schedule logSource=\u0026#34;pkg/controller/generic_controller.go:76\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Starting controller\u0026#34; controller=downloadrequest logSource=\u0026#34;pkg/controller/generic_controller.go:76\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Starting controller\u0026#34; controller=gc-controller logSource=\u0026#34;pkg/controller/generic_controller.go:76\u0026#34; time=\u0026#34;2020-08-25T15:33:09Z\u0026#34; level=info msg=\u0026#34;Starting controller\u0026#34; controller=serverstatusrequest logSource=\u0026#34;pkg/controller/generic_controller.go:76\u0026#34; Quiesce Before moving on to the MySQL use case, it is important to talk about quiescence. To quiesce is to pause or alter a device or application to achieve a consistent state, usually in preparation for a backup or other maintenance. Quiescence is very important when backing up real world applications because in flight or cached write operations of the filesystem during the backup process can cause corruption of the backed up data. It is a common mistake for engineers to back up their data without quiescing the filesystem and noticing corruption when they need to restore from that backup. A simple form of quiescence is the unix command fsfreeze, but in most cases, application specific quiescence should be used instead.\nMySQL use case For the our use case, we\u0026rsquo;ll use Velero with a real world application, MySQL.\n  First deploy MySQL, based on the MySQL use case:\nkubectl apply -f ./mysql Notice that the Statefulset also includes 5 annotations:\nannotations:backup.velero.io/backup-volumes:datapre.hook.backup.velero.io/command:\u0026#39;[\u0026#34;/sbin/fsfreeze\u0026#34;, \u0026#34;--freeze\u0026#34;, \u0026#34;/var/lib/mysql\u0026#34;]\u0026#39;pre.hook.backup.velero.io/container:fsfreezepost.hook.backup.velero.io/command:\u0026#39;[\u0026#34;/sbin/fsfreeze\u0026#34;, \u0026#34;--unfreeze\u0026#34;, \u0026#34;/var/lib/mysql\u0026#34;]\u0026#39;post.hook.backup.velero.io/container:fsfreezeThe first annotation specifies which volume to backup using restic. The other annotations are used to perform an fsfreeze on the volume mount point using pre and post backup hooks, for more details about Velero pre/post backup hooks see their documentation here and here.\nWe have to specify to use the fsfreeze ubuntu container since the MySQL container doesn\u0026rsquo;t support fsfreeze\n- name:fsfreezeimage:ubuntu:bionicsecurityContext:privileged:truevolumeMounts:- name:datamountPath:/var/lib/mysqlcommand:- \u0026#34;/bin/bash\u0026#34;- \u0026#34;-c\u0026#34;- \u0026#34;sleep infinity\u0026#34;  Wait for the pod to spin up:\n$ kubectl get pods -n mysql NAME READY STATUS RESTARTS AGE client 1/1 Running 0 24m mysql-0 2/2 Running 0 24m   Exec into the MySQL pod and populate it with data using the commands below.\n$ kubectl exec mysql-0 -n mysql -ti -c mysql -- mysql mysql\u0026gt; create database shop; mysql\u0026gt; use shop; mysql\u0026gt; create table books (title VARCHAR(256), price decimal(4,2)); mysql\u0026gt; insert into books value (\u0026#39;Gates of Fire\u0026#39;, 13.99); mysql\u0026gt; select * from books; +---------------+-------+ | title | price | +---------------+-------+ | Gates of Fire | 13.99 | +---------------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; exit   Create the Velero backup:\nvelero backup create mysql-backup --include-namespaces mysql --wait   Confirm that all the Kubernetes objects are there and the restic backups completed successfully:\nvelero backup describe mysql-backup --details   After the backup is finished, delete the StatefulSet and PVC.\n ‚ö†Ô∏è It\u0026rsquo;s important to make sure that the StatefulSet is deleted because the restore would be unable to complete if a StatefulSet pod is recreated during the restore process.\n kubectl delete statefulset mysql -n mysql kubectl delete pvc data-mysql-0 -n mysql   Make sure that the pod is fully terminated:\n$ kubectl get pods -n mysql NAME READY STATUS RESTARTS AGE client 1/1 Running 0 25m   Restore MySQL using Velero:\nvelero restore create --from-backup mysql-backup --wait   Wait for the MySQL pod to spin up and see if the data is backed up:\n$ kubectl exec mysql-0 -n mysql -ti -c mysql -- mysql mysql\u0026gt; use shop; mysql\u0026gt; select * from books; +---------------+-------+ | title | price | +---------------+-------+ | Gates of Fire | 13.99 | +---------------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; exit   The data should be there and the backup was restored successfully!\n","excerpt":"Using Velero to backup your Ondat volumes Velero is an open source tool to safely backup and ‚Ä¶","ref":"/docs/usecases/velero-backups/","title":"Velero Backups"},{"body":"Ondat supports offline resize of volumes, either through editing a PVC storage request, or by updating the volume config via the CLI or UI. A volume cannot be resized while it is in use. To ensure that it is not, for a resize operation to take place the volume must not be attached to a node. This requires that any pods using a volume be scaled down for the resize to take place.\nNote, that Ondat only supports increasing volume size. For more information on how the resize works, see our Resize Concepts page.\nResizing a Volume In order to resize a PVC the storage request field must be updated.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc-1 spec: storageClassName: storageos accessModes: - ReadWriteOnce resources: requests: storage: 5Gi The Volume must be offline for this to take effect. Therefore, before performing the operation, scale down any pods using the volume. This will ensure that it is not in use.\nIn order to edit a PVC you can use kubectl edit or kubectl apply to make changes.\n ‚ö†Ô∏è Resizing a volume without updating the PVC directly will NOT result in the PVC being updated. The methods below are included for completeness. In Kubernetes environments editing the PVC is the preferred method for resizing a volume.\n To resize a volume using the Ondat CLI use the volume update command\n$ storageos update volume size pvc-a47cfa03-cc92-4ec9-84ab-00e5516c64fa 10GiB Name: pvc-a47cfa03-cc92-4ec9-84ab-00e5516c64fa ID: 925e667f-91d3-465a-9391-8fdb56d0c9ff Size: 11 GB Description: AttachedOn: Replicas: 1x ready Labels: - csi.storage.k8s.io/pv/name pvc-a47cfa03-cc92-4ec9-84ab-00e5516c64fa - csi.storage.k8s.io/pvc/name pvc-1 - csi.storage.k8s.io/pvc/namespace default - foo bar - pool default - storageos.com/replicas 1 Volume pvc-a47cfa03-cc92-4ec9-84ab-00e5516c64fa (925e667f-91d3-465a-9391-8fdb56d0c9ff) updated. Size changed. To resize a volume using the Ondat UI, navigate to the volumes section and click the edit pencil in order to update the volume config.\n","excerpt":"Ondat supports offline resize of volumes, either through editing a PVC storage request, or by ‚Ä¶","ref":"/docs/operations/resize/","title":"Volume Resize"},{"body":"ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.\nUsing Ondat persistent volumes with Apache Zookeeper means that if a pod fails, the cluster is only in a degraded state for as long as it takes Kubernetes to restart the pod. When the pod comes back up, the pod data is immediately available. Should Kubernetes schedule the Zookeeper pod on a new node, Ondat allows for the data to be available to the pod, irrespective of whether or not the original Ondat master volume is located on the same node.\nAs Zookeeper has features to allow it to handle replication, and as such careful consideration of whether to allow Ondat or Zookeeper to handle replication is required.\nBefore you start, ensure you have Ondat installed and ready on a Kubernetes cluster. See our guide on how to install Ondat on Kubernetes for more information.\nDeploying Zookeeper on Kubernetes Pre-requisites  Ondat is assumed to have been installed; check for the latest available version here.  Helm To simplify the deployment of Zookeeper, we\u0026rsquo;ve used this Zookeeper helm chart (incubator) (version 1.2.2, app version 3.4.10) and rendered it into the example deployment files you can find in our GitHub repository.\nDeployment Clone the use cases repository You can find the latest files in the Ondat use cases repository in /zookeeper/\ngit clone https://github.com/storageos/use-cases.git storageos-usecases StatefulSet defintion ---apiVersion:apps/v1beta1kind:StatefulSetmetadata:name:zookeeper...spec:replicas:3# \u0026lt;--- number of zookeeper pods...containers:- name:zookeeperimage:\u0026#34;gcr.io/google_samples/k8szk:v3\u0026#34;imagePullPolicy:IfNotPresent...volumeMounts:- name:datamountPath:/var/lib/zookeepervolumeClaimTemplates:- metadata:name:dataspec:accessModes:- \u0026#34;ReadWriteOnce\u0026#34;storageClassName:\u0026#34;storageos\u0026#34;# \u0026lt;--- the StorageClass to useresources:requests:storage:\u0026#34;5Gi\u0026#34;# \u0026lt;--- storage requested per podThis excerpt is from the StatefulSet definition (10-statefulset.yaml). The file contains the PersistentVolumeClaim template that will dynamically provision the necessary storage, using the Ondat storage class. Dynamic provisioning occurs as a volumeMount has been declared with the same name as a VolumeClaimTemplate.\nCreate the kubernetes objects cd storageos-usecases kubectl apply -f ./zookeeper/ Confirm Zookeeper is up and running $ kubectl get pods NAME READY STATUS RESTARTS AGE zookeeper-0 1/1 Running 0 2m30s zookeeper-1 1/1 Running 0 112s zookeeper-2 1/1 Running 0 56s zookeeper-test-client 1/1 Running 0 2m30s Connect to Zookeeper Connect to the zookeeper client pod and list existing topics using the service endpoint\nkubectl exec -it zookeeper-test-client /bin/bash and issue a command to the zookeeper service\nzkCli.sh -server zookeeper ls /zookeeper ","excerpt":"ZooKeeper is a centralized service for maintaining configuration information, naming, providing ‚Ä¶","ref":"/docs/usecases/zookeeper/","title":"Zookeeper"}]